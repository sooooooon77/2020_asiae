{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 학습의 자동 중단 ✨\n",
    "- 와인 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "## 학습이 진행되어도 테스트셋 오차가 줄지 않으면 학습을 멈추게 하는 함수\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = pd.read_csv('wine.csv', header = None)\n",
    "df = df_pre.sample(frac = 0.15)  ## 전체 샘플 중 15%만 불러오게 함\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 12, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8242 - accuracy: 0.7860\n",
      "Epoch 00001: val_loss improved from inf to 0.52527, saving model to ./model\\01-0.5253.hdf5\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7475 - accuracy: 0.7963 - val_loss: 0.5253 - val_accuracy: 0.8230\n",
      "Epoch 2/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6060 - accuracy: 0.8120\n",
      "Epoch 00002: val_loss improved from 0.52527 to 0.42333, saving model to ./model\\02-0.4233.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5938 - accuracy: 0.8147 - val_loss: 0.4233 - val_accuracy: 0.8385\n",
      "Epoch 3/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4616 - accuracy: 0.8340\n",
      "Epoch 00003: val_loss improved from 0.42333 to 0.37321, saving model to ./model\\03-0.3732.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4782 - accuracy: 0.8270 - val_loss: 0.3732 - val_accuracy: 0.8354\n",
      "Epoch 4/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4165 - accuracy: 0.8260\n",
      "Epoch 00004: val_loss did not improve from 0.37321\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.8270 - val_loss: 0.3959 - val_accuracy: 0.8323\n",
      "Epoch 5/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4498 - accuracy: 0.7880\n",
      "Epoch 00005: val_loss did not improve from 0.37321\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4450 - accuracy: 0.7887 - val_loss: 0.4084 - val_accuracy: 0.8137\n",
      "Epoch 6/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4301 - accuracy: 0.7860\n",
      "Epoch 00006: val_loss improved from 0.37321 to 0.37074, saving model to ./model\\06-0.3707.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4451 - accuracy: 0.7779 - val_loss: 0.3707 - val_accuracy: 0.8478\n",
      "Epoch 7/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3967 - accuracy: 0.8340\n",
      "Epoch 00007: val_loss improved from 0.37074 to 0.33176, saving model to ./model\\07-0.3318.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4054 - accuracy: 0.8270 - val_loss: 0.3318 - val_accuracy: 0.8540\n",
      "Epoch 8/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3702 - accuracy: 0.8580\n",
      "Epoch 00008: val_loss improved from 0.33176 to 0.31200, saving model to ./model\\08-0.3120.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3678 - accuracy: 0.8515 - val_loss: 0.3120 - val_accuracy: 0.8634\n",
      "Epoch 9/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3468 - accuracy: 0.8540\n",
      "Epoch 00009: val_loss improved from 0.31200 to 0.30211, saving model to ./model\\09-0.3021.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3511 - accuracy: 0.8545 - val_loss: 0.3021 - val_accuracy: 0.8789\n",
      "Epoch 10/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3405 - accuracy: 0.8480\n",
      "Epoch 00010: val_loss improved from 0.30211 to 0.29367, saving model to ./model\\10-0.2937.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3411 - accuracy: 0.8560 - val_loss: 0.2937 - val_accuracy: 0.8851\n",
      "Epoch 11/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3350 - accuracy: 0.8660\n",
      "Epoch 00011: val_loss improved from 0.29367 to 0.28484, saving model to ./model\\11-0.2848.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3326 - accuracy: 0.8622 - val_loss: 0.2848 - val_accuracy: 0.8913\n",
      "Epoch 12/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3460 - accuracy: 0.8600\n",
      "Epoch 00012: val_loss improved from 0.28484 to 0.27743, saving model to ./model\\12-0.2774.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3219 - accuracy: 0.8744 - val_loss: 0.2774 - val_accuracy: 0.9006\n",
      "Epoch 13/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3190 - accuracy: 0.8800\n",
      "Epoch 00013: val_loss improved from 0.27743 to 0.27262, saving model to ./model\\13-0.2726.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3098 - accuracy: 0.8806 - val_loss: 0.2726 - val_accuracy: 0.9006\n",
      "Epoch 14/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2945 - accuracy: 0.8820\n",
      "Epoch 00014: val_loss improved from 0.27262 to 0.27032, saving model to ./model\\14-0.2703.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3012 - accuracy: 0.8851 - val_loss: 0.2703 - val_accuracy: 0.9006\n",
      "Epoch 15/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3019 - accuracy: 0.8920\n",
      "Epoch 00015: val_loss improved from 0.27032 to 0.26721, saving model to ./model\\15-0.2672.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2956 - accuracy: 0.8928 - val_loss: 0.2672 - val_accuracy: 0.9099\n",
      "Epoch 16/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2832 - accuracy: 0.8980\n",
      "Epoch 00016: val_loss improved from 0.26721 to 0.26059, saving model to ./model\\16-0.2606.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2897 - accuracy: 0.8974 - val_loss: 0.2606 - val_accuracy: 0.9130\n",
      "Epoch 17/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2835 - accuracy: 0.8980\n",
      "Epoch 00017: val_loss improved from 0.26059 to 0.25277, saving model to ./model\\17-0.2528.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2837 - accuracy: 0.9005 - val_loss: 0.2528 - val_accuracy: 0.9130\n",
      "Epoch 18/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2831 - accuracy: 0.9020\n",
      "Epoch 00018: val_loss improved from 0.25277 to 0.24501, saving model to ./model\\18-0.2450.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2770 - accuracy: 0.9081 - val_loss: 0.2450 - val_accuracy: 0.9130\n",
      "Epoch 19/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2638 - accuracy: 0.9140\n",
      "Epoch 00019: val_loss improved from 0.24501 to 0.23902, saving model to ./model\\19-0.2390.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2720 - accuracy: 0.9081 - val_loss: 0.2390 - val_accuracy: 0.9193\n",
      "Epoch 20/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2650 - accuracy: 0.9120\n",
      "Epoch 00020: val_loss improved from 0.23902 to 0.23477, saving model to ./model\\20-0.2348.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2669 - accuracy: 0.9112 - val_loss: 0.2348 - val_accuracy: 0.9130\n",
      "Epoch 21/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2731 - accuracy: 0.9160\n",
      "Epoch 00021: val_loss improved from 0.23477 to 0.23393, saving model to ./model\\21-0.2339.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2613 - accuracy: 0.9204 - val_loss: 0.2339 - val_accuracy: 0.9130\n",
      "Epoch 22/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2633 - accuracy: 0.9140\n",
      "Epoch 00022: val_loss did not improve from 0.23393\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2578 - accuracy: 0.9158 - val_loss: 0.2344 - val_accuracy: 0.9130\n",
      "Epoch 23/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2499 - accuracy: 0.9140\n",
      "Epoch 00023: val_loss improved from 0.23393 to 0.23181, saving model to ./model\\23-0.2318.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2556 - accuracy: 0.9112 - val_loss: 0.2318 - val_accuracy: 0.9130\n",
      "Epoch 24/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2548 - accuracy: 0.9080\n",
      "Epoch 00024: val_loss improved from 0.23181 to 0.22714, saving model to ./model\\24-0.2271.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2532 - accuracy: 0.9096 - val_loss: 0.2271 - val_accuracy: 0.9099\n",
      "Epoch 25/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2518 - accuracy: 0.9140\n",
      "Epoch 00025: val_loss improved from 0.22714 to 0.22353, saving model to ./model\\25-0.2235.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2505 - accuracy: 0.9142 - val_loss: 0.2235 - val_accuracy: 0.9068\n",
      "Epoch 26/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2562 - accuracy: 0.9120\n",
      "Epoch 00026: val_loss improved from 0.22353 to 0.22142, saving model to ./model\\26-0.2214.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2484 - accuracy: 0.9142 - val_loss: 0.2214 - val_accuracy: 0.9099\n",
      "Epoch 27/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2478 - accuracy: 0.9180\n",
      "Epoch 00027: val_loss improved from 0.22142 to 0.21951, saving model to ./model\\27-0.2195.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2472 - accuracy: 0.9173 - val_loss: 0.2195 - val_accuracy: 0.9099\n",
      "Epoch 28/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2603 - accuracy: 0.9220\n",
      "Epoch 00028: val_loss improved from 0.21951 to 0.21682, saving model to ./model\\28-0.2168.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2456 - accuracy: 0.9204 - val_loss: 0.2168 - val_accuracy: 0.9130\n",
      "Epoch 29/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2533 - accuracy: 0.9200\n",
      "Epoch 00029: val_loss improved from 0.21682 to 0.21484, saving model to ./model\\29-0.2148.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2451 - accuracy: 0.9204 - val_loss: 0.2148 - val_accuracy: 0.9161\n",
      "Epoch 30/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2460 - accuracy: 0.9200\n",
      "Epoch 00030: val_loss improved from 0.21484 to 0.21402, saving model to ./model\\30-0.2140.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2447 - accuracy: 0.9219 - val_loss: 0.2140 - val_accuracy: 0.9193\n",
      "Epoch 31/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2602 - accuracy: 0.9240\n",
      "Epoch 00031: val_loss did not improve from 0.21402\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2425 - accuracy: 0.9219 - val_loss: 0.2154 - val_accuracy: 0.9130\n",
      "Epoch 32/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2387 - accuracy: 0.9260\n",
      "Epoch 00032: val_loss did not improve from 0.21402\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2405 - accuracy: 0.9250 - val_loss: 0.2173 - val_accuracy: 0.9161\n",
      "Epoch 33/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2427 - accuracy: 0.9180\n",
      "Epoch 00033: val_loss did not improve from 0.21402\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9204 - val_loss: 0.2163 - val_accuracy: 0.9193\n",
      "Epoch 34/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2308 - accuracy: 0.9320\n",
      "Epoch 00034: val_loss improved from 0.21402 to 0.21229, saving model to ./model\\34-0.2123.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2387 - accuracy: 0.9219 - val_loss: 0.2123 - val_accuracy: 0.9193\n",
      "Epoch 35/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2582 - accuracy: 0.9120\n",
      "Epoch 00035: val_loss improved from 0.21229 to 0.20795, saving model to ./model\\35-0.2080.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2371 - accuracy: 0.9234 - val_loss: 0.2080 - val_accuracy: 0.9193\n",
      "Epoch 36/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2575 - accuracy: 0.9240\n",
      "Epoch 00036: val_loss improved from 0.20795 to 0.20560, saving model to ./model\\36-0.2056.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2363 - accuracy: 0.9280 - val_loss: 0.2056 - val_accuracy: 0.9193\n",
      "Epoch 37/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2596 - accuracy: 0.9200\n",
      "Epoch 00037: val_loss improved from 0.20560 to 0.20422, saving model to ./model\\37-0.2042.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2360 - accuracy: 0.9280 - val_loss: 0.2042 - val_accuracy: 0.9193\n",
      "Epoch 38/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2464 - accuracy: 0.9180\n",
      "Epoch 00038: val_loss improved from 0.20422 to 0.20360, saving model to ./model\\38-0.2036.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2353 - accuracy: 0.9280 - val_loss: 0.2036 - val_accuracy: 0.9193\n",
      "Epoch 39/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2466 - accuracy: 0.9240\n",
      "Epoch 00039: val_loss did not improve from 0.20360\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2338 - accuracy: 0.9296 - val_loss: 0.2043 - val_accuracy: 0.9224\n",
      "Epoch 40/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2052 - accuracy: 0.9340\n",
      "Epoch 00040: val_loss did not improve from 0.20360\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2323 - accuracy: 0.9265 - val_loss: 0.2060 - val_accuracy: 0.9255\n",
      "Epoch 41/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2265 - accuracy: 0.9260\n",
      "Epoch 00041: val_loss did not improve from 0.20360\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2318 - accuracy: 0.9250 - val_loss: 0.2077 - val_accuracy: 0.9161\n",
      "Epoch 42/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2294 - accuracy: 0.9280\n",
      "Epoch 00042: val_loss did not improve from 0.20360\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2323 - accuracy: 0.9204 - val_loss: 0.2053 - val_accuracy: 0.9193\n",
      "Epoch 43/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2226 - accuracy: 0.9300\n",
      "Epoch 00043: val_loss improved from 0.20360 to 0.19889, saving model to ./model\\43-0.1989.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2303 - accuracy: 0.9234 - val_loss: 0.1989 - val_accuracy: 0.9255\n",
      "Epoch 44/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2496 - accuracy: 0.9220\n",
      "Epoch 00044: val_loss improved from 0.19889 to 0.19589, saving model to ./model\\44-0.1959.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2290 - accuracy: 0.9296 - val_loss: 0.1959 - val_accuracy: 0.9224\n",
      "Epoch 45/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2149 - accuracy: 0.9380\n",
      "Epoch 00045: val_loss improved from 0.19589 to 0.19496, saving model to ./model\\45-0.1950.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2312 - accuracy: 0.9280 - val_loss: 0.1950 - val_accuracy: 0.9224\n",
      "Epoch 46/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2167 - accuracy: 0.9400\n",
      "Epoch 00046: val_loss did not improve from 0.19496\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2287 - accuracy: 0.9311 - val_loss: 0.1978 - val_accuracy: 0.9255\n",
      "Epoch 47/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2291 - accuracy: 0.9280\n",
      "Epoch 00047: val_loss did not improve from 0.19496\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2271 - accuracy: 0.9250 - val_loss: 0.2054 - val_accuracy: 0.9130\n",
      "Epoch 48/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2271 - accuracy: 0.9200\n",
      "Epoch 00048: val_loss did not improve from 0.19496\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2292 - accuracy: 0.9188 - val_loss: 0.2049 - val_accuracy: 0.9130\n",
      "Epoch 49/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2273 - accuracy: 0.9160\n",
      "Epoch 00049: val_loss did not improve from 0.19496\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2288 - accuracy: 0.9188 - val_loss: 0.1982 - val_accuracy: 0.9255\n",
      "Epoch 50/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2309 - accuracy: 0.9180\n",
      "Epoch 00050: val_loss improved from 0.19496 to 0.19195, saving model to ./model\\50-0.1920.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2249 - accuracy: 0.9219 - val_loss: 0.1920 - val_accuracy: 0.9255\n",
      "Epoch 51/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2479 - accuracy: 0.9220\n",
      "Epoch 00051: val_loss improved from 0.19195 to 0.18960, saving model to ./model\\51-0.1896.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2235 - accuracy: 0.9311 - val_loss: 0.1896 - val_accuracy: 0.9224\n",
      "Epoch 52/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2426 - accuracy: 0.9120\n",
      "Epoch 00052: val_loss improved from 0.18960 to 0.18944, saving model to ./model\\52-0.1894.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2277 - accuracy: 0.9234 - val_loss: 0.1894 - val_accuracy: 0.9224\n",
      "Epoch 53/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2083 - accuracy: 0.9260\n",
      "Epoch 00053: val_loss improved from 0.18944 to 0.18804, saving model to ./model\\53-0.1880.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2285 - accuracy: 0.9188 - val_loss: 0.1880 - val_accuracy: 0.9286\n",
      "Epoch 54/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2480 - accuracy: 0.9200\n",
      "Epoch 00054: val_loss did not improve from 0.18804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2246 - accuracy: 0.9280 - val_loss: 0.1917 - val_accuracy: 0.9255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2287 - accuracy: 0.9260\n",
      "Epoch 00055: val_loss did not improve from 0.18804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2213 - accuracy: 0.9265 - val_loss: 0.1963 - val_accuracy: 0.9224\n",
      "Epoch 56/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2352 - accuracy: 0.9200\n",
      "Epoch 00056: val_loss did not improve from 0.18804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2229 - accuracy: 0.9204 - val_loss: 0.1928 - val_accuracy: 0.9286\n",
      "Epoch 57/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2110 - accuracy: 0.9320\n",
      "Epoch 00057: val_loss improved from 0.18804 to 0.18561, saving model to ./model\\57-0.1856.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2202 - accuracy: 0.9265 - val_loss: 0.1856 - val_accuracy: 0.9286\n",
      "Epoch 58/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2324 - accuracy: 0.9280\n",
      "Epoch 00058: val_loss improved from 0.18561 to 0.18334, saving model to ./model\\58-0.1833.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2194 - accuracy: 0.9311 - val_loss: 0.1833 - val_accuracy: 0.9317\n",
      "Epoch 59/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2386 - accuracy: 0.9200\n",
      "Epoch 00059: val_loss improved from 0.18334 to 0.18244, saving model to ./model\\59-0.1824.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2212 - accuracy: 0.9265 - val_loss: 0.1824 - val_accuracy: 0.9286\n",
      "Epoch 60/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2307 - accuracy: 0.9300\n",
      "Epoch 00060: val_loss improved from 0.18244 to 0.18187, saving model to ./model\\60-0.1819.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2207 - accuracy: 0.9265 - val_loss: 0.1819 - val_accuracy: 0.9317\n",
      "Epoch 61/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2499 - accuracy: 0.9120\n",
      "Epoch 00061: val_loss did not improve from 0.18187\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2185 - accuracy: 0.9265 - val_loss: 0.1832 - val_accuracy: 0.9286\n",
      "Epoch 62/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2180 - accuracy: 0.9300\n",
      "Epoch 00062: val_loss did not improve from 0.18187\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2162 - accuracy: 0.9311 - val_loss: 0.1839 - val_accuracy: 0.9286\n",
      "Epoch 63/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2192 - accuracy: 0.9280\n",
      "Epoch 00063: val_loss did not improve from 0.18187\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2154 - accuracy: 0.9280 - val_loss: 0.1824 - val_accuracy: 0.9286\n",
      "Epoch 64/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2146 - accuracy: 0.9320\n",
      "Epoch 00064: val_loss improved from 0.18187 to 0.18017, saving model to ./model\\64-0.1802.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2144 - accuracy: 0.9265 - val_loss: 0.1802 - val_accuracy: 0.9317\n",
      "Epoch 65/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2269 - accuracy: 0.9220\n",
      "Epoch 00065: val_loss improved from 0.18017 to 0.17817, saving model to ./model\\65-0.1782.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2141 - accuracy: 0.9280 - val_loss: 0.1782 - val_accuracy: 0.9317\n",
      "Epoch 66/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2246 - accuracy: 0.9260\n",
      "Epoch 00066: val_loss improved from 0.17817 to 0.17667, saving model to ./model\\66-0.1767.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2139 - accuracy: 0.9311 - val_loss: 0.1767 - val_accuracy: 0.9286\n",
      "Epoch 67/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1945 - accuracy: 0.9420\n",
      "Epoch 00067: val_loss improved from 0.17667 to 0.17646, saving model to ./model\\67-0.1765.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2147 - accuracy: 0.9326 - val_loss: 0.1765 - val_accuracy: 0.9317\n",
      "Epoch 68/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2061 - accuracy: 0.9380\n",
      "Epoch 00068: val_loss did not improve from 0.17646\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2121 - accuracy: 0.9311 - val_loss: 0.1807 - val_accuracy: 0.9255\n",
      "Epoch 69/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1977 - accuracy: 0.9380\n",
      "Epoch 00069: val_loss did not improve from 0.17646\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2114 - accuracy: 0.9265 - val_loss: 0.1882 - val_accuracy: 0.9255\n",
      "Epoch 70/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2237 - accuracy: 0.9120\n",
      "Epoch 00070: val_loss did not improve from 0.17646\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2152 - accuracy: 0.9173 - val_loss: 0.1853 - val_accuracy: 0.9255\n",
      "Epoch 71/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2237 - accuracy: 0.9160\n",
      "Epoch 00071: val_loss improved from 0.17646 to 0.17546, saving model to ./model\\71-0.1755.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2129 - accuracy: 0.9234 - val_loss: 0.1755 - val_accuracy: 0.9348\n",
      "Epoch 72/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2089 - accuracy: 0.9280\n",
      "Epoch 00072: val_loss improved from 0.17546 to 0.17123, saving model to ./model\\72-0.1712.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2087 - accuracy: 0.9280 - val_loss: 0.1712 - val_accuracy: 0.9379\n",
      "Epoch 73/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2028 - accuracy: 0.9380\n",
      "Epoch 00073: val_loss improved from 0.17123 to 0.17038, saving model to ./model\\73-0.1704.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2106 - accuracy: 0.9311 - val_loss: 0.1704 - val_accuracy: 0.9348\n",
      "Epoch 74/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2352 - accuracy: 0.9240\n",
      "Epoch 00074: val_loss did not improve from 0.17038\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2101 - accuracy: 0.9342 - val_loss: 0.1710 - val_accuracy: 0.9379\n",
      "Epoch 75/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2008 - accuracy: 0.9360\n",
      "Epoch 00075: val_loss did not improve from 0.17038\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2070 - accuracy: 0.9296 - val_loss: 0.1730 - val_accuracy: 0.9348\n",
      "Epoch 76/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2141 - accuracy: 0.9240\n",
      "Epoch 00076: val_loss did not improve from 0.17038\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2067 - accuracy: 0.9265 - val_loss: 0.1723 - val_accuracy: 0.9348\n",
      "Epoch 77/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1843 - accuracy: 0.9360\n",
      "Epoch 00077: val_loss did not improve from 0.17038\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2072 - accuracy: 0.9265 - val_loss: 0.1707 - val_accuracy: 0.9379\n",
      "Epoch 78/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2229 - accuracy: 0.9180\n",
      "Epoch 00078: val_loss did not improve from 0.17038\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2056 - accuracy: 0.9280 - val_loss: 0.1707 - val_accuracy: 0.9379\n",
      "Epoch 79/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2121 - accuracy: 0.9220\n",
      "Epoch 00079: val_loss improved from 0.17038 to 0.16732, saving model to ./model\\79-0.1673.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2042 - accuracy: 0.9265 - val_loss: 0.1673 - val_accuracy: 0.9441\n",
      "Epoch 80/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1982 - accuracy: 0.9380\n",
      "Epoch 00080: val_loss improved from 0.16732 to 0.16633, saving model to ./model\\80-0.1663.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2040 - accuracy: 0.9326 - val_loss: 0.1663 - val_accuracy: 0.9348\n",
      "Epoch 81/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2165 - accuracy: 0.9300\n",
      "Epoch 00081: val_loss improved from 0.16633 to 0.16584, saving model to ./model\\81-0.1658.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2059 - accuracy: 0.9326 - val_loss: 0.1658 - val_accuracy: 0.9379\n",
      "Epoch 82/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2376 - accuracy: 0.9160\n",
      "Epoch 00082: val_loss improved from 0.16584 to 0.16562, saving model to ./model\\82-0.1656.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2056 - accuracy: 0.9326 - val_loss: 0.1656 - val_accuracy: 0.9441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2075 - accuracy: 0.9320\n",
      "Epoch 00083: val_loss did not improve from 0.16562\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2025 - accuracy: 0.9311 - val_loss: 0.1659 - val_accuracy: 0.9410\n",
      "Epoch 84/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1971 - accuracy: 0.9360\n",
      "Epoch 00084: val_loss did not improve from 0.16562\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2015 - accuracy: 0.9311 - val_loss: 0.1671 - val_accuracy: 0.9410\n",
      "Epoch 85/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2207 - accuracy: 0.9240\n",
      "Epoch 00085: val_loss did not improve from 0.16562\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2010 - accuracy: 0.9296 - val_loss: 0.1669 - val_accuracy: 0.9410\n",
      "Epoch 86/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1870 - accuracy: 0.9380\n",
      "Epoch 00086: val_loss did not improve from 0.16562\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2007 - accuracy: 0.9296 - val_loss: 0.1658 - val_accuracy: 0.9410\n",
      "Epoch 87/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2136 - accuracy: 0.9260\n",
      "Epoch 00087: val_loss improved from 0.16562 to 0.16498, saving model to ./model\\87-0.1650.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1999 - accuracy: 0.9296 - val_loss: 0.1650 - val_accuracy: 0.9410\n",
      "Epoch 88/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1742 - accuracy: 0.9380\n",
      "Epoch 00088: val_loss improved from 0.16498 to 0.16355, saving model to ./model\\88-0.1636.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1995 - accuracy: 0.9280 - val_loss: 0.1636 - val_accuracy: 0.9410\n",
      "Epoch 89/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1809 - accuracy: 0.9400\n",
      "Epoch 00089: val_loss did not improve from 0.16355\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1983 - accuracy: 0.9311 - val_loss: 0.1650 - val_accuracy: 0.9441\n",
      "Epoch 90/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1843 - accuracy: 0.9300\n",
      "Epoch 00090: val_loss did not improve from 0.16355\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1980 - accuracy: 0.9296 - val_loss: 0.1675 - val_accuracy: 0.9472\n",
      "Epoch 91/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2003 - accuracy: 0.9240\n",
      "Epoch 00091: val_loss did not improve from 0.16355\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1986 - accuracy: 0.9265 - val_loss: 0.1640 - val_accuracy: 0.9441\n",
      "Epoch 92/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2086 - accuracy: 0.9220\n",
      "Epoch 00092: val_loss improved from 0.16355 to 0.16093, saving model to ./model\\92-0.1609.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1968 - accuracy: 0.9280 - val_loss: 0.1609 - val_accuracy: 0.9441\n",
      "Epoch 93/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2027 - accuracy: 0.9340\n",
      "Epoch 00093: val_loss improved from 0.16093 to 0.16042, saving model to ./model\\93-0.1604.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1967 - accuracy: 0.9326 - val_loss: 0.1604 - val_accuracy: 0.9410\n",
      "Epoch 94/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2071 - accuracy: 0.9280\n",
      "Epoch 00094: val_loss did not improve from 0.16042\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1966 - accuracy: 0.9326 - val_loss: 0.1606 - val_accuracy: 0.9441\n",
      "Epoch 95/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2016 - accuracy: 0.9360\n",
      "Epoch 00095: val_loss did not improve from 0.16042\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1948 - accuracy: 0.9326 - val_loss: 0.1619 - val_accuracy: 0.9441\n",
      "Epoch 96/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2022 - accuracy: 0.9260\n",
      "Epoch 00096: val_loss did not improve from 0.16042\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1946 - accuracy: 0.9326 - val_loss: 0.1611 - val_accuracy: 0.9441\n",
      "Epoch 97/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1938 - accuracy: 0.9320\n",
      "Epoch 00097: val_loss improved from 0.16042 to 0.15925, saving model to ./model\\97-0.1592.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1941 - accuracy: 0.9326 - val_loss: 0.1592 - val_accuracy: 0.9472\n",
      "Epoch 98/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1836 - accuracy: 0.9400\n",
      "Epoch 00098: val_loss improved from 0.15925 to 0.15910, saving model to ./model\\98-0.1591.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1928 - accuracy: 0.9342 - val_loss: 0.1591 - val_accuracy: 0.9472\n",
      "Epoch 99/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1958 - accuracy: 0.9340\n",
      "Epoch 00099: val_loss improved from 0.15910 to 0.15844, saving model to ./model\\99-0.1584.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1921 - accuracy: 0.9326 - val_loss: 0.1584 - val_accuracy: 0.9472\n",
      "Epoch 100/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1873 - accuracy: 0.9340\n",
      "Epoch 00100: val_loss improved from 0.15844 to 0.15757, saving model to ./model\\100-0.1576.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1915 - accuracy: 0.9326 - val_loss: 0.1576 - val_accuracy: 0.9472\n",
      "Epoch 101/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1742 - accuracy: 0.9380\n",
      "Epoch 00101: val_loss did not improve from 0.15757\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1911 - accuracy: 0.9326 - val_loss: 0.1587 - val_accuracy: 0.9503\n",
      "Epoch 102/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1811 - accuracy: 0.9360\n",
      "Epoch 00102: val_loss did not improve from 0.15757\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.9342 - val_loss: 0.1627 - val_accuracy: 0.9503\n",
      "Epoch 103/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1908 - accuracy: 0.9340\n",
      "Epoch 00103: val_loss did not improve from 0.15757\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1929 - accuracy: 0.9311 - val_loss: 0.1586 - val_accuracy: 0.9503\n",
      "Epoch 104/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2002 - accuracy: 0.9280\n",
      "Epoch 00104: val_loss improved from 0.15757 to 0.15401, saving model to ./model\\104-0.1540.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1904 - accuracy: 0.9342 - val_loss: 0.1540 - val_accuracy: 0.9472\n",
      "Epoch 105/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1903 - accuracy: 0.9300\n",
      "Epoch 00105: val_loss improved from 0.15401 to 0.15347, saving model to ./model\\105-0.1535.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1895 - accuracy: 0.9326 - val_loss: 0.1535 - val_accuracy: 0.9472\n",
      "Epoch 106/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2017 - accuracy: 0.9260\n",
      "Epoch 00106: val_loss did not improve from 0.15347\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1891 - accuracy: 0.9326 - val_loss: 0.1537 - val_accuracy: 0.9503\n",
      "Epoch 107/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1814 - accuracy: 0.9340\n",
      "Epoch 00107: val_loss did not improve from 0.15347\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1870 - accuracy: 0.9326 - val_loss: 0.1558 - val_accuracy: 0.9503\n",
      "Epoch 108/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1968 - accuracy: 0.9280\n",
      "Epoch 00108: val_loss did not improve from 0.15347\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1877 - accuracy: 0.9357 - val_loss: 0.1550 - val_accuracy: 0.9503\n",
      "Epoch 109/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1923 - accuracy: 0.9360\n",
      "Epoch 00109: val_loss improved from 0.15347 to 0.15227, saving model to ./model\\109-0.1523.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1870 - accuracy: 0.9342 - val_loss: 0.1523 - val_accuracy: 0.9472\n",
      "Epoch 110/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1949 - accuracy: 0.9320\n",
      "Epoch 00110: val_loss improved from 0.15227 to 0.15177, saving model to ./model\\110-0.1518.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1858 - accuracy: 0.9342 - val_loss: 0.1518 - val_accuracy: 0.9472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1890 - accuracy: 0.9380\n",
      "Epoch 00111: val_loss did not improve from 0.15177\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1851 - accuracy: 0.9342 - val_loss: 0.1518 - val_accuracy: 0.9534\n",
      "Epoch 112/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1931 - accuracy: 0.9280\n",
      "Epoch 00112: val_loss did not improve from 0.15177\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1842 - accuracy: 0.9326 - val_loss: 0.1533 - val_accuracy: 0.9503\n",
      "Epoch 113/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1969 - accuracy: 0.9300\n",
      "Epoch 00113: val_loss did not improve from 0.15177\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1850 - accuracy: 0.9357 - val_loss: 0.1526 - val_accuracy: 0.9503\n",
      "Epoch 114/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1889 - accuracy: 0.9320\n",
      "Epoch 00114: val_loss improved from 0.15177 to 0.14922, saving model to ./model\\114-0.1492.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1838 - accuracy: 0.9357 - val_loss: 0.1492 - val_accuracy: 0.9472\n",
      "Epoch 115/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1852 - accuracy: 0.9360\n",
      "Epoch 00115: val_loss improved from 0.14922 to 0.14857, saving model to ./model\\115-0.1486.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1831 - accuracy: 0.9342 - val_loss: 0.1486 - val_accuracy: 0.9503\n",
      "Epoch 116/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1763 - accuracy: 0.9380\n",
      "Epoch 00116: val_loss improved from 0.14857 to 0.14851, saving model to ./model\\116-0.1485.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1830 - accuracy: 0.9342 - val_loss: 0.1485 - val_accuracy: 0.9534\n",
      "Epoch 117/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1741 - accuracy: 0.9380\n",
      "Epoch 00117: val_loss did not improve from 0.14851\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1817 - accuracy: 0.9326 - val_loss: 0.1493 - val_accuracy: 0.9503\n",
      "Epoch 118/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1796 - accuracy: 0.9360\n",
      "Epoch 00118: val_loss did not improve from 0.14851\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1812 - accuracy: 0.9342 - val_loss: 0.1496 - val_accuracy: 0.9503\n",
      "Epoch 119/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1691 - accuracy: 0.9440\n",
      "Epoch 00119: val_loss did not improve from 0.14851\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1813 - accuracy: 0.9372 - val_loss: 0.1490 - val_accuracy: 0.9503\n",
      "Epoch 120/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1680 - accuracy: 0.9360\n",
      "Epoch 00120: val_loss did not improve from 0.14851\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1799 - accuracy: 0.9342 - val_loss: 0.1494 - val_accuracy: 0.9503\n",
      "Epoch 121/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1784 - accuracy: 0.9400\n",
      "Epoch 00121: val_loss improved from 0.14851 to 0.14772, saving model to ./model\\121-0.1477.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1799 - accuracy: 0.9387 - val_loss: 0.1477 - val_accuracy: 0.9534\n",
      "Epoch 122/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1807 - accuracy: 0.9320\n",
      "Epoch 00122: val_loss improved from 0.14772 to 0.14685, saving model to ./model\\122-0.1469.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1787 - accuracy: 0.9357 - val_loss: 0.1469 - val_accuracy: 0.9565\n",
      "Epoch 123/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1770 - accuracy: 0.9340\n",
      "Epoch 00123: val_loss did not improve from 0.14685\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1785 - accuracy: 0.9326 - val_loss: 0.1471 - val_accuracy: 0.9565\n",
      "Epoch 124/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1873 - accuracy: 0.9320\n",
      "Epoch 00124: val_loss did not improve from 0.14685\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1783 - accuracy: 0.9357 - val_loss: 0.1478 - val_accuracy: 0.9503\n",
      "Epoch 125/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1610 - accuracy: 0.9460\n",
      "Epoch 00125: val_loss improved from 0.14685 to 0.14610, saving model to ./model\\125-0.1461.hdf5\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1778 - accuracy: 0.9372 - val_loss: 0.1461 - val_accuracy: 0.9565\n",
      "Epoch 126/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1776 - accuracy: 0.9340\n",
      "Epoch 00126: val_loss improved from 0.14610 to 0.14546, saving model to ./model\\126-0.1455.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1767 - accuracy: 0.9342 - val_loss: 0.1455 - val_accuracy: 0.9565\n",
      "Epoch 127/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1750 - accuracy: 0.9340\n",
      "Epoch 00127: val_loss improved from 0.14546 to 0.14483, saving model to ./model\\127-0.1448.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1760 - accuracy: 0.9357 - val_loss: 0.1448 - val_accuracy: 0.9565\n",
      "Epoch 128/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1849 - accuracy: 0.9280\n",
      "Epoch 00128: val_loss improved from 0.14483 to 0.14390, saving model to ./model\\128-0.1439.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1757 - accuracy: 0.9342 - val_loss: 0.1439 - val_accuracy: 0.9565\n",
      "Epoch 129/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1877 - accuracy: 0.9220\n",
      "Epoch 00129: val_loss improved from 0.14390 to 0.14287, saving model to ./model\\129-0.1429.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1750 - accuracy: 0.9326 - val_loss: 0.1429 - val_accuracy: 0.9534\n",
      "Epoch 130/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1775 - accuracy: 0.9280\n",
      "Epoch 00130: val_loss improved from 0.14287 to 0.14211, saving model to ./model\\130-0.1421.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1753 - accuracy: 0.9326 - val_loss: 0.1421 - val_accuracy: 0.9503\n",
      "Epoch 131/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1877 - accuracy: 0.9280\n",
      "Epoch 00131: val_loss improved from 0.14211 to 0.14142, saving model to ./model\\131-0.1414.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1753 - accuracy: 0.9342 - val_loss: 0.1414 - val_accuracy: 0.9565\n",
      "Epoch 132/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1673 - accuracy: 0.9400\n",
      "Epoch 00132: val_loss did not improve from 0.14142\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1734 - accuracy: 0.9357 - val_loss: 0.1432 - val_accuracy: 0.9503\n",
      "Epoch 133/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1802 - accuracy: 0.9320\n",
      "Epoch 00133: val_loss did not improve from 0.14142\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1742 - accuracy: 0.9357 - val_loss: 0.1427 - val_accuracy: 0.9503\n",
      "Epoch 134/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1804 - accuracy: 0.9360\n",
      "Epoch 00134: val_loss improved from 0.14142 to 0.13936, saving model to ./model\\134-0.1394.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1732 - accuracy: 0.9357 - val_loss: 0.1394 - val_accuracy: 0.9565\n",
      "Epoch 135/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1773 - accuracy: 0.9340\n",
      "Epoch 00135: val_loss improved from 0.13936 to 0.13862, saving model to ./model\\135-0.1386.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1718 - accuracy: 0.9342 - val_loss: 0.1386 - val_accuracy: 0.9565\n",
      "Epoch 136/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1775 - accuracy: 0.9320\n",
      "Epoch 00136: val_loss improved from 0.13862 to 0.13811, saving model to ./model\\136-0.1381.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1719 - accuracy: 0.9357 - val_loss: 0.1381 - val_accuracy: 0.9565\n",
      "Epoch 137/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1745 - accuracy: 0.9280\n",
      "Epoch 00137: val_loss improved from 0.13811 to 0.13797, saving model to ./model\\137-0.1380.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1710 - accuracy: 0.9342 - val_loss: 0.1380 - val_accuracy: 0.9565\n",
      "Epoch 138/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1901 - accuracy: 0.9220\n",
      "Epoch 00138: val_loss did not improve from 0.13797\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1705 - accuracy: 0.9342 - val_loss: 0.1380 - val_accuracy: 0.9565\n",
      "Epoch 139/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1655 - accuracy: 0.9360\n",
      "Epoch 00139: val_loss improved from 0.13797 to 0.13750, saving model to ./model\\139-0.1375.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1697 - accuracy: 0.9342 - val_loss: 0.1375 - val_accuracy: 0.9565\n",
      "Epoch 140/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1660 - accuracy: 0.9360\n",
      "Epoch 00140: val_loss did not improve from 0.13750\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1691 - accuracy: 0.9342 - val_loss: 0.1378 - val_accuracy: 0.9534\n",
      "Epoch 141/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1706 - accuracy: 0.9340\n",
      "Epoch 00141: val_loss improved from 0.13750 to 0.13740, saving model to ./model\\141-0.1374.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1687 - accuracy: 0.9372 - val_loss: 0.1374 - val_accuracy: 0.9534\n",
      "Epoch 142/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1683 - accuracy: 0.9380\n",
      "Epoch 00142: val_loss improved from 0.13740 to 0.13669, saving model to ./model\\142-0.1367.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1682 - accuracy: 0.9357 - val_loss: 0.1367 - val_accuracy: 0.9565\n",
      "Epoch 143/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1689 - accuracy: 0.9340\n",
      "Epoch 00143: val_loss did not improve from 0.13669\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1681 - accuracy: 0.9357 - val_loss: 0.1367 - val_accuracy: 0.9565\n",
      "Epoch 144/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1527 - accuracy: 0.9440\n",
      "Epoch 00144: val_loss did not improve from 0.13669\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1674 - accuracy: 0.9357 - val_loss: 0.1389 - val_accuracy: 0.9472\n",
      "Epoch 145/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1634 - accuracy: 0.9360\n",
      "Epoch 00145: val_loss did not improve from 0.13669\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1677 - accuracy: 0.9357 - val_loss: 0.1419 - val_accuracy: 0.9410\n",
      "Epoch 146/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1657 - accuracy: 0.9360\n",
      "Epoch 00146: val_loss improved from 0.13669 to 0.13632, saving model to ./model\\146-0.1363.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1690 - accuracy: 0.9342 - val_loss: 0.1363 - val_accuracy: 0.9503\n",
      "Epoch 147/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1626 - accuracy: 0.9280\n",
      "Epoch 00147: val_loss improved from 0.13632 to 0.13501, saving model to ./model\\147-0.1350.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1658 - accuracy: 0.9357 - val_loss: 0.1350 - val_accuracy: 0.9565\n",
      "Epoch 148/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1781 - accuracy: 0.9380\n",
      "Epoch 00148: val_loss improved from 0.13501 to 0.13477, saving model to ./model\\148-0.1348.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1671 - accuracy: 0.9403 - val_loss: 0.1348 - val_accuracy: 0.9534\n",
      "Epoch 149/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1779 - accuracy: 0.9320\n",
      "Epoch 00149: val_loss improved from 0.13477 to 0.13371, saving model to ./model\\149-0.1337.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1671 - accuracy: 0.9357 - val_loss: 0.1337 - val_accuracy: 0.9565\n",
      "Epoch 150/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1606 - accuracy: 0.9400\n",
      "Epoch 00150: val_loss did not improve from 0.13371\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1642 - accuracy: 0.9372 - val_loss: 0.1374 - val_accuracy: 0.9472\n",
      "Epoch 151/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1619 - accuracy: 0.9360\n",
      "Epoch 00151: val_loss did not improve from 0.13371\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1667 - accuracy: 0.9387 - val_loss: 0.1398 - val_accuracy: 0.9441\n",
      "Epoch 152/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1746 - accuracy: 0.9360\n",
      "Epoch 00152: val_loss improved from 0.13371 to 0.13175, saving model to ./model\\152-0.1318.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1668 - accuracy: 0.9372 - val_loss: 0.1318 - val_accuracy: 0.9565\n",
      "Epoch 153/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1813 - accuracy: 0.9280\n",
      "Epoch 00153: val_loss improved from 0.13175 to 0.13167, saving model to ./model\\153-0.1317.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1629 - accuracy: 0.9357 - val_loss: 0.1317 - val_accuracy: 0.9565\n",
      "Epoch 154/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1590 - accuracy: 0.9400\n",
      "Epoch 00154: val_loss improved from 0.13167 to 0.13007, saving model to ./model\\154-0.1301.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1666 - accuracy: 0.9372 - val_loss: 0.1301 - val_accuracy: 0.9565\n",
      "Epoch 155/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1653 - accuracy: 0.9400\n",
      "Epoch 00155: val_loss did not improve from 0.13007\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1622 - accuracy: 0.9372 - val_loss: 0.1360 - val_accuracy: 0.9472\n",
      "Epoch 156/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1708 - accuracy: 0.9420\n",
      "Epoch 00156: val_loss did not improve from 0.13007\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1655 - accuracy: 0.9433 - val_loss: 0.1357 - val_accuracy: 0.9472\n",
      "Epoch 157/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1754 - accuracy: 0.9360\n",
      "Epoch 00157: val_loss improved from 0.13007 to 0.12849, saving model to ./model\\157-0.1285.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1636 - accuracy: 0.9418 - val_loss: 0.1285 - val_accuracy: 0.9565\n",
      "Epoch 158/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1670 - accuracy: 0.9360\n",
      "Epoch 00158: val_loss did not improve from 0.12849\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1616 - accuracy: 0.9372 - val_loss: 0.1300 - val_accuracy: 0.9565\n",
      "Epoch 159/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1806 - accuracy: 0.9360\n",
      "Epoch 00159: val_loss improved from 0.12849 to 0.12813, saving model to ./model\\159-0.1281.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1645 - accuracy: 0.9403 - val_loss: 0.1281 - val_accuracy: 0.9565\n",
      "Epoch 160/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1577 - accuracy: 0.9340\n",
      "Epoch 00160: val_loss did not improve from 0.12813\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1622 - accuracy: 0.9342 - val_loss: 0.1297 - val_accuracy: 0.9472\n",
      "Epoch 161/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1366 - accuracy: 0.9480\n",
      "Epoch 00161: val_loss improved from 0.12813 to 0.12807, saving model to ./model\\161-0.1281.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1601 - accuracy: 0.9357 - val_loss: 0.1281 - val_accuracy: 0.9534\n",
      "Epoch 162/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1558 - accuracy: 0.9340\n",
      "Epoch 00162: val_loss improved from 0.12807 to 0.12727, saving model to ./model\\162-0.1273.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1588 - accuracy: 0.9357 - val_loss: 0.1273 - val_accuracy: 0.9565\n",
      "Epoch 163/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1526 - accuracy: 0.9360\n",
      "Epoch 00163: val_loss improved from 0.12727 to 0.12682, saving model to ./model\\163-0.1268.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1582 - accuracy: 0.9342 - val_loss: 0.1268 - val_accuracy: 0.9565\n",
      "Epoch 164/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1556 - accuracy: 0.9340\n",
      "Epoch 00164: val_loss improved from 0.12682 to 0.12681, saving model to ./model\\164-0.1268.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1580 - accuracy: 0.9342 - val_loss: 0.1268 - val_accuracy: 0.9565\n",
      "Epoch 165/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1461 - accuracy: 0.9380\n",
      "Epoch 00165: val_loss did not improve from 0.12681\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.9357 - val_loss: 0.1291 - val_accuracy: 0.9472\n",
      "Epoch 166/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1702 - accuracy: 0.9320\n",
      "Epoch 00166: val_loss did not improve from 0.12681\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1581 - accuracy: 0.9357 - val_loss: 0.1290 - val_accuracy: 0.9472\n",
      "Epoch 167/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1594 - accuracy: 0.9340\n",
      "Epoch 00167: val_loss improved from 0.12681 to 0.12511, saving model to ./model\\167-0.1251.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1572 - accuracy: 0.9342 - val_loss: 0.1251 - val_accuracy: 0.9565\n",
      "Epoch 168/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1737 - accuracy: 0.9300\n",
      "Epoch 00168: val_loss did not improve from 0.12511\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1556 - accuracy: 0.9372 - val_loss: 0.1257 - val_accuracy: 0.9565\n",
      "Epoch 169/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1670 - accuracy: 0.9300\n",
      "Epoch 00169: val_loss improved from 0.12511 to 0.12432, saving model to ./model\\169-0.1243.hdf5\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1588 - accuracy: 0.9387 - val_loss: 0.1243 - val_accuracy: 0.9565\n",
      "Epoch 170/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1633 - accuracy: 0.9320\n",
      "Epoch 00170: val_loss did not improve from 0.12432\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1569 - accuracy: 0.9387 - val_loss: 0.1248 - val_accuracy: 0.9534\n",
      "Epoch 171/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1561 - accuracy: 0.9340\n",
      "Epoch 00171: val_loss did not improve from 0.12432\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1546 - accuracy: 0.9357 - val_loss: 0.1265 - val_accuracy: 0.9503\n",
      "Epoch 172/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1726 - accuracy: 0.9260\n",
      "Epoch 00172: val_loss improved from 0.12432 to 0.12283, saving model to ./model\\172-0.1228.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1550 - accuracy: 0.9372 - val_loss: 0.1228 - val_accuracy: 0.9565\n",
      "Epoch 173/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1587 - accuracy: 0.9360\n",
      "Epoch 00173: val_loss did not improve from 0.12283\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1530 - accuracy: 0.9372 - val_loss: 0.1249 - val_accuracy: 0.9503\n",
      "Epoch 174/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1520 - accuracy: 0.9460\n",
      "Epoch 00174: val_loss improved from 0.12283 to 0.12218, saving model to ./model\\174-0.1222.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1597 - accuracy: 0.9418 - val_loss: 0.1222 - val_accuracy: 0.9565\n",
      "Epoch 175/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1668 - accuracy: 0.9340\n",
      "Epoch 00175: val_loss did not improve from 0.12218\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1540 - accuracy: 0.9372 - val_loss: 0.1275 - val_accuracy: 0.9503\n",
      "Epoch 176/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1525 - accuracy: 0.9380\n",
      "Epoch 00176: val_loss did not improve from 0.12218\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1569 - accuracy: 0.9418 - val_loss: 0.1245 - val_accuracy: 0.9503\n",
      "Epoch 177/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1314 - accuracy: 0.9480\n",
      "Epoch 00177: val_loss improved from 0.12218 to 0.12090, saving model to ./model\\177-0.1209.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1557 - accuracy: 0.9357 - val_loss: 0.1209 - val_accuracy: 0.9565\n",
      "Epoch 178/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1607 - accuracy: 0.9320\n",
      "Epoch 00178: val_loss improved from 0.12090 to 0.12038, saving model to ./model\\178-0.1204.hdf5\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1521 - accuracy: 0.9357 - val_loss: 0.1204 - val_accuracy: 0.9565\n",
      "Epoch 179/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1488 - accuracy: 0.9400\n",
      "Epoch 00179: val_loss improved from 0.12038 to 0.12034, saving model to ./model\\179-0.1203.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1513 - accuracy: 0.9357 - val_loss: 0.1203 - val_accuracy: 0.9565\n",
      "Epoch 180/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1528 - accuracy: 0.9340\n",
      "Epoch 00180: val_loss did not improve from 0.12034\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1510 - accuracy: 0.9387 - val_loss: 0.1209 - val_accuracy: 0.9565\n",
      "Epoch 181/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1277 - accuracy: 0.9520\n",
      "Epoch 00181: val_loss improved from 0.12034 to 0.12006, saving model to ./model\\181-0.1201.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1510 - accuracy: 0.9403 - val_loss: 0.1201 - val_accuracy: 0.9565\n",
      "Epoch 182/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1430 - accuracy: 0.9420\n",
      "Epoch 00182: val_loss did not improve from 0.12006\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1492 - accuracy: 0.9387 - val_loss: 0.1212 - val_accuracy: 0.9565\n",
      "Epoch 183/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1357 - accuracy: 0.9520\n",
      "Epoch 00183: val_loss improved from 0.12006 to 0.11943, saving model to ./model\\183-0.1194.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1497 - accuracy: 0.9433 - val_loss: 0.1194 - val_accuracy: 0.9534\n",
      "Epoch 184/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1493 - accuracy: 0.9420\n",
      "Epoch 00184: val_loss improved from 0.11943 to 0.11768, saving model to ./model\\184-0.1177.hdf5\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1487 - accuracy: 0.9433 - val_loss: 0.1177 - val_accuracy: 0.9565\n",
      "Epoch 185/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1433 - accuracy: 0.9420\n",
      "Epoch 00185: val_loss improved from 0.11768 to 0.11758, saving model to ./model\\185-0.1176.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1493 - accuracy: 0.9372 - val_loss: 0.1176 - val_accuracy: 0.9565\n",
      "Epoch 186/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1437 - accuracy: 0.9420\n",
      "Epoch 00186: val_loss did not improve from 0.11758\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 0.9418 - val_loss: 0.1206 - val_accuracy: 0.9565\n",
      "Epoch 187/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1598 - accuracy: 0.9380\n",
      "Epoch 00187: val_loss improved from 0.11758 to 0.11692, saving model to ./model\\187-0.1169.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1494 - accuracy: 0.9418 - val_loss: 0.1169 - val_accuracy: 0.9565\n",
      "Epoch 188/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1472 - accuracy: 0.9420\n",
      "Epoch 00188: val_loss did not improve from 0.11692\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1476 - accuracy: 0.9418 - val_loss: 0.1173 - val_accuracy: 0.9534\n",
      "Epoch 189/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1319 - accuracy: 0.9480\n",
      "Epoch 00189: val_loss improved from 0.11692 to 0.11586, saving model to ./model\\189-0.1159.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1501 - accuracy: 0.9403 - val_loss: 0.1159 - val_accuracy: 0.9565\n",
      "Epoch 190/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1431 - accuracy: 0.9420\n",
      "Epoch 00190: val_loss did not improve from 0.11586\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1481 - accuracy: 0.9403 - val_loss: 0.1217 - val_accuracy: 0.9596\n",
      "Epoch 191/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1604 - accuracy: 0.9400\n",
      "Epoch 00191: val_loss improved from 0.11586 to 0.11473, saving model to ./model\\191-0.1147.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1499 - accuracy: 0.9464 - val_loss: 0.1147 - val_accuracy: 0.9534\n",
      "Epoch 192/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1596 - accuracy: 0.9380\n",
      "Epoch 00192: val_loss did not improve from 0.11473\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1463 - accuracy: 0.9418 - val_loss: 0.1165 - val_accuracy: 0.9534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1433 - accuracy: 0.9480\n",
      "Epoch 00193: val_loss improved from 0.11473 to 0.11402, saving model to ./model\\193-0.1140.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1496 - accuracy: 0.9403 - val_loss: 0.1140 - val_accuracy: 0.9534\n",
      "Epoch 194/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1407 - accuracy: 0.9400\n",
      "Epoch 00194: val_loss did not improve from 0.11402\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1445 - accuracy: 0.9418 - val_loss: 0.1183 - val_accuracy: 0.9596\n",
      "Epoch 195/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1563 - accuracy: 0.9400\n",
      "Epoch 00195: val_loss did not improve from 0.11402\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1479 - accuracy: 0.9464 - val_loss: 0.1165 - val_accuracy: 0.9596\n",
      "Epoch 196/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1418 - accuracy: 0.9440\n",
      "Epoch 00196: val_loss improved from 0.11402 to 0.11313, saving model to ./model\\196-0.1131.hdf5\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1450 - accuracy: 0.9418 - val_loss: 0.1131 - val_accuracy: 0.9534\n",
      "Epoch 197/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1395 - accuracy: 0.9440\n",
      "Epoch 00197: val_loss did not improve from 0.11313\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.9387 - val_loss: 0.1136 - val_accuracy: 0.9534\n",
      "Epoch 198/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1563 - accuracy: 0.9420\n",
      "Epoch 00198: val_loss improved from 0.11313 to 0.11285, saving model to ./model\\198-0.1129.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1475 - accuracy: 0.9403 - val_loss: 0.1129 - val_accuracy: 0.9627\n",
      "Epoch 199/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1478 - accuracy: 0.9460\n",
      "Epoch 00199: val_loss did not improve from 0.11285\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1436 - accuracy: 0.9464 - val_loss: 0.1179 - val_accuracy: 0.9658\n",
      "Epoch 200/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1406 - accuracy: 0.9520\n",
      "Epoch 00200: val_loss improved from 0.11285 to 0.11282, saving model to ./model\\200-0.1128.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1451 - accuracy: 0.9479 - val_loss: 0.1128 - val_accuracy: 0.9596\n",
      "Epoch 201/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1292 - accuracy: 0.9520\n",
      "Epoch 00201: val_loss improved from 0.11282 to 0.11218, saving model to ./model\\201-0.1122.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1442 - accuracy: 0.9433 - val_loss: 0.1122 - val_accuracy: 0.9534\n",
      "Epoch 202/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1513 - accuracy: 0.9400\n",
      "Epoch 00202: val_loss did not improve from 0.11218\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1429 - accuracy: 0.9418 - val_loss: 0.1124 - val_accuracy: 0.9627\n",
      "Epoch 203/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1432 - accuracy: 0.9400\n",
      "Epoch 00203: val_loss did not improve from 0.11218\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1413 - accuracy: 0.9418 - val_loss: 0.1144 - val_accuracy: 0.9596\n",
      "Epoch 204/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1445 - accuracy: 0.9480\n",
      "Epoch 00204: val_loss did not improve from 0.11218\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1421 - accuracy: 0.9449 - val_loss: 0.1133 - val_accuracy: 0.9596\n",
      "Epoch 205/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1462 - accuracy: 0.9400\n",
      "Epoch 00205: val_loss improved from 0.11218 to 0.11132, saving model to ./model\\205-0.1113.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1414 - accuracy: 0.9449 - val_loss: 0.1113 - val_accuracy: 0.9565\n",
      "Epoch 206/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1468 - accuracy: 0.9400\n",
      "Epoch 00206: val_loss improved from 0.11132 to 0.11090, saving model to ./model\\206-0.1109.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1404 - accuracy: 0.9403 - val_loss: 0.1109 - val_accuracy: 0.9565\n",
      "Epoch 207/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1238 - accuracy: 0.9460\n",
      "Epoch 00207: val_loss improved from 0.11090 to 0.11063, saving model to ./model\\207-0.1106.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1402 - accuracy: 0.9403 - val_loss: 0.1106 - val_accuracy: 0.9627\n",
      "Epoch 208/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1482 - accuracy: 0.9420\n",
      "Epoch 00208: val_loss did not improve from 0.11063\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1395 - accuracy: 0.9464 - val_loss: 0.1107 - val_accuracy: 0.9627\n",
      "Epoch 209/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1343 - accuracy: 0.9480\n",
      "Epoch 00209: val_loss improved from 0.11063 to 0.10996, saving model to ./model\\209-0.1100.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1390 - accuracy: 0.9495 - val_loss: 0.1100 - val_accuracy: 0.9627\n",
      "Epoch 210/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1382 - accuracy: 0.9540\n",
      "Epoch 00210: val_loss improved from 0.10996 to 0.10941, saving model to ./model\\210-0.1094.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1383 - accuracy: 0.9479 - val_loss: 0.1094 - val_accuracy: 0.9596\n",
      "Epoch 211/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1277 - accuracy: 0.9520\n",
      "Epoch 00211: val_loss did not improve from 0.10941\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1382 - accuracy: 0.9464 - val_loss: 0.1098 - val_accuracy: 0.9658\n",
      "Epoch 212/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1317 - accuracy: 0.9580\n",
      "Epoch 00212: val_loss did not improve from 0.10941\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1379 - accuracy: 0.9510 - val_loss: 0.1104 - val_accuracy: 0.9627\n",
      "Epoch 213/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1467 - accuracy: 0.9480\n",
      "Epoch 00213: val_loss improved from 0.10941 to 0.10804, saving model to ./model\\213-0.1080.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1377 - accuracy: 0.9510 - val_loss: 0.1080 - val_accuracy: 0.9596\n",
      "Epoch 214/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1120 - accuracy: 0.9480\n",
      "Epoch 00214: val_loss improved from 0.10804 to 0.10757, saving model to ./model\\214-0.1076.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1383 - accuracy: 0.9433 - val_loss: 0.1076 - val_accuracy: 0.9565\n",
      "Epoch 215/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1404 - accuracy: 0.9420\n",
      "Epoch 00215: val_loss did not improve from 0.10757\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1368 - accuracy: 0.9449 - val_loss: 0.1095 - val_accuracy: 0.9627\n",
      "Epoch 216/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1429 - accuracy: 0.9520\n",
      "Epoch 00216: val_loss did not improve from 0.10757\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1371 - accuracy: 0.9495 - val_loss: 0.1097 - val_accuracy: 0.9627\n",
      "Epoch 217/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1443 - accuracy: 0.9500\n",
      "Epoch 00217: val_loss improved from 0.10757 to 0.10678, saving model to ./model\\217-0.1068.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1367 - accuracy: 0.9525 - val_loss: 0.1068 - val_accuracy: 0.9565\n",
      "Epoch 218/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1442 - accuracy: 0.9420\n",
      "Epoch 00218: val_loss did not improve from 0.10678\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1363 - accuracy: 0.9449 - val_loss: 0.1085 - val_accuracy: 0.9534\n",
      "Epoch 219/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1445 - accuracy: 0.9420\n",
      "Epoch 00219: val_loss improved from 0.10678 to 0.10623, saving model to ./model\\219-0.1062.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1396 - accuracy: 0.9418 - val_loss: 0.1062 - val_accuracy: 0.9565\n",
      "Epoch 220/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1399 - accuracy: 0.9440\n",
      "Epoch 00220: val_loss did not improve from 0.10623\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1343 - accuracy: 0.9464 - val_loss: 0.1139 - val_accuracy: 0.9627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1447 - accuracy: 0.9480\n",
      "Epoch 00221: val_loss did not improve from 0.10623\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1408 - accuracy: 0.9495 - val_loss: 0.1083 - val_accuracy: 0.9658\n",
      "Epoch 222/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1198 - accuracy: 0.9640\n",
      "Epoch 00222: val_loss did not improve from 0.10623\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1339 - accuracy: 0.9495 - val_loss: 0.1078 - val_accuracy: 0.9534\n",
      "Epoch 223/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1383 - accuracy: 0.9420\n",
      "Epoch 00223: val_loss did not improve from 0.10623\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1400 - accuracy: 0.9418 - val_loss: 0.1080 - val_accuracy: 0.9534\n",
      "Epoch 224/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1455 - accuracy: 0.9400\n",
      "Epoch 00224: val_loss improved from 0.10623 to 0.10526, saving model to ./model\\224-0.1053.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1398 - accuracy: 0.9403 - val_loss: 0.1053 - val_accuracy: 0.9596\n",
      "Epoch 225/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1373 - accuracy: 0.9440\n",
      "Epoch 00225: val_loss did not improve from 0.10526\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1333 - accuracy: 0.9479 - val_loss: 0.1104 - val_accuracy: 0.9627\n",
      "Epoch 226/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1304 - accuracy: 0.9540\n",
      "Epoch 00226: val_loss did not improve from 0.10526\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1361 - accuracy: 0.9510 - val_loss: 0.1061 - val_accuracy: 0.9658\n",
      "Epoch 227/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1410 - accuracy: 0.9520\n",
      "Epoch 00227: val_loss improved from 0.10526 to 0.10320, saving model to ./model\\227-0.1032.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1331 - accuracy: 0.9525 - val_loss: 0.1032 - val_accuracy: 0.9596\n",
      "Epoch 228/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1393 - accuracy: 0.9420\n",
      "Epoch 00228: val_loss improved from 0.10320 to 0.10274, saving model to ./model\\228-0.1027.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1330 - accuracy: 0.9433 - val_loss: 0.1027 - val_accuracy: 0.9596\n",
      "Epoch 229/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1386 - accuracy: 0.9420\n",
      "Epoch 00229: val_loss did not improve from 0.10274\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1331 - accuracy: 0.9495 - val_loss: 0.1030 - val_accuracy: 0.9627\n",
      "Epoch 230/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1252 - accuracy: 0.9540\n",
      "Epoch 00230: val_loss did not improve from 0.10274\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1316 - accuracy: 0.9510 - val_loss: 0.1032 - val_accuracy: 0.9689\n",
      "Epoch 231/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1148 - accuracy: 0.9600\n",
      "Epoch 00231: val_loss did not improve from 0.10274\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1313 - accuracy: 0.9464 - val_loss: 0.1034 - val_accuracy: 0.9658\n",
      "Epoch 232/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1317 - accuracy: 0.9480\n",
      "Epoch 00232: val_loss did not improve from 0.10274\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1310 - accuracy: 0.9510 - val_loss: 0.1043 - val_accuracy: 0.9658\n",
      "Epoch 233/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1369 - accuracy: 0.9540\n",
      "Epoch 00233: val_loss improved from 0.10274 to 0.10248, saving model to ./model\\233-0.1025.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1310 - accuracy: 0.9525 - val_loss: 0.1025 - val_accuracy: 0.9689\n",
      "Epoch 234/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1361 - accuracy: 0.9480\n",
      "Epoch 00234: val_loss improved from 0.10248 to 0.10156, saving model to ./model\\234-0.1016.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1300 - accuracy: 0.9510 - val_loss: 0.1016 - val_accuracy: 0.9596\n",
      "Epoch 235/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1234 - accuracy: 0.9480\n",
      "Epoch 00235: val_loss did not improve from 0.10156\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1309 - accuracy: 0.9433 - val_loss: 0.1016 - val_accuracy: 0.9627\n",
      "Epoch 236/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1336 - accuracy: 0.9500\n",
      "Epoch 00236: val_loss did not improve from 0.10156\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1292 - accuracy: 0.9525 - val_loss: 0.1060 - val_accuracy: 0.9658\n",
      "Epoch 237/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1389 - accuracy: 0.9500\n",
      "Epoch 00237: val_loss improved from 0.10156 to 0.10114, saving model to ./model\\237-0.1011.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1323 - accuracy: 0.9525 - val_loss: 0.1011 - val_accuracy: 0.9658\n",
      "Epoch 238/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1269 - accuracy: 0.9520\n",
      "Epoch 00238: val_loss improved from 0.10114 to 0.10111, saving model to ./model\\238-0.1011.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1320 - accuracy: 0.9464 - val_loss: 0.1011 - val_accuracy: 0.9565\n",
      "Epoch 239/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1111 - accuracy: 0.9600\n",
      "Epoch 00239: val_loss did not improve from 0.10111\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1310 - accuracy: 0.9449 - val_loss: 0.1024 - val_accuracy: 0.9658\n",
      "Epoch 240/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1347 - accuracy: 0.9500\n",
      "Epoch 00240: val_loss did not improve from 0.10111\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1317 - accuracy: 0.9541 - val_loss: 0.1094 - val_accuracy: 0.9658\n",
      "Epoch 241/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1411 - accuracy: 0.9480\n",
      "Epoch 00241: val_loss improved from 0.10111 to 0.09978, saving model to ./model\\241-0.0998.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1349 - accuracy: 0.9510 - val_loss: 0.0998 - val_accuracy: 0.9689\n",
      "Epoch 242/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1322 - accuracy: 0.9440\n",
      "Epoch 00242: val_loss improved from 0.09978 to 0.09953, saving model to ./model\\242-0.0995.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1276 - accuracy: 0.9495 - val_loss: 0.0995 - val_accuracy: 0.9596\n",
      "Epoch 243/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1240 - accuracy: 0.9520\n",
      "Epoch 00243: val_loss improved from 0.09953 to 0.09940, saving model to ./model\\243-0.0994.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1286 - accuracy: 0.9479 - val_loss: 0.0994 - val_accuracy: 0.9658\n",
      "Epoch 244/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1274 - accuracy: 0.9500\n",
      "Epoch 00244: val_loss did not improve from 0.09940\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1271 - accuracy: 0.9495 - val_loss: 0.0999 - val_accuracy: 0.9689\n",
      "Epoch 245/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1328 - accuracy: 0.9520\n",
      "Epoch 00245: val_loss did not improve from 0.09940\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1267 - accuracy: 0.9510 - val_loss: 0.0996 - val_accuracy: 0.9689\n",
      "Epoch 246/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1336 - accuracy: 0.9500\n",
      "Epoch 00246: val_loss improved from 0.09940 to 0.09902, saving model to ./model\\246-0.0990.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1264 - accuracy: 0.9525 - val_loss: 0.0990 - val_accuracy: 0.9689\n",
      "Epoch 247/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1281 - accuracy: 0.9520\n",
      "Epoch 00247: val_loss improved from 0.09902 to 0.09876, saving model to ./model\\247-0.0988.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1267 - accuracy: 0.9525 - val_loss: 0.0988 - val_accuracy: 0.9658\n",
      "Epoch 248/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1097 - accuracy: 0.9680\n",
      "Epoch 00248: val_loss did not improve from 0.09876\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1267 - accuracy: 0.9525 - val_loss: 0.1011 - val_accuracy: 0.9658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1192 - accuracy: 0.9600\n",
      "Epoch 00249: val_loss did not improve from 0.09876\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1257 - accuracy: 0.9571 - val_loss: 0.1103 - val_accuracy: 0.9658\n",
      "Epoch 250/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1287 - accuracy: 0.9600\n",
      "Epoch 00250: val_loss did not improve from 0.09876\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1324 - accuracy: 0.9541 - val_loss: 0.0995 - val_accuracy: 0.9658\n",
      "Epoch 251/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1289 - accuracy: 0.9540\n",
      "Epoch 00251: val_loss did not improve from 0.09876\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1251 - accuracy: 0.9571 - val_loss: 0.0997 - val_accuracy: 0.9534\n",
      "Epoch 252/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1465 - accuracy: 0.9400\n",
      "Epoch 00252: val_loss improved from 0.09876 to 0.09845, saving model to ./model\\252-0.0985.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1317 - accuracy: 0.9464 - val_loss: 0.0985 - val_accuracy: 0.9565\n",
      "Epoch 253/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1182 - accuracy: 0.9540\n",
      "Epoch 00253: val_loss did not improve from 0.09845\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1276 - accuracy: 0.9495 - val_loss: 0.0991 - val_accuracy: 0.9658\n",
      "Epoch 254/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1150 - accuracy: 0.9640\n",
      "Epoch 00254: val_loss did not improve from 0.09845\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1240 - accuracy: 0.9587 - val_loss: 0.1152 - val_accuracy: 0.9658\n",
      "Epoch 255/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1329 - accuracy: 0.9600\n",
      "Epoch 00255: val_loss improved from 0.09845 to 0.09680, saving model to ./model\\255-0.0968.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1366 - accuracy: 0.9571 - val_loss: 0.0968 - val_accuracy: 0.9689\n",
      "Epoch 256/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1268 - accuracy: 0.9580\n",
      "Epoch 00256: val_loss did not improve from 0.09680\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1244 - accuracy: 0.9556 - val_loss: 0.0987 - val_accuracy: 0.9565\n",
      "Epoch 257/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1152 - accuracy: 0.9540\n",
      "Epoch 00257: val_loss improved from 0.09680 to 0.09551, saving model to ./model\\257-0.0955.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1307 - accuracy: 0.9464 - val_loss: 0.0955 - val_accuracy: 0.9596\n",
      "Epoch 258/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1391 - accuracy: 0.9420\n",
      "Epoch 00258: val_loss did not improve from 0.09551\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1262 - accuracy: 0.9525 - val_loss: 0.0987 - val_accuracy: 0.9689\n",
      "Epoch 259/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1265 - accuracy: 0.9560\n",
      "Epoch 00259: val_loss did not improve from 0.09551\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1241 - accuracy: 0.9587 - val_loss: 0.0975 - val_accuracy: 0.9689\n",
      "Epoch 260/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1255 - accuracy: 0.9520\n",
      "Epoch 00260: val_loss improved from 0.09551 to 0.09390, saving model to ./model\\260-0.0939.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1226 - accuracy: 0.9556 - val_loss: 0.0939 - val_accuracy: 0.9658\n",
      "Epoch 261/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1220 - accuracy: 0.9460\n",
      "Epoch 00261: val_loss improved from 0.09390 to 0.09370, saving model to ./model\\261-0.0937.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1229 - accuracy: 0.9525 - val_loss: 0.0937 - val_accuracy: 0.9689\n",
      "Epoch 262/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1120 - accuracy: 0.9580\n",
      "Epoch 00262: val_loss did not improve from 0.09370\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1224 - accuracy: 0.9525 - val_loss: 0.0952 - val_accuracy: 0.9689\n",
      "Epoch 263/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1090 - accuracy: 0.9620\n",
      "Epoch 00263: val_loss did not improve from 0.09370\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1210 - accuracy: 0.9587 - val_loss: 0.0979 - val_accuracy: 0.9658\n",
      "Epoch 264/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1259 - accuracy: 0.9560\n",
      "Epoch 00264: val_loss did not improve from 0.09370\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1220 - accuracy: 0.9587 - val_loss: 0.0942 - val_accuracy: 0.9658\n",
      "Epoch 265/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1322 - accuracy: 0.9500\n",
      "Epoch 00265: val_loss did not improve from 0.09370\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.9587 - val_loss: 0.0937 - val_accuracy: 0.9627\n",
      "Epoch 266/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1027 - accuracy: 0.9640\n",
      "Epoch 00266: val_loss improved from 0.09370 to 0.09312, saving model to ./model\\266-0.0931.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1232 - accuracy: 0.9495 - val_loss: 0.0931 - val_accuracy: 0.9689\n",
      "Epoch 267/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1257 - accuracy: 0.9500\n",
      "Epoch 00267: val_loss did not improve from 0.09312\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1200 - accuracy: 0.9525 - val_loss: 0.0982 - val_accuracy: 0.9689\n",
      "Epoch 268/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1154 - accuracy: 0.9660\n",
      "Epoch 00268: val_loss did not improve from 0.09312\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1239 - accuracy: 0.9617 - val_loss: 0.0961 - val_accuracy: 0.9720\n",
      "Epoch 269/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1287 - accuracy: 0.9540\n",
      "Epoch 00269: val_loss did not improve from 0.09312\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1189 - accuracy: 0.9587 - val_loss: 0.0951 - val_accuracy: 0.9596\n",
      "Epoch 270/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1309 - accuracy: 0.9440\n",
      "Epoch 00270: val_loss did not improve from 0.09312\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1252 - accuracy: 0.9479 - val_loss: 0.0989 - val_accuracy: 0.9534\n",
      "Epoch 271/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1251 - accuracy: 0.9460\n",
      "Epoch 00271: val_loss improved from 0.09312 to 0.09249, saving model to ./model\\271-0.0925.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1289 - accuracy: 0.9449 - val_loss: 0.0925 - val_accuracy: 0.9658\n",
      "Epoch 272/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1198 - accuracy: 0.9520\n",
      "Epoch 00272: val_loss did not improve from 0.09249\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1202 - accuracy: 0.9541 - val_loss: 0.1051 - val_accuracy: 0.9752\n",
      "Epoch 273/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1288 - accuracy: 0.9540\n",
      "Epoch 00273: val_loss did not improve from 0.09249\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1248 - accuracy: 0.9587 - val_loss: 0.0947 - val_accuracy: 0.9689\n",
      "Epoch 274/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1208 - accuracy: 0.9560\n",
      "Epoch 00274: val_loss improved from 0.09249 to 0.09207, saving model to ./model\\274-0.0921.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1178 - accuracy: 0.9571 - val_loss: 0.0921 - val_accuracy: 0.9658\n",
      "Epoch 275/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1189 - accuracy: 0.9540\n",
      "Epoch 00275: val_loss improved from 0.09207 to 0.09128, saving model to ./model\\275-0.0913.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1197 - accuracy: 0.9541 - val_loss: 0.0913 - val_accuracy: 0.9658\n",
      "Epoch 276/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1188 - accuracy: 0.9580\n",
      "Epoch 00276: val_loss did not improve from 0.09128\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1180 - accuracy: 0.9556 - val_loss: 0.0926 - val_accuracy: 0.9720\n",
      "Epoch 277/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1162 - accuracy: 0.9620\n",
      "Epoch 00277: val_loss did not improve from 0.09128\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1164 - accuracy: 0.9602 - val_loss: 0.0952 - val_accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1080 - accuracy: 0.9620\n",
      "Epoch 00278: val_loss did not improve from 0.09128\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.9587 - val_loss: 0.0919 - val_accuracy: 0.9720\n",
      "Epoch 279/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1149 - accuracy: 0.9600\n",
      "Epoch 00279: val_loss improved from 0.09128 to 0.09078, saving model to ./model\\279-0.0908.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1157 - accuracy: 0.9617 - val_loss: 0.0908 - val_accuracy: 0.9658\n",
      "Epoch 280/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1091 - accuracy: 0.9580\n",
      "Epoch 00280: val_loss did not improve from 0.09078\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1162 - accuracy: 0.9541 - val_loss: 0.0910 - val_accuracy: 0.9658\n",
      "Epoch 281/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1086 - accuracy: 0.9580\n",
      "Epoch 00281: val_loss did not improve from 0.09078\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9541 - val_loss: 0.0931 - val_accuracy: 0.9720\n",
      "Epoch 282/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1242 - accuracy: 0.9560\n",
      "Epoch 00282: val_loss did not improve from 0.09078\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1159 - accuracy: 0.9602 - val_loss: 0.0936 - val_accuracy: 0.9720\n",
      "Epoch 283/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1137 - accuracy: 0.9660\n",
      "Epoch 00283: val_loss improved from 0.09078 to 0.09037, saving model to ./model\\283-0.0904.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1160 - accuracy: 0.9632 - val_loss: 0.0904 - val_accuracy: 0.9658\n",
      "Epoch 284/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1189 - accuracy: 0.9580\n",
      "Epoch 00284: val_loss improved from 0.09037 to 0.09035, saving model to ./model\\284-0.0903.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1142 - accuracy: 0.9571 - val_loss: 0.0903 - val_accuracy: 0.9689\n",
      "Epoch 285/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1026 - accuracy: 0.9680\n",
      "Epoch 00285: val_loss did not improve from 0.09035\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.9617 - val_loss: 0.0913 - val_accuracy: 0.9689\n",
      "Epoch 286/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1110 - accuracy: 0.9600\n",
      "Epoch 00286: val_loss did not improve from 0.09035\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.9587 - val_loss: 0.0905 - val_accuracy: 0.9689\n",
      "Epoch 287/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1039 - accuracy: 0.9680\n",
      "Epoch 00287: val_loss improved from 0.09035 to 0.08871, saving model to ./model\\287-0.0887.hdf5\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1133 - accuracy: 0.9632 - val_loss: 0.0887 - val_accuracy: 0.9689\n",
      "Epoch 288/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1143 - accuracy: 0.9600\n",
      "Epoch 00288: val_loss did not improve from 0.08871\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1133 - accuracy: 0.9602 - val_loss: 0.0892 - val_accuracy: 0.9689\n",
      "Epoch 289/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1086 - accuracy: 0.9600\n",
      "Epoch 00289: val_loss did not improve from 0.08871\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1134 - accuracy: 0.9617 - val_loss: 0.0908 - val_accuracy: 0.9720\n",
      "Epoch 290/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1220 - accuracy: 0.9600\n",
      "Epoch 00290: val_loss improved from 0.08871 to 0.08770, saving model to ./model\\290-0.0877.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1127 - accuracy: 0.9648 - val_loss: 0.0877 - val_accuracy: 0.9689\n",
      "Epoch 291/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1101 - accuracy: 0.9600\n",
      "Epoch 00291: val_loss did not improve from 0.08770\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.9571 - val_loss: 0.0878 - val_accuracy: 0.9689\n",
      "Epoch 292/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0988 - accuracy: 0.9620\n",
      "Epoch 00292: val_loss did not improve from 0.08770\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1129 - accuracy: 0.9571 - val_loss: 0.0911 - val_accuracy: 0.9720\n",
      "Epoch 293/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1215 - accuracy: 0.9600\n",
      "Epoch 00293: val_loss did not improve from 0.08770\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1135 - accuracy: 0.9632 - val_loss: 0.0955 - val_accuracy: 0.9752\n",
      "Epoch 294/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1159 - accuracy: 0.9660\n",
      "Epoch 00294: val_loss improved from 0.08770 to 0.08765, saving model to ./model\\294-0.0876.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1147 - accuracy: 0.9648 - val_loss: 0.0876 - val_accuracy: 0.9658\n",
      "Epoch 295/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1095 - accuracy: 0.9600\n",
      "Epoch 00295: val_loss did not improve from 0.08765\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.9587 - val_loss: 0.0882 - val_accuracy: 0.9658\n",
      "Epoch 296/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1023 - accuracy: 0.9540\n",
      "Epoch 00296: val_loss improved from 0.08765 to 0.08668, saving model to ./model\\296-0.0867.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1151 - accuracy: 0.9510 - val_loss: 0.0867 - val_accuracy: 0.9689\n",
      "Epoch 297/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1116 - accuracy: 0.9640\n",
      "Epoch 00297: val_loss did not improve from 0.08668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1099 - accuracy: 0.9648 - val_loss: 0.0969 - val_accuracy: 0.9752\n",
      "Epoch 298/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1149 - accuracy: 0.9640\n",
      "Epoch 00298: val_loss did not improve from 0.08668\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9632 - val_loss: 0.0913 - val_accuracy: 0.9720\n",
      "Epoch 299/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1059 - accuracy: 0.9700\n",
      "Epoch 00299: val_loss improved from 0.08668 to 0.08547, saving model to ./model\\299-0.0855.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1144 - accuracy: 0.9663 - val_loss: 0.0855 - val_accuracy: 0.9689\n",
      "Epoch 300/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1071 - accuracy: 0.9640\n",
      "Epoch 00300: val_loss improved from 0.08547 to 0.08535, saving model to ./model\\300-0.0853.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1097 - accuracy: 0.9632 - val_loss: 0.0853 - val_accuracy: 0.9689\n",
      "Epoch 301/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1116 - accuracy: 0.9640\n",
      "Epoch 00301: val_loss did not improve from 0.08535\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1089 - accuracy: 0.9632 - val_loss: 0.0865 - val_accuracy: 0.9720\n",
      "Epoch 302/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1146 - accuracy: 0.9640\n",
      "Epoch 00302: val_loss did not improve from 0.08535\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1092 - accuracy: 0.9648 - val_loss: 0.0871 - val_accuracy: 0.9720\n",
      "Epoch 303/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0917 - accuracy: 0.9720\n",
      "Epoch 00303: val_loss did not improve from 0.08535\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.9648 - val_loss: 0.0857 - val_accuracy: 0.9720\n",
      "Epoch 304/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1026 - accuracy: 0.9640\n",
      "Epoch 00304: val_loss did not improve from 0.08535\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.9648 - val_loss: 0.0865 - val_accuracy: 0.9720\n",
      "Epoch 305/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1196 - accuracy: 0.9580\n",
      "Epoch 00305: val_loss improved from 0.08535 to 0.08503, saving model to ./model\\305-0.0850.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1094 - accuracy: 0.9648 - val_loss: 0.0850 - val_accuracy: 0.9720\n",
      "Epoch 306/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1036 - accuracy: 0.9660\n",
      "Epoch 00306: val_loss improved from 0.08503 to 0.08392, saving model to ./model\\306-0.0839.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1078 - accuracy: 0.9648 - val_loss: 0.0839 - val_accuracy: 0.9720\n",
      "Epoch 307/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1046 - accuracy: 0.9600\n",
      "Epoch 00307: val_loss improved from 0.08392 to 0.08343, saving model to ./model\\307-0.0834.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1098 - accuracy: 0.9571 - val_loss: 0.0834 - val_accuracy: 0.9752\n",
      "Epoch 308/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1129 - accuracy: 0.9600\n",
      "Epoch 00308: val_loss did not improve from 0.08343\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.9648 - val_loss: 0.0878 - val_accuracy: 0.9720\n",
      "Epoch 309/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1166 - accuracy: 0.9600\n",
      "Epoch 00309: val_loss did not improve from 0.08343\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1089 - accuracy: 0.9648 - val_loss: 0.0867 - val_accuracy: 0.9720\n",
      "Epoch 310/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1003 - accuracy: 0.9700\n",
      "Epoch 00310: val_loss improved from 0.08343 to 0.08292, saving model to ./model\\310-0.0829.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1076 - accuracy: 0.9678 - val_loss: 0.0829 - val_accuracy: 0.9689\n",
      "Epoch 311/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0991 - accuracy: 0.9720\n",
      "Epoch 00311: val_loss improved from 0.08292 to 0.08286, saving model to ./model\\311-0.0829.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1076 - accuracy: 0.9648 - val_loss: 0.0829 - val_accuracy: 0.9720\n",
      "Epoch 312/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0989 - accuracy: 0.9660\n",
      "Epoch 00312: val_loss did not improve from 0.08286\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1066 - accuracy: 0.9632 - val_loss: 0.0857 - val_accuracy: 0.9720\n",
      "Epoch 313/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1095 - accuracy: 0.9640\n",
      "Epoch 00313: val_loss did not improve from 0.08286\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1076 - accuracy: 0.9663 - val_loss: 0.0855 - val_accuracy: 0.9720\n",
      "Epoch 314/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0995 - accuracy: 0.9720\n",
      "Epoch 00314: val_loss did not improve from 0.08286\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1084 - accuracy: 0.9678 - val_loss: 0.0831 - val_accuracy: 0.9720\n",
      "Epoch 315/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1141 - accuracy: 0.9600\n",
      "Epoch 00315: val_loss did not improve from 0.08286\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.9648 - val_loss: 0.0829 - val_accuracy: 0.9720\n",
      "Epoch 316/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1129 - accuracy: 0.9660\n",
      "Epoch 00316: val_loss improved from 0.08286 to 0.08230, saving model to ./model\\316-0.0823.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1050 - accuracy: 0.9663 - val_loss: 0.0823 - val_accuracy: 0.9720\n",
      "Epoch 317/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1080 - accuracy: 0.9640\n",
      "Epoch 00317: val_loss did not improve from 0.08230\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.9648 - val_loss: 0.0835 - val_accuracy: 0.9720\n",
      "Epoch 318/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1035 - accuracy: 0.9700\n",
      "Epoch 00318: val_loss did not improve from 0.08230\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9694 - val_loss: 0.0865 - val_accuracy: 0.9752\n",
      "Epoch 319/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1015 - accuracy: 0.9660\n",
      "Epoch 00319: val_loss did not improve from 0.08230\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.9632 - val_loss: 0.0835 - val_accuracy: 0.9720\n",
      "Epoch 320/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1064 - accuracy: 0.9660\n",
      "Epoch 00320: val_loss improved from 0.08230 to 0.08130, saving model to ./model\\320-0.0813.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1039 - accuracy: 0.9678 - val_loss: 0.0813 - val_accuracy: 0.9720\n",
      "Epoch 321/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1140 - accuracy: 0.9560\n",
      "Epoch 00321: val_loss improved from 0.08130 to 0.08112, saving model to ./model\\321-0.0811.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1051 - accuracy: 0.9617 - val_loss: 0.0811 - val_accuracy: 0.9752\n",
      "Epoch 322/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1072 - accuracy: 0.9560\n",
      "Epoch 00322: val_loss improved from 0.08112 to 0.08112, saving model to ./model\\322-0.0811.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1065 - accuracy: 0.9571 - val_loss: 0.0811 - val_accuracy: 0.9720\n",
      "Epoch 323/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1010 - accuracy: 0.9700\n",
      "Epoch 00323: val_loss did not improve from 0.08112\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.9694 - val_loss: 0.0888 - val_accuracy: 0.9783\n",
      "Epoch 324/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1019 - accuracy: 0.9640\n",
      "Epoch 00324: val_loss did not improve from 0.08112\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.9648 - val_loss: 0.0822 - val_accuracy: 0.9720\n",
      "Epoch 325/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1018 - accuracy: 0.9700\n",
      "Epoch 00325: val_loss improved from 0.08112 to 0.07988, saving model to ./model\\325-0.0799.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1028 - accuracy: 0.9709 - val_loss: 0.0799 - val_accuracy: 0.9752\n",
      "Epoch 326/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1154 - accuracy: 0.9520\n",
      "Epoch 00326: val_loss did not improve from 0.07988\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9602 - val_loss: 0.0801 - val_accuracy: 0.9720\n",
      "Epoch 327/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1024 - accuracy: 0.9620\n",
      "Epoch 00327: val_loss did not improve from 0.07988\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1049 - accuracy: 0.9617 - val_loss: 0.0799 - val_accuracy: 0.9720\n",
      "Epoch 328/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1038 - accuracy: 0.9700\n",
      "Epoch 00328: val_loss did not improve from 0.07988\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9678 - val_loss: 0.0808 - val_accuracy: 0.9720\n",
      "Epoch 329/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1013 - accuracy: 0.9720\n",
      "Epoch 00329: val_loss improved from 0.07988 to 0.07886, saving model to ./model\\329-0.0789.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1022 - accuracy: 0.9678 - val_loss: 0.0789 - val_accuracy: 0.9752\n",
      "Epoch 330/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0967 - accuracy: 0.9660\n",
      "Epoch 00330: val_loss improved from 0.07886 to 0.07853, saving model to ./model\\330-0.0785.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1027 - accuracy: 0.9617 - val_loss: 0.0785 - val_accuracy: 0.9752\n",
      "Epoch 331/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1118 - accuracy: 0.9620\n",
      "Epoch 00331: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1024 - accuracy: 0.9663 - val_loss: 0.0793 - val_accuracy: 0.9720\n",
      "Epoch 332/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1043 - accuracy: 0.9660\n",
      "Epoch 00332: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9678 - val_loss: 0.0795 - val_accuracy: 0.9752\n",
      "Epoch 333/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1082 - accuracy: 0.9660\n",
      "Epoch 00333: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1015 - accuracy: 0.9678 - val_loss: 0.0790 - val_accuracy: 0.9720\n",
      "Epoch 334/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1023 - accuracy: 0.9700\n",
      "Epoch 00334: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1024 - accuracy: 0.9694 - val_loss: 0.0795 - val_accuracy: 0.9720\n",
      "Epoch 335/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0931 - accuracy: 0.9720\n",
      "Epoch 00335: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1023 - accuracy: 0.9678 - val_loss: 0.0805 - val_accuracy: 0.9720\n",
      "Epoch 336/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0841 - accuracy: 0.9700\n",
      "Epoch 00336: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1009 - accuracy: 0.9678 - val_loss: 0.0845 - val_accuracy: 0.9752\n",
      "Epoch 337/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0981 - accuracy: 0.9720\n",
      "Epoch 00337: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1009 - accuracy: 0.9678 - val_loss: 0.0842 - val_accuracy: 0.9752\n",
      "Epoch 338/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0953 - accuracy: 0.9700\n",
      "Epoch 00338: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1018 - accuracy: 0.9648 - val_loss: 0.0794 - val_accuracy: 0.9720\n",
      "Epoch 339/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1013 - accuracy: 0.9680\n",
      "Epoch 00339: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1004 - accuracy: 0.9663 - val_loss: 0.0789 - val_accuracy: 0.9752\n",
      "Epoch 340/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0983 - accuracy: 0.9620\n",
      "Epoch 00340: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1016 - accuracy: 0.9632 - val_loss: 0.0786 - val_accuracy: 0.9720\n",
      "Epoch 341/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0907 - accuracy: 0.9640\n",
      "Epoch 00341: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1003 - accuracy: 0.9632 - val_loss: 0.0805 - val_accuracy: 0.9752\n",
      "Epoch 342/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1075 - accuracy: 0.9700\n",
      "Epoch 00342: val_loss did not improve from 0.07853\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1002 - accuracy: 0.9709 - val_loss: 0.0811 - val_accuracy: 0.9752\n",
      "Epoch 343/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1018 - accuracy: 0.9700\n",
      "Epoch 00343: val_loss improved from 0.07853 to 0.07784, saving model to ./model\\343-0.0778.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0994 - accuracy: 0.9694 - val_loss: 0.0778 - val_accuracy: 0.9720\n",
      "Epoch 344/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0965 - accuracy: 0.9720\n",
      "Epoch 00344: val_loss improved from 0.07784 to 0.07748, saving model to ./model\\344-0.0775.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0986 - accuracy: 0.9694 - val_loss: 0.0775 - val_accuracy: 0.9720\n",
      "Epoch 345/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0961 - accuracy: 0.9740\n",
      "Epoch 00345: val_loss did not improve from 0.07748\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0973 - accuracy: 0.9709 - val_loss: 0.0821 - val_accuracy: 0.9752\n",
      "Epoch 346/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0928 - accuracy: 0.9680\n",
      "Epoch 00346: val_loss did not improve from 0.07748\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0984 - accuracy: 0.9663 - val_loss: 0.0827 - val_accuracy: 0.9783\n",
      "Epoch 347/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0943 - accuracy: 0.9700\n",
      "Epoch 00347: val_loss did not improve from 0.07748\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0985 - accuracy: 0.9663 - val_loss: 0.0780 - val_accuracy: 0.9752\n",
      "Epoch 348/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0883 - accuracy: 0.9800\n",
      "Epoch 00348: val_loss improved from 0.07748 to 0.07697, saving model to ./model\\348-0.0770.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0968 - accuracy: 0.9709 - val_loss: 0.0770 - val_accuracy: 0.9752\n",
      "Epoch 349/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0978 - accuracy: 0.9700\n",
      "Epoch 00349: val_loss did not improve from 0.07697\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0968 - accuracy: 0.9694 - val_loss: 0.0772 - val_accuracy: 0.9752\n",
      "Epoch 350/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0933 - accuracy: 0.9720\n",
      "Epoch 00350: val_loss did not improve from 0.07697\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0960 - accuracy: 0.9709 - val_loss: 0.0804 - val_accuracy: 0.9752\n",
      "Epoch 351/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1028 - accuracy: 0.9660\n",
      "Epoch 00351: val_loss did not improve from 0.07697\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0978 - accuracy: 0.9663 - val_loss: 0.0781 - val_accuracy: 0.9752\n",
      "Epoch 352/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1028 - accuracy: 0.9680\n",
      "Epoch 00352: val_loss improved from 0.07697 to 0.07662, saving model to ./model\\352-0.0766.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0959 - accuracy: 0.9709 - val_loss: 0.0766 - val_accuracy: 0.9720\n",
      "Epoch 353/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1044 - accuracy: 0.9600\n",
      "Epoch 00353: val_loss improved from 0.07662 to 0.07613, saving model to ./model\\353-0.0761.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0992 - accuracy: 0.9632 - val_loss: 0.0761 - val_accuracy: 0.9720\n",
      "Epoch 354/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0972 - accuracy: 0.9660\n",
      "Epoch 00354: val_loss did not improve from 0.07613\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0977 - accuracy: 0.9678 - val_loss: 0.0784 - val_accuracy: 0.9752\n",
      "Epoch 355/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0998 - accuracy: 0.9680\n",
      "Epoch 00355: val_loss did not improve from 0.07613\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0964 - accuracy: 0.9709 - val_loss: 0.0772 - val_accuracy: 0.9752\n",
      "Epoch 356/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0979 - accuracy: 0.9660\n",
      "Epoch 00356: val_loss improved from 0.07613 to 0.07541, saving model to ./model\\356-0.0754.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0957 - accuracy: 0.9709 - val_loss: 0.0754 - val_accuracy: 0.9752\n",
      "Epoch 357/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1043 - accuracy: 0.9680\n",
      "Epoch 00357: val_loss improved from 0.07541 to 0.07491, saving model to ./model\\357-0.0749.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0953 - accuracy: 0.9709 - val_loss: 0.0749 - val_accuracy: 0.9752\n",
      "Epoch 358/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0857 - accuracy: 0.9780\n",
      "Epoch 00358: val_loss did not improve from 0.07491\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.9694 - val_loss: 0.0759 - val_accuracy: 0.9752\n",
      "Epoch 359/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0881 - accuracy: 0.9700\n",
      "Epoch 00359: val_loss did not improve from 0.07491\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0939 - accuracy: 0.9709 - val_loss: 0.0827 - val_accuracy: 0.9783\n",
      "Epoch 360/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0991 - accuracy: 0.9640\n",
      "Epoch 00360: val_loss did not improve from 0.07491\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0974 - accuracy: 0.9648 - val_loss: 0.0777 - val_accuracy: 0.9845\n",
      "Epoch 361/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0998 - accuracy: 0.9700\n",
      "Epoch 00361: val_loss improved from 0.07491 to 0.07293, saving model to ./model\\361-0.0729.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0936 - accuracy: 0.9709 - val_loss: 0.0729 - val_accuracy: 0.9752\n",
      "Epoch 362/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1026 - accuracy: 0.9640\n",
      "Epoch 00362: val_loss did not improve from 0.07293\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0949 - accuracy: 0.9663 - val_loss: 0.0731 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0969 - accuracy: 0.9600\n",
      "Epoch 00363: val_loss did not improve from 0.07293\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0958 - accuracy: 0.9648 - val_loss: 0.0745 - val_accuracy: 0.9783\n",
      "Epoch 364/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0810 - accuracy: 0.9780\n",
      "Epoch 00364: val_loss did not improve from 0.07293\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0921 - accuracy: 0.9709 - val_loss: 0.0839 - val_accuracy: 0.9814\n",
      "Epoch 365/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0951 - accuracy: 0.9660\n",
      "Epoch 00365: val_loss improved from 0.07293 to 0.07274, saving model to ./model\\365-0.0727.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0979 - accuracy: 0.9663 - val_loss: 0.0727 - val_accuracy: 0.9752\n",
      "Epoch 366/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0887 - accuracy: 0.9760\n",
      "Epoch 00366: val_loss did not improve from 0.07274\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0914 - accuracy: 0.9709 - val_loss: 0.0744 - val_accuracy: 0.9752\n",
      "Epoch 367/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1021 - accuracy: 0.9580\n",
      "Epoch 00367: val_loss improved from 0.07274 to 0.07140, saving model to ./model\\367-0.0714.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1008 - accuracy: 0.9587 - val_loss: 0.0714 - val_accuracy: 0.9752\n",
      "Epoch 368/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1032 - accuracy: 0.9680\n",
      "Epoch 00368: val_loss did not improve from 0.07140\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0943 - accuracy: 0.9724 - val_loss: 0.0819 - val_accuracy: 0.9814\n",
      "Epoch 369/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0979 - accuracy: 0.9700\n",
      "Epoch 00369: val_loss did not improve from 0.07140\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0959 - accuracy: 0.9694 - val_loss: 0.0738 - val_accuracy: 0.9845\n",
      "Epoch 370/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0978 - accuracy: 0.9680\n",
      "Epoch 00370: val_loss did not improve from 0.07140\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0903 - accuracy: 0.9724 - val_loss: 0.0716 - val_accuracy: 0.9752\n",
      "Epoch 371/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0896 - accuracy: 0.9640\n",
      "Epoch 00371: val_loss improved from 0.07140 to 0.07120, saving model to ./model\\371-0.0712.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0974 - accuracy: 0.9632 - val_loss: 0.0712 - val_accuracy: 0.9752\n",
      "Epoch 372/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0743 - accuracy: 0.9780\n",
      "Epoch 00372: val_loss did not improve from 0.07120\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0909 - accuracy: 0.9709 - val_loss: 0.0841 - val_accuracy: 0.9814\n",
      "Epoch 373/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0946 - accuracy: 0.9660\n",
      "Epoch 00373: val_loss did not improve from 0.07120\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0998 - accuracy: 0.9663 - val_loss: 0.0732 - val_accuracy: 0.9752\n",
      "Epoch 374/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0968 - accuracy: 0.9700\n",
      "Epoch 00374: val_loss did not improve from 0.07120\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0927 - accuracy: 0.9694 - val_loss: 0.0760 - val_accuracy: 0.9752\n",
      "Epoch 375/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1046 - accuracy: 0.9520\n",
      "Epoch 00375: val_loss did not improve from 0.07120\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1017 - accuracy: 0.9556 - val_loss: 0.0725 - val_accuracy: 0.9720\n",
      "Epoch 376/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1044 - accuracy: 0.9620\n",
      "Epoch 00376: val_loss did not improve from 0.07120\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 0.9648 - val_loss: 0.0762 - val_accuracy: 0.9845\n",
      "Epoch 377/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0910 - accuracy: 0.9700\n",
      "Epoch 00377: val_loss did not improve from 0.07120\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0926 - accuracy: 0.9724 - val_loss: 0.0759 - val_accuracy: 0.9845\n",
      "Epoch 378/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0879 - accuracy: 0.9740\n",
      "Epoch 00378: val_loss improved from 0.07120 to 0.07117, saving model to ./model\\378-0.0712.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0918 - accuracy: 0.9709 - val_loss: 0.0712 - val_accuracy: 0.9752\n",
      "Epoch 379/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0980 - accuracy: 0.9660\n",
      "Epoch 00379: val_loss improved from 0.07117 to 0.07091, saving model to ./model\\379-0.0709.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0905 - accuracy: 0.9709 - val_loss: 0.0709 - val_accuracy: 0.9752\n",
      "Epoch 380/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0862 - accuracy: 0.9700\n",
      "Epoch 00380: val_loss did not improve from 0.07091\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0901 - accuracy: 0.9709 - val_loss: 0.0726 - val_accuracy: 0.9783\n",
      "Epoch 381/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0937 - accuracy: 0.9700\n",
      "Epoch 00381: val_loss did not improve from 0.07091\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0905 - accuracy: 0.9709 - val_loss: 0.0765 - val_accuracy: 0.9814\n",
      "Epoch 382/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0895 - accuracy: 0.9700\n",
      "Epoch 00382: val_loss improved from 0.07091 to 0.07054, saving model to ./model\\382-0.0705.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0900 - accuracy: 0.9694 - val_loss: 0.0705 - val_accuracy: 0.9752\n",
      "Epoch 383/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0854 - accuracy: 0.9740\n",
      "Epoch 00383: val_loss improved from 0.07054 to 0.06976, saving model to ./model\\383-0.0698.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0900 - accuracy: 0.9724 - val_loss: 0.0698 - val_accuracy: 0.9752\n",
      "Epoch 384/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0857 - accuracy: 0.9760\n",
      "Epoch 00384: val_loss did not improve from 0.06976\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9709 - val_loss: 0.0714 - val_accuracy: 0.9783\n",
      "Epoch 385/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0872 - accuracy: 0.9740\n",
      "Epoch 00385: val_loss did not improve from 0.06976\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9724 - val_loss: 0.0715 - val_accuracy: 0.9814\n",
      "Epoch 386/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0991 - accuracy: 0.9680\n",
      "Epoch 00386: val_loss improved from 0.06976 to 0.06965, saving model to ./model\\386-0.0697.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0883 - accuracy: 0.9724 - val_loss: 0.0697 - val_accuracy: 0.9752\n",
      "Epoch 387/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0906 - accuracy: 0.9740\n",
      "Epoch 00387: val_loss improved from 0.06965 to 0.06893, saving model to ./model\\387-0.0689.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0889 - accuracy: 0.9724 - val_loss: 0.0689 - val_accuracy: 0.9752\n",
      "Epoch 388/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0948 - accuracy: 0.9720\n",
      "Epoch 00388: val_loss did not improve from 0.06893\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0900 - accuracy: 0.9724 - val_loss: 0.0690 - val_accuracy: 0.9752\n",
      "Epoch 389/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0823 - accuracy: 0.9720\n",
      "Epoch 00389: val_loss did not improve from 0.06893\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0892 - accuracy: 0.9724 - val_loss: 0.0703 - val_accuracy: 0.9752\n",
      "Epoch 390/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0801 - accuracy: 0.9740\n",
      "Epoch 00390: val_loss did not improve from 0.06893\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9709 - val_loss: 0.0744 - val_accuracy: 0.9845\n",
      "Epoch 391/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0881 - accuracy: 0.9680\n",
      "Epoch 00391: val_loss did not improve from 0.06893\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9694 - val_loss: 0.0695 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0842 - accuracy: 0.9720\n",
      "Epoch 00392: val_loss did not improve from 0.06893\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9709 - val_loss: 0.0693 - val_accuracy: 0.9752\n",
      "Epoch 393/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0814 - accuracy: 0.9740\n",
      "Epoch 00393: val_loss did not improve from 0.06893\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9709 - val_loss: 0.0715 - val_accuracy: 0.9845\n",
      "Epoch 394/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0911 - accuracy: 0.9680\n",
      "Epoch 00394: val_loss did not improve from 0.06893\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9694 - val_loss: 0.0697 - val_accuracy: 0.9845\n",
      "Epoch 395/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0848 - accuracy: 0.9700\n",
      "Epoch 00395: val_loss improved from 0.06893 to 0.06690, saving model to ./model\\395-0.0669.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0855 - accuracy: 0.9709 - val_loss: 0.0669 - val_accuracy: 0.9752\n",
      "Epoch 396/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0839 - accuracy: 0.9760\n",
      "Epoch 00396: val_loss did not improve from 0.06690\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0869 - accuracy: 0.9709 - val_loss: 0.0678 - val_accuracy: 0.9752\n",
      "Epoch 397/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0807 - accuracy: 0.9700\n",
      "Epoch 00397: val_loss did not improve from 0.06690\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9709 - val_loss: 0.0747 - val_accuracy: 0.9814\n",
      "Epoch 398/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0866 - accuracy: 0.9700\n",
      "Epoch 00398: val_loss did not improve from 0.06690\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0876 - accuracy: 0.9678 - val_loss: 0.0678 - val_accuracy: 0.9752\n",
      "Epoch 399/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0774 - accuracy: 0.9720\n",
      "Epoch 00399: val_loss did not improve from 0.06690\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0863 - accuracy: 0.9694 - val_loss: 0.0672 - val_accuracy: 0.9720\n",
      "Epoch 400/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0888 - accuracy: 0.9640\n",
      "Epoch 00400: val_loss did not improve from 0.06690\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9648 - val_loss: 0.0682 - val_accuracy: 0.9783\n",
      "Epoch 401/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0762 - accuracy: 0.9720\n",
      "Epoch 00401: val_loss did not improve from 0.06690\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0807 - accuracy: 0.9709 - val_loss: 0.0832 - val_accuracy: 0.9752\n",
      "Epoch 402/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1033 - accuracy: 0.9620\n",
      "Epoch 00402: val_loss improved from 0.06690 to 0.06647, saving model to ./model\\402-0.0665.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0903 - accuracy: 0.9678 - val_loss: 0.0665 - val_accuracy: 0.9814\n",
      "Epoch 403/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0831 - accuracy: 0.9700\n",
      "Epoch 00403: val_loss improved from 0.06647 to 0.06455, saving model to ./model\\403-0.0645.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0811 - accuracy: 0.9709 - val_loss: 0.0645 - val_accuracy: 0.9752\n",
      "Epoch 404/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0858 - accuracy: 0.9740\n",
      "Epoch 00404: val_loss did not improve from 0.06455\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0841 - accuracy: 0.9709 - val_loss: 0.0646 - val_accuracy: 0.9845\n",
      "Epoch 405/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0767 - accuracy: 0.9680\n",
      "Epoch 00405: val_loss did not improve from 0.06455\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0787 - accuracy: 0.9709 - val_loss: 0.0700 - val_accuracy: 0.9845\n",
      "Epoch 406/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0849 - accuracy: 0.9720\n",
      "Epoch 00406: val_loss improved from 0.06455 to 0.06219, saving model to ./model\\406-0.0622.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0816 - accuracy: 0.9724 - val_loss: 0.0622 - val_accuracy: 0.9814\n",
      "Epoch 407/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0765 - accuracy: 0.9660\n",
      "Epoch 00407: val_loss improved from 0.06219 to 0.06124, saving model to ./model\\407-0.0612.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0802 - accuracy: 0.9694 - val_loss: 0.0612 - val_accuracy: 0.9752\n",
      "Epoch 408/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0842 - accuracy: 0.9740\n",
      "Epoch 00408: val_loss did not improve from 0.06124\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9724 - val_loss: 0.0634 - val_accuracy: 0.9845\n",
      "Epoch 409/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0771 - accuracy: 0.9760\n",
      "Epoch 00409: val_loss did not improve from 0.06124\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9694 - val_loss: 0.0661 - val_accuracy: 0.9876\n",
      "Epoch 410/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0763 - accuracy: 0.9740\n",
      "Epoch 00410: val_loss improved from 0.06124 to 0.05978, saving model to ./model\\410-0.0598.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0798 - accuracy: 0.9709 - val_loss: 0.0598 - val_accuracy: 0.9783\n",
      "Epoch 411/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0870 - accuracy: 0.9700\n",
      "Epoch 00411: val_loss improved from 0.05978 to 0.05966, saving model to ./model\\411-0.0597.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0806 - accuracy: 0.9709 - val_loss: 0.0597 - val_accuracy: 0.9783\n",
      "Epoch 412/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0652 - accuracy: 0.9800\n",
      "Epoch 00412: val_loss did not improve from 0.05966\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0781 - accuracy: 0.9724 - val_loss: 0.0709 - val_accuracy: 0.9845\n",
      "Epoch 413/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0875 - accuracy: 0.9640\n",
      "Epoch 00413: val_loss did not improve from 0.05966\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0878 - accuracy: 0.9648 - val_loss: 0.0600 - val_accuracy: 0.9845\n",
      "Epoch 414/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0711 - accuracy: 0.9720\n",
      "Epoch 00414: val_loss did not improve from 0.05966\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0808 - accuracy: 0.9678 - val_loss: 0.0660 - val_accuracy: 0.9720\n",
      "Epoch 415/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1071 - accuracy: 0.9600\n",
      "Epoch 00415: val_loss improved from 0.05966 to 0.05910, saving model to ./model\\415-0.0591.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0940 - accuracy: 0.9632 - val_loss: 0.0591 - val_accuracy: 0.9814\n",
      "Epoch 416/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0749 - accuracy: 0.9760\n",
      "Epoch 00416: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0786 - accuracy: 0.9694 - val_loss: 0.0718 - val_accuracy: 0.9783\n",
      "Epoch 417/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0836 - accuracy: 0.9660\n",
      "Epoch 00417: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0806 - accuracy: 0.9709 - val_loss: 0.0611 - val_accuracy: 0.9845\n",
      "Epoch 418/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0746 - accuracy: 0.9740\n",
      "Epoch 00418: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0747 - accuracy: 0.9724 - val_loss: 0.0616 - val_accuracy: 0.9752\n",
      "Epoch 419/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0854 - accuracy: 0.9700\n",
      "Epoch 00419: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9663 - val_loss: 0.0595 - val_accuracy: 0.9783\n",
      "Epoch 420/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0792 - accuracy: 0.9740\n",
      "Epoch 00420: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0755 - accuracy: 0.9724 - val_loss: 0.0786 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0850 - accuracy: 0.9680\n",
      "Epoch 00421: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9678 - val_loss: 0.0615 - val_accuracy: 0.9845\n",
      "Epoch 422/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0672 - accuracy: 0.9760\n",
      "Epoch 00422: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0802 - accuracy: 0.9663 - val_loss: 0.0643 - val_accuracy: 0.9752\n",
      "Epoch 423/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0697 - accuracy: 0.9700\n",
      "Epoch 00423: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.9632 - val_loss: 0.0626 - val_accuracy: 0.9845\n",
      "Epoch 424/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0781 - accuracy: 0.9680\n",
      "Epoch 00424: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0814 - accuracy: 0.9694 - val_loss: 0.0819 - val_accuracy: 0.9689\n",
      "Epoch 425/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0969 - accuracy: 0.9600\n",
      "Epoch 00425: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0855 - accuracy: 0.9663 - val_loss: 0.0599 - val_accuracy: 0.9752\n",
      "Epoch 426/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0809 - accuracy: 0.9700\n",
      "Epoch 00426: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9678 - val_loss: 0.0619 - val_accuracy: 0.9752\n",
      "Epoch 427/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0827 - accuracy: 0.9660\n",
      "Epoch 00427: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0840 - accuracy: 0.9694 - val_loss: 0.0641 - val_accuracy: 0.9845\n",
      "Epoch 428/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0818 - accuracy: 0.9740\n",
      "Epoch 00428: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0797 - accuracy: 0.9724 - val_loss: 0.0742 - val_accuracy: 0.9752\n",
      "Epoch 429/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0766 - accuracy: 0.9760\n",
      "Epoch 00429: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0807 - accuracy: 0.9709 - val_loss: 0.0591 - val_accuracy: 0.9814\n",
      "Epoch 430/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0817 - accuracy: 0.9700\n",
      "Epoch 00430: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0767 - accuracy: 0.9709 - val_loss: 0.0595 - val_accuracy: 0.9752\n",
      "Epoch 431/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0660 - accuracy: 0.9760\n",
      "Epoch 00431: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0780 - accuracy: 0.9724 - val_loss: 0.0608 - val_accuracy: 0.9845\n",
      "Epoch 432/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0740 - accuracy: 0.9760\n",
      "Epoch 00432: val_loss did not improve from 0.05910\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 0.9724 - val_loss: 0.0699 - val_accuracy: 0.9845\n",
      "Epoch 433/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0721 - accuracy: 0.9760\n",
      "Epoch 00433: val_loss improved from 0.05910 to 0.05844, saving model to ./model\\433-0.0584.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0779 - accuracy: 0.9709 - val_loss: 0.0584 - val_accuracy: 0.9845\n",
      "Epoch 434/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0858 - accuracy: 0.9660\n",
      "Epoch 00434: val_loss improved from 0.05844 to 0.05789, saving model to ./model\\434-0.0579.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0747 - accuracy: 0.9709 - val_loss: 0.0579 - val_accuracy: 0.9783\n",
      "Epoch 435/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0840 - accuracy: 0.9740\n",
      "Epoch 00435: val_loss improved from 0.05789 to 0.05691, saving model to ./model\\435-0.0569.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0828 - accuracy: 0.9709 - val_loss: 0.0569 - val_accuracy: 0.9845\n",
      "Epoch 436/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0744 - accuracy: 0.9760\n",
      "Epoch 00436: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9724 - val_loss: 0.0684 - val_accuracy: 0.9845\n",
      "Epoch 437/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0764 - accuracy: 0.9660\n",
      "Epoch 00437: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 0.9694 - val_loss: 0.0626 - val_accuracy: 0.9845\n",
      "Epoch 438/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0748 - accuracy: 0.9760\n",
      "Epoch 00438: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9740 - val_loss: 0.0578 - val_accuracy: 0.9845\n",
      "Epoch 439/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0774 - accuracy: 0.9720\n",
      "Epoch 00439: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0743 - accuracy: 0.9724 - val_loss: 0.0581 - val_accuracy: 0.9845\n",
      "Epoch 440/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0749 - accuracy: 0.9680\n",
      "Epoch 00440: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0731 - accuracy: 0.9709 - val_loss: 0.0600 - val_accuracy: 0.9845\n",
      "Epoch 441/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0575 - accuracy: 0.9740\n",
      "Epoch 00441: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0719 - accuracy: 0.9709 - val_loss: 0.0627 - val_accuracy: 0.9876\n",
      "Epoch 442/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0783 - accuracy: 0.9680\n",
      "Epoch 00442: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0722 - accuracy: 0.9709 - val_loss: 0.0596 - val_accuracy: 0.9845\n",
      "Epoch 443/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0849 - accuracy: 0.9620\n",
      "Epoch 00443: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9709 - val_loss: 0.0576 - val_accuracy: 0.9845\n",
      "Epoch 444/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0820 - accuracy: 0.9700\n",
      "Epoch 00444: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0737 - accuracy: 0.9740 - val_loss: 0.0586 - val_accuracy: 0.9845\n",
      "Epoch 445/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0681 - accuracy: 0.9700\n",
      "Epoch 00445: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0724 - accuracy: 0.9724 - val_loss: 0.0630 - val_accuracy: 0.9876\n",
      "Epoch 446/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0646 - accuracy: 0.9780\n",
      "Epoch 00446: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0725 - accuracy: 0.9740 - val_loss: 0.0617 - val_accuracy: 0.9876\n",
      "Epoch 447/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0724 - accuracy: 0.9760\n",
      "Epoch 00447: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0722 - accuracy: 0.9724 - val_loss: 0.0595 - val_accuracy: 0.9876\n",
      "Epoch 448/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0803 - accuracy: 0.9680\n",
      "Epoch 00448: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.9724 - val_loss: 0.0584 - val_accuracy: 0.9845\n",
      "Epoch 449/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0739 - accuracy: 0.9720\n",
      "Epoch 00449: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9740 - val_loss: 0.0581 - val_accuracy: 0.9845\n",
      "Epoch 450/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0598 - accuracy: 0.9760\n",
      "Epoch 00450: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9724 - val_loss: 0.0593 - val_accuracy: 0.9876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0638 - accuracy: 0.9740\n",
      "Epoch 00451: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0704 - accuracy: 0.9740 - val_loss: 0.0595 - val_accuracy: 0.9876\n",
      "Epoch 452/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0633 - accuracy: 0.9800\n",
      "Epoch 00452: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 0.9724 - val_loss: 0.0585 - val_accuracy: 0.9876\n",
      "Epoch 453/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0762 - accuracy: 0.9680\n",
      "Epoch 00453: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0703 - accuracy: 0.9724 - val_loss: 0.0578 - val_accuracy: 0.9845\n",
      "Epoch 454/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0686 - accuracy: 0.9700\n",
      "Epoch 00454: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0716 - accuracy: 0.9709 - val_loss: 0.0582 - val_accuracy: 0.9845\n",
      "Epoch 455/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0608 - accuracy: 0.9780\n",
      "Epoch 00455: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0694 - accuracy: 0.9724 - val_loss: 0.0671 - val_accuracy: 0.9845\n",
      "Epoch 456/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0816 - accuracy: 0.9680\n",
      "Epoch 00456: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0731 - accuracy: 0.9740 - val_loss: 0.0663 - val_accuracy: 0.9845\n",
      "Epoch 457/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0794 - accuracy: 0.9720\n",
      "Epoch 00457: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0716 - accuracy: 0.9724 - val_loss: 0.0582 - val_accuracy: 0.9845\n",
      "Epoch 458/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0684 - accuracy: 0.9740\n",
      "Epoch 00458: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0713 - accuracy: 0.9724 - val_loss: 0.0579 - val_accuracy: 0.9845\n",
      "Epoch 459/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0696 - accuracy: 0.9740\n",
      "Epoch 00459: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0716 - accuracy: 0.9740 - val_loss: 0.0618 - val_accuracy: 0.9876\n",
      "Epoch 460/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0717 - accuracy: 0.9740\n",
      "Epoch 00460: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0699 - accuracy: 0.9755 - val_loss: 0.0587 - val_accuracy: 0.9876\n",
      "Epoch 461/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0700 - accuracy: 0.9780\n",
      "Epoch 00461: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 0.9724 - val_loss: 0.0570 - val_accuracy: 0.9845\n",
      "Epoch 462/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0679 - accuracy: 0.9760\n",
      "Epoch 00462: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 0.9740 - val_loss: 0.0579 - val_accuracy: 0.9876\n",
      "Epoch 463/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0610 - accuracy: 0.9780\n",
      "Epoch 00463: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9709 - val_loss: 0.0598 - val_accuracy: 0.9876\n",
      "Epoch 464/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0783 - accuracy: 0.9660\n",
      "Epoch 00464: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0685 - accuracy: 0.9709 - val_loss: 0.0585 - val_accuracy: 0.9876\n",
      "Epoch 465/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0720 - accuracy: 0.9700\n",
      "Epoch 00465: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0691 - accuracy: 0.9724 - val_loss: 0.0573 - val_accuracy: 0.9845\n",
      "Epoch 466/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0717 - accuracy: 0.9700\n",
      "Epoch 00466: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0692 - accuracy: 0.9709 - val_loss: 0.0608 - val_accuracy: 0.9876\n",
      "Epoch 467/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0713 - accuracy: 0.9680\n",
      "Epoch 00467: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0701 - accuracy: 0.9709 - val_loss: 0.0599 - val_accuracy: 0.9876\n",
      "Epoch 468/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0528 - accuracy: 0.9800\n",
      "Epoch 00468: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9694 - val_loss: 0.0576 - val_accuracy: 0.9876\n",
      "Epoch 469/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0594 - accuracy: 0.9720\n",
      "Epoch 00469: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0675 - accuracy: 0.9724 - val_loss: 0.0688 - val_accuracy: 0.9845\n",
      "Epoch 470/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0809 - accuracy: 0.9680\n",
      "Epoch 00470: val_loss did not improve from 0.05691\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0729 - accuracy: 0.9694 - val_loss: 0.0609 - val_accuracy: 0.9876\n",
      "Epoch 471/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0711 - accuracy: 0.9700\n",
      "Epoch 00471: val_loss improved from 0.05691 to 0.05583, saving model to ./model\\471-0.0558.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0672 - accuracy: 0.9709 - val_loss: 0.0558 - val_accuracy: 0.9845\n",
      "Epoch 472/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0627 - accuracy: 0.9740\n",
      "Epoch 00472: val_loss did not improve from 0.05583\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.9740 - val_loss: 0.0562 - val_accuracy: 0.9876\n",
      "Epoch 473/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0616 - accuracy: 0.9720\n",
      "Epoch 00473: val_loss did not improve from 0.05583\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0675 - accuracy: 0.9709 - val_loss: 0.0650 - val_accuracy: 0.9876\n",
      "Epoch 474/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0554 - accuracy: 0.9800\n",
      "Epoch 00474: val_loss did not improve from 0.05583\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9740 - val_loss: 0.0559 - val_accuracy: 0.9876\n",
      "Epoch 475/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0661 - accuracy: 0.9720\n",
      "Epoch 00475: val_loss did not improve from 0.05583\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0680 - accuracy: 0.9724 - val_loss: 0.0571 - val_accuracy: 0.9752\n",
      "Epoch 476/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0828 - accuracy: 0.9700\n",
      "Epoch 00476: val_loss improved from 0.05583 to 0.05557, saving model to ./model\\476-0.0556.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0753 - accuracy: 0.9724 - val_loss: 0.0556 - val_accuracy: 0.9876\n",
      "Epoch 477/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0617 - accuracy: 0.9740\n",
      "Epoch 00477: val_loss did not improve from 0.05557\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9724 - val_loss: 0.0671 - val_accuracy: 0.9814\n",
      "Epoch 478/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0691 - accuracy: 0.9740\n",
      "Epoch 00478: val_loss did not improve from 0.05557\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.9755 - val_loss: 0.0583 - val_accuracy: 0.9876\n",
      "Epoch 479/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0692 - accuracy: 0.9700\n",
      "Epoch 00479: val_loss improved from 0.05557 to 0.05435, saving model to ./model\\479-0.0543.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0662 - accuracy: 0.9709 - val_loss: 0.0543 - val_accuracy: 0.9845\n",
      "Epoch 480/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0763 - accuracy: 0.9760\n",
      "Epoch 00480: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0722 - accuracy: 0.9740 - val_loss: 0.0544 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0760 - accuracy: 0.9740\n",
      "Epoch 00481: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0682 - accuracy: 0.9740 - val_loss: 0.0620 - val_accuracy: 0.9876\n",
      "Epoch 482/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0609 - accuracy: 0.9780\n",
      "Epoch 00482: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0703 - accuracy: 0.9709 - val_loss: 0.0603 - val_accuracy: 0.9876\n",
      "Epoch 483/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0610 - accuracy: 0.9780\n",
      "Epoch 00483: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0685 - accuracy: 0.9770 - val_loss: 0.0551 - val_accuracy: 0.9814\n",
      "Epoch 484/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0694 - accuracy: 0.9720\n",
      "Epoch 00484: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0699 - accuracy: 0.9740 - val_loss: 0.0558 - val_accuracy: 0.9876\n",
      "Epoch 485/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0665 - accuracy: 0.9720\n",
      "Epoch 00485: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0648 - accuracy: 0.9724 - val_loss: 0.0665 - val_accuracy: 0.9845\n",
      "Epoch 486/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0659 - accuracy: 0.9760\n",
      "Epoch 00486: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0695 - accuracy: 0.9755 - val_loss: 0.0618 - val_accuracy: 0.9876\n",
      "Epoch 487/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0736 - accuracy: 0.9720\n",
      "Epoch 00487: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9755 - val_loss: 0.0556 - val_accuracy: 0.9876\n",
      "Epoch 488/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0764 - accuracy: 0.9680\n",
      "Epoch 00488: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0655 - accuracy: 0.9724 - val_loss: 0.0555 - val_accuracy: 0.9876\n",
      "Epoch 489/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0518 - accuracy: 0.9760\n",
      "Epoch 00489: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9724 - val_loss: 0.0573 - val_accuracy: 0.9876\n",
      "Epoch 490/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0629 - accuracy: 0.9680\n",
      "Epoch 00490: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0648 - accuracy: 0.9724 - val_loss: 0.0590 - val_accuracy: 0.9876\n",
      "Epoch 491/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0667 - accuracy: 0.9800\n",
      "Epoch 00491: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 0.9755 - val_loss: 0.0554 - val_accuracy: 0.9876\n",
      "Epoch 492/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0703 - accuracy: 0.9740\n",
      "Epoch 00492: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0677 - accuracy: 0.9770 - val_loss: 0.0552 - val_accuracy: 0.9845\n",
      "Epoch 493/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0545 - accuracy: 0.9840\n",
      "Epoch 00493: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0668 - accuracy: 0.9755 - val_loss: 0.0654 - val_accuracy: 0.9876\n",
      "Epoch 494/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0634 - accuracy: 0.9780\n",
      "Epoch 00494: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0695 - accuracy: 0.9740 - val_loss: 0.0712 - val_accuracy: 0.9814\n",
      "Epoch 495/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0720 - accuracy: 0.9700\n",
      "Epoch 00495: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0709 - accuracy: 0.9724 - val_loss: 0.0556 - val_accuracy: 0.9845\n",
      "Epoch 496/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0674 - accuracy: 0.9720\n",
      "Epoch 00496: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9755 - val_loss: 0.0564 - val_accuracy: 0.9814\n",
      "Epoch 497/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0690 - accuracy: 0.9820\n",
      "Epoch 00497: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0699 - accuracy: 0.9755 - val_loss: 0.0592 - val_accuracy: 0.9876\n",
      "Epoch 498/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0555 - accuracy: 0.9760\n",
      "Epoch 00498: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0666 - accuracy: 0.9724 - val_loss: 0.0668 - val_accuracy: 0.9876\n",
      "Epoch 499/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0713 - accuracy: 0.9760\n",
      "Epoch 00499: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0692 - accuracy: 0.9740 - val_loss: 0.0555 - val_accuracy: 0.9876\n",
      "Epoch 500/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0694 - accuracy: 0.9740\n",
      "Epoch 00500: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0648 - accuracy: 0.9740 - val_loss: 0.0551 - val_accuracy: 0.9814\n",
      "Epoch 501/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0802 - accuracy: 0.9700\n",
      "Epoch 00501: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0679 - accuracy: 0.9755 - val_loss: 0.0566 - val_accuracy: 0.9876\n",
      "Epoch 502/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0708 - accuracy: 0.9660\n",
      "Epoch 00502: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0638 - accuracy: 0.9709 - val_loss: 0.0626 - val_accuracy: 0.9845\n",
      "Epoch 503/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0739 - accuracy: 0.9740\n",
      "Epoch 00503: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9770 - val_loss: 0.0581 - val_accuracy: 0.9876\n",
      "Epoch 504/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0742 - accuracy: 0.9740\n",
      "Epoch 00504: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0645 - accuracy: 0.9770 - val_loss: 0.0559 - val_accuracy: 0.9876\n",
      "Epoch 505/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0446 - accuracy: 0.9840\n",
      "Epoch 00505: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0664 - accuracy: 0.9724 - val_loss: 0.0600 - val_accuracy: 0.9876\n",
      "Epoch 506/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0745 - accuracy: 0.9720\n",
      "Epoch 00506: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0659 - accuracy: 0.9770 - val_loss: 0.0669 - val_accuracy: 0.9845\n",
      "Epoch 507/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0784 - accuracy: 0.9680\n",
      "Epoch 00507: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9678 - val_loss: 0.0551 - val_accuracy: 0.9876\n",
      "Epoch 508/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0738 - accuracy: 0.9700\n",
      "Epoch 00508: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0652 - accuracy: 0.9740 - val_loss: 0.0556 - val_accuracy: 0.9814\n",
      "Epoch 509/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0605 - accuracy: 0.9780\n",
      "Epoch 00509: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9755 - val_loss: 0.0576 - val_accuracy: 0.9876\n",
      "Epoch 510/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0667 - accuracy: 0.9720\n",
      "Epoch 00510: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0662 - accuracy: 0.9740 - val_loss: 0.0640 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 511/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0629 - accuracy: 0.9820\n",
      "Epoch 00511: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0685 - accuracy: 0.9740 - val_loss: 0.0562 - val_accuracy: 0.9876\n",
      "Epoch 512/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0715 - accuracy: 0.9700\n",
      "Epoch 00512: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0637 - accuracy: 0.9740 - val_loss: 0.0561 - val_accuracy: 0.9845\n",
      "Epoch 513/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0686 - accuracy: 0.9740\n",
      "Epoch 00513: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0666 - accuracy: 0.9740 - val_loss: 0.0586 - val_accuracy: 0.9876\n",
      "Epoch 514/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0590 - accuracy: 0.9740\n",
      "Epoch 00514: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9740 - val_loss: 0.0686 - val_accuracy: 0.9814\n",
      "Epoch 515/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0702 - accuracy: 0.9720\n",
      "Epoch 00515: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0664 - accuracy: 0.9740 - val_loss: 0.0563 - val_accuracy: 0.9876\n",
      "Epoch 516/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0653 - accuracy: 0.9760\n",
      "Epoch 00516: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0648 - accuracy: 0.9755 - val_loss: 0.0549 - val_accuracy: 0.9876\n",
      "Epoch 517/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0717 - accuracy: 0.9740\n",
      "Epoch 00517: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0654 - accuracy: 0.9755 - val_loss: 0.0582 - val_accuracy: 0.9876\n",
      "Epoch 518/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0669 - accuracy: 0.9720\n",
      "Epoch 00518: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0612 - accuracy: 0.9740 - val_loss: 0.0641 - val_accuracy: 0.9876\n",
      "Epoch 519/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0685 - accuracy: 0.9720\n",
      "Epoch 00519: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0654 - accuracy: 0.9724 - val_loss: 0.0576 - val_accuracy: 0.9876\n",
      "Epoch 520/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0458 - accuracy: 0.9800\n",
      "Epoch 00520: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0614 - accuracy: 0.9755 - val_loss: 0.0546 - val_accuracy: 0.9876\n",
      "Epoch 521/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0677 - accuracy: 0.9740\n",
      "Epoch 00521: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0640 - accuracy: 0.9740 - val_loss: 0.0547 - val_accuracy: 0.9876\n",
      "Epoch 522/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0659 - accuracy: 0.9740\n",
      "Epoch 00522: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0620 - accuracy: 0.9770 - val_loss: 0.0617 - val_accuracy: 0.9876\n",
      "Epoch 523/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0711 - accuracy: 0.9760\n",
      "Epoch 00523: val_loss did not improve from 0.05435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0631 - accuracy: 0.9770 - val_loss: 0.0583 - val_accuracy: 0.9876\n",
      "Epoch 524/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0697 - accuracy: 0.9720\n",
      "Epoch 00524: val_loss improved from 0.05435 to 0.05413, saving model to ./model\\524-0.0541.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0602 - accuracy: 0.9770 - val_loss: 0.0541 - val_accuracy: 0.9876\n",
      "Epoch 525/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0660 - accuracy: 0.9740\n",
      "Epoch 00525: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 0.9770 - val_loss: 0.0542 - val_accuracy: 0.9876\n",
      "Epoch 526/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0662 - accuracy: 0.9760\n",
      "Epoch 00526: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0637 - accuracy: 0.9755 - val_loss: 0.0587 - val_accuracy: 0.9876\n",
      "Epoch 527/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0692 - accuracy: 0.9700\n",
      "Epoch 00527: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0605 - accuracy: 0.9770 - val_loss: 0.0614 - val_accuracy: 0.9845\n",
      "Epoch 528/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0652 - accuracy: 0.9760\n",
      "Epoch 00528: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0618 - accuracy: 0.9770 - val_loss: 0.0577 - val_accuracy: 0.9876\n",
      "Epoch 529/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0640 - accuracy: 0.9720\n",
      "Epoch 00529: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0602 - accuracy: 0.9755 - val_loss: 0.0556 - val_accuracy: 0.9876\n",
      "Epoch 530/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0555 - accuracy: 0.9780\n",
      "Epoch 00530: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0617 - accuracy: 0.9755 - val_loss: 0.0560 - val_accuracy: 0.9876\n",
      "Epoch 531/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0668 - accuracy: 0.9740\n",
      "Epoch 00531: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0612 - accuracy: 0.9755 - val_loss: 0.0568 - val_accuracy: 0.9876\n",
      "Epoch 532/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0579 - accuracy: 0.9760\n",
      "Epoch 00532: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 0.9740 - val_loss: 0.0561 - val_accuracy: 0.9876\n",
      "Epoch 533/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0445 - accuracy: 0.9840\n",
      "Epoch 00533: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0608 - accuracy: 0.9755 - val_loss: 0.0566 - val_accuracy: 0.9876\n",
      "Epoch 534/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0558 - accuracy: 0.9740\n",
      "Epoch 00534: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0599 - accuracy: 0.9770 - val_loss: 0.0606 - val_accuracy: 0.9845\n",
      "Epoch 535/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0534 - accuracy: 0.9800\n",
      "Epoch 00535: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.9770 - val_loss: 0.0617 - val_accuracy: 0.9845\n",
      "Epoch 536/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0669 - accuracy: 0.9720\n",
      "Epoch 00536: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0608 - accuracy: 0.9770 - val_loss: 0.0572 - val_accuracy: 0.9876\n",
      "Epoch 537/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0543 - accuracy: 0.9780\n",
      "Epoch 00537: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9755 - val_loss: 0.0545 - val_accuracy: 0.9876\n",
      "Epoch 538/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0619 - accuracy: 0.9820\n",
      "Epoch 00538: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0613 - accuracy: 0.9770 - val_loss: 0.0551 - val_accuracy: 0.9876\n",
      "Epoch 539/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0597 - accuracy: 0.9760\n",
      "Epoch 00539: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0587 - accuracy: 0.9770 - val_loss: 0.0586 - val_accuracy: 0.9876\n",
      "Epoch 540/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0577 - accuracy: 0.9800\n",
      "Epoch 00540: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0591 - accuracy: 0.9786 - val_loss: 0.0641 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0708 - accuracy: 0.9700\n",
      "Epoch 00541: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.9755 - val_loss: 0.0550 - val_accuracy: 0.9876\n",
      "Epoch 542/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0710 - accuracy: 0.9700\n",
      "Epoch 00542: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0588 - accuracy: 0.9755 - val_loss: 0.0552 - val_accuracy: 0.9845\n",
      "Epoch 543/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0638 - accuracy: 0.9780\n",
      "Epoch 00543: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 0.9770 - val_loss: 0.0549 - val_accuracy: 0.9876\n",
      "Epoch 544/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0596 - accuracy: 0.9780\n",
      "Epoch 00544: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 0.9786 - val_loss: 0.0701 - val_accuracy: 0.9845\n",
      "Epoch 545/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0680 - accuracy: 0.9700\n",
      "Epoch 00545: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0670 - accuracy: 0.9694 - val_loss: 0.0543 - val_accuracy: 0.9876\n",
      "Epoch 546/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0619 - accuracy: 0.9760\n",
      "Epoch 00546: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0639 - accuracy: 0.9724 - val_loss: 0.0570 - val_accuracy: 0.9752\n",
      "Epoch 547/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0754 - accuracy: 0.9740\n",
      "Epoch 00547: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0697 - accuracy: 0.9740 - val_loss: 0.0564 - val_accuracy: 0.9876\n",
      "Epoch 548/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0666 - accuracy: 0.9720\n",
      "Epoch 00548: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.9755 - val_loss: 0.0689 - val_accuracy: 0.9845\n",
      "Epoch 549/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0698 - accuracy: 0.9700\n",
      "Epoch 00549: val_loss did not improve from 0.05413\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0652 - accuracy: 0.9740 - val_loss: 0.0545 - val_accuracy: 0.9876\n",
      "Epoch 550/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0651 - accuracy: 0.9740\n",
      "Epoch 00550: val_loss improved from 0.05413 to 0.05244, saving model to ./model\\550-0.0524.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0593 - accuracy: 0.9755 - val_loss: 0.0524 - val_accuracy: 0.9876\n",
      "Epoch 551/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0461 - accuracy: 0.9820\n",
      "Epoch 00551: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0627 - accuracy: 0.9786 - val_loss: 0.0527 - val_accuracy: 0.9876\n",
      "Epoch 552/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0628 - accuracy: 0.9780\n",
      "Epoch 00552: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0590 - accuracy: 0.9770 - val_loss: 0.0614 - val_accuracy: 0.9845\n",
      "Epoch 553/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0665 - accuracy: 0.9680\n",
      "Epoch 00553: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0602 - accuracy: 0.9740 - val_loss: 0.0558 - val_accuracy: 0.9876\n",
      "Epoch 554/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0492 - accuracy: 0.9840\n",
      "Epoch 00554: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 0.9786 - val_loss: 0.0533 - val_accuracy: 0.9876\n",
      "Epoch 555/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0754 - accuracy: 0.9740\n",
      "Epoch 00555: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0625 - accuracy: 0.9786 - val_loss: 0.0530 - val_accuracy: 0.9876\n",
      "Epoch 556/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0668 - accuracy: 0.9780\n",
      "Epoch 00556: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0608 - accuracy: 0.9801 - val_loss: 0.0554 - val_accuracy: 0.9876\n",
      "Epoch 557/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0610 - accuracy: 0.9780\n",
      "Epoch 00557: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0577 - accuracy: 0.9770 - val_loss: 0.0603 - val_accuracy: 0.9845\n",
      "Epoch 558/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0615 - accuracy: 0.9740\n",
      "Epoch 00558: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0586 - accuracy: 0.9770 - val_loss: 0.0543 - val_accuracy: 0.9876\n",
      "Epoch 559/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0607 - accuracy: 0.9780\n",
      "Epoch 00559: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0565 - accuracy: 0.9786 - val_loss: 0.0533 - val_accuracy: 0.9876\n",
      "Epoch 560/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0661 - accuracy: 0.9800\n",
      "Epoch 00560: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0620 - accuracy: 0.9801 - val_loss: 0.0532 - val_accuracy: 0.9876\n",
      "Epoch 561/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0473 - accuracy: 0.9800\n",
      "Epoch 00561: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 0.9786 - val_loss: 0.0685 - val_accuracy: 0.9876\n",
      "Epoch 562/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0571 - accuracy: 0.9760\n",
      "Epoch 00562: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0634 - accuracy: 0.9740 - val_loss: 0.0647 - val_accuracy: 0.9845\n",
      "Epoch 563/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0522 - accuracy: 0.9800\n",
      "Epoch 00563: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0630 - accuracy: 0.9740 - val_loss: 0.0529 - val_accuracy: 0.9876\n",
      "Epoch 564/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0573 - accuracy: 0.9760\n",
      "Epoch 00564: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 0.9786 - val_loss: 0.0531 - val_accuracy: 0.9876\n",
      "Epoch 565/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0440 - accuracy: 0.9820\n",
      "Epoch 00565: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0555 - accuracy: 0.9786 - val_loss: 0.0598 - val_accuracy: 0.9845\n",
      "Epoch 566/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0588 - accuracy: 0.9780\n",
      "Epoch 00566: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0604 - accuracy: 0.9755 - val_loss: 0.0547 - val_accuracy: 0.9876\n",
      "Epoch 567/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0550 - accuracy: 0.9780\n",
      "Epoch 00567: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0551 - accuracy: 0.9786 - val_loss: 0.0541 - val_accuracy: 0.9845\n",
      "Epoch 568/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0649 - accuracy: 0.9760\n",
      "Epoch 00568: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0672 - accuracy: 0.9770 - val_loss: 0.0526 - val_accuracy: 0.9876\n",
      "Epoch 569/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0653 - accuracy: 0.9780\n",
      "Epoch 00569: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0614 - accuracy: 0.9786 - val_loss: 0.0611 - val_accuracy: 0.9845\n",
      "Epoch 570/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0566 - accuracy: 0.9760\n",
      "Epoch 00570: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0582 - accuracy: 0.9740 - val_loss: 0.0615 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0630 - accuracy: 0.9760\n",
      "Epoch 00571: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0569 - accuracy: 0.9740 - val_loss: 0.0533 - val_accuracy: 0.9876\n",
      "Epoch 572/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0493 - accuracy: 0.9780\n",
      "Epoch 00572: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0592 - accuracy: 0.9770 - val_loss: 0.0529 - val_accuracy: 0.9876\n",
      "Epoch 573/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0617 - accuracy: 0.9780\n",
      "Epoch 00573: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0566 - accuracy: 0.9786 - val_loss: 0.0639 - val_accuracy: 0.9814\n",
      "Epoch 574/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0527 - accuracy: 0.9760\n",
      "Epoch 00574: val_loss did not improve from 0.05244\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9740 - val_loss: 0.0561 - val_accuracy: 0.9876\n",
      "Epoch 575/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0453 - accuracy: 0.9840\n",
      "Epoch 00575: val_loss improved from 0.05244 to 0.05191, saving model to ./model\\575-0.0519.hdf5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0548 - accuracy: 0.9801 - val_loss: 0.0519 - val_accuracy: 0.9876\n",
      "Epoch 576/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0579 - accuracy: 0.9840\n",
      "Epoch 00576: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0622 - accuracy: 0.9770 - val_loss: 0.0525 - val_accuracy: 0.9876\n",
      "Epoch 577/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0544 - accuracy: 0.9780\n",
      "Epoch 00577: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0554 - accuracy: 0.9801 - val_loss: 0.0703 - val_accuracy: 0.9814\n",
      "Epoch 578/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0767 - accuracy: 0.9640\n",
      "Epoch 00578: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0656 - accuracy: 0.9709 - val_loss: 0.0555 - val_accuracy: 0.9876\n",
      "Epoch 579/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0470 - accuracy: 0.9840\n",
      "Epoch 00579: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0530 - val_accuracy: 0.9876\n",
      "Epoch 580/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0514 - accuracy: 0.9800\n",
      "Epoch 00580: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0549 - accuracy: 0.9801 - val_loss: 0.0572 - val_accuracy: 0.9845\n",
      "Epoch 581/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0543 - accuracy: 0.9840\n",
      "Epoch 00581: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0579 - accuracy: 0.9786 - val_loss: 0.0549 - val_accuracy: 0.9876\n",
      "Epoch 582/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0416 - accuracy: 0.9900\n",
      "Epoch 00582: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0541 - accuracy: 0.9847 - val_loss: 0.0535 - val_accuracy: 0.9876\n",
      "Epoch 583/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0689 - accuracy: 0.9780\n",
      "Epoch 00583: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0614 - accuracy: 0.9816 - val_loss: 0.0526 - val_accuracy: 0.9876\n",
      "Epoch 584/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0472 - accuracy: 0.9880\n",
      "Epoch 00584: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.0596 - val_accuracy: 0.9845\n",
      "Epoch 585/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0541 - accuracy: 0.9820\n",
      "Epoch 00585: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 0.9786 - val_loss: 0.0565 - val_accuracy: 0.9876\n",
      "Epoch 586/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0564 - accuracy: 0.9860\n",
      "Epoch 00586: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0556 - accuracy: 0.9832 - val_loss: 0.0523 - val_accuracy: 0.9876\n",
      "Epoch 587/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0588 - accuracy: 0.9840\n",
      "Epoch 00587: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0584 - accuracy: 0.9832 - val_loss: 0.0538 - val_accuracy: 0.9876\n",
      "Epoch 588/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0575 - accuracy: 0.9780\n",
      "Epoch 00588: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0545 - accuracy: 0.9816 - val_loss: 0.0659 - val_accuracy: 0.9876\n",
      "Epoch 589/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0588 - accuracy: 0.9840\n",
      "Epoch 00589: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9801 - val_loss: 0.0533 - val_accuracy: 0.9876\n",
      "Epoch 590/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0499 - accuracy: 0.9880\n",
      "Epoch 00590: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 0.9847 - val_loss: 0.0530 - val_accuracy: 0.9876\n",
      "Epoch 591/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0662 - accuracy: 0.9820\n",
      "Epoch 00591: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 0.9847 - val_loss: 0.0570 - val_accuracy: 0.9845\n",
      "Epoch 592/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0502 - accuracy: 0.9840\n",
      "Epoch 00592: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0554 - accuracy: 0.9862 - val_loss: 0.0636 - val_accuracy: 0.9876\n",
      "Epoch 593/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0595 - accuracy: 0.9780\n",
      "Epoch 00593: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0593 - accuracy: 0.9801 - val_loss: 0.0547 - val_accuracy: 0.9876\n",
      "Epoch 594/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0592 - accuracy: 0.9800\n",
      "Epoch 00594: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0535 - accuracy: 0.9832 - val_loss: 0.0525 - val_accuracy: 0.9876\n",
      "Epoch 595/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0544 - accuracy: 0.9800\n",
      "Epoch 00595: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9801 - val_loss: 0.0527 - val_accuracy: 0.9876\n",
      "Epoch 596/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0475 - accuracy: 0.9840\n",
      "Epoch 00596: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0535 - accuracy: 0.9816 - val_loss: 0.0582 - val_accuracy: 0.9845\n",
      "Epoch 597/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0425 - accuracy: 0.9840\n",
      "Epoch 00597: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0541 - accuracy: 0.9786 - val_loss: 0.0541 - val_accuracy: 0.9876\n",
      "Epoch 598/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0553 - accuracy: 0.9840\n",
      "Epoch 00598: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9832 - val_loss: 0.0521 - val_accuracy: 0.9876\n",
      "Epoch 599/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0663 - accuracy: 0.9800\n",
      "Epoch 00599: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0567 - accuracy: 0.9832 - val_loss: 0.0521 - val_accuracy: 0.9876\n",
      "Epoch 600/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0448 - accuracy: 0.9880\n",
      "Epoch 00600: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0545 - accuracy: 0.9832 - val_loss: 0.0586 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0466 - accuracy: 0.9820\n",
      "Epoch 00601: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0525 - accuracy: 0.9816 - val_loss: 0.0799 - val_accuracy: 0.9814\n",
      "Epoch 602/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0649 - accuracy: 0.9760\n",
      "Epoch 00602: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9740 - val_loss: 0.0526 - val_accuracy: 0.9876\n",
      "Epoch 603/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0482 - accuracy: 0.9800\n",
      "Epoch 00603: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 0.9770 - val_loss: 0.0539 - val_accuracy: 0.9876\n",
      "Epoch 604/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0668 - accuracy: 0.9800\n",
      "Epoch 00604: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0617 - accuracy: 0.9816 - val_loss: 0.0561 - val_accuracy: 0.9876\n",
      "Epoch 605/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0555 - accuracy: 0.9800\n",
      "Epoch 00605: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0578 - accuracy: 0.9770 - val_loss: 0.0620 - val_accuracy: 0.9876\n",
      "Epoch 606/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0505 - accuracy: 0.9780\n",
      "Epoch 00606: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0546 - accuracy: 0.9816 - val_loss: 0.0532 - val_accuracy: 0.9876\n",
      "Epoch 607/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0631 - accuracy: 0.9800\n",
      "Epoch 00607: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0564 - accuracy: 0.9847 - val_loss: 0.0534 - val_accuracy: 0.9876\n",
      "Epoch 608/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0644 - accuracy: 0.9860\n",
      "Epoch 00608: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0561 - accuracy: 0.9862 - val_loss: 0.0573 - val_accuracy: 0.9845\n",
      "Epoch 609/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0547 - accuracy: 0.9820\n",
      "Epoch 00609: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.0645 - val_accuracy: 0.9876\n",
      "Epoch 610/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0699 - accuracy: 0.9720\n",
      "Epoch 00610: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0570 - accuracy: 0.9786 - val_loss: 0.0567 - val_accuracy: 0.9845\n",
      "Epoch 611/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0590 - accuracy: 0.9800\n",
      "Epoch 00611: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0520 - accuracy: 0.9832 - val_loss: 0.0544 - val_accuracy: 0.9876\n",
      "Epoch 612/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0330 - accuracy: 0.9920\n",
      "Epoch 00612: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0571 - accuracy: 0.9832 - val_loss: 0.0562 - val_accuracy: 0.9845\n",
      "Epoch 613/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0519 - accuracy: 0.9820\n",
      "Epoch 00613: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0560 - accuracy: 0.9770 - val_loss: 0.0656 - val_accuracy: 0.9876\n",
      "Epoch 614/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0568 - accuracy: 0.9800\n",
      "Epoch 00614: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0545 - accuracy: 0.9816 - val_loss: 0.0529 - val_accuracy: 0.9876\n",
      "Epoch 615/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0575 - accuracy: 0.9800\n",
      "Epoch 00615: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0581 - accuracy: 0.9801 - val_loss: 0.0553 - val_accuracy: 0.9783\n",
      "Epoch 616/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0644 - accuracy: 0.9760\n",
      "Epoch 00616: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0644 - accuracy: 0.9786 - val_loss: 0.0542 - val_accuracy: 0.9876\n",
      "Epoch 617/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0561 - accuracy: 0.9780\n",
      "Epoch 00617: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0529 - accuracy: 0.9786 - val_loss: 0.0719 - val_accuracy: 0.9845\n",
      "Epoch 618/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0657 - accuracy: 0.9720\n",
      "Epoch 00618: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0597 - accuracy: 0.9770 - val_loss: 0.0535 - val_accuracy: 0.9876\n",
      "Epoch 619/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0535 - accuracy: 0.9840\n",
      "Epoch 00619: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0523 - accuracy: 0.9847 - val_loss: 0.0524 - val_accuracy: 0.9876\n",
      "Epoch 620/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0628 - accuracy: 0.9800\n",
      "Epoch 00620: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0561 - accuracy: 0.9832 - val_loss: 0.0543 - val_accuracy: 0.9876\n",
      "Epoch 621/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0574 - accuracy: 0.9820\n",
      "Epoch 00621: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0521 - accuracy: 0.9847 - val_loss: 0.0616 - val_accuracy: 0.9876\n",
      "Epoch 622/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0497 - accuracy: 0.9880\n",
      "Epoch 00622: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0539 - accuracy: 0.9832 - val_loss: 0.0556 - val_accuracy: 0.9876\n",
      "Epoch 623/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0508 - accuracy: 0.9860\n",
      "Epoch 00623: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0514 - accuracy: 0.9847 - val_loss: 0.0538 - val_accuracy: 0.9876\n",
      "Epoch 624/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0532 - accuracy: 0.9840\n",
      "Epoch 00624: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0508 - accuracy: 0.9862 - val_loss: 0.0553 - val_accuracy: 0.9876\n",
      "Epoch 625/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0601 - accuracy: 0.9820\n",
      "Epoch 00625: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.9847 - val_loss: 0.0553 - val_accuracy: 0.9876\n",
      "Epoch 626/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0562 - accuracy: 0.9820\n",
      "Epoch 00626: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9832 - val_loss: 0.0536 - val_accuracy: 0.9876\n",
      "Epoch 627/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0566 - accuracy: 0.9760\n",
      "Epoch 00627: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.9801 - val_loss: 0.0535 - val_accuracy: 0.9876\n",
      "Epoch 628/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0545 - accuracy: 0.9800\n",
      "Epoch 00628: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9847 - val_loss: 0.0562 - val_accuracy: 0.9845\n",
      "Epoch 629/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0459 - accuracy: 0.9880\n",
      "Epoch 00629: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 0.0563 - val_accuracy: 0.9845\n",
      "Epoch 630/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0589 - accuracy: 0.9800\n",
      "Epoch 00630: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 0.0541 - val_accuracy: 0.9876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 631/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0501 - accuracy: 0.9860\n",
      "Epoch 00631: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.9847 - val_loss: 0.0540 - val_accuracy: 0.9876\n",
      "Epoch 632/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0569 - accuracy: 0.9840\n",
      "Epoch 00632: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0507 - accuracy: 0.9862 - val_loss: 0.0580 - val_accuracy: 0.9876\n",
      "Epoch 633/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0551 - accuracy: 0.9840\n",
      "Epoch 00633: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9847 - val_loss: 0.0539 - val_accuracy: 0.9876\n",
      "Epoch 634/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0490 - accuracy: 0.9860\n",
      "Epoch 00634: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0498 - accuracy: 0.9862 - val_loss: 0.0530 - val_accuracy: 0.9876\n",
      "Epoch 635/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0473 - accuracy: 0.9840\n",
      "Epoch 00635: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0562 - accuracy: 0.9832 - val_loss: 0.0526 - val_accuracy: 0.9876\n",
      "Epoch 636/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0480 - accuracy: 0.9820\n",
      "Epoch 00636: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.0599 - val_accuracy: 0.9876\n",
      "Epoch 637/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0538 - accuracy: 0.9840\n",
      "Epoch 00637: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0526 - accuracy: 0.9816 - val_loss: 0.0557 - val_accuracy: 0.9876\n",
      "Epoch 638/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0485 - accuracy: 0.9840\n",
      "Epoch 00638: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0491 - accuracy: 0.9847 - val_loss: 0.0521 - val_accuracy: 0.9876\n",
      "Epoch 639/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0480 - accuracy: 0.9840\n",
      "Epoch 00639: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0520 - accuracy: 0.9832 - val_loss: 0.0520 - val_accuracy: 0.9876\n",
      "Epoch 640/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0418 - accuracy: 0.9860\n",
      "Epoch 00640: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 0.0614 - val_accuracy: 0.9876\n",
      "Epoch 641/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0614 - accuracy: 0.9760\n",
      "Epoch 00641: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0526 - accuracy: 0.9801 - val_loss: 0.0619 - val_accuracy: 0.9876\n",
      "Epoch 642/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0504 - accuracy: 0.9840\n",
      "Epoch 00642: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 0.0523 - val_accuracy: 0.9876\n",
      "Epoch 643/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0633 - accuracy: 0.9800\n",
      "Epoch 00643: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.0533 - val_accuracy: 0.9876\n",
      "Epoch 644/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0510 - accuracy: 0.9860\n",
      "Epoch 00644: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0572 - accuracy: 0.9832 - val_loss: 0.0548 - val_accuracy: 0.9876\n",
      "Epoch 645/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0441 - accuracy: 0.9880\n",
      "Epoch 00645: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0503 - accuracy: 0.9847 - val_loss: 0.0682 - val_accuracy: 0.9876\n",
      "Epoch 646/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0488 - accuracy: 0.9820\n",
      "Epoch 00646: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0550 - accuracy: 0.9770 - val_loss: 0.0541 - val_accuracy: 0.9876\n",
      "Epoch 647/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0365 - accuracy: 0.9900\n",
      "Epoch 00647: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0518 - accuracy: 0.9877 - val_loss: 0.0524 - val_accuracy: 0.9876\n",
      "Epoch 648/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0419 - accuracy: 0.9900\n",
      "Epoch 00648: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9847 - val_loss: 0.0573 - val_accuracy: 0.9876\n",
      "Epoch 649/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0500 - accuracy: 0.9820\n",
      "Epoch 00649: val_loss did not improve from 0.05191\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0522 - accuracy: 0.9816 - val_loss: 0.0676 - val_accuracy: 0.9876\n",
      "Epoch 650/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0506 - accuracy: 0.9780\n",
      "Epoch 00650: val_loss improved from 0.05191 to 0.05123, saving model to ./model\\650-0.0512.hdf5\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0547 - accuracy: 0.9801 - val_loss: 0.0512 - val_accuracy: 0.9876\n",
      "Epoch 651/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0577 - accuracy: 0.9800\n",
      "Epoch 00651: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 0.0522 - val_accuracy: 0.9876\n",
      "Epoch 652/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0542 - accuracy: 0.9840\n",
      "Epoch 00652: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0566 - accuracy: 0.9832 - val_loss: 0.0544 - val_accuracy: 0.9876\n",
      "Epoch 653/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0572 - accuracy: 0.9820\n",
      "Epoch 00653: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0514 - accuracy: 0.9832 - val_loss: 0.0678 - val_accuracy: 0.9876\n",
      "Epoch 654/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0531 - accuracy: 0.9780\n",
      "Epoch 00654: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0530 - accuracy: 0.9770 - val_loss: 0.0519 - val_accuracy: 0.9876\n",
      "Epoch 655/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0430 - accuracy: 0.9900\n",
      "Epoch 00655: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0519 - accuracy: 0.9877 - val_loss: 0.0536 - val_accuracy: 0.9876\n",
      "Epoch 656/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0723 - accuracy: 0.9780\n",
      "Epoch 00656: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0617 - accuracy: 0.9801 - val_loss: 0.0530 - val_accuracy: 0.9876\n",
      "Epoch 657/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0557 - accuracy: 0.9820\n",
      "Epoch 00657: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9847 - val_loss: 0.0675 - val_accuracy: 0.9876\n",
      "Epoch 658/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0580 - accuracy: 0.9760\n",
      "Epoch 00658: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.9786 - val_loss: 0.0585 - val_accuracy: 0.9876\n",
      "Epoch 659/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0568 - accuracy: 0.9860\n",
      "Epoch 00659: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0501 - accuracy: 0.9862 - val_loss: 0.0532 - val_accuracy: 0.9876\n",
      "Epoch 660/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0563 - accuracy: 0.9880\n",
      "Epoch 00660: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9862 - val_loss: 0.0540 - val_accuracy: 0.9876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0578 - accuracy: 0.9840\n",
      "Epoch 00661: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0503 - accuracy: 0.9877 - val_loss: 0.0626 - val_accuracy: 0.9876\n",
      "Epoch 662/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0557 - accuracy: 0.9780\n",
      "Epoch 00662: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0515 - accuracy: 0.9816 - val_loss: 0.0592 - val_accuracy: 0.9876\n",
      "Epoch 663/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0470 - accuracy: 0.9920\n",
      "Epoch 00663: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9877 - val_loss: 0.0536 - val_accuracy: 0.9876\n",
      "Epoch 664/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0630 - accuracy: 0.9820\n",
      "Epoch 00664: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0542 - accuracy: 0.9832 - val_loss: 0.0534 - val_accuracy: 0.9876\n",
      "Epoch 665/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0591 - accuracy: 0.9800\n",
      "Epoch 00665: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0544 - accuracy: 0.9816 - val_loss: 0.0577 - val_accuracy: 0.9876\n",
      "Epoch 666/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0469 - accuracy: 0.9880\n",
      "Epoch 00666: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 0.0597 - val_accuracy: 0.9876\n",
      "Epoch 667/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0525 - accuracy: 0.9820\n",
      "Epoch 00667: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0494 - accuracy: 0.9832 - val_loss: 0.0536 - val_accuracy: 0.9876\n",
      "Epoch 668/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0513 - accuracy: 0.9860\n",
      "Epoch 00668: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.0534 - val_accuracy: 0.9876\n",
      "Epoch 669/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0490 - accuracy: 0.9860\n",
      "Epoch 00669: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.9847 - val_loss: 0.0558 - val_accuracy: 0.9876\n",
      "Epoch 670/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0484 - accuracy: 0.9820\n",
      "Epoch 00670: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0474 - accuracy: 0.9847 - val_loss: 0.0536 - val_accuracy: 0.9876\n",
      "Epoch 671/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0453 - accuracy: 0.9840\n",
      "Epoch 00671: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0478 - accuracy: 0.9832 - val_loss: 0.0537 - val_accuracy: 0.9876\n",
      "Epoch 672/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0425 - accuracy: 0.9880\n",
      "Epoch 00672: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9832 - val_loss: 0.0573 - val_accuracy: 0.9876\n",
      "Epoch 673/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0448 - accuracy: 0.9800\n",
      "Epoch 00673: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.0590 - val_accuracy: 0.9907\n",
      "Epoch 674/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0490 - accuracy: 0.9800\n",
      "Epoch 00674: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.9816 - val_loss: 0.0544 - val_accuracy: 0.9876\n",
      "Epoch 675/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0529 - accuracy: 0.9820\n",
      "Epoch 00675: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 0.0527 - val_accuracy: 0.9876\n",
      "Epoch 676/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0442 - accuracy: 0.9900\n",
      "Epoch 00676: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0537 - accuracy: 0.9847 - val_loss: 0.0545 - val_accuracy: 0.9876\n",
      "Epoch 677/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0505 - accuracy: 0.9820\n",
      "Epoch 00677: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.0708 - val_accuracy: 0.9876\n",
      "Epoch 678/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0466 - accuracy: 0.9800\n",
      "Epoch 00678: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0535 - accuracy: 0.9786 - val_loss: 0.0547 - val_accuracy: 0.9876\n",
      "Epoch 679/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0524 - accuracy: 0.9900\n",
      "Epoch 00679: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0492 - accuracy: 0.9893 - val_loss: 0.0550 - val_accuracy: 0.9845\n",
      "Epoch 680/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0685 - accuracy: 0.9780\n",
      "Epoch 00680: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9816 - val_loss: 0.0536 - val_accuracy: 0.9876\n",
      "Epoch 681/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0481 - accuracy: 0.9860\n",
      "Epoch 00681: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9847 - val_loss: 0.0706 - val_accuracy: 0.9876\n",
      "Epoch 682/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0538 - accuracy: 0.9780\n",
      "Epoch 00682: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0544 - accuracy: 0.9786 - val_loss: 0.0694 - val_accuracy: 0.9876\n",
      "Epoch 683/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0633 - accuracy: 0.9740\n",
      "Epoch 00683: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0542 - accuracy: 0.9786 - val_loss: 0.0526 - val_accuracy: 0.9876\n",
      "Epoch 684/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0585 - accuracy: 0.9780\n",
      "Epoch 00684: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0494 - accuracy: 0.9832 - val_loss: 0.0521 - val_accuracy: 0.9876\n",
      "Epoch 685/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0561 - accuracy: 0.9840\n",
      "Epoch 00685: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0534 - accuracy: 0.9847 - val_loss: 0.0538 - val_accuracy: 0.9876\n",
      "Epoch 686/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0400 - accuracy: 0.9840\n",
      "Epoch 00686: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0457 - accuracy: 0.9832 - val_loss: 0.0682 - val_accuracy: 0.9876\n",
      "Epoch 687/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0586 - accuracy: 0.9740\n",
      "Epoch 00687: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0554 - accuracy: 0.9770 - val_loss: 0.0591 - val_accuracy: 0.9876\n",
      "Epoch 688/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0567 - accuracy: 0.9780\n",
      "Epoch 00688: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0501 - accuracy: 0.9801 - val_loss: 0.0522 - val_accuracy: 0.9876\n",
      "Epoch 689/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0449 - accuracy: 0.9900\n",
      "Epoch 00689: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 0.0528 - val_accuracy: 0.9876\n",
      "Epoch 690/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0488 - accuracy: 0.9860\n",
      "Epoch 00690: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0473 - accuracy: 0.9847 - val_loss: 0.0580 - val_accuracy: 0.9907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0369 - accuracy: 0.9860\n",
      "Epoch 00691: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0481 - accuracy: 0.9816 - val_loss: 0.0569 - val_accuracy: 0.9907\n",
      "Epoch 692/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0483 - accuracy: 0.9860\n",
      "Epoch 00692: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0471 - accuracy: 0.9847 - val_loss: 0.0550 - val_accuracy: 0.9876\n",
      "Epoch 693/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0536 - accuracy: 0.9820\n",
      "Epoch 00693: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9862 - val_loss: 0.0564 - val_accuracy: 0.9907\n",
      "Epoch 694/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0502 - accuracy: 0.9840\n",
      "Epoch 00694: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0455 - accuracy: 0.9862 - val_loss: 0.0568 - val_accuracy: 0.9876\n",
      "Epoch 695/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0460 - accuracy: 0.9880\n",
      "Epoch 00695: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0459 - accuracy: 0.9862 - val_loss: 0.0582 - val_accuracy: 0.9876\n",
      "Epoch 696/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0482 - accuracy: 0.9820\n",
      "Epoch 00696: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0454 - accuracy: 0.9832 - val_loss: 0.0607 - val_accuracy: 0.9876\n",
      "Epoch 697/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0352 - accuracy: 0.9880\n",
      "Epoch 00697: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0462 - accuracy: 0.9832 - val_loss: 0.0570 - val_accuracy: 0.9876\n",
      "Epoch 698/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0475 - accuracy: 0.9860\n",
      "Epoch 00698: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 0.0540 - val_accuracy: 0.9876\n",
      "Epoch 699/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0418 - accuracy: 0.9880\n",
      "Epoch 00699: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9877 - val_loss: 0.0550 - val_accuracy: 0.9876\n",
      "Epoch 700/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0290 - accuracy: 0.9900\n",
      "Epoch 00700: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9816 - val_loss: 0.0650 - val_accuracy: 0.9876\n",
      "Epoch 701/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0499 - accuracy: 0.9800\n",
      "Epoch 00701: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0498 - accuracy: 0.9816 - val_loss: 0.0577 - val_accuracy: 0.9907\n",
      "Epoch 702/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0447 - accuracy: 0.9840\n",
      "Epoch 00702: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0472 - accuracy: 0.9832 - val_loss: 0.0524 - val_accuracy: 0.9876\n",
      "Epoch 703/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0517 - accuracy: 0.9800\n",
      "Epoch 00703: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.9832 - val_loss: 0.0527 - val_accuracy: 0.9876\n",
      "Epoch 704/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0525 - accuracy: 0.9800\n",
      "Epoch 00704: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.9832 - val_loss: 0.0535 - val_accuracy: 0.9876\n",
      "Epoch 705/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0349 - accuracy: 0.9900\n",
      "Epoch 00705: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0455 - accuracy: 0.9862 - val_loss: 0.0551 - val_accuracy: 0.9876\n",
      "Epoch 706/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0495 - accuracy: 0.9860\n",
      "Epoch 00706: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.0574 - val_accuracy: 0.9907\n",
      "Epoch 707/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0449 - accuracy: 0.9900\n",
      "Epoch 00707: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9893 - val_loss: 0.0570 - val_accuracy: 0.9907\n",
      "Epoch 708/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0391 - accuracy: 0.9900\n",
      "Epoch 00708: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9893 - val_loss: 0.0586 - val_accuracy: 0.9876\n",
      "Epoch 709/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0478 - accuracy: 0.9840\n",
      "Epoch 00709: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.0583 - val_accuracy: 0.9876\n",
      "Epoch 710/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0470 - accuracy: 0.9860\n",
      "Epoch 00710: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9877 - val_loss: 0.0571 - val_accuracy: 0.9876\n",
      "Epoch 711/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0479 - accuracy: 0.9860\n",
      "Epoch 00711: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.0580 - val_accuracy: 0.9876\n",
      "Epoch 712/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0458 - accuracy: 0.9860\n",
      "Epoch 00712: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9877 - val_loss: 0.0579 - val_accuracy: 0.9876\n",
      "Epoch 713/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0461 - accuracy: 0.9880\n",
      "Epoch 00713: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9877 - val_loss: 0.0550 - val_accuracy: 0.9907\n",
      "Epoch 714/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0493 - accuracy: 0.9860\n",
      "Epoch 00714: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0455 - accuracy: 0.9893 - val_loss: 0.0543 - val_accuracy: 0.9876\n",
      "Epoch 715/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0344 - accuracy: 0.9940\n",
      "Epoch 00715: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0459 - accuracy: 0.9908 - val_loss: 0.0587 - val_accuracy: 0.9876\n",
      "Epoch 716/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0522 - accuracy: 0.9840\n",
      "Epoch 00716: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0454 - accuracy: 0.9862 - val_loss: 0.0632 - val_accuracy: 0.9876\n",
      "Epoch 717/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0487 - accuracy: 0.9760\n",
      "Epoch 00717: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0469 - accuracy: 0.9786 - val_loss: 0.0539 - val_accuracy: 0.9876\n",
      "Epoch 718/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0435 - accuracy: 0.9860\n",
      "Epoch 00718: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9877 - val_loss: 0.0525 - val_accuracy: 0.9876\n",
      "Epoch 719/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0481 - accuracy: 0.9820\n",
      "Epoch 00719: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9832 - val_loss: 0.0543 - val_accuracy: 0.9876\n",
      "Epoch 720/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0508 - accuracy: 0.9780\n",
      "Epoch 00720: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.9832 - val_loss: 0.0621 - val_accuracy: 0.9876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0419 - accuracy: 0.9840\n",
      "Epoch 00721: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0471 - accuracy: 0.9801 - val_loss: 0.0574 - val_accuracy: 0.9907\n",
      "Epoch 722/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0365 - accuracy: 0.9920\n",
      "Epoch 00722: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 0.9862 - val_loss: 0.0528 - val_accuracy: 0.9876\n",
      "Epoch 723/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0479 - accuracy: 0.9880\n",
      "Epoch 00723: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 0.9877 - val_loss: 0.0532 - val_accuracy: 0.9876\n",
      "Epoch 724/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0529 - accuracy: 0.9860\n",
      "Epoch 00724: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.9862 - val_loss: 0.0576 - val_accuracy: 0.9907\n",
      "Epoch 725/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0504 - accuracy: 0.9820\n",
      "Epoch 00725: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9862 - val_loss: 0.0563 - val_accuracy: 0.9907\n",
      "Epoch 726/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0490 - accuracy: 0.9860\n",
      "Epoch 00726: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.9877 - val_loss: 0.0550 - val_accuracy: 0.9876\n",
      "Epoch 727/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0414 - accuracy: 0.9920\n",
      "Epoch 00727: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 0.9893 - val_loss: 0.0574 - val_accuracy: 0.9907\n",
      "Epoch 728/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0515 - accuracy: 0.9860\n",
      "Epoch 00728: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0433 - accuracy: 0.9893 - val_loss: 0.0627 - val_accuracy: 0.9876\n",
      "Epoch 729/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0522 - accuracy: 0.9800\n",
      "Epoch 00729: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0446 - accuracy: 0.9847 - val_loss: 0.0592 - val_accuracy: 0.9876\n",
      "Epoch 730/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0337 - accuracy: 0.9900\n",
      "Epoch 00730: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.0578 - val_accuracy: 0.9907\n",
      "Epoch 731/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0428 - accuracy: 0.9900\n",
      "Epoch 00731: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0435 - accuracy: 0.9877 - val_loss: 0.0578 - val_accuracy: 0.9907\n",
      "Epoch 732/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0398 - accuracy: 0.9840\n",
      "Epoch 00732: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0435 - accuracy: 0.9862 - val_loss: 0.0562 - val_accuracy: 0.9907\n",
      "Epoch 733/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0378 - accuracy: 0.9880\n",
      "Epoch 00733: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9877 - val_loss: 0.0601 - val_accuracy: 0.9876\n",
      "Epoch 734/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0457 - accuracy: 0.9820\n",
      "Epoch 00734: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9832 - val_loss: 0.0606 - val_accuracy: 0.9876\n",
      "Epoch 735/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0486 - accuracy: 0.9800\n",
      "Epoch 00735: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0435 - accuracy: 0.9832 - val_loss: 0.0539 - val_accuracy: 0.9876\n",
      "Epoch 736/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0480 - accuracy: 0.9840\n",
      "Epoch 00736: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0434 - accuracy: 0.9862 - val_loss: 0.0530 - val_accuracy: 0.9876\n",
      "Epoch 737/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0453 - accuracy: 0.9860\n",
      "Epoch 00737: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0451 - accuracy: 0.9847 - val_loss: 0.0573 - val_accuracy: 0.9907\n",
      "Epoch 738/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0440 - accuracy: 0.9840\n",
      "Epoch 00738: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0430 - accuracy: 0.9847 - val_loss: 0.0668 - val_accuracy: 0.9876\n",
      "Epoch 739/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0348 - accuracy: 0.9860\n",
      "Epoch 00739: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9816 - val_loss: 0.0545 - val_accuracy: 0.9876\n",
      "Epoch 740/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0481 - accuracy: 0.9860\n",
      "Epoch 00740: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 0.0561 - val_accuracy: 0.9845\n",
      "Epoch 741/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0499 - accuracy: 0.9800\n",
      "Epoch 00741: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.9816 - val_loss: 0.0574 - val_accuracy: 0.9907\n",
      "Epoch 742/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0503 - accuracy: 0.9860\n",
      "Epoch 00742: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9893 - val_loss: 0.0711 - val_accuracy: 0.9876\n",
      "Epoch 743/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0546 - accuracy: 0.9800\n",
      "Epoch 00743: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.9816 - val_loss: 0.0570 - val_accuracy: 0.9907\n",
      "Epoch 744/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0531 - accuracy: 0.9860\n",
      "Epoch 00744: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0478 - accuracy: 0.9862 - val_loss: 0.0555 - val_accuracy: 0.9876\n",
      "Epoch 745/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0524 - accuracy: 0.9860\n",
      "Epoch 00745: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9862 - val_loss: 0.0582 - val_accuracy: 0.9907\n",
      "Epoch 746/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0419 - accuracy: 0.9880\n",
      "Epoch 00746: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0437 - accuracy: 0.9893 - val_loss: 0.0622 - val_accuracy: 0.9876\n",
      "Epoch 747/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0486 - accuracy: 0.9800\n",
      "Epoch 00747: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0433 - accuracy: 0.9832 - val_loss: 0.0577 - val_accuracy: 0.9907\n",
      "Epoch 748/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0439 - accuracy: 0.9840\n",
      "Epoch 00748: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0423 - accuracy: 0.9862 - val_loss: 0.0550 - val_accuracy: 0.9876\n",
      "Epoch 749/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0375 - accuracy: 0.9860\n",
      "Epoch 00749: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.0549 - val_accuracy: 0.9876\n",
      "Epoch 750/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0532 - accuracy: 0.9820\n",
      "Epoch 00750: val_loss did not improve from 0.05123\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9847 - val_loss: 0.0599 - val_accuracy: 0.9907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/31 [..............................] - ETA: 0s - loss: 0.1308 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "31/31 [==============================] - 0s 615us/step - loss: 0.0486 - accuracy: 0.9856\n",
      "\n",
      " Accuracy : 0.9856\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장 폴더 만들기\n",
    "import os\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1,\n",
    "                              save_best_only = True)\n",
    "\n",
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 100)\n",
    "\n",
    "# 모델 실행\n",
    "history = model.fit(X, Y, validation_split = 0.33, epochs = 3500, batch_size = 500,  ## 33%는 테스트셋으로 사용\n",
    "                     callbacks = [early_stopping_callback, checkpointer])\n",
    "\n",
    "# 결과 출력 => 모델의 최종 형태를 이용하여 모델 평가\n",
    "print(\"\\n Accuracy : %.4f\" % (model.evaluate(X, Y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 오차 및 정확도 그래프 그리기 ✨\n",
    "- 와인 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc = history.history['accuracy']\n",
    "\n",
    "# x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = numpy.arange(len(y_acc))\n",
    "plt.plot(x_len, y_acc, \"o\", c = 'blue', markersize = 3, label = 'train_accuracy')\n",
    "plt.plot(x_len, y_vloss, \"o\", c = 'red', markersize = 3, label = 'test_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# => 오차는 떨어지고 정확도는 올라감 => 학습이 잘되었다는 것\n",
    "# => 어느 순간 학습셋 정확도가 계속 올라가는데, 테스트셋 오차가 다시 올라가면 => 과적합이 일어났다는 증거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 선형 회귀 적용하기 ✨\n",
    "- 보스턴 집값 데이터\n",
    "\n",
    "🐶 주어진 환경 요인과 집값의 변동을 학습해서 환경 요인만 놓고 집값을 예측하는 것      \n",
    "🦊 지금까지는 모델을 쌓을 때 마지막에 sigmoid (0, 1) -> 이제는 relu (연속된 값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "51/51 [==============================] - 0s 616us/step - loss: 6179.0347\n",
      "Epoch 2/200\n",
      "51/51 [==============================] - 0s 586us/step - loss: 527.4108\n",
      "Epoch 3/200\n",
      "51/51 [==============================] - 0s 635us/step - loss: 355.2221\n",
      "Epoch 4/200\n",
      "51/51 [==============================] - 0s 625us/step - loss: 196.1154\n",
      "Epoch 5/200\n",
      "51/51 [==============================] - 0s 643us/step - loss: 132.4047\n",
      "Epoch 6/200\n",
      "51/51 [==============================] - 0s 617us/step - loss: 91.6433\n",
      "Epoch 7/200\n",
      "51/51 [==============================] - 0s 673us/step - loss: 79.8189\n",
      "Epoch 8/200\n",
      "51/51 [==============================] - 0s 664us/step - loss: 73.8476\n",
      "Epoch 9/200\n",
      "51/51 [==============================] - 0s 656us/step - loss: 69.4761\n",
      "Epoch 10/200\n",
      "51/51 [==============================] - 0s 618us/step - loss: 68.2942\n",
      "Epoch 11/200\n",
      "51/51 [==============================] - 0s 606us/step - loss: 66.6846\n",
      "Epoch 12/200\n",
      "51/51 [==============================] - 0s 621us/step - loss: 64.7698\n",
      "Epoch 13/200\n",
      "51/51 [==============================] - 0s 617us/step - loss: 63.4050\n",
      "Epoch 14/200\n",
      "51/51 [==============================] - 0s 612us/step - loss: 61.7138\n",
      "Epoch 15/200\n",
      "51/51 [==============================] - 0s 624us/step - loss: 59.6468\n",
      "Epoch 16/200\n",
      "51/51 [==============================] - 0s 642us/step - loss: 59.2467\n",
      "Epoch 17/200\n",
      "51/51 [==============================] - 0s 644us/step - loss: 59.1448\n",
      "Epoch 18/200\n",
      "51/51 [==============================] - 0s 628us/step - loss: 57.1167\n",
      "Epoch 19/200\n",
      "51/51 [==============================] - 0s 619us/step - loss: 57.1225\n",
      "Epoch 20/200\n",
      "51/51 [==============================] - 0s 620us/step - loss: 57.1566\n",
      "Epoch 21/200\n",
      "51/51 [==============================] - 0s 603us/step - loss: 55.5613\n",
      "Epoch 22/200\n",
      "51/51 [==============================] - 0s 631us/step - loss: 55.1292\n",
      "Epoch 23/200\n",
      "51/51 [==============================] - 0s 594us/step - loss: 54.2268\n",
      "Epoch 24/200\n",
      "51/51 [==============================] - 0s 623us/step - loss: 54.0241\n",
      "Epoch 25/200\n",
      "51/51 [==============================] - 0s 629us/step - loss: 53.1213\n",
      "Epoch 26/200\n",
      "51/51 [==============================] - 0s 646us/step - loss: 52.4253\n",
      "Epoch 27/200\n",
      "51/51 [==============================] - 0s 644us/step - loss: 52.9790\n",
      "Epoch 28/200\n",
      "51/51 [==============================] - 0s 662us/step - loss: 51.9478\n",
      "Epoch 29/200\n",
      "51/51 [==============================] - 0s 631us/step - loss: 50.7151\n",
      "Epoch 30/200\n",
      "51/51 [==============================] - 0s 645us/step - loss: 49.5084\n",
      "Epoch 31/200\n",
      "51/51 [==============================] - 0s 602us/step - loss: 49.9956\n",
      "Epoch 32/200\n",
      "51/51 [==============================] - 0s 621us/step - loss: 49.2190\n",
      "Epoch 33/200\n",
      "51/51 [==============================] - 0s 604us/step - loss: 46.3913\n",
      "Epoch 34/200\n",
      "51/51 [==============================] - 0s 610us/step - loss: 45.9999\n",
      "Epoch 35/200\n",
      "51/51 [==============================] - 0s 549us/step - loss: 44.5807\n",
      "Epoch 36/200\n",
      "51/51 [==============================] - 0s 490us/step - loss: 43.8846\n",
      "Epoch 37/200\n",
      "51/51 [==============================] - 0s 590us/step - loss: 42.8540\n",
      "Epoch 38/200\n",
      "51/51 [==============================] - 0s 640us/step - loss: 42.7704\n",
      "Epoch 39/200\n",
      "51/51 [==============================] - 0s 628us/step - loss: 41.9799\n",
      "Epoch 40/200\n",
      "51/51 [==============================] - 0s 623us/step - loss: 40.8189\n",
      "Epoch 41/200\n",
      "51/51 [==============================] - 0s 601us/step - loss: 39.7121\n",
      "Epoch 42/200\n",
      "51/51 [==============================] - 0s 625us/step - loss: 39.2073\n",
      "Epoch 43/200\n",
      "51/51 [==============================] - 0s 687us/step - loss: 39.3411\n",
      "Epoch 44/200\n",
      "51/51 [==============================] - 0s 654us/step - loss: 37.5785\n",
      "Epoch 45/200\n",
      "51/51 [==============================] - 0s 684us/step - loss: 37.8973\n",
      "Epoch 46/200\n",
      "51/51 [==============================] - 0s 703us/step - loss: 37.2425\n",
      "Epoch 47/200\n",
      "51/51 [==============================] - 0s 665us/step - loss: 38.1110\n",
      "Epoch 48/200\n",
      "51/51 [==============================] - 0s 704us/step - loss: 35.5374\n",
      "Epoch 49/200\n",
      "51/51 [==============================] - 0s 666us/step - loss: 35.1866\n",
      "Epoch 50/200\n",
      "51/51 [==============================] - 0s 637us/step - loss: 34.3760\n",
      "Epoch 51/200\n",
      "51/51 [==============================] - 0s 645us/step - loss: 35.2375\n",
      "Epoch 52/200\n",
      "51/51 [==============================] - 0s 665us/step - loss: 34.8553\n",
      "Epoch 53/200\n",
      "51/51 [==============================] - 0s 623us/step - loss: 34.2371\n",
      "Epoch 54/200\n",
      "51/51 [==============================] - 0s 586us/step - loss: 33.2307\n",
      "Epoch 55/200\n",
      "51/51 [==============================] - 0s 623us/step - loss: 32.3618\n",
      "Epoch 56/200\n",
      "51/51 [==============================] - 0s 626us/step - loss: 32.0492\n",
      "Epoch 57/200\n",
      "51/51 [==============================] - 0s 626us/step - loss: 32.6629\n",
      "Epoch 58/200\n",
      "51/51 [==============================] - 0s 568us/step - loss: 33.6288\n",
      "Epoch 59/200\n",
      "51/51 [==============================] - 0s 586us/step - loss: 32.3473\n",
      "Epoch 60/200\n",
      "51/51 [==============================] - 0s 575us/step - loss: 31.5007\n",
      "Epoch 61/200\n",
      "51/51 [==============================] - 0s 585us/step - loss: 31.3617\n",
      "Epoch 62/200\n",
      "51/51 [==============================] - 0s 601us/step - loss: 30.2240\n",
      "Epoch 63/200\n",
      "51/51 [==============================] - 0s 601us/step - loss: 30.6202\n",
      "Epoch 64/200\n",
      "51/51 [==============================] - 0s 554us/step - loss: 30.6269\n",
      "Epoch 65/200\n",
      "51/51 [==============================] - 0s 566us/step - loss: 30.4810\n",
      "Epoch 66/200\n",
      "51/51 [==============================] - 0s 536us/step - loss: 28.6994\n",
      "Epoch 67/200\n",
      "51/51 [==============================] - 0s 540us/step - loss: 29.0652\n",
      "Epoch 68/200\n",
      "51/51 [==============================] - 0s 542us/step - loss: 28.5431\n",
      "Epoch 69/200\n",
      "51/51 [==============================] - 0s 553us/step - loss: 28.6581\n",
      "Epoch 70/200\n",
      "51/51 [==============================] - 0s 558us/step - loss: 27.9836\n",
      "Epoch 71/200\n",
      "51/51 [==============================] - 0s 583us/step - loss: 28.2598\n",
      "Epoch 72/200\n",
      "51/51 [==============================] - 0s 548us/step - loss: 30.0198\n",
      "Epoch 73/200\n",
      "51/51 [==============================] - 0s 490us/step - loss: 27.2746\n",
      "Epoch 74/200\n",
      "51/51 [==============================] - 0s 517us/step - loss: 27.2831\n",
      "Epoch 75/200\n",
      "51/51 [==============================] - 0s 543us/step - loss: 26.7412\n",
      "Epoch 76/200\n",
      "51/51 [==============================] - 0s 579us/step - loss: 29.8471\n",
      "Epoch 77/200\n",
      "51/51 [==============================] - 0s 541us/step - loss: 26.9325\n",
      "Epoch 78/200\n",
      "51/51 [==============================] - 0s 529us/step - loss: 27.2185\n",
      "Epoch 79/200\n",
      "51/51 [==============================] - 0s 520us/step - loss: 27.1256\n",
      "Epoch 80/200\n",
      "51/51 [==============================] - 0s 569us/step - loss: 28.1231\n",
      "Epoch 81/200\n",
      "51/51 [==============================] - 0s 576us/step - loss: 26.9190\n",
      "Epoch 82/200\n",
      "51/51 [==============================] - 0s 556us/step - loss: 26.3975\n",
      "Epoch 83/200\n",
      "51/51 [==============================] - 0s 535us/step - loss: 27.5875\n",
      "Epoch 84/200\n",
      "51/51 [==============================] - 0s 557us/step - loss: 26.1012\n",
      "Epoch 85/200\n",
      "51/51 [==============================] - 0s 585us/step - loss: 28.2475\n",
      "Epoch 86/200\n",
      "51/51 [==============================] - 0s 567us/step - loss: 27.4766\n",
      "Epoch 87/200\n",
      "51/51 [==============================] - 0s 567us/step - loss: 32.0099\n",
      "Epoch 88/200\n",
      "51/51 [==============================] - 0s 533us/step - loss: 25.6204\n",
      "Epoch 89/200\n",
      "51/51 [==============================] - 0s 532us/step - loss: 26.2588\n",
      "Epoch 90/200\n",
      "51/51 [==============================] - 0s 554us/step - loss: 25.2405\n",
      "Epoch 91/200\n",
      "51/51 [==============================] - 0s 567us/step - loss: 25.8998\n",
      "Epoch 92/200\n",
      "51/51 [==============================] - 0s 578us/step - loss: 25.0769\n",
      "Epoch 93/200\n",
      "51/51 [==============================] - 0s 576us/step - loss: 24.9226\n",
      "Epoch 94/200\n",
      "51/51 [==============================] - 0s 597us/step - loss: 25.8561\n",
      "Epoch 95/200\n",
      "51/51 [==============================] - 0s 538us/step - loss: 25.9842\n",
      "Epoch 96/200\n",
      "51/51 [==============================] - 0s 570us/step - loss: 27.3105\n",
      "Epoch 97/200\n",
      "51/51 [==============================] - 0s 560us/step - loss: 25.7649\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 549us/step - loss: 27.1582\n",
      "Epoch 99/200\n",
      "51/51 [==============================] - 0s 554us/step - loss: 26.1818\n",
      "Epoch 100/200\n",
      "51/51 [==============================] - 0s 519us/step - loss: 24.5368\n",
      "Epoch 101/200\n",
      "51/51 [==============================] - 0s 557us/step - loss: 24.5186\n",
      "Epoch 102/200\n",
      "51/51 [==============================] - 0s 587us/step - loss: 26.1143\n",
      "Epoch 103/200\n",
      "51/51 [==============================] - 0s 549us/step - loss: 24.8473\n",
      "Epoch 104/200\n",
      "51/51 [==============================] - 0s 579us/step - loss: 24.7569\n",
      "Epoch 105/200\n",
      "51/51 [==============================] - 0s 547us/step - loss: 23.8286\n",
      "Epoch 106/200\n",
      "51/51 [==============================] - 0s 539us/step - loss: 24.1230\n",
      "Epoch 107/200\n",
      "51/51 [==============================] - 0s 543us/step - loss: 28.0019\n",
      "Epoch 108/200\n",
      "51/51 [==============================] - 0s 438us/step - loss: 24.8288\n",
      "Epoch 109/200\n",
      "51/51 [==============================] - 0s 440us/step - loss: 25.5432\n",
      "Epoch 110/200\n",
      "51/51 [==============================] - 0s 485us/step - loss: 24.8361\n",
      "Epoch 111/200\n",
      "51/51 [==============================] - 0s 433us/step - loss: 23.9592\n",
      "Epoch 112/200\n",
      "51/51 [==============================] - 0s 487us/step - loss: 24.4983\n",
      "Epoch 113/200\n",
      "51/51 [==============================] - 0s 432us/step - loss: 26.0754\n",
      "Epoch 114/200\n",
      "51/51 [==============================] - 0s 466us/step - loss: 23.5859\n",
      "Epoch 115/200\n",
      "51/51 [==============================] - 0s 504us/step - loss: 24.3895\n",
      "Epoch 116/200\n",
      "51/51 [==============================] - 0s 475us/step - loss: 25.0502\n",
      "Epoch 117/200\n",
      "51/51 [==============================] - 0s 452us/step - loss: 22.7941\n",
      "Epoch 118/200\n",
      "51/51 [==============================] - 0s 455us/step - loss: 22.9032\n",
      "Epoch 119/200\n",
      "51/51 [==============================] - 0s 533us/step - loss: 24.3898\n",
      "Epoch 120/200\n",
      "51/51 [==============================] - 0s 536us/step - loss: 24.7578\n",
      "Epoch 121/200\n",
      "51/51 [==============================] - 0s 574us/step - loss: 23.3171\n",
      "Epoch 122/200\n",
      "51/51 [==============================] - 0s 545us/step - loss: 23.5356\n",
      "Epoch 123/200\n",
      "51/51 [==============================] - 0s 508us/step - loss: 22.9677\n",
      "Epoch 124/200\n",
      "51/51 [==============================] - 0s 470us/step - loss: 22.9027\n",
      "Epoch 125/200\n",
      "51/51 [==============================] - 0s 478us/step - loss: 22.9853\n",
      "Epoch 126/200\n",
      "51/51 [==============================] - 0s 458us/step - loss: 23.6009\n",
      "Epoch 127/200\n",
      "51/51 [==============================] - 0s 459us/step - loss: 22.5860\n",
      "Epoch 128/200\n",
      "51/51 [==============================] - 0s 456us/step - loss: 21.7569\n",
      "Epoch 129/200\n",
      "51/51 [==============================] - 0s 521us/step - loss: 21.6602\n",
      "Epoch 130/200\n",
      "51/51 [==============================] - 0s 564us/step - loss: 22.5073\n",
      "Epoch 131/200\n",
      "51/51 [==============================] - 0s 533us/step - loss: 23.2527\n",
      "Epoch 132/200\n",
      "51/51 [==============================] - 0s 523us/step - loss: 21.9824\n",
      "Epoch 133/200\n",
      "51/51 [==============================] - 0s 527us/step - loss: 21.6193\n",
      "Epoch 134/200\n",
      "51/51 [==============================] - 0s 582us/step - loss: 22.9706\n",
      "Epoch 135/200\n",
      "51/51 [==============================] - 0s 558us/step - loss: 22.2921\n",
      "Epoch 136/200\n",
      "51/51 [==============================] - 0s 550us/step - loss: 20.6922\n",
      "Epoch 137/200\n",
      "51/51 [==============================] - 0s 547us/step - loss: 20.2527\n",
      "Epoch 138/200\n",
      "51/51 [==============================] - 0s 518us/step - loss: 20.6926\n",
      "Epoch 139/200\n",
      "51/51 [==============================] - 0s 373us/step - loss: 19.5901\n",
      "Epoch 140/200\n",
      "51/51 [==============================] - 0s 366us/step - loss: 19.8479\n",
      "Epoch 141/200\n",
      "51/51 [==============================] - 0s 391us/step - loss: 20.3814\n",
      "Epoch 142/200\n",
      "51/51 [==============================] - 0s 421us/step - loss: 20.1312\n",
      "Epoch 143/200\n",
      "51/51 [==============================] - 0s 463us/step - loss: 19.1753\n",
      "Epoch 144/200\n",
      "51/51 [==============================] - 0s 587us/step - loss: 19.1368\n",
      "Epoch 145/200\n",
      "51/51 [==============================] - 0s 524us/step - loss: 19.3743\n",
      "Epoch 146/200\n",
      "51/51 [==============================] - 0s 517us/step - loss: 20.0527\n",
      "Epoch 147/200\n",
      "51/51 [==============================] - 0s 528us/step - loss: 19.7658\n",
      "Epoch 148/200\n",
      "51/51 [==============================] - 0s 574us/step - loss: 19.1958\n",
      "Epoch 149/200\n",
      "51/51 [==============================] - 0s 537us/step - loss: 19.8896\n",
      "Epoch 150/200\n",
      "51/51 [==============================] - 0s 471us/step - loss: 20.3034\n",
      "Epoch 151/200\n",
      "51/51 [==============================] - 0s 464us/step - loss: 19.2485\n",
      "Epoch 152/200\n",
      "51/51 [==============================] - 0s 533us/step - loss: 19.9609\n",
      "Epoch 153/200\n",
      "51/51 [==============================] - 0s 528us/step - loss: 18.9444\n",
      "Epoch 154/200\n",
      "51/51 [==============================] - 0s 546us/step - loss: 18.5956\n",
      "Epoch 155/200\n",
      "51/51 [==============================] - 0s 577us/step - loss: 19.6925\n",
      "Epoch 156/200\n",
      "51/51 [==============================] - 0s 540us/step - loss: 18.7273\n",
      "Epoch 157/200\n",
      "51/51 [==============================] - 0s 493us/step - loss: 19.7274\n",
      "Epoch 158/200\n",
      "51/51 [==============================] - 0s 461us/step - loss: 20.3448\n",
      "Epoch 159/200\n",
      "51/51 [==============================] - 0s 506us/step - loss: 20.3195\n",
      "Epoch 160/200\n",
      "51/51 [==============================] - 0s 541us/step - loss: 18.8720\n",
      "Epoch 161/200\n",
      "51/51 [==============================] - 0s 518us/step - loss: 19.0847\n",
      "Epoch 162/200\n",
      "51/51 [==============================] - 0s 532us/step - loss: 17.9704\n",
      "Epoch 163/200\n",
      "51/51 [==============================] - 0s 558us/step - loss: 17.9796\n",
      "Epoch 164/200\n",
      "51/51 [==============================] - 0s 552us/step - loss: 19.5922\n",
      "Epoch 165/200\n",
      "51/51 [==============================] - 0s 524us/step - loss: 20.6982\n",
      "Epoch 166/200\n",
      "51/51 [==============================] - 0s 568us/step - loss: 19.6454\n",
      "Epoch 167/200\n",
      "51/51 [==============================] - 0s 556us/step - loss: 18.3652\n",
      "Epoch 168/200\n",
      "51/51 [==============================] - 0s 536us/step - loss: 18.6824\n",
      "Epoch 169/200\n",
      "51/51 [==============================] - 0s 553us/step - loss: 17.8136\n",
      "Epoch 170/200\n",
      "51/51 [==============================] - 0s 553us/step - loss: 19.2380\n",
      "Epoch 171/200\n",
      "51/51 [==============================] - 0s 540us/step - loss: 18.2012\n",
      "Epoch 172/200\n",
      "51/51 [==============================] - 0s 572us/step - loss: 18.6058\n",
      "Epoch 173/200\n",
      "51/51 [==============================] - 0s 562us/step - loss: 20.2308\n",
      "Epoch 174/200\n",
      "51/51 [==============================] - 0s 541us/step - loss: 18.7130\n",
      "Epoch 175/200\n",
      "51/51 [==============================] - 0s 477us/step - loss: 19.7913\n",
      "Epoch 176/200\n",
      "51/51 [==============================] - 0s 517us/step - loss: 17.8950\n",
      "Epoch 177/200\n",
      "51/51 [==============================] - 0s 444us/step - loss: 17.7741\n",
      "Epoch 178/200\n",
      "51/51 [==============================] - 0s 568us/step - loss: 19.7076\n",
      "Epoch 179/200\n",
      "51/51 [==============================] - 0s 520us/step - loss: 17.3037\n",
      "Epoch 180/200\n",
      "51/51 [==============================] - 0s 543us/step - loss: 17.0865\n",
      "Epoch 181/200\n",
      "51/51 [==============================] - 0s 555us/step - loss: 19.5063\n",
      "Epoch 182/200\n",
      "51/51 [==============================] - 0s 544us/step - loss: 18.9002\n",
      "Epoch 183/200\n",
      "51/51 [==============================] - 0s 536us/step - loss: 19.9206\n",
      "Epoch 184/200\n",
      "51/51 [==============================] - 0s 579us/step - loss: 19.0686\n",
      "Epoch 185/200\n",
      "51/51 [==============================] - 0s 562us/step - loss: 18.2880\n",
      "Epoch 186/200\n",
      "51/51 [==============================] - 0s 541us/step - loss: 16.7161\n",
      "Epoch 187/200\n",
      "51/51 [==============================] - 0s 521us/step - loss: 18.2667\n",
      "Epoch 188/200\n",
      "51/51 [==============================] - 0s 517us/step - loss: 18.7612\n",
      "Epoch 189/200\n",
      "51/51 [==============================] - 0s 529us/step - loss: 19.4902\n",
      "Epoch 190/200\n",
      "51/51 [==============================] - 0s 558us/step - loss: 17.6122\n",
      "Epoch 191/200\n",
      "51/51 [==============================] - 0s 557us/step - loss: 17.0401\n",
      "Epoch 192/200\n",
      "51/51 [==============================] - 0s 525us/step - loss: 20.1968\n",
      "Epoch 193/200\n",
      "51/51 [==============================] - 0s 540us/step - loss: 17.6367\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 541us/step - loss: 18.9450\n",
      "Epoch 195/200\n",
      "51/51 [==============================] - 0s 523us/step - loss: 17.2929\n",
      "Epoch 196/200\n",
      "51/51 [==============================] - 0s 565us/step - loss: 19.1072\n",
      "Epoch 197/200\n",
      "51/51 [==============================] - 0s 570us/step - loss: 17.7384\n",
      "Epoch 198/200\n",
      "51/51 [==============================] - 0s 587us/step - loss: 17.5169\n",
      "Epoch 199/200\n",
      "51/51 [==============================] - 0s 591us/step - loss: 17.8385\n",
      "Epoch 200/200\n",
      "51/51 [==============================] - 0s 642us/step - loss: 16.5491\n",
      "실제 가격 : 22.600, 예상 가격 : 19.257\n",
      "실제 가격 : 50.000, 예상 가격 : 25.890\n",
      "실제 가격 : 23.000, 예상 가격 : 21.569\n",
      "실제 가격 : 8.300, 예상 가격 : 11.177\n",
      "실제 가격 : 21.200, 예상 가격 : 19.183\n",
      "실제 가격 : 19.900, 예상 가격 : 21.620\n",
      "실제 가격 : 20.600, 예상 가격 : 16.241\n",
      "실제 가격 : 18.700, 예상 가격 : 22.841\n",
      "실제 가격 : 16.100, 예상 가격 : 17.481\n",
      "실제 가격 : 18.600, 예상 가격 : 13.820\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# df = pd.read_csv('housing2.csv')   ## 엑셀로 직접 나눈 데이터\n",
    "df = pd.read_csv('housing.csv', delim_whitespace = True, header = None)   ##화이트공간(빈공간)으로 나누어졌다라는 뜻\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:, 0:13]\n",
    "Y = dataset[:, 13]    # 가격 (단위 : $1.000)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3,\n",
    "                                                   random_state = seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 13, activation = 'relu'))\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error',    #손실함수 : 최소 제곱법 -> 선형 회귀이기 때문에\n",
    "             optimizer = 'adam')\n",
    "         ## metrics = ['accuracy'] : 안 쓰는 이유 = 선형 회귀는 이진분류처럼 예측값과 실제값의 같다 다르다 계산 불가능하기 때문\n",
    "    \n",
    "model.fit(X_train, Y_train, epochs = 200, batch_size = 10)\n",
    "\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제 가격 : {:.3f}, 예상 가격 : {:.3f}\" .format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 피마 인디언 당뇨병 데이터 ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 10.3692 - accuracy: 0.6257\n",
      "Epoch 2/1500\n",
      "11/11 [==============================] - 0s 806us/step - loss: 8.5059 - accuracy: 0.6271\n",
      "Epoch 3/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 6.7811 - accuracy: 0.6314\n",
      "Epoch 4/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 5.1179 - accuracy: 0.6414\n",
      "Epoch 5/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3.7199 - accuracy: 0.6500\n",
      "Epoch 6/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 2.6774 - accuracy: 0.6614\n",
      "Epoch 7/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 2.0324 - accuracy: 0.6543\n",
      "Epoch 8/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 1.7675 - accuracy: 0.6471\n",
      "Epoch 9/1500\n",
      "11/11 [==============================] - 0s 648us/step - loss: 1.5712 - accuracy: 0.6314\n",
      "Epoch 10/1500\n",
      "11/11 [==============================] - 0s 730us/step - loss: 1.4292 - accuracy: 0.6100\n",
      "Epoch 11/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 1.2743 - accuracy: 0.5914\n",
      "Epoch 12/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 1.1826 - accuracy: 0.6057\n",
      "Epoch 13/1500\n",
      "11/11 [==============================] - 0s 812us/step - loss: 1.1240 - accuracy: 0.6043\n",
      "Epoch 14/1500\n",
      "11/11 [==============================] - 0s 649us/step - loss: 1.0744 - accuracy: 0.5886\n",
      "Epoch 15/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 1.0224 - accuracy: 0.6071\n",
      "Epoch 16/1500\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.9784 - accuracy: 0.5971\n",
      "Epoch 17/1500\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.9359 - accuracy: 0.6314\n",
      "Epoch 18/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.8899 - accuracy: 0.6343\n",
      "Epoch 19/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.8587 - accuracy: 0.6300\n",
      "Epoch 20/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.8233 - accuracy: 0.6486\n",
      "Epoch 21/1500\n",
      "11/11 [==============================] - 0s 646us/step - loss: 0.7993 - accuracy: 0.6314\n",
      "Epoch 22/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.7745 - accuracy: 0.6443\n",
      "Epoch 23/1500\n",
      "11/11 [==============================] - 0s 668us/step - loss: 0.7567 - accuracy: 0.6414\n",
      "Epoch 24/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.7403 - accuracy: 0.6600\n",
      "Epoch 25/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.7316 - accuracy: 0.6643\n",
      "Epoch 26/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.7220 - accuracy: 0.6529\n",
      "Epoch 27/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.7114 - accuracy: 0.6600\n",
      "Epoch 28/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.7045 - accuracy: 0.6643\n",
      "Epoch 29/1500\n",
      "11/11 [==============================] - 0s 616us/step - loss: 0.7000 - accuracy: 0.6600\n",
      "Epoch 30/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.6923 - accuracy: 0.6614\n",
      "Epoch 31/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.6881 - accuracy: 0.6800\n",
      "Epoch 32/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.6856 - accuracy: 0.6529\n",
      "Epoch 33/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.6774 - accuracy: 0.6714\n",
      "Epoch 34/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.6738 - accuracy: 0.6786\n",
      "Epoch 35/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.6696 - accuracy: 0.6743\n",
      "Epoch 36/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.6639 - accuracy: 0.6771\n",
      "Epoch 37/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.6595 - accuracy: 0.6843\n",
      "Epoch 38/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.6548 - accuracy: 0.6786\n",
      "Epoch 39/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.6533 - accuracy: 0.6900\n",
      "Epoch 40/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.6492 - accuracy: 0.6857\n",
      "Epoch 41/1500\n",
      "11/11 [==============================] - 0s 689us/step - loss: 0.6476 - accuracy: 0.6900\n",
      "Epoch 42/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.6493 - accuracy: 0.6800\n",
      "Epoch 43/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.6477 - accuracy: 0.6871\n",
      "Epoch 44/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.6456 - accuracy: 0.6871\n",
      "Epoch 45/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.6394 - accuracy: 0.6871\n",
      "Epoch 46/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.6365 - accuracy: 0.6843\n",
      "Epoch 47/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.6344 - accuracy: 0.6857\n",
      "Epoch 48/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.6305 - accuracy: 0.6943\n",
      "Epoch 49/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.6295 - accuracy: 0.6900\n",
      "Epoch 50/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.6278 - accuracy: 0.6871\n",
      "Epoch 51/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.6270 - accuracy: 0.6900\n",
      "Epoch 52/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.6237 - accuracy: 0.6986\n",
      "Epoch 53/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.6234 - accuracy: 0.6914\n",
      "Epoch 54/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.6202 - accuracy: 0.6957\n",
      "Epoch 55/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.6173 - accuracy: 0.7071\n",
      "Epoch 56/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.6174 - accuracy: 0.7043\n",
      "Epoch 57/1500\n",
      "11/11 [==============================] - 0s 823us/step - loss: 0.6206 - accuracy: 0.6900\n",
      "Epoch 58/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.6154 - accuracy: 0.7043\n",
      "Epoch 59/1500\n",
      "11/11 [==============================] - 0s 670us/step - loss: 0.6165 - accuracy: 0.6971\n",
      "Epoch 60/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.6133 - accuracy: 0.7029\n",
      "Epoch 61/1500\n",
      "11/11 [==============================] - 0s 714us/step - loss: 0.6101 - accuracy: 0.7086\n",
      "Epoch 62/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.6094 - accuracy: 0.7086\n",
      "Epoch 63/1500\n",
      "11/11 [==============================] - 0s 619us/step - loss: 0.6087 - accuracy: 0.7100\n",
      "Epoch 64/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.6063 - accuracy: 0.7071\n",
      "Epoch 65/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.6047 - accuracy: 0.7071\n",
      "Epoch 66/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.6033 - accuracy: 0.7043\n",
      "Epoch 67/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.6047 - accuracy: 0.7057\n",
      "Epoch 68/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.6022 - accuracy: 0.7086\n",
      "Epoch 69/1500\n",
      "11/11 [==============================] - 0s 665us/step - loss: 0.6041 - accuracy: 0.7086\n",
      "Epoch 70/1500\n",
      "11/11 [==============================] - 0s 539us/step - loss: 0.6025 - accuracy: 0.7057\n",
      "Epoch 71/1500\n",
      "11/11 [==============================] - 0s 591us/step - loss: 0.6000 - accuracy: 0.7057\n",
      "Epoch 72/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5975 - accuracy: 0.7143\n",
      "Epoch 73/1500\n",
      "11/11 [==============================] - 0s 556us/step - loss: 0.6003 - accuracy: 0.6986\n",
      "Epoch 74/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.6077 - accuracy: 0.7000\n",
      "Epoch 75/1500\n",
      "11/11 [==============================] - 0s 611us/step - loss: 0.5994 - accuracy: 0.7057\n",
      "Epoch 76/1500\n",
      "11/11 [==============================] - 0s 543us/step - loss: 0.5991 - accuracy: 0.7100\n",
      "Epoch 77/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.5954 - accuracy: 0.7186\n",
      "Epoch 78/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5916 - accuracy: 0.7057\n",
      "Epoch 79/1500\n",
      "11/11 [==============================] - 0s 643us/step - loss: 0.5916 - accuracy: 0.7086\n",
      "Epoch 80/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 641us/step - loss: 0.5907 - accuracy: 0.7029\n",
      "Epoch 81/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5962 - accuracy: 0.7043\n",
      "Epoch 82/1500\n",
      "11/11 [==============================] - 0s 591us/step - loss: 0.5915 - accuracy: 0.7057\n",
      "Epoch 83/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.5906 - accuracy: 0.7043\n",
      "Epoch 84/1500\n",
      "11/11 [==============================] - 0s 747us/step - loss: 0.5875 - accuracy: 0.7014\n",
      "Epoch 85/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.5855 - accuracy: 0.7071\n",
      "Epoch 86/1500\n",
      "11/11 [==============================] - 0s 534us/step - loss: 0.5851 - accuracy: 0.7114\n",
      "Epoch 87/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.5832 - accuracy: 0.7171\n",
      "Epoch 88/1500\n",
      "11/11 [==============================] - 0s 538us/step - loss: 0.5827 - accuracy: 0.7086\n",
      "Epoch 89/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.5831 - accuracy: 0.7086\n",
      "Epoch 90/1500\n",
      "11/11 [==============================] - 0s 663us/step - loss: 0.5833 - accuracy: 0.7100\n",
      "Epoch 91/1500\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.5834 - accuracy: 0.7086\n",
      "Epoch 92/1500\n",
      "11/11 [==============================] - 0s 573us/step - loss: 0.5878 - accuracy: 0.7014\n",
      "Epoch 93/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.5836 - accuracy: 0.7057\n",
      "Epoch 94/1500\n",
      "11/11 [==============================] - 0s 545us/step - loss: 0.5798 - accuracy: 0.7157\n",
      "Epoch 95/1500\n",
      "11/11 [==============================] - 0s 734us/step - loss: 0.5787 - accuracy: 0.7014\n",
      "Epoch 96/1500\n",
      "11/11 [==============================] - 0s 604us/step - loss: 0.5802 - accuracy: 0.7043\n",
      "Epoch 97/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.5786 - accuracy: 0.6957\n",
      "Epoch 98/1500\n",
      "11/11 [==============================] - 0s 668us/step - loss: 0.5759 - accuracy: 0.7071\n",
      "Epoch 99/1500\n",
      "11/11 [==============================] - 0s 730us/step - loss: 0.5759 - accuracy: 0.7029\n",
      "Epoch 100/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.5739 - accuracy: 0.7143\n",
      "Epoch 101/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5762 - accuracy: 0.7000\n",
      "Epoch 102/1500\n",
      "11/11 [==============================] - 0s 620us/step - loss: 0.5744 - accuracy: 0.7071\n",
      "Epoch 103/1500\n",
      "11/11 [==============================] - 0s 681us/step - loss: 0.5693 - accuracy: 0.7057\n",
      "Epoch 104/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.5767 - accuracy: 0.6929\n",
      "Epoch 105/1500\n",
      "11/11 [==============================] - 0s 589us/step - loss: 0.5765 - accuracy: 0.7014\n",
      "Epoch 106/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.5703 - accuracy: 0.7014\n",
      "Epoch 107/1500\n",
      "11/11 [==============================] - 0s 619us/step - loss: 0.5680 - accuracy: 0.7114\n",
      "Epoch 108/1500\n",
      "11/11 [==============================] - 0s 703us/step - loss: 0.5664 - accuracy: 0.7114\n",
      "Epoch 109/1500\n",
      "11/11 [==============================] - 0s 623us/step - loss: 0.5643 - accuracy: 0.7057\n",
      "Epoch 110/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5663 - accuracy: 0.7057\n",
      "Epoch 111/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.5632 - accuracy: 0.7071\n",
      "Epoch 112/1500\n",
      "11/11 [==============================] - 0s 599us/step - loss: 0.5623 - accuracy: 0.7043\n",
      "Epoch 113/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5639 - accuracy: 0.7071\n",
      "Epoch 114/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.5636 - accuracy: 0.7043\n",
      "Epoch 115/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.5677 - accuracy: 0.7071\n",
      "Epoch 116/1500\n",
      "11/11 [==============================] - 0s 547us/step - loss: 0.5680 - accuracy: 0.7029\n",
      "Epoch 117/1500\n",
      "11/11 [==============================] - 0s 609us/step - loss: 0.5599 - accuracy: 0.7100\n",
      "Epoch 118/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.5845 - accuracy: 0.6986\n",
      "Epoch 119/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.5716 - accuracy: 0.7014\n",
      "Epoch 120/1500\n",
      "11/11 [==============================] - 0s 699us/step - loss: 0.5560 - accuracy: 0.7071\n",
      "Epoch 121/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5612 - accuracy: 0.7100\n",
      "Epoch 122/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.5613 - accuracy: 0.7071\n",
      "Epoch 123/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5635 - accuracy: 0.7171\n",
      "Epoch 124/1500\n",
      "11/11 [==============================] - 0s 654us/step - loss: 0.5575 - accuracy: 0.7129\n",
      "Epoch 125/1500\n",
      "11/11 [==============================] - 0s 767us/step - loss: 0.5534 - accuracy: 0.7086\n",
      "Epoch 126/1500\n",
      "11/11 [==============================] - 0s 734us/step - loss: 0.5547 - accuracy: 0.7171\n",
      "Epoch 127/1500\n",
      "11/11 [==============================] - 0s 649us/step - loss: 0.5562 - accuracy: 0.7086\n",
      "Epoch 128/1500\n",
      "11/11 [==============================] - 0s 621us/step - loss: 0.5560 - accuracy: 0.7086\n",
      "Epoch 129/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5673 - accuracy: 0.7057\n",
      "Epoch 130/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.5514 - accuracy: 0.7157\n",
      "Epoch 131/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5553 - accuracy: 0.7057\n",
      "Epoch 132/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.5512 - accuracy: 0.7171\n",
      "Epoch 133/1500\n",
      "11/11 [==============================] - 0s 648us/step - loss: 0.5517 - accuracy: 0.7100\n",
      "Epoch 134/1500\n",
      "11/11 [==============================] - 0s 583us/step - loss: 0.5542 - accuracy: 0.7157\n",
      "Epoch 135/1500\n",
      "11/11 [==============================] - 0s 727us/step - loss: 0.5592 - accuracy: 0.7129\n",
      "Epoch 136/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.5519 - accuracy: 0.7129\n",
      "Epoch 137/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.5554 - accuracy: 0.7171\n",
      "Epoch 138/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.5561 - accuracy: 0.7114\n",
      "Epoch 139/1500\n",
      "11/11 [==============================] - 0s 700us/step - loss: 0.5511 - accuracy: 0.7057\n",
      "Epoch 140/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5532 - accuracy: 0.7086\n",
      "Epoch 141/1500\n",
      "11/11 [==============================] - 0s 616us/step - loss: 0.5467 - accuracy: 0.7114\n",
      "Epoch 142/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.5542 - accuracy: 0.7129\n",
      "Epoch 143/1500\n",
      "11/11 [==============================] - 0s 577us/step - loss: 0.5488 - accuracy: 0.7171\n",
      "Epoch 144/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5501 - accuracy: 0.7071\n",
      "Epoch 145/1500\n",
      "11/11 [==============================] - 0s 593us/step - loss: 0.5594 - accuracy: 0.7143\n",
      "Epoch 146/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5503 - accuracy: 0.7100\n",
      "Epoch 147/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.5485 - accuracy: 0.7086\n",
      "Epoch 148/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5521 - accuracy: 0.7143\n",
      "Epoch 149/1500\n",
      "11/11 [==============================] - 0s 662us/step - loss: 0.5462 - accuracy: 0.7100\n",
      "Epoch 150/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.5448 - accuracy: 0.7143\n",
      "Epoch 151/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5463 - accuracy: 0.7143\n",
      "Epoch 152/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5456 - accuracy: 0.7086\n",
      "Epoch 153/1500\n",
      "11/11 [==============================] - 0s 669us/step - loss: 0.5484 - accuracy: 0.7114\n",
      "Epoch 154/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5480 - accuracy: 0.7171\n",
      "Epoch 155/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5464 - accuracy: 0.7100\n",
      "Epoch 156/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.5523 - accuracy: 0.7229\n",
      "Epoch 157/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.5462 - accuracy: 0.7129\n",
      "Epoch 158/1500\n",
      "11/11 [==============================] - 0s 691us/step - loss: 0.5458 - accuracy: 0.7171\n",
      "Epoch 159/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 544us/step - loss: 0.5448 - accuracy: 0.7086\n",
      "Epoch 160/1500\n",
      "11/11 [==============================] - 0s 601us/step - loss: 0.5432 - accuracy: 0.7143\n",
      "Epoch 161/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5478 - accuracy: 0.7157\n",
      "Epoch 162/1500\n",
      "11/11 [==============================] - 0s 655us/step - loss: 0.5458 - accuracy: 0.7114\n",
      "Epoch 163/1500\n",
      "11/11 [==============================] - 0s 723us/step - loss: 0.5435 - accuracy: 0.7186\n",
      "Epoch 164/1500\n",
      "11/11 [==============================] - 0s 664us/step - loss: 0.5460 - accuracy: 0.7186\n",
      "Epoch 165/1500\n",
      "11/11 [==============================] - 0s 714us/step - loss: 0.5448 - accuracy: 0.7129\n",
      "Epoch 166/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.5457 - accuracy: 0.7157\n",
      "Epoch 167/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.5422 - accuracy: 0.7114\n",
      "Epoch 168/1500\n",
      "11/11 [==============================] - 0s 595us/step - loss: 0.5427 - accuracy: 0.7071\n",
      "Epoch 169/1500\n",
      "11/11 [==============================] - 0s 657us/step - loss: 0.5467 - accuracy: 0.7100\n",
      "Epoch 170/1500\n",
      "11/11 [==============================] - 0s 716us/step - loss: 0.5438 - accuracy: 0.7157\n",
      "Epoch 171/1500\n",
      "11/11 [==============================] - 0s 699us/step - loss: 0.5465 - accuracy: 0.7114\n",
      "Epoch 172/1500\n",
      "11/11 [==============================] - 0s 663us/step - loss: 0.5404 - accuracy: 0.7157\n",
      "Epoch 173/1500\n",
      "11/11 [==============================] - 0s 578us/step - loss: 0.5403 - accuracy: 0.7186\n",
      "Epoch 174/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.5452 - accuracy: 0.7143\n",
      "Epoch 175/1500\n",
      "11/11 [==============================] - 0s 653us/step - loss: 0.5391 - accuracy: 0.7243\n",
      "Epoch 176/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5462 - accuracy: 0.7086\n",
      "Epoch 177/1500\n",
      "11/11 [==============================] - 0s 543us/step - loss: 0.5530 - accuracy: 0.6957\n",
      "Epoch 178/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5467 - accuracy: 0.7114\n",
      "Epoch 179/1500\n",
      "11/11 [==============================] - 0s 592us/step - loss: 0.5458 - accuracy: 0.7229\n",
      "Epoch 180/1500\n",
      "11/11 [==============================] - 0s 730us/step - loss: 0.5402 - accuracy: 0.7186\n",
      "Epoch 181/1500\n",
      "11/11 [==============================] - 0s 524us/step - loss: 0.5396 - accuracy: 0.7114\n",
      "Epoch 182/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5411 - accuracy: 0.7186\n",
      "Epoch 183/1500\n",
      "11/11 [==============================] - 0s 655us/step - loss: 0.5368 - accuracy: 0.7200\n",
      "Epoch 184/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5406 - accuracy: 0.7114\n",
      "Epoch 185/1500\n",
      "11/11 [==============================] - 0s 618us/step - loss: 0.5466 - accuracy: 0.7214\n",
      "Epoch 186/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.5402 - accuracy: 0.7157\n",
      "Epoch 187/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5395 - accuracy: 0.7143\n",
      "Epoch 188/1500\n",
      "11/11 [==============================] - 0s 617us/step - loss: 0.5419 - accuracy: 0.7214\n",
      "Epoch 189/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5410 - accuracy: 0.7129\n",
      "Epoch 190/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.5405 - accuracy: 0.7143\n",
      "Epoch 191/1500\n",
      "11/11 [==============================] - 0s 624us/step - loss: 0.5386 - accuracy: 0.7229\n",
      "Epoch 192/1500\n",
      "11/11 [==============================] - 0s 669us/step - loss: 0.5348 - accuracy: 0.7200\n",
      "Epoch 193/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.5353 - accuracy: 0.7229\n",
      "Epoch 194/1500\n",
      "11/11 [==============================] - 0s 700us/step - loss: 0.5365 - accuracy: 0.7200\n",
      "Epoch 195/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5371 - accuracy: 0.7157\n",
      "Epoch 196/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5349 - accuracy: 0.7214\n",
      "Epoch 197/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.5367 - accuracy: 0.7157\n",
      "Epoch 198/1500\n",
      "11/11 [==============================] - 0s 578us/step - loss: 0.5387 - accuracy: 0.7157\n",
      "Epoch 199/1500\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.5367 - accuracy: 0.7257\n",
      "Epoch 200/1500\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.5376 - accuracy: 0.7186\n",
      "Epoch 201/1500\n",
      "11/11 [==============================] - 0s 855us/step - loss: 0.5356 - accuracy: 0.7143\n",
      "Epoch 202/1500\n",
      "11/11 [==============================] - 0s 779us/step - loss: 0.5394 - accuracy: 0.7129\n",
      "Epoch 203/1500\n",
      "11/11 [==============================] - 0s 646us/step - loss: 0.5380 - accuracy: 0.7200\n",
      "Epoch 204/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.5356 - accuracy: 0.7286\n",
      "Epoch 205/1500\n",
      "11/11 [==============================] - 0s 595us/step - loss: 0.5385 - accuracy: 0.7271\n",
      "Epoch 206/1500\n",
      "11/11 [==============================] - 0s 556us/step - loss: 0.5351 - accuracy: 0.7186\n",
      "Epoch 207/1500\n",
      "11/11 [==============================] - 0s 655us/step - loss: 0.5402 - accuracy: 0.7200\n",
      "Epoch 208/1500\n",
      "11/11 [==============================] - 0s 702us/step - loss: 0.5464 - accuracy: 0.7229\n",
      "Epoch 209/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.5409 - accuracy: 0.7300\n",
      "Epoch 210/1500\n",
      "11/11 [==============================] - 0s 581us/step - loss: 0.5322 - accuracy: 0.7186\n",
      "Epoch 211/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5391 - accuracy: 0.7114\n",
      "Epoch 212/1500\n",
      "11/11 [==============================] - 0s 616us/step - loss: 0.5328 - accuracy: 0.7257\n",
      "Epoch 213/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5312 - accuracy: 0.7271\n",
      "Epoch 214/1500\n",
      "11/11 [==============================] - 0s 577us/step - loss: 0.5302 - accuracy: 0.7271\n",
      "Epoch 215/1500\n",
      "11/11 [==============================] - 0s 724us/step - loss: 0.5317 - accuracy: 0.7271\n",
      "Epoch 216/1500\n",
      "11/11 [==============================] - 0s 650us/step - loss: 0.5334 - accuracy: 0.7286\n",
      "Epoch 217/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.5394 - accuracy: 0.7214\n",
      "Epoch 218/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5409 - accuracy: 0.7157\n",
      "Epoch 219/1500\n",
      "11/11 [==============================] - 0s 653us/step - loss: 0.5377 - accuracy: 0.7100\n",
      "Epoch 220/1500\n",
      "11/11 [==============================] - 0s 587us/step - loss: 0.5326 - accuracy: 0.7229\n",
      "Epoch 221/1500\n",
      "11/11 [==============================] - 0s 709us/step - loss: 0.5324 - accuracy: 0.7243\n",
      "Epoch 222/1500\n",
      "11/11 [==============================] - 0s 724us/step - loss: 0.5350 - accuracy: 0.7229\n",
      "Epoch 223/1500\n",
      "11/11 [==============================] - 0s 749us/step - loss: 0.5326 - accuracy: 0.7257\n",
      "Epoch 224/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.5310 - accuracy: 0.7229\n",
      "Epoch 225/1500\n",
      "11/11 [==============================] - 0s 691us/step - loss: 0.5277 - accuracy: 0.7171\n",
      "Epoch 226/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5341 - accuracy: 0.7314\n",
      "Epoch 227/1500\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.73 - 0s 544us/step - loss: 0.5289 - accuracy: 0.7214\n",
      "Epoch 228/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.5326 - accuracy: 0.7300\n",
      "Epoch 229/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.5301 - accuracy: 0.7257\n",
      "Epoch 230/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5284 - accuracy: 0.7143\n",
      "Epoch 231/1500\n",
      "11/11 [==============================] - 0s 590us/step - loss: 0.5289 - accuracy: 0.7271\n",
      "Epoch 232/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5289 - accuracy: 0.7243\n",
      "Epoch 233/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5284 - accuracy: 0.7243\n",
      "Epoch 234/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5297 - accuracy: 0.7229\n",
      "Epoch 235/1500\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.5342 - accuracy: 0.7286\n",
      "Epoch 236/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5410 - accuracy: 0.7143\n",
      "Epoch 237/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 630us/step - loss: 0.5328 - accuracy: 0.7186\n",
      "Epoch 238/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5324 - accuracy: 0.7286\n",
      "Epoch 239/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.5282 - accuracy: 0.7229\n",
      "Epoch 240/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.5318 - accuracy: 0.7300\n",
      "Epoch 241/1500\n",
      "11/11 [==============================] - 0s 553us/step - loss: 0.5301 - accuracy: 0.7286\n",
      "Epoch 242/1500\n",
      "11/11 [==============================] - 0s 663us/step - loss: 0.5320 - accuracy: 0.7314\n",
      "Epoch 243/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5431 - accuracy: 0.7214\n",
      "Epoch 244/1500\n",
      "11/11 [==============================] - 0s 572us/step - loss: 0.5279 - accuracy: 0.7300\n",
      "Epoch 245/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5311 - accuracy: 0.7286\n",
      "Epoch 246/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.5304 - accuracy: 0.7300\n",
      "Epoch 247/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.5313 - accuracy: 0.7314\n",
      "Epoch 248/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5359 - accuracy: 0.7214\n",
      "Epoch 249/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.5300 - accuracy: 0.7157\n",
      "Epoch 250/1500\n",
      "11/11 [==============================] - 0s 653us/step - loss: 0.5251 - accuracy: 0.7357\n",
      "Epoch 251/1500\n",
      "11/11 [==============================] - 0s 734us/step - loss: 0.5368 - accuracy: 0.7200\n",
      "Epoch 252/1500\n",
      "11/11 [==============================] - 0s 549us/step - loss: 0.5443 - accuracy: 0.7186\n",
      "Epoch 253/1500\n",
      "11/11 [==============================] - 0s 657us/step - loss: 0.5262 - accuracy: 0.7257\n",
      "Epoch 254/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.5301 - accuracy: 0.7200\n",
      "Epoch 255/1500\n",
      "11/11 [==============================] - 0s 708us/step - loss: 0.5251 - accuracy: 0.7257\n",
      "Epoch 256/1500\n",
      "11/11 [==============================] - 0s 476us/step - loss: 0.5267 - accuracy: 0.7314\n",
      "Epoch 257/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.5296 - accuracy: 0.7214\n",
      "Epoch 258/1500\n",
      "11/11 [==============================] - 0s 678us/step - loss: 0.5255 - accuracy: 0.7214\n",
      "Epoch 259/1500\n",
      "11/11 [==============================] - 0s 730us/step - loss: 0.5243 - accuracy: 0.7300\n",
      "Epoch 260/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5280 - accuracy: 0.7229\n",
      "Epoch 261/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.5228 - accuracy: 0.7329\n",
      "Epoch 262/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5269 - accuracy: 0.7329\n",
      "Epoch 263/1500\n",
      "11/11 [==============================] - 0s 665us/step - loss: 0.5334 - accuracy: 0.7257\n",
      "Epoch 264/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5302 - accuracy: 0.7314\n",
      "Epoch 265/1500\n",
      "11/11 [==============================] - 0s 746us/step - loss: 0.5284 - accuracy: 0.7271\n",
      "Epoch 266/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.5248 - accuracy: 0.7329\n",
      "Epoch 267/1500\n",
      "11/11 [==============================] - 0s 496us/step - loss: 0.5270 - accuracy: 0.7400\n",
      "Epoch 268/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.5254 - accuracy: 0.7286\n",
      "Epoch 269/1500\n",
      "11/11 [==============================] - 0s 606us/step - loss: 0.5333 - accuracy: 0.7257\n",
      "Epoch 270/1500\n",
      "11/11 [==============================] - 0s 775us/step - loss: 0.5309 - accuracy: 0.7200\n",
      "Epoch 271/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.5224 - accuracy: 0.7357\n",
      "Epoch 272/1500\n",
      "11/11 [==============================] - 0s 666us/step - loss: 0.5280 - accuracy: 0.7229\n",
      "Epoch 273/1500\n",
      "11/11 [==============================] - 0s 593us/step - loss: 0.5289 - accuracy: 0.7329\n",
      "Epoch 274/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.5263 - accuracy: 0.7229\n",
      "Epoch 275/1500\n",
      "11/11 [==============================] - 0s 603us/step - loss: 0.5273 - accuracy: 0.7286\n",
      "Epoch 276/1500\n",
      "11/11 [==============================] - 0s 649us/step - loss: 0.5318 - accuracy: 0.7243\n",
      "Epoch 277/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.5209 - accuracy: 0.7314\n",
      "Epoch 278/1500\n",
      "11/11 [==============================] - 0s 573us/step - loss: 0.5244 - accuracy: 0.7243\n",
      "Epoch 279/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.5265 - accuracy: 0.7243\n",
      "Epoch 280/1500\n",
      "11/11 [==============================] - 0s 655us/step - loss: 0.5236 - accuracy: 0.7329\n",
      "Epoch 281/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5322 - accuracy: 0.7257\n",
      "Epoch 282/1500\n",
      "11/11 [==============================] - 0s 563us/step - loss: 0.5337 - accuracy: 0.7457\n",
      "Epoch 283/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.5273 - accuracy: 0.7386\n",
      "Epoch 284/1500\n",
      "11/11 [==============================] - 0s 613us/step - loss: 0.5264 - accuracy: 0.7343\n",
      "Epoch 285/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5236 - accuracy: 0.7286\n",
      "Epoch 286/1500\n",
      "11/11 [==============================] - 0s 558us/step - loss: 0.5213 - accuracy: 0.7286\n",
      "Epoch 287/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5195 - accuracy: 0.7300\n",
      "Epoch 288/1500\n",
      "11/11 [==============================] - 0s 578us/step - loss: 0.5196 - accuracy: 0.7357\n",
      "Epoch 289/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5215 - accuracy: 0.7200\n",
      "Epoch 290/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5197 - accuracy: 0.7400\n",
      "Epoch 291/1500\n",
      "11/11 [==============================] - 0s 687us/step - loss: 0.5288 - accuracy: 0.7300\n",
      "Epoch 292/1500\n",
      "11/11 [==============================] - 0s 672us/step - loss: 0.5202 - accuracy: 0.7214\n",
      "Epoch 293/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5199 - accuracy: 0.7314\n",
      "Epoch 294/1500\n",
      "11/11 [==============================] - 0s 482us/step - loss: 0.5216 - accuracy: 0.7243\n",
      "Epoch 295/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5232 - accuracy: 0.7286\n",
      "Epoch 296/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5182 - accuracy: 0.7357\n",
      "Epoch 297/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5192 - accuracy: 0.7186\n",
      "Epoch 298/1500\n",
      "11/11 [==============================] - 0s 671us/step - loss: 0.5197 - accuracy: 0.7386\n",
      "Epoch 299/1500\n",
      "11/11 [==============================] - 0s 553us/step - loss: 0.5284 - accuracy: 0.7143\n",
      "Epoch 300/1500\n",
      "11/11 [==============================] - 0s 648us/step - loss: 0.5215 - accuracy: 0.7314\n",
      "Epoch 301/1500\n",
      "11/11 [==============================] - 0s 650us/step - loss: 0.5194 - accuracy: 0.7443\n",
      "Epoch 302/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.5222 - accuracy: 0.7357\n",
      "Epoch 303/1500\n",
      "11/11 [==============================] - 0s 681us/step - loss: 0.5165 - accuracy: 0.7271\n",
      "Epoch 304/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5211 - accuracy: 0.7229\n",
      "Epoch 305/1500\n",
      "11/11 [==============================] - 0s 668us/step - loss: 0.5236 - accuracy: 0.7286\n",
      "Epoch 306/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5152 - accuracy: 0.7271\n",
      "Epoch 307/1500\n",
      "11/11 [==============================] - 0s 681us/step - loss: 0.5247 - accuracy: 0.7214\n",
      "Epoch 308/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5198 - accuracy: 0.7329\n",
      "Epoch 309/1500\n",
      "11/11 [==============================] - 0s 592us/step - loss: 0.5186 - accuracy: 0.7300\n",
      "Epoch 310/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5162 - accuracy: 0.7257\n",
      "Epoch 311/1500\n",
      "11/11 [==============================] - 0s 537us/step - loss: 0.5157 - accuracy: 0.7271\n",
      "Epoch 312/1500\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.5149 - accuracy: 0.7371\n",
      "Epoch 313/1500\n",
      "11/11 [==============================] - 0s 605us/step - loss: 0.5185 - accuracy: 0.7271\n",
      "Epoch 314/1500\n",
      "11/11 [==============================] - 0s 753us/step - loss: 0.5153 - accuracy: 0.7314\n",
      "Epoch 315/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 806us/step - loss: 0.5162 - accuracy: 0.7357\n",
      "Epoch 316/1500\n",
      "11/11 [==============================] - 0s 661us/step - loss: 0.5128 - accuracy: 0.7371\n",
      "Epoch 317/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.5138 - accuracy: 0.7429\n",
      "Epoch 318/1500\n",
      "11/11 [==============================] - 0s 684us/step - loss: 0.5181 - accuracy: 0.7443\n",
      "Epoch 319/1500\n",
      "11/11 [==============================] - 0s 715us/step - loss: 0.5336 - accuracy: 0.7243\n",
      "Epoch 320/1500\n",
      "11/11 [==============================] - 0s 660us/step - loss: 0.5238 - accuracy: 0.7400\n",
      "Epoch 321/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.5189 - accuracy: 0.7357\n",
      "Epoch 322/1500\n",
      "11/11 [==============================] - 0s 571us/step - loss: 0.5248 - accuracy: 0.7243\n",
      "Epoch 323/1500\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.5101 - accuracy: 0.7357\n",
      "Epoch 324/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5099 - accuracy: 0.7371\n",
      "Epoch 325/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5144 - accuracy: 0.7414\n",
      "Epoch 326/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.5109 - accuracy: 0.7414\n",
      "Epoch 327/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.5085 - accuracy: 0.7429\n",
      "Epoch 328/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5131 - accuracy: 0.7329\n",
      "Epoch 329/1500\n",
      "11/11 [==============================] - 0s 594us/step - loss: 0.5089 - accuracy: 0.7429\n",
      "Epoch 330/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.5079 - accuracy: 0.7386\n",
      "Epoch 331/1500\n",
      "11/11 [==============================] - 0s 595us/step - loss: 0.5168 - accuracy: 0.7257\n",
      "Epoch 332/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.5141 - accuracy: 0.7443\n",
      "Epoch 333/1500\n",
      "11/11 [==============================] - 0s 617us/step - loss: 0.5161 - accuracy: 0.7429\n",
      "Epoch 334/1500\n",
      "11/11 [==============================] - 0s 517us/step - loss: 0.5149 - accuracy: 0.7443\n",
      "Epoch 335/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.5148 - accuracy: 0.7414\n",
      "Epoch 336/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.5100 - accuracy: 0.7557\n",
      "Epoch 337/1500\n",
      "11/11 [==============================] - 0s 542us/step - loss: 0.5116 - accuracy: 0.7343\n",
      "Epoch 338/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.5049 - accuracy: 0.7486\n",
      "Epoch 339/1500\n",
      "11/11 [==============================] - 0s 583us/step - loss: 0.5056 - accuracy: 0.7429\n",
      "Epoch 340/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.5091 - accuracy: 0.7414\n",
      "Epoch 341/1500\n",
      "11/11 [==============================] - 0s 540us/step - loss: 0.5046 - accuracy: 0.7300\n",
      "Epoch 342/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5051 - accuracy: 0.7457\n",
      "Epoch 343/1500\n",
      "11/11 [==============================] - 0s 537us/step - loss: 0.5020 - accuracy: 0.7429\n",
      "Epoch 344/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5041 - accuracy: 0.7414\n",
      "Epoch 345/1500\n",
      "11/11 [==============================] - 0s 528us/step - loss: 0.5056 - accuracy: 0.7514\n",
      "Epoch 346/1500\n",
      "11/11 [==============================] - 0s 665us/step - loss: 0.5026 - accuracy: 0.7414\n",
      "Epoch 347/1500\n",
      "11/11 [==============================] - 0s 487us/step - loss: 0.5060 - accuracy: 0.7400\n",
      "Epoch 348/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5098 - accuracy: 0.7414\n",
      "Epoch 349/1500\n",
      "11/11 [==============================] - 0s 553us/step - loss: 0.5060 - accuracy: 0.7571\n",
      "Epoch 350/1500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.5182 - accuracy: 0.7457\n",
      "Epoch 351/1500\n",
      "11/11 [==============================] - 0s 572us/step - loss: 0.5051 - accuracy: 0.7586\n",
      "Epoch 352/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.5051 - accuracy: 0.7514\n",
      "Epoch 353/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.5061 - accuracy: 0.7371\n",
      "Epoch 354/1500\n",
      "11/11 [==============================] - 0s 685us/step - loss: 0.5031 - accuracy: 0.7486\n",
      "Epoch 355/1500\n",
      "11/11 [==============================] - 0s 715us/step - loss: 0.4997 - accuracy: 0.7486\n",
      "Epoch 356/1500\n",
      "11/11 [==============================] - 0s 658us/step - loss: 0.5008 - accuracy: 0.7471\n",
      "Epoch 357/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.5007 - accuracy: 0.7414\n",
      "Epoch 358/1500\n",
      "11/11 [==============================] - 0s 613us/step - loss: 0.5060 - accuracy: 0.7414\n",
      "Epoch 359/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5020 - accuracy: 0.7486\n",
      "Epoch 360/1500\n",
      "11/11 [==============================] - 0s 691us/step - loss: 0.5008 - accuracy: 0.7486\n",
      "Epoch 361/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.5075 - accuracy: 0.7529\n",
      "Epoch 362/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5058 - accuracy: 0.7486\n",
      "Epoch 363/1500\n",
      "11/11 [==============================] - 0s 655us/step - loss: 0.5027 - accuracy: 0.7486\n",
      "Epoch 364/1500\n",
      "11/11 [==============================] - 0s 785us/step - loss: 0.5008 - accuracy: 0.7500\n",
      "Epoch 365/1500\n",
      "11/11 [==============================] - 0s 587us/step - loss: 0.5090 - accuracy: 0.7429\n",
      "Epoch 366/1500\n",
      "11/11 [==============================] - 0s 729us/step - loss: 0.5147 - accuracy: 0.7514\n",
      "Epoch 367/1500\n",
      "11/11 [==============================] - 0s 622us/step - loss: 0.5070 - accuracy: 0.7514\n",
      "Epoch 368/1500\n",
      "11/11 [==============================] - 0s 550us/step - loss: 0.5044 - accuracy: 0.7429\n",
      "Epoch 369/1500\n",
      "11/11 [==============================] - 0s 703us/step - loss: 0.5230 - accuracy: 0.7371\n",
      "Epoch 370/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.5011 - accuracy: 0.7471\n",
      "Epoch 371/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.5042 - accuracy: 0.7500\n",
      "Epoch 372/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.5021 - accuracy: 0.7471\n",
      "Epoch 373/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.5006 - accuracy: 0.7443\n",
      "Epoch 374/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4984 - accuracy: 0.7457\n",
      "Epoch 375/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5069 - accuracy: 0.7514\n",
      "Epoch 376/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.5003 - accuracy: 0.7529\n",
      "Epoch 377/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.4952 - accuracy: 0.7557\n",
      "Epoch 378/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4990 - accuracy: 0.7443\n",
      "Epoch 379/1500\n",
      "11/11 [==============================] - 0s 622us/step - loss: 0.4956 - accuracy: 0.7557\n",
      "Epoch 380/1500\n",
      "11/11 [==============================] - 0s 646us/step - loss: 0.4979 - accuracy: 0.7629\n",
      "Epoch 381/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4951 - accuracy: 0.7543\n",
      "Epoch 382/1500\n",
      "11/11 [==============================] - 0s 674us/step - loss: 0.5032 - accuracy: 0.7543\n",
      "Epoch 383/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.4999 - accuracy: 0.7543\n",
      "Epoch 384/1500\n",
      "11/11 [==============================] - 0s 554us/step - loss: 0.5058 - accuracy: 0.7457\n",
      "Epoch 385/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.5030 - accuracy: 0.7543\n",
      "Epoch 386/1500\n",
      "11/11 [==============================] - 0s 649us/step - loss: 0.4983 - accuracy: 0.7400\n",
      "Epoch 387/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4956 - accuracy: 0.7457\n",
      "Epoch 388/1500\n",
      "11/11 [==============================] - 0s 700us/step - loss: 0.4984 - accuracy: 0.7486\n",
      "Epoch 389/1500\n",
      "11/11 [==============================] - 0s 672us/step - loss: 0.4962 - accuracy: 0.7500\n",
      "Epoch 390/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5005 - accuracy: 0.7443\n",
      "Epoch 391/1500\n",
      "11/11 [==============================] - 0s 710us/step - loss: 0.4947 - accuracy: 0.7500\n",
      "Epoch 392/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5111 - accuracy: 0.7357\n",
      "Epoch 393/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 576us/step - loss: 0.5050 - accuracy: 0.7529\n",
      "Epoch 394/1500\n",
      "11/11 [==============================] - 0s 638us/step - loss: 0.4998 - accuracy: 0.7600\n",
      "Epoch 395/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4963 - accuracy: 0.7457\n",
      "Epoch 396/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.5010 - accuracy: 0.7457\n",
      "Epoch 397/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5012 - accuracy: 0.7543\n",
      "Epoch 398/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.5106 - accuracy: 0.7486\n",
      "Epoch 399/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4938 - accuracy: 0.7571\n",
      "Epoch 400/1500\n",
      "11/11 [==============================] - 0s 656us/step - loss: 0.4925 - accuracy: 0.7471\n",
      "Epoch 401/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4971 - accuracy: 0.7543\n",
      "Epoch 402/1500\n",
      "11/11 [==============================] - 0s 647us/step - loss: 0.4983 - accuracy: 0.7629\n",
      "Epoch 403/1500\n",
      "11/11 [==============================] - 0s 807us/step - loss: 0.4961 - accuracy: 0.7586\n",
      "Epoch 404/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4987 - accuracy: 0.7543\n",
      "Epoch 405/1500\n",
      "11/11 [==============================] - 0s 765us/step - loss: 0.4977 - accuracy: 0.7643\n",
      "Epoch 406/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5135 - accuracy: 0.7457\n",
      "Epoch 407/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4997 - accuracy: 0.7500\n",
      "Epoch 408/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4984 - accuracy: 0.7486\n",
      "Epoch 409/1500\n",
      "11/11 [==============================] - 0s 575us/step - loss: 0.4953 - accuracy: 0.7557\n",
      "Epoch 410/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4976 - accuracy: 0.7486\n",
      "Epoch 411/1500\n",
      "11/11 [==============================] - 0s 576us/step - loss: 0.4930 - accuracy: 0.7571\n",
      "Epoch 412/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.4996 - accuracy: 0.7586\n",
      "Epoch 413/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5001 - accuracy: 0.7371\n",
      "Epoch 414/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4936 - accuracy: 0.7514\n",
      "Epoch 415/1500\n",
      "11/11 [==============================] - 0s 647us/step - loss: 0.4919 - accuracy: 0.7529\n",
      "Epoch 416/1500\n",
      "11/11 [==============================] - 0s 649us/step - loss: 0.4902 - accuracy: 0.7500\n",
      "Epoch 417/1500\n",
      "11/11 [==============================] - 0s 557us/step - loss: 0.4934 - accuracy: 0.7529\n",
      "Epoch 418/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.5037 - accuracy: 0.7586\n",
      "Epoch 419/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.5085 - accuracy: 0.7457\n",
      "Epoch 420/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.5108 - accuracy: 0.7543\n",
      "Epoch 421/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.5094 - accuracy: 0.7457\n",
      "Epoch 422/1500\n",
      "11/11 [==============================] - 0s 794us/step - loss: 0.4975 - accuracy: 0.7600\n",
      "Epoch 423/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4887 - accuracy: 0.7700\n",
      "Epoch 424/1500\n",
      "11/11 [==============================] - 0s 704us/step - loss: 0.4889 - accuracy: 0.7686\n",
      "Epoch 425/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4948 - accuracy: 0.7629\n",
      "Epoch 426/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4931 - accuracy: 0.7600\n",
      "Epoch 427/1500\n",
      "11/11 [==============================] - 0s 624us/step - loss: 0.4922 - accuracy: 0.7600\n",
      "Epoch 428/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.4918 - accuracy: 0.7600\n",
      "Epoch 429/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4898 - accuracy: 0.7529\n",
      "Epoch 430/1500\n",
      "11/11 [==============================] - 0s 597us/step - loss: 0.4937 - accuracy: 0.7486\n",
      "Epoch 431/1500\n",
      "11/11 [==============================] - 0s 789us/step - loss: 0.4883 - accuracy: 0.7486\n",
      "Epoch 432/1500\n",
      "11/11 [==============================] - 0s 607us/step - loss: 0.4892 - accuracy: 0.7514\n",
      "Epoch 433/1500\n",
      "11/11 [==============================] - 0s 638us/step - loss: 0.4913 - accuracy: 0.7543\n",
      "Epoch 434/1500\n",
      "11/11 [==============================] - 0s 545us/step - loss: 0.4902 - accuracy: 0.7557\n",
      "Epoch 435/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4914 - accuracy: 0.7486\n",
      "Epoch 436/1500\n",
      "11/11 [==============================] - 0s 586us/step - loss: 0.4964 - accuracy: 0.7486\n",
      "Epoch 437/1500\n",
      "11/11 [==============================] - 0s 676us/step - loss: 0.4981 - accuracy: 0.7557\n",
      "Epoch 438/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4985 - accuracy: 0.7529\n",
      "Epoch 439/1500\n",
      "11/11 [==============================] - 0s 655us/step - loss: 0.4938 - accuracy: 0.7514\n",
      "Epoch 440/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4869 - accuracy: 0.7586\n",
      "Epoch 441/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4883 - accuracy: 0.7571\n",
      "Epoch 442/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4887 - accuracy: 0.7571\n",
      "Epoch 443/1500\n",
      "11/11 [==============================] - 0s 662us/step - loss: 0.4958 - accuracy: 0.7557\n",
      "Epoch 444/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4931 - accuracy: 0.7586\n",
      "Epoch 445/1500\n",
      "11/11 [==============================] - 0s 580us/step - loss: 0.4992 - accuracy: 0.7600\n",
      "Epoch 446/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4950 - accuracy: 0.7557\n",
      "Epoch 447/1500\n",
      "11/11 [==============================] - 0s 619us/step - loss: 0.4879 - accuracy: 0.7671\n",
      "Epoch 448/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4941 - accuracy: 0.7614\n",
      "Epoch 449/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.4872 - accuracy: 0.7586\n",
      "Epoch 450/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4890 - accuracy: 0.7529\n",
      "Epoch 451/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.4869 - accuracy: 0.7543\n",
      "Epoch 452/1500\n",
      "11/11 [==============================] - 0s 724us/step - loss: 0.4891 - accuracy: 0.7443\n",
      "Epoch 453/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4942 - accuracy: 0.7557\n",
      "Epoch 454/1500\n",
      "11/11 [==============================] - 0s 607us/step - loss: 0.4850 - accuracy: 0.7586\n",
      "Epoch 455/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4878 - accuracy: 0.7543\n",
      "Epoch 456/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4885 - accuracy: 0.7557\n",
      "Epoch 457/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4999 - accuracy: 0.7400\n",
      "Epoch 458/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.4919 - accuracy: 0.7686\n",
      "Epoch 459/1500\n",
      "11/11 [==============================] - 0s 547us/step - loss: 0.4943 - accuracy: 0.7486\n",
      "Epoch 460/1500\n",
      "11/11 [==============================] - 0s 736us/step - loss: 0.4833 - accuracy: 0.7614\n",
      "Epoch 461/1500\n",
      "11/11 [==============================] - 0s 638us/step - loss: 0.4847 - accuracy: 0.7643\n",
      "Epoch 462/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4856 - accuracy: 0.7586\n",
      "Epoch 463/1500\n",
      "11/11 [==============================] - 0s 669us/step - loss: 0.4911 - accuracy: 0.7457\n",
      "Epoch 464/1500\n",
      "11/11 [==============================] - 0s 668us/step - loss: 0.4950 - accuracy: 0.7629\n",
      "Epoch 465/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4842 - accuracy: 0.7600\n",
      "Epoch 466/1500\n",
      "11/11 [==============================] - 0s 538us/step - loss: 0.4935 - accuracy: 0.7586\n",
      "Epoch 467/1500\n",
      "11/11 [==============================] - 0s 670us/step - loss: 0.4838 - accuracy: 0.7586\n",
      "Epoch 468/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4825 - accuracy: 0.7629\n",
      "Epoch 469/1500\n",
      "11/11 [==============================] - 0s 668us/step - loss: 0.4850 - accuracy: 0.7514\n",
      "Epoch 470/1500\n",
      "11/11 [==============================] - 0s 808us/step - loss: 0.4866 - accuracy: 0.7514\n",
      "Epoch 471/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 622us/step - loss: 0.4860 - accuracy: 0.7657\n",
      "Epoch 472/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4891 - accuracy: 0.7557\n",
      "Epoch 473/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.4874 - accuracy: 0.7557\n",
      "Epoch 474/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4903 - accuracy: 0.7514\n",
      "Epoch 475/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.4870 - accuracy: 0.7614\n",
      "Epoch 476/1500\n",
      "11/11 [==============================] - 0s 714us/step - loss: 0.4883 - accuracy: 0.7600\n",
      "Epoch 477/1500\n",
      "11/11 [==============================] - 0s 811us/step - loss: 0.4806 - accuracy: 0.7557\n",
      "Epoch 478/1500\n",
      "11/11 [==============================] - 0s 616us/step - loss: 0.4829 - accuracy: 0.7500\n",
      "Epoch 479/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4826 - accuracy: 0.7614\n",
      "Epoch 480/1500\n",
      "11/11 [==============================] - 0s 617us/step - loss: 0.4835 - accuracy: 0.7471\n",
      "Epoch 481/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.4838 - accuracy: 0.7629\n",
      "Epoch 482/1500\n",
      "11/11 [==============================] - 0s 524us/step - loss: 0.4861 - accuracy: 0.7614\n",
      "Epoch 483/1500\n",
      "11/11 [==============================] - 0s 723us/step - loss: 0.4834 - accuracy: 0.7543\n",
      "Epoch 484/1500\n",
      "11/11 [==============================] - 0s 552us/step - loss: 0.4947 - accuracy: 0.7557\n",
      "Epoch 485/1500\n",
      "11/11 [==============================] - 0s 740us/step - loss: 0.4910 - accuracy: 0.7514\n",
      "Epoch 486/1500\n",
      "11/11 [==============================] - 0s 621us/step - loss: 0.4880 - accuracy: 0.7686\n",
      "Epoch 487/1500\n",
      "11/11 [==============================] - 0s 584us/step - loss: 0.4854 - accuracy: 0.7514\n",
      "Epoch 488/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4855 - accuracy: 0.7629\n",
      "Epoch 489/1500\n",
      "11/11 [==============================] - 0s 617us/step - loss: 0.4887 - accuracy: 0.7671\n",
      "Epoch 490/1500\n",
      "11/11 [==============================] - 0s 716us/step - loss: 0.4883 - accuracy: 0.7643\n",
      "Epoch 491/1500\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.4820 - accuracy: 0.7600\n",
      "Epoch 492/1500\n",
      "11/11 [==============================] - 0s 716us/step - loss: 0.4837 - accuracy: 0.7614\n",
      "Epoch 493/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4805 - accuracy: 0.7600\n",
      "Epoch 494/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4802 - accuracy: 0.7629\n",
      "Epoch 495/1500\n",
      "11/11 [==============================] - 0s 654us/step - loss: 0.4829 - accuracy: 0.7629\n",
      "Epoch 496/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4821 - accuracy: 0.7586\n",
      "Epoch 497/1500\n",
      "11/11 [==============================] - 0s 710us/step - loss: 0.4846 - accuracy: 0.7414\n",
      "Epoch 498/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4789 - accuracy: 0.7614\n",
      "Epoch 499/1500\n",
      "11/11 [==============================] - 0s 601us/step - loss: 0.4824 - accuracy: 0.7571\n",
      "Epoch 500/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4849 - accuracy: 0.7543\n",
      "Epoch 501/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4840 - accuracy: 0.7614\n",
      "Epoch 502/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4852 - accuracy: 0.7557\n",
      "Epoch 503/1500\n",
      "11/11 [==============================] - 0s 815us/step - loss: 0.4901 - accuracy: 0.7557\n",
      "Epoch 504/1500\n",
      "11/11 [==============================] - 0s 728us/step - loss: 0.4917 - accuracy: 0.7600\n",
      "Epoch 505/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4889 - accuracy: 0.7543\n",
      "Epoch 506/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4804 - accuracy: 0.7757\n",
      "Epoch 507/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4805 - accuracy: 0.7571\n",
      "Epoch 508/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4787 - accuracy: 0.7629\n",
      "Epoch 509/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4769 - accuracy: 0.7571\n",
      "Epoch 510/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4924 - accuracy: 0.7686\n",
      "Epoch 511/1500\n",
      "11/11 [==============================] - 0s 665us/step - loss: 0.5060 - accuracy: 0.7543\n",
      "Epoch 512/1500\n",
      "11/11 [==============================] - 0s 732us/step - loss: 0.4831 - accuracy: 0.7543\n",
      "Epoch 513/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4791 - accuracy: 0.7729\n",
      "Epoch 514/1500\n",
      "11/11 [==============================] - 0s 817us/step - loss: 0.4851 - accuracy: 0.7614\n",
      "Epoch 515/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4792 - accuracy: 0.7643\n",
      "Epoch 516/1500\n",
      "11/11 [==============================] - 0s 691us/step - loss: 0.4907 - accuracy: 0.7500\n",
      "Epoch 517/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4883 - accuracy: 0.7757\n",
      "Epoch 518/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4903 - accuracy: 0.7557\n",
      "Epoch 519/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4802 - accuracy: 0.7543\n",
      "Epoch 520/1500\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.73 - 0s 815us/step - loss: 0.4878 - accuracy: 0.7586\n",
      "Epoch 521/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4826 - accuracy: 0.7614\n",
      "Epoch 522/1500\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.4826 - accuracy: 0.7643\n",
      "Epoch 523/1500\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.4749 - accuracy: 0.7686\n",
      "Epoch 524/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4796 - accuracy: 0.7586\n",
      "Epoch 525/1500\n",
      "11/11 [==============================] - 0s 817us/step - loss: 0.4805 - accuracy: 0.7586\n",
      "Epoch 526/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4898 - accuracy: 0.7557\n",
      "Epoch 527/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4812 - accuracy: 0.7700\n",
      "Epoch 528/1500\n",
      "11/11 [==============================] - 0s 732us/step - loss: 0.4743 - accuracy: 0.7657\n",
      "Epoch 529/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4789 - accuracy: 0.7571\n",
      "Epoch 530/1500\n",
      "11/11 [==============================] - 0s 730us/step - loss: 0.4801 - accuracy: 0.7714\n",
      "Epoch 531/1500\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.4775 - accuracy: 0.7614\n",
      "Epoch 532/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.4750 - accuracy: 0.7743\n",
      "Epoch 533/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4801 - accuracy: 0.7629\n",
      "Epoch 534/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4777 - accuracy: 0.7714\n",
      "Epoch 535/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4720 - accuracy: 0.7643\n",
      "Epoch 536/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4759 - accuracy: 0.7629\n",
      "Epoch 537/1500\n",
      "11/11 [==============================] - 0s 704us/step - loss: 0.4741 - accuracy: 0.7629\n",
      "Epoch 538/1500\n",
      "11/11 [==============================] - 0s 731us/step - loss: 0.4768 - accuracy: 0.7629\n",
      "Epoch 539/1500\n",
      "11/11 [==============================] - 0s 539us/step - loss: 0.4740 - accuracy: 0.7600\n",
      "Epoch 540/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4756 - accuracy: 0.7629\n",
      "Epoch 541/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4729 - accuracy: 0.7686\n",
      "Epoch 542/1500\n",
      "11/11 [==============================] - 0s 658us/step - loss: 0.4744 - accuracy: 0.7700\n",
      "Epoch 543/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4850 - accuracy: 0.7643\n",
      "Epoch 544/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4802 - accuracy: 0.7600\n",
      "Epoch 545/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.4762 - accuracy: 0.7643\n",
      "Epoch 546/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4758 - accuracy: 0.7557\n",
      "Epoch 547/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.4727 - accuracy: 0.7671\n",
      "Epoch 548/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.4767 - accuracy: 0.7657\n",
      "Epoch 549/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 775us/step - loss: 0.4741 - accuracy: 0.7714\n",
      "Epoch 550/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4760 - accuracy: 0.7600\n",
      "Epoch 551/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4858 - accuracy: 0.7586\n",
      "Epoch 552/1500\n",
      "11/11 [==============================] - 0s 740us/step - loss: 0.4839 - accuracy: 0.7657\n",
      "Epoch 553/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4811 - accuracy: 0.7600\n",
      "Epoch 554/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4819 - accuracy: 0.7586\n",
      "Epoch 555/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4786 - accuracy: 0.7571\n",
      "Epoch 556/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4846 - accuracy: 0.7571\n",
      "Epoch 557/1500\n",
      "11/11 [==============================] - 0s 655us/step - loss: 0.4843 - accuracy: 0.7586\n",
      "Epoch 558/1500\n",
      "11/11 [==============================] - 0s 733us/step - loss: 0.4808 - accuracy: 0.7629\n",
      "Epoch 559/1500\n",
      "11/11 [==============================] - 0s 558us/step - loss: 0.4807 - accuracy: 0.7529\n",
      "Epoch 560/1500\n",
      "11/11 [==============================] - 0s 695us/step - loss: 0.4751 - accuracy: 0.7657\n",
      "Epoch 561/1500\n",
      "11/11 [==============================] - 0s 547us/step - loss: 0.4757 - accuracy: 0.7657\n",
      "Epoch 562/1500\n",
      "11/11 [==============================] - 0s 723us/step - loss: 0.4714 - accuracy: 0.7671\n",
      "Epoch 563/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4739 - accuracy: 0.7557\n",
      "Epoch 564/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4706 - accuracy: 0.7629\n",
      "Epoch 565/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4695 - accuracy: 0.7643\n",
      "Epoch 566/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4768 - accuracy: 0.7629\n",
      "Epoch 567/1500\n",
      "11/11 [==============================] - 0s 607us/step - loss: 0.4766 - accuracy: 0.7614\n",
      "Epoch 568/1500\n",
      "11/11 [==============================] - 0s 669us/step - loss: 0.4763 - accuracy: 0.7671\n",
      "Epoch 569/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4701 - accuracy: 0.7586\n",
      "Epoch 570/1500\n",
      "11/11 [==============================] - 0s 676us/step - loss: 0.4762 - accuracy: 0.7671\n",
      "Epoch 571/1500\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.4749 - accuracy: 0.7571\n",
      "Epoch 572/1500\n",
      "11/11 [==============================] - 0s 609us/step - loss: 0.4698 - accuracy: 0.7614\n",
      "Epoch 573/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5140 - accuracy: 0.7457\n",
      "Epoch 574/1500\n",
      "11/11 [==============================] - 0s 542us/step - loss: 0.4914 - accuracy: 0.7586\n",
      "Epoch 575/1500\n",
      "11/11 [==============================] - 0s 572us/step - loss: 0.4725 - accuracy: 0.7629\n",
      "Epoch 576/1500\n",
      "11/11 [==============================] - 0s 587us/step - loss: 0.4696 - accuracy: 0.7586\n",
      "Epoch 577/1500\n",
      "11/11 [==============================] - 0s 610us/step - loss: 0.4679 - accuracy: 0.7700\n",
      "Epoch 578/1500\n",
      "11/11 [==============================] - 0s 651us/step - loss: 0.4715 - accuracy: 0.7657\n",
      "Epoch 579/1500\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.4719 - accuracy: 0.7829\n",
      "Epoch 580/1500\n",
      "11/11 [==============================] - 0s 638us/step - loss: 0.4928 - accuracy: 0.7571\n",
      "Epoch 581/1500\n",
      "11/11 [==============================] - 0s 650us/step - loss: 0.4780 - accuracy: 0.7643\n",
      "Epoch 582/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4855 - accuracy: 0.7486\n",
      "Epoch 583/1500\n",
      "11/11 [==============================] - 0s 612us/step - loss: 0.4784 - accuracy: 0.7629\n",
      "Epoch 584/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4719 - accuracy: 0.7671\n",
      "Epoch 585/1500\n",
      "11/11 [==============================] - 0s 617us/step - loss: 0.4834 - accuracy: 0.7514\n",
      "Epoch 586/1500\n",
      "11/11 [==============================] - 0s 726us/step - loss: 0.4642 - accuracy: 0.7771\n",
      "Epoch 587/1500\n",
      "11/11 [==============================] - 0s 564us/step - loss: 0.4774 - accuracy: 0.7643\n",
      "Epoch 588/1500\n",
      "11/11 [==============================] - 0s 696us/step - loss: 0.4689 - accuracy: 0.7557\n",
      "Epoch 589/1500\n",
      "11/11 [==============================] - 0s 665us/step - loss: 0.4658 - accuracy: 0.7657\n",
      "Epoch 590/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4724 - accuracy: 0.7600\n",
      "Epoch 591/1500\n",
      "11/11 [==============================] - 0s 574us/step - loss: 0.4706 - accuracy: 0.7629\n",
      "Epoch 592/1500\n",
      "11/11 [==============================] - 0s 732us/step - loss: 0.4706 - accuracy: 0.7643\n",
      "Epoch 593/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4829 - accuracy: 0.7700\n",
      "Epoch 594/1500\n",
      "11/11 [==============================] - 0s 624us/step - loss: 0.4660 - accuracy: 0.7671\n",
      "Epoch 595/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4736 - accuracy: 0.7600\n",
      "Epoch 596/1500\n",
      "11/11 [==============================] - 0s 723us/step - loss: 0.4671 - accuracy: 0.7571\n",
      "Epoch 597/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4623 - accuracy: 0.7771\n",
      "Epoch 598/1500\n",
      "11/11 [==============================] - 0s 677us/step - loss: 0.4799 - accuracy: 0.7543\n",
      "Epoch 599/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4734 - accuracy: 0.7729\n",
      "Epoch 600/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4780 - accuracy: 0.7500\n",
      "Epoch 601/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.4702 - accuracy: 0.7671\n",
      "Epoch 602/1500\n",
      "11/11 [==============================] - 0s 617us/step - loss: 0.4635 - accuracy: 0.7729\n",
      "Epoch 603/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4658 - accuracy: 0.7629\n",
      "Epoch 604/1500\n",
      "11/11 [==============================] - 0s 645us/step - loss: 0.4613 - accuracy: 0.7714\n",
      "Epoch 605/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4662 - accuracy: 0.7657\n",
      "Epoch 606/1500\n",
      "11/11 [==============================] - 0s 574us/step - loss: 0.4675 - accuracy: 0.7543\n",
      "Epoch 607/1500\n",
      "11/11 [==============================] - 0s 842us/step - loss: 0.4670 - accuracy: 0.7671\n",
      "Epoch 608/1500\n",
      "11/11 [==============================] - 0s 654us/step - loss: 0.4597 - accuracy: 0.7743\n",
      "Epoch 609/1500\n",
      "11/11 [==============================] - 0s 552us/step - loss: 0.4601 - accuracy: 0.7614\n",
      "Epoch 610/1500\n",
      "11/11 [==============================] - 0s 564us/step - loss: 0.4634 - accuracy: 0.7671\n",
      "Epoch 611/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.4627 - accuracy: 0.7786\n",
      "Epoch 612/1500\n",
      "11/11 [==============================] - 0s 621us/step - loss: 0.4844 - accuracy: 0.7671\n",
      "Epoch 613/1500\n",
      "11/11 [==============================] - 0s 610us/step - loss: 0.4670 - accuracy: 0.7600\n",
      "Epoch 614/1500\n",
      "11/11 [==============================] - 0s 638us/step - loss: 0.4639 - accuracy: 0.7743\n",
      "Epoch 615/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4673 - accuracy: 0.7686\n",
      "Epoch 616/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4603 - accuracy: 0.7829\n",
      "Epoch 617/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4646 - accuracy: 0.7657\n",
      "Epoch 618/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4632 - accuracy: 0.7714\n",
      "Epoch 619/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4809 - accuracy: 0.7586\n",
      "Epoch 620/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4719 - accuracy: 0.7586\n",
      "Epoch 621/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4595 - accuracy: 0.7743\n",
      "Epoch 622/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4579 - accuracy: 0.7657\n",
      "Epoch 623/1500\n",
      "11/11 [==============================] - 0s 559us/step - loss: 0.4658 - accuracy: 0.7614\n",
      "Epoch 624/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4588 - accuracy: 0.7786\n",
      "Epoch 625/1500\n",
      "11/11 [==============================] - 0s 677us/step - loss: 0.4591 - accuracy: 0.7629\n",
      "Epoch 626/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4578 - accuracy: 0.7729\n",
      "Epoch 627/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 647us/step - loss: 0.4601 - accuracy: 0.7686\n",
      "Epoch 628/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4563 - accuracy: 0.7671\n",
      "Epoch 629/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4624 - accuracy: 0.7686\n",
      "Epoch 630/1500\n",
      "11/11 [==============================] - 0s 620us/step - loss: 0.4794 - accuracy: 0.7486\n",
      "Epoch 631/1500\n",
      "11/11 [==============================] - 0s 599us/step - loss: 0.4815 - accuracy: 0.7629\n",
      "Epoch 632/1500\n",
      "11/11 [==============================] - 0s 679us/step - loss: 0.4705 - accuracy: 0.7629\n",
      "Epoch 633/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4599 - accuracy: 0.7700\n",
      "Epoch 634/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4614 - accuracy: 0.7800\n",
      "Epoch 635/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4578 - accuracy: 0.7629\n",
      "Epoch 636/1500\n",
      "11/11 [==============================] - 0s 654us/step - loss: 0.4559 - accuracy: 0.7843\n",
      "Epoch 637/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4591 - accuracy: 0.7771\n",
      "Epoch 638/1500\n",
      "11/11 [==============================] - 0s 624us/step - loss: 0.4612 - accuracy: 0.7586\n",
      "Epoch 639/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4666 - accuracy: 0.7686\n",
      "Epoch 640/1500\n",
      "11/11 [==============================] - 0s 535us/step - loss: 0.4618 - accuracy: 0.7686\n",
      "Epoch 641/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4587 - accuracy: 0.7686\n",
      "Epoch 642/1500\n",
      "11/11 [==============================] - 0s 554us/step - loss: 0.4618 - accuracy: 0.7700\n",
      "Epoch 643/1500\n",
      "11/11 [==============================] - 0s 578us/step - loss: 0.4722 - accuracy: 0.7714\n",
      "Epoch 644/1500\n",
      "11/11 [==============================] - 0s 584us/step - loss: 0.4597 - accuracy: 0.7743\n",
      "Epoch 645/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4563 - accuracy: 0.7743\n",
      "Epoch 646/1500\n",
      "11/11 [==============================] - 0s 572us/step - loss: 0.4565 - accuracy: 0.7786\n",
      "Epoch 647/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4612 - accuracy: 0.7771\n",
      "Epoch 648/1500\n",
      "11/11 [==============================] - 0s 599us/step - loss: 0.4596 - accuracy: 0.7586\n",
      "Epoch 649/1500\n",
      "11/11 [==============================] - 0s 684us/step - loss: 0.4678 - accuracy: 0.7629\n",
      "Epoch 650/1500\n",
      "11/11 [==============================] - 0s 583us/step - loss: 0.4716 - accuracy: 0.7500\n",
      "Epoch 651/1500\n",
      "11/11 [==============================] - 0s 620us/step - loss: 0.4833 - accuracy: 0.7557\n",
      "Epoch 652/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4666 - accuracy: 0.7743\n",
      "Epoch 653/1500\n",
      "11/11 [==============================] - 0s 653us/step - loss: 0.4687 - accuracy: 0.7529\n",
      "Epoch 654/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4716 - accuracy: 0.7671\n",
      "Epoch 655/1500\n",
      "11/11 [==============================] - 0s 618us/step - loss: 0.4551 - accuracy: 0.7700\n",
      "Epoch 656/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4549 - accuracy: 0.7743\n",
      "Epoch 657/1500\n",
      "11/11 [==============================] - 0s 578us/step - loss: 0.4638 - accuracy: 0.7571\n",
      "Epoch 658/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4559 - accuracy: 0.7729\n",
      "Epoch 659/1500\n",
      "11/11 [==============================] - 0s 707us/step - loss: 0.4550 - accuracy: 0.7657\n",
      "Epoch 660/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4589 - accuracy: 0.7729\n",
      "Epoch 661/1500\n",
      "11/11 [==============================] - 0s 515us/step - loss: 0.4547 - accuracy: 0.7771\n",
      "Epoch 662/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4723 - accuracy: 0.7571\n",
      "Epoch 663/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4679 - accuracy: 0.7486\n",
      "Epoch 664/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4796 - accuracy: 0.7700\n",
      "Epoch 665/1500\n",
      "11/11 [==============================] - 0s 612us/step - loss: 0.4839 - accuracy: 0.7600\n",
      "Epoch 666/1500\n",
      "11/11 [==============================] - 0s 754us/step - loss: 0.4763 - accuracy: 0.7714\n",
      "Epoch 667/1500\n",
      "11/11 [==============================] - 0s 584us/step - loss: 0.4680 - accuracy: 0.7643\n",
      "Epoch 668/1500\n",
      "11/11 [==============================] - 0s 700us/step - loss: 0.4731 - accuracy: 0.7700\n",
      "Epoch 669/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4595 - accuracy: 0.7686\n",
      "Epoch 670/1500\n",
      "11/11 [==============================] - 0s 734us/step - loss: 0.4525 - accuracy: 0.7743\n",
      "Epoch 671/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4590 - accuracy: 0.7686\n",
      "Epoch 672/1500\n",
      "11/11 [==============================] - 0s 614us/step - loss: 0.4500 - accuracy: 0.7743\n",
      "Epoch 673/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4543 - accuracy: 0.7786\n",
      "Epoch 674/1500\n",
      "11/11 [==============================] - 0s 596us/step - loss: 0.4575 - accuracy: 0.7700\n",
      "Epoch 675/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4586 - accuracy: 0.7843\n",
      "Epoch 676/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4654 - accuracy: 0.7671\n",
      "Epoch 677/1500\n",
      "11/11 [==============================] - 0s 660us/step - loss: 0.4582 - accuracy: 0.7629\n",
      "Epoch 678/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.4650 - accuracy: 0.7757\n",
      "Epoch 679/1500\n",
      "11/11 [==============================] - 0s 705us/step - loss: 0.4666 - accuracy: 0.7686\n",
      "Epoch 680/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4630 - accuracy: 0.7643\n",
      "Epoch 681/1500\n",
      "11/11 [==============================] - 0s 736us/step - loss: 0.4675 - accuracy: 0.7786\n",
      "Epoch 682/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4670 - accuracy: 0.7686\n",
      "Epoch 683/1500\n",
      "11/11 [==============================] - 0s 696us/step - loss: 0.4524 - accuracy: 0.7729\n",
      "Epoch 684/1500\n",
      "11/11 [==============================] - 0s 732us/step - loss: 0.4545 - accuracy: 0.7729\n",
      "Epoch 685/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.4517 - accuracy: 0.7686\n",
      "Epoch 686/1500\n",
      "11/11 [==============================] - 0s 724us/step - loss: 0.4571 - accuracy: 0.7743\n",
      "Epoch 687/1500\n",
      "11/11 [==============================] - 0s 558us/step - loss: 0.4555 - accuracy: 0.7743\n",
      "Epoch 688/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4552 - accuracy: 0.7686\n",
      "Epoch 689/1500\n",
      "11/11 [==============================] - 0s 693us/step - loss: 0.4597 - accuracy: 0.7771\n",
      "Epoch 690/1500\n",
      "11/11 [==============================] - 0s 744us/step - loss: 0.4593 - accuracy: 0.7614\n",
      "Epoch 691/1500\n",
      "11/11 [==============================] - 0s 522us/step - loss: 0.4555 - accuracy: 0.7700\n",
      "Epoch 692/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4537 - accuracy: 0.7814\n",
      "Epoch 693/1500\n",
      "11/11 [==============================] - 0s 587us/step - loss: 0.4524 - accuracy: 0.7714\n",
      "Epoch 694/1500\n",
      "11/11 [==============================] - 0s 655us/step - loss: 0.4533 - accuracy: 0.7757\n",
      "Epoch 695/1500\n",
      "11/11 [==============================] - 0s 782us/step - loss: 0.4521 - accuracy: 0.7671\n",
      "Epoch 696/1500\n",
      "11/11 [==============================] - 0s 711us/step - loss: 0.4592 - accuracy: 0.7729\n",
      "Epoch 697/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4558 - accuracy: 0.7671\n",
      "Epoch 698/1500\n",
      "11/11 [==============================] - 0s 681us/step - loss: 0.4553 - accuracy: 0.7671\n",
      "Epoch 699/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4504 - accuracy: 0.7729\n",
      "Epoch 700/1500\n",
      "11/11 [==============================] - 0s 715us/step - loss: 0.4497 - accuracy: 0.7829\n",
      "Epoch 701/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4541 - accuracy: 0.7629\n",
      "Epoch 702/1500\n",
      "11/11 [==============================] - 0s 555us/step - loss: 0.4598 - accuracy: 0.7743\n",
      "Epoch 703/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4531 - accuracy: 0.7714\n",
      "Epoch 704/1500\n",
      "11/11 [==============================] - 0s 568us/step - loss: 0.4484 - accuracy: 0.7829\n",
      "Epoch 705/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 535us/step - loss: 0.4540 - accuracy: 0.7857\n",
      "Epoch 706/1500\n",
      "11/11 [==============================] - 0s 663us/step - loss: 0.4524 - accuracy: 0.7714\n",
      "Epoch 707/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4557 - accuracy: 0.7829\n",
      "Epoch 708/1500\n",
      "11/11 [==============================] - 0s 600us/step - loss: 0.4543 - accuracy: 0.7800\n",
      "Epoch 709/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.4523 - accuracy: 0.7814\n",
      "Epoch 710/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4568 - accuracy: 0.7643\n",
      "Epoch 711/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4614 - accuracy: 0.7729\n",
      "Epoch 712/1500\n",
      "11/11 [==============================] - 0s 643us/step - loss: 0.4541 - accuracy: 0.7729\n",
      "Epoch 713/1500\n",
      "11/11 [==============================] - 0s 604us/step - loss: 0.4568 - accuracy: 0.7714\n",
      "Epoch 714/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4601 - accuracy: 0.7657\n",
      "Epoch 715/1500\n",
      "11/11 [==============================] - 0s 647us/step - loss: 0.4729 - accuracy: 0.7629\n",
      "Epoch 716/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4586 - accuracy: 0.7814\n",
      "Epoch 717/1500\n",
      "11/11 [==============================] - 0s 669us/step - loss: 0.4737 - accuracy: 0.7600\n",
      "Epoch 718/1500\n",
      "11/11 [==============================] - 0s 648us/step - loss: 0.4470 - accuracy: 0.7700\n",
      "Epoch 719/1500\n",
      "11/11 [==============================] - 0s 648us/step - loss: 0.4537 - accuracy: 0.7786\n",
      "Epoch 720/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.4607 - accuracy: 0.7614\n",
      "Epoch 721/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.4499 - accuracy: 0.7786\n",
      "Epoch 722/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4602 - accuracy: 0.7757\n",
      "Epoch 723/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.4642 - accuracy: 0.7514\n",
      "Epoch 724/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4647 - accuracy: 0.7600\n",
      "Epoch 725/1500\n",
      "11/11 [==============================] - 0s 601us/step - loss: 0.4617 - accuracy: 0.7657\n",
      "Epoch 726/1500\n",
      "11/11 [==============================] - 0s 673us/step - loss: 0.4516 - accuracy: 0.7757\n",
      "Epoch 727/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4494 - accuracy: 0.7786\n",
      "Epoch 728/1500\n",
      "11/11 [==============================] - 0s 707us/step - loss: 0.4517 - accuracy: 0.7886\n",
      "Epoch 729/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4612 - accuracy: 0.7729\n",
      "Epoch 730/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4495 - accuracy: 0.7743\n",
      "Epoch 731/1500\n",
      "11/11 [==============================] - 0s 547us/step - loss: 0.4472 - accuracy: 0.7829\n",
      "Epoch 732/1500\n",
      "11/11 [==============================] - 0s 648us/step - loss: 0.4549 - accuracy: 0.7557\n",
      "Epoch 733/1500\n",
      "11/11 [==============================] - 0s 581us/step - loss: 0.4518 - accuracy: 0.7671\n",
      "Epoch 734/1500\n",
      "11/11 [==============================] - 0s 666us/step - loss: 0.4469 - accuracy: 0.7800\n",
      "Epoch 735/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4476 - accuracy: 0.7771\n",
      "Epoch 736/1500\n",
      "11/11 [==============================] - 0s 643us/step - loss: 0.4432 - accuracy: 0.7714\n",
      "Epoch 737/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4454 - accuracy: 0.7871\n",
      "Epoch 738/1500\n",
      "11/11 [==============================] - 0s 585us/step - loss: 0.4471 - accuracy: 0.7829\n",
      "Epoch 739/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4449 - accuracy: 0.7857\n",
      "Epoch 740/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4556 - accuracy: 0.7771\n",
      "Epoch 741/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.4464 - accuracy: 0.7800\n",
      "Epoch 742/1500\n",
      "11/11 [==============================] - 0s 663us/step - loss: 0.4478 - accuracy: 0.7729\n",
      "Epoch 743/1500\n",
      "11/11 [==============================] - 0s 659us/step - loss: 0.4451 - accuracy: 0.7743\n",
      "Epoch 744/1500\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.4498 - accuracy: 0.7843\n",
      "Epoch 745/1500\n",
      "11/11 [==============================] - 0s 600us/step - loss: 0.4457 - accuracy: 0.7743\n",
      "Epoch 746/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.4475 - accuracy: 0.7857\n",
      "Epoch 747/1500\n",
      "11/11 [==============================] - 0s 735us/step - loss: 0.4413 - accuracy: 0.7914\n",
      "Epoch 748/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4489 - accuracy: 0.7586\n",
      "Epoch 749/1500\n",
      "11/11 [==============================] - 0s 706us/step - loss: 0.4487 - accuracy: 0.7786\n",
      "Epoch 750/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4490 - accuracy: 0.7800\n",
      "Epoch 751/1500\n",
      "11/11 [==============================] - 0s 662us/step - loss: 0.4554 - accuracy: 0.7514\n",
      "Epoch 752/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4514 - accuracy: 0.7786\n",
      "Epoch 753/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.4457 - accuracy: 0.7857\n",
      "Epoch 754/1500\n",
      "11/11 [==============================] - 0s 582us/step - loss: 0.4435 - accuracy: 0.7814\n",
      "Epoch 755/1500\n",
      "11/11 [==============================] - 0s 556us/step - loss: 0.4556 - accuracy: 0.7743\n",
      "Epoch 756/1500\n",
      "11/11 [==============================] - 0s 661us/step - loss: 0.4459 - accuracy: 0.7786\n",
      "Epoch 757/1500\n",
      "11/11 [==============================] - 0s 686us/step - loss: 0.4481 - accuracy: 0.7857\n",
      "Epoch 758/1500\n",
      "11/11 [==============================] - 0s 737us/step - loss: 0.4546 - accuracy: 0.7729\n",
      "Epoch 759/1500\n",
      "11/11 [==============================] - 0s 688us/step - loss: 0.4485 - accuracy: 0.7771\n",
      "Epoch 760/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4479 - accuracy: 0.7871\n",
      "Epoch 761/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4489 - accuracy: 0.7671\n",
      "Epoch 762/1500\n",
      "11/11 [==============================] - 0s 539us/step - loss: 0.4417 - accuracy: 0.7814\n",
      "Epoch 763/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4538 - accuracy: 0.7686\n",
      "Epoch 764/1500\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.4499 - accuracy: 0.7800\n",
      "Epoch 765/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4461 - accuracy: 0.7786\n",
      "Epoch 766/1500\n",
      "11/11 [==============================] - 0s 668us/step - loss: 0.4494 - accuracy: 0.7743\n",
      "Epoch 767/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4591 - accuracy: 0.7757\n",
      "Epoch 768/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4536 - accuracy: 0.7729\n",
      "Epoch 769/1500\n",
      "11/11 [==============================] - 0s 546us/step - loss: 0.4462 - accuracy: 0.7843\n",
      "Epoch 770/1500\n",
      "11/11 [==============================] - 0s 619us/step - loss: 0.4458 - accuracy: 0.7800\n",
      "Epoch 771/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4540 - accuracy: 0.7800\n",
      "Epoch 772/1500\n",
      "11/11 [==============================] - 0s 688us/step - loss: 0.4430 - accuracy: 0.7843\n",
      "Epoch 773/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4451 - accuracy: 0.7800\n",
      "Epoch 774/1500\n",
      "11/11 [==============================] - 0s 603us/step - loss: 0.4466 - accuracy: 0.7771\n",
      "Epoch 775/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4412 - accuracy: 0.7900\n",
      "Epoch 776/1500\n",
      "11/11 [==============================] - 0s 580us/step - loss: 0.4423 - accuracy: 0.7771\n",
      "Epoch 777/1500\n",
      "11/11 [==============================] - 0s 724us/step - loss: 0.4444 - accuracy: 0.7871\n",
      "Epoch 778/1500\n",
      "11/11 [==============================] - 0s 668us/step - loss: 0.4412 - accuracy: 0.7914\n",
      "Epoch 779/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4409 - accuracy: 0.7814\n",
      "Epoch 780/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4484 - accuracy: 0.7843\n",
      "Epoch 781/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4429 - accuracy: 0.7829\n",
      "Epoch 782/1500\n",
      "11/11 [==============================] - 0s 606us/step - loss: 0.4475 - accuracy: 0.7714\n",
      "Epoch 783/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 725us/step - loss: 0.4488 - accuracy: 0.7657\n",
      "Epoch 784/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4498 - accuracy: 0.7729\n",
      "Epoch 785/1500\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.78 - 0s 631us/step - loss: 0.4525 - accuracy: 0.7757\n",
      "Epoch 786/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4473 - accuracy: 0.7671\n",
      "Epoch 787/1500\n",
      "11/11 [==============================] - 0s 576us/step - loss: 0.4522 - accuracy: 0.7814\n",
      "Epoch 788/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4445 - accuracy: 0.7814\n",
      "Epoch 789/1500\n",
      "11/11 [==============================] - 0s 666us/step - loss: 0.4581 - accuracy: 0.7786\n",
      "Epoch 790/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4461 - accuracy: 0.7829\n",
      "Epoch 791/1500\n",
      "11/11 [==============================] - 0s 667us/step - loss: 0.4575 - accuracy: 0.7686\n",
      "Epoch 792/1500\n",
      "11/11 [==============================] - 0s 717us/step - loss: 0.4502 - accuracy: 0.7729\n",
      "Epoch 793/1500\n",
      "11/11 [==============================] - 0s 579us/step - loss: 0.4460 - accuracy: 0.7814\n",
      "Epoch 794/1500\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.4534 - accuracy: 0.7729\n",
      "Epoch 795/1500\n",
      "11/11 [==============================] - 0s 590us/step - loss: 0.4590 - accuracy: 0.7743\n",
      "Epoch 796/1500\n",
      "11/11 [==============================] - 0s 771us/step - loss: 0.4458 - accuracy: 0.7700\n",
      "Epoch 797/1500\n",
      "11/11 [==============================] - 0s 591us/step - loss: 0.4426 - accuracy: 0.7800\n",
      "Epoch 798/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4503 - accuracy: 0.7729\n",
      "Epoch 799/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4496 - accuracy: 0.7771\n",
      "Epoch 800/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.4424 - accuracy: 0.7743\n",
      "Epoch 801/1500\n",
      "11/11 [==============================] - 0s 672us/step - loss: 0.4436 - accuracy: 0.7743\n",
      "Epoch 802/1500\n",
      "11/11 [==============================] - 0s 678us/step - loss: 0.4452 - accuracy: 0.7829\n",
      "Epoch 803/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4447 - accuracy: 0.7729\n",
      "Epoch 804/1500\n",
      "11/11 [==============================] - 0s 672us/step - loss: 0.4398 - accuracy: 0.7857\n",
      "Epoch 805/1500\n",
      "11/11 [==============================] - 0s 785us/step - loss: 0.4407 - accuracy: 0.7843\n",
      "Epoch 806/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4381 - accuracy: 0.7829\n",
      "Epoch 807/1500\n",
      "11/11 [==============================] - 0s 684us/step - loss: 0.4382 - accuracy: 0.7814\n",
      "Epoch 808/1500\n",
      "11/11 [==============================] - 0s 566us/step - loss: 0.4386 - accuracy: 0.7914\n",
      "Epoch 809/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4429 - accuracy: 0.7743\n",
      "Epoch 810/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4423 - accuracy: 0.7714\n",
      "Epoch 811/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4419 - accuracy: 0.7929\n",
      "Epoch 812/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4459 - accuracy: 0.7657\n",
      "Epoch 813/1500\n",
      "11/11 [==============================] - 0s 695us/step - loss: 0.4436 - accuracy: 0.7829\n",
      "Epoch 814/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4421 - accuracy: 0.7886\n",
      "Epoch 815/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4445 - accuracy: 0.7800\n",
      "Epoch 816/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4402 - accuracy: 0.7786\n",
      "Epoch 817/1500\n",
      "11/11 [==============================] - 0s 595us/step - loss: 0.4646 - accuracy: 0.7700\n",
      "Epoch 818/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4448 - accuracy: 0.7800\n",
      "Epoch 819/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4412 - accuracy: 0.7843\n",
      "Epoch 820/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4388 - accuracy: 0.7971\n",
      "Epoch 821/1500\n",
      "11/11 [==============================] - 0s 574us/step - loss: 0.4482 - accuracy: 0.7757\n",
      "Epoch 822/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4397 - accuracy: 0.7857\n",
      "Epoch 823/1500\n",
      "11/11 [==============================] - 0s 611us/step - loss: 0.4385 - accuracy: 0.7800\n",
      "Epoch 824/1500\n",
      "11/11 [==============================] - 0s 622us/step - loss: 0.4464 - accuracy: 0.7786\n",
      "Epoch 825/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4414 - accuracy: 0.7771\n",
      "Epoch 826/1500\n",
      "11/11 [==============================] - 0s 729us/step - loss: 0.4383 - accuracy: 0.7871\n",
      "Epoch 827/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4365 - accuracy: 0.7843\n",
      "Epoch 828/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4404 - accuracy: 0.7843\n",
      "Epoch 829/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4391 - accuracy: 0.7814\n",
      "Epoch 830/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4406 - accuracy: 0.7771\n",
      "Epoch 831/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4433 - accuracy: 0.7786\n",
      "Epoch 832/1500\n",
      "11/11 [==============================] - 0s 643us/step - loss: 0.4410 - accuracy: 0.7786\n",
      "Epoch 833/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4483 - accuracy: 0.7886\n",
      "Epoch 834/1500\n",
      "11/11 [==============================] - 0s 600us/step - loss: 0.4386 - accuracy: 0.7843\n",
      "Epoch 835/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4340 - accuracy: 0.7857\n",
      "Epoch 836/1500\n",
      "11/11 [==============================] - 0s 656us/step - loss: 0.4408 - accuracy: 0.7843\n",
      "Epoch 837/1500\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.4491 - accuracy: 0.7814\n",
      "Epoch 838/1500\n",
      "11/11 [==============================] - 0s 622us/step - loss: 0.4394 - accuracy: 0.7814\n",
      "Epoch 839/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4402 - accuracy: 0.7829\n",
      "Epoch 840/1500\n",
      "11/11 [==============================] - 0s 620us/step - loss: 0.4442 - accuracy: 0.7757\n",
      "Epoch 841/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4461 - accuracy: 0.7743\n",
      "Epoch 842/1500\n",
      "11/11 [==============================] - 0s 616us/step - loss: 0.4661 - accuracy: 0.7643\n",
      "Epoch 843/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4476 - accuracy: 0.7857\n",
      "Epoch 844/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4416 - accuracy: 0.7714\n",
      "Epoch 845/1500\n",
      "11/11 [==============================] - 0s 762us/step - loss: 0.4396 - accuracy: 0.7829\n",
      "Epoch 846/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4462 - accuracy: 0.7700\n",
      "Epoch 847/1500\n",
      "11/11 [==============================] - 0s 728us/step - loss: 0.4472 - accuracy: 0.7786\n",
      "Epoch 848/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4425 - accuracy: 0.7814\n",
      "Epoch 849/1500\n",
      "11/11 [==============================] - 0s 680us/step - loss: 0.4392 - accuracy: 0.7743\n",
      "Epoch 850/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4385 - accuracy: 0.7843\n",
      "Epoch 851/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4377 - accuracy: 0.7786\n",
      "Epoch 852/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4388 - accuracy: 0.7843\n",
      "Epoch 853/1500\n",
      "11/11 [==============================] - 0s 574us/step - loss: 0.4634 - accuracy: 0.7557\n",
      "Epoch 854/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4680 - accuracy: 0.7714\n",
      "Epoch 855/1500\n",
      "11/11 [==============================] - 0s 572us/step - loss: 0.4498 - accuracy: 0.7571\n",
      "Epoch 856/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4370 - accuracy: 0.7800\n",
      "Epoch 857/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.4348 - accuracy: 0.7871\n",
      "Epoch 858/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4371 - accuracy: 0.7829\n",
      "Epoch 859/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4397 - accuracy: 0.7771\n",
      "Epoch 860/1500\n",
      "11/11 [==============================] - 0s 690us/step - loss: 0.4384 - accuracy: 0.7843\n",
      "Epoch 861/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 635us/step - loss: 0.4391 - accuracy: 0.7900\n",
      "Epoch 862/1500\n",
      "11/11 [==============================] - 0s 691us/step - loss: 0.4356 - accuracy: 0.7800\n",
      "Epoch 863/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4361 - accuracy: 0.7800\n",
      "Epoch 864/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4360 - accuracy: 0.7829\n",
      "Epoch 865/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4435 - accuracy: 0.7829\n",
      "Epoch 866/1500\n",
      "11/11 [==============================] - 0s 556us/step - loss: 0.4399 - accuracy: 0.7714\n",
      "Epoch 867/1500\n",
      "11/11 [==============================] - 0s 689us/step - loss: 0.4368 - accuracy: 0.7886\n",
      "Epoch 868/1500\n",
      "11/11 [==============================] - 0s 646us/step - loss: 0.4401 - accuracy: 0.7700\n",
      "Epoch 869/1500\n",
      "11/11 [==============================] - 0s 624us/step - loss: 0.4397 - accuracy: 0.7900\n",
      "Epoch 870/1500\n",
      "11/11 [==============================] - 0s 643us/step - loss: 0.4487 - accuracy: 0.7671\n",
      "Epoch 871/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4408 - accuracy: 0.7743\n",
      "Epoch 872/1500\n",
      "11/11 [==============================] - 0s 520us/step - loss: 0.4377 - accuracy: 0.7786\n",
      "Epoch 873/1500\n",
      "11/11 [==============================] - 0s 663us/step - loss: 0.4346 - accuracy: 0.7843\n",
      "Epoch 874/1500\n",
      "11/11 [==============================] - 0s 583us/step - loss: 0.4404 - accuracy: 0.7857\n",
      "Epoch 875/1500\n",
      "11/11 [==============================] - 0s 618us/step - loss: 0.4424 - accuracy: 0.7829\n",
      "Epoch 876/1500\n",
      "11/11 [==============================] - 0s 538us/step - loss: 0.4395 - accuracy: 0.7971\n",
      "Epoch 877/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4315 - accuracy: 0.8000\n",
      "Epoch 878/1500\n",
      "11/11 [==============================] - 0s 537us/step - loss: 0.4426 - accuracy: 0.7914\n",
      "Epoch 879/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4354 - accuracy: 0.7829\n",
      "Epoch 880/1500\n",
      "11/11 [==============================] - 0s 549us/step - loss: 0.4368 - accuracy: 0.7886\n",
      "Epoch 881/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4439 - accuracy: 0.7757\n",
      "Epoch 882/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.4392 - accuracy: 0.7671\n",
      "Epoch 883/1500\n",
      "11/11 [==============================] - 0s 673us/step - loss: 0.4642 - accuracy: 0.7629\n",
      "Epoch 884/1500\n",
      "11/11 [==============================] - 0s 671us/step - loss: 0.4393 - accuracy: 0.7871\n",
      "Epoch 885/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4393 - accuracy: 0.7786\n",
      "Epoch 886/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4346 - accuracy: 0.7957\n",
      "Epoch 887/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4411 - accuracy: 0.7743\n",
      "Epoch 888/1500\n",
      "11/11 [==============================] - 0s 535us/step - loss: 0.4491 - accuracy: 0.7743\n",
      "Epoch 889/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4491 - accuracy: 0.7757\n",
      "Epoch 890/1500\n",
      "11/11 [==============================] - 0s 692us/step - loss: 0.4408 - accuracy: 0.7843\n",
      "Epoch 891/1500\n",
      "11/11 [==============================] - 0s 648us/step - loss: 0.4431 - accuracy: 0.7757\n",
      "Epoch 892/1500\n",
      "11/11 [==============================] - 0s 716us/step - loss: 0.4456 - accuracy: 0.7643\n",
      "Epoch 893/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.4468 - accuracy: 0.7843\n",
      "Epoch 894/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4394 - accuracy: 0.7814\n",
      "Epoch 895/1500\n",
      "11/11 [==============================] - 0s 534us/step - loss: 0.4378 - accuracy: 0.7714\n",
      "Epoch 896/1500\n",
      "11/11 [==============================] - 0s 727us/step - loss: 0.4478 - accuracy: 0.7814\n",
      "Epoch 897/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4448 - accuracy: 0.7743\n",
      "Epoch 898/1500\n",
      "11/11 [==============================] - 0s 605us/step - loss: 0.4446 - accuracy: 0.7786\n",
      "Epoch 899/1500\n",
      "11/11 [==============================] - 0s 594us/step - loss: 0.4353 - accuracy: 0.7843\n",
      "Epoch 900/1500\n",
      "11/11 [==============================] - 0s 651us/step - loss: 0.4428 - accuracy: 0.7914\n",
      "Epoch 901/1500\n",
      "11/11 [==============================] - 0s 606us/step - loss: 0.4356 - accuracy: 0.7871\n",
      "Epoch 902/1500\n",
      "11/11 [==============================] - 0s 650us/step - loss: 0.4312 - accuracy: 0.7871\n",
      "Epoch 903/1500\n",
      "11/11 [==============================] - 0s 543us/step - loss: 0.4361 - accuracy: 0.7829\n",
      "Epoch 904/1500\n",
      "11/11 [==============================] - 0s 595us/step - loss: 0.4332 - accuracy: 0.7843\n",
      "Epoch 905/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4420 - accuracy: 0.7829\n",
      "Epoch 906/1500\n",
      "11/11 [==============================] - 0s 609us/step - loss: 0.4331 - accuracy: 0.7929\n",
      "Epoch 907/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4312 - accuracy: 0.7929\n",
      "Epoch 908/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4379 - accuracy: 0.7829\n",
      "Epoch 909/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4362 - accuracy: 0.7886\n",
      "Epoch 910/1500\n",
      "11/11 [==============================] - 0s 702us/step - loss: 0.4409 - accuracy: 0.7786\n",
      "Epoch 911/1500\n",
      "11/11 [==============================] - 0s 692us/step - loss: 0.4400 - accuracy: 0.7757\n",
      "Epoch 912/1500\n",
      "11/11 [==============================] - 0s 583us/step - loss: 0.4471 - accuracy: 0.7771\n",
      "Epoch 913/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4494 - accuracy: 0.7829\n",
      "Epoch 914/1500\n",
      "11/11 [==============================] - 0s 612us/step - loss: 0.4547 - accuracy: 0.7686\n",
      "Epoch 915/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4495 - accuracy: 0.7743\n",
      "Epoch 916/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4332 - accuracy: 0.7771\n",
      "Epoch 917/1500\n",
      "11/11 [==============================] - 0s 675us/step - loss: 0.4391 - accuracy: 0.7771\n",
      "Epoch 918/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4391 - accuracy: 0.7971\n",
      "Epoch 919/1500\n",
      "11/11 [==============================] - 0s 646us/step - loss: 0.4410 - accuracy: 0.7786\n",
      "Epoch 920/1500\n",
      "11/11 [==============================] - 0s 545us/step - loss: 0.4348 - accuracy: 0.7814\n",
      "Epoch 921/1500\n",
      "11/11 [==============================] - 0s 669us/step - loss: 0.4339 - accuracy: 0.7857\n",
      "Epoch 922/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4342 - accuracy: 0.7814\n",
      "Epoch 923/1500\n",
      "11/11 [==============================] - 0s 696us/step - loss: 0.4339 - accuracy: 0.7814\n",
      "Epoch 924/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4385 - accuracy: 0.7800\n",
      "Epoch 925/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4360 - accuracy: 0.7843\n",
      "Epoch 926/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.4420 - accuracy: 0.7800\n",
      "Epoch 927/1500\n",
      "11/11 [==============================] - 0s 533us/step - loss: 0.4556 - accuracy: 0.7614\n",
      "Epoch 928/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4459 - accuracy: 0.7786\n",
      "Epoch 929/1500\n",
      "11/11 [==============================] - 0s 660us/step - loss: 0.4503 - accuracy: 0.7729\n",
      "Epoch 930/1500\n",
      "11/11 [==============================] - 0s 603us/step - loss: 0.4388 - accuracy: 0.7857\n",
      "Epoch 931/1500\n",
      "11/11 [==============================] - 0s 657us/step - loss: 0.4371 - accuracy: 0.7757\n",
      "Epoch 932/1500\n",
      "11/11 [==============================] - 0s 565us/step - loss: 0.4364 - accuracy: 0.7786\n",
      "Epoch 933/1500\n",
      "11/11 [==============================] - 0s 551us/step - loss: 0.4366 - accuracy: 0.7743\n",
      "Epoch 934/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4385 - accuracy: 0.7814\n",
      "Epoch 935/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4302 - accuracy: 0.7857\n",
      "Epoch 936/1500\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.4318 - accuracy: 0.7914\n",
      "Epoch 937/1500\n",
      "11/11 [==============================] - 0s 813us/step - loss: 0.4377 - accuracy: 0.7786\n",
      "Epoch 938/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.4393 - accuracy: 0.7771\n",
      "Epoch 939/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 721us/step - loss: 0.4359 - accuracy: 0.7671\n",
      "Epoch 940/1500\n",
      "11/11 [==============================] - 0s 547us/step - loss: 0.4365 - accuracy: 0.7871\n",
      "Epoch 941/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4387 - accuracy: 0.7700\n",
      "Epoch 942/1500\n",
      "11/11 [==============================] - 0s 664us/step - loss: 0.4292 - accuracy: 0.7886\n",
      "Epoch 943/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4287 - accuracy: 0.7900\n",
      "Epoch 944/1500\n",
      "11/11 [==============================] - 0s 645us/step - loss: 0.4490 - accuracy: 0.7800\n",
      "Epoch 945/1500\n",
      "11/11 [==============================] - 0s 703us/step - loss: 0.4385 - accuracy: 0.7714\n",
      "Epoch 946/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4326 - accuracy: 0.7757\n",
      "Epoch 947/1500\n",
      "11/11 [==============================] - 0s 592us/step - loss: 0.4337 - accuracy: 0.7900\n",
      "Epoch 948/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4406 - accuracy: 0.7800\n",
      "Epoch 949/1500\n",
      "11/11 [==============================] - 0s 606us/step - loss: 0.4342 - accuracy: 0.7929\n",
      "Epoch 950/1500\n",
      "11/11 [==============================] - 0s 551us/step - loss: 0.4365 - accuracy: 0.7914\n",
      "Epoch 951/1500\n",
      "11/11 [==============================] - 0s 665us/step - loss: 0.4318 - accuracy: 0.7857\n",
      "Epoch 952/1500\n",
      "11/11 [==============================] - 0s 715us/step - loss: 0.4321 - accuracy: 0.7829\n",
      "Epoch 953/1500\n",
      "11/11 [==============================] - 0s 623us/step - loss: 0.4288 - accuracy: 0.7886\n",
      "Epoch 954/1500\n",
      "11/11 [==============================] - 0s 727us/step - loss: 0.4355 - accuracy: 0.7900\n",
      "Epoch 955/1500\n",
      "11/11 [==============================] - 0s 592us/step - loss: 0.4441 - accuracy: 0.7857\n",
      "Epoch 956/1500\n",
      "11/11 [==============================] - 0s 713us/step - loss: 0.4436 - accuracy: 0.7729\n",
      "Epoch 957/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4386 - accuracy: 0.7843\n",
      "Epoch 958/1500\n",
      "11/11 [==============================] - 0s 612us/step - loss: 0.4384 - accuracy: 0.7943\n",
      "Epoch 959/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4342 - accuracy: 0.7857\n",
      "Epoch 960/1500\n",
      "11/11 [==============================] - 0s 601us/step - loss: 0.4307 - accuracy: 0.7843\n",
      "Epoch 961/1500\n",
      "11/11 [==============================] - 0s 595us/step - loss: 0.4324 - accuracy: 0.7843\n",
      "Epoch 962/1500\n",
      "11/11 [==============================] - 0s 670us/step - loss: 0.4326 - accuracy: 0.7900\n",
      "Epoch 963/1500\n",
      "11/11 [==============================] - 0s 611us/step - loss: 0.4371 - accuracy: 0.7814\n",
      "Epoch 964/1500\n",
      "11/11 [==============================] - 0s 659us/step - loss: 0.4387 - accuracy: 0.7671\n",
      "Epoch 965/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4358 - accuracy: 0.7886\n",
      "Epoch 966/1500\n",
      "11/11 [==============================] - 0s 681us/step - loss: 0.4317 - accuracy: 0.7871\n",
      "Epoch 967/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4521 - accuracy: 0.7586\n",
      "Epoch 968/1500\n",
      "11/11 [==============================] - 0s 676us/step - loss: 0.4361 - accuracy: 0.7800\n",
      "Epoch 969/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4447 - accuracy: 0.7700\n",
      "Epoch 970/1500\n",
      "11/11 [==============================] - 0s 656us/step - loss: 0.4358 - accuracy: 0.7900\n",
      "Epoch 971/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4458 - accuracy: 0.7729\n",
      "Epoch 972/1500\n",
      "11/11 [==============================] - 0s 682us/step - loss: 0.4337 - accuracy: 0.7800\n",
      "Epoch 973/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4436 - accuracy: 0.7657\n",
      "Epoch 974/1500\n",
      "11/11 [==============================] - 0s 732us/step - loss: 0.4379 - accuracy: 0.7857\n",
      "Epoch 975/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4336 - accuracy: 0.7943\n",
      "Epoch 976/1500\n",
      "11/11 [==============================] - 0s 575us/step - loss: 0.4362 - accuracy: 0.7729\n",
      "Epoch 977/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4359 - accuracy: 0.7914\n",
      "Epoch 978/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4369 - accuracy: 0.7757\n",
      "Epoch 979/1500\n",
      "11/11 [==============================] - 0s 668us/step - loss: 0.4308 - accuracy: 0.7871\n",
      "Epoch 980/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.4415 - accuracy: 0.7871\n",
      "Epoch 981/1500\n",
      "11/11 [==============================] - 0s 549us/step - loss: 0.4397 - accuracy: 0.7771\n",
      "Epoch 982/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4582 - accuracy: 0.7729\n",
      "Epoch 983/1500\n",
      "11/11 [==============================] - 0s 623us/step - loss: 0.4387 - accuracy: 0.7857\n",
      "Epoch 984/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4310 - accuracy: 0.7786\n",
      "Epoch 985/1500\n",
      "11/11 [==============================] - 0s 546us/step - loss: 0.4381 - accuracy: 0.7800\n",
      "Epoch 986/1500\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.4281 - accuracy: 0.7843\n",
      "Epoch 987/1500\n",
      "11/11 [==============================] - 0s 819us/step - loss: 0.4350 - accuracy: 0.7857\n",
      "Epoch 988/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4400 - accuracy: 0.7671\n",
      "Epoch 989/1500\n",
      "11/11 [==============================] - 0s 621us/step - loss: 0.4302 - accuracy: 0.7829\n",
      "Epoch 990/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4324 - accuracy: 0.7914\n",
      "Epoch 991/1500\n",
      "11/11 [==============================] - 0s 578us/step - loss: 0.4390 - accuracy: 0.7871\n",
      "Epoch 992/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4334 - accuracy: 0.7900\n",
      "Epoch 993/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4425 - accuracy: 0.7843\n",
      "Epoch 994/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4344 - accuracy: 0.7714\n",
      "Epoch 995/1500\n",
      "11/11 [==============================] - 0s 992us/step - loss: 0.4314 - accuracy: 0.7757\n",
      "Epoch 996/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.4356 - accuracy: 0.7829\n",
      "Epoch 997/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4314 - accuracy: 0.7800\n",
      "Epoch 998/1500\n",
      "11/11 [==============================] - 0s 648us/step - loss: 0.4469 - accuracy: 0.7743\n",
      "Epoch 999/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4458 - accuracy: 0.7757\n",
      "Epoch 1000/1500\n",
      "11/11 [==============================] - 0s 579us/step - loss: 0.4445 - accuracy: 0.7800\n",
      "Epoch 1001/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4328 - accuracy: 0.7900\n",
      "Epoch 1002/1500\n",
      "11/11 [==============================] - 0s 604us/step - loss: 0.4419 - accuracy: 0.7871\n",
      "Epoch 1003/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4320 - accuracy: 0.7886\n",
      "Epoch 1004/1500\n",
      "11/11 [==============================] - 0s 613us/step - loss: 0.4364 - accuracy: 0.7871\n",
      "Epoch 1005/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4321 - accuracy: 0.7743\n",
      "Epoch 1006/1500\n",
      "11/11 [==============================] - 0s 584us/step - loss: 0.4377 - accuracy: 0.7843\n",
      "Epoch 1007/1500\n",
      "11/11 [==============================] - 0s 624us/step - loss: 0.4264 - accuracy: 0.7943\n",
      "Epoch 1008/1500\n",
      "11/11 [==============================] - 0s 507us/step - loss: 0.4287 - accuracy: 0.7814\n",
      "Epoch 1009/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4326 - accuracy: 0.7800\n",
      "Epoch 1010/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4400 - accuracy: 0.7914\n",
      "Epoch 1011/1500\n",
      "11/11 [==============================] - 0s 645us/step - loss: 0.4326 - accuracy: 0.7829\n",
      "Epoch 1012/1500\n",
      "11/11 [==============================] - 0s 543us/step - loss: 0.4311 - accuracy: 0.7829\n",
      "Epoch 1013/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4811 - accuracy: 0.7586\n",
      "Epoch 1014/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4516 - accuracy: 0.7686\n",
      "Epoch 1015/1500\n",
      "11/11 [==============================] - 0s 716us/step - loss: 0.4436 - accuracy: 0.7871\n",
      "Epoch 1016/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4328 - accuracy: 0.7886\n",
      "Epoch 1017/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 641us/step - loss: 0.4347 - accuracy: 0.7857\n",
      "Epoch 1018/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4337 - accuracy: 0.7857\n",
      "Epoch 1019/1500\n",
      "11/11 [==============================] - 0s 607us/step - loss: 0.4254 - accuracy: 0.7886\n",
      "Epoch 1020/1500\n",
      "11/11 [==============================] - 0s 733us/step - loss: 0.4309 - accuracy: 0.7900\n",
      "Epoch 1021/1500\n",
      "11/11 [==============================] - 0s 653us/step - loss: 0.4281 - accuracy: 0.7814\n",
      "Epoch 1022/1500\n",
      "11/11 [==============================] - 0s 687us/step - loss: 0.4324 - accuracy: 0.7871\n",
      "Epoch 1023/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4283 - accuracy: 0.7886\n",
      "Epoch 1024/1500\n",
      "11/11 [==============================] - 0s 606us/step - loss: 0.4277 - accuracy: 0.7829\n",
      "Epoch 1025/1500\n",
      "11/11 [==============================] - 0s 677us/step - loss: 0.4259 - accuracy: 0.7943\n",
      "Epoch 1026/1500\n",
      "11/11 [==============================] - 0s 567us/step - loss: 0.4298 - accuracy: 0.7814\n",
      "Epoch 1027/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4364 - accuracy: 0.7829\n",
      "Epoch 1028/1500\n",
      "11/11 [==============================] - 0s 707us/step - loss: 0.4388 - accuracy: 0.7829\n",
      "Epoch 1029/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4305 - accuracy: 0.7929\n",
      "Epoch 1030/1500\n",
      "11/11 [==============================] - 0s 607us/step - loss: 0.4265 - accuracy: 0.7886\n",
      "Epoch 1031/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.4459 - accuracy: 0.7700\n",
      "Epoch 1032/1500\n",
      "11/11 [==============================] - 0s 612us/step - loss: 0.4372 - accuracy: 0.7900\n",
      "Epoch 1033/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4371 - accuracy: 0.7800\n",
      "Epoch 1034/1500\n",
      "11/11 [==============================] - 0s 611us/step - loss: 0.4310 - accuracy: 0.7843\n",
      "Epoch 1035/1500\n",
      "11/11 [==============================] - 0s 724us/step - loss: 0.4264 - accuracy: 0.7871\n",
      "Epoch 1036/1500\n",
      "11/11 [==============================] - 0s 546us/step - loss: 0.4286 - accuracy: 0.7900\n",
      "Epoch 1037/1500\n",
      "11/11 [==============================] - 0s 663us/step - loss: 0.4251 - accuracy: 0.7900\n",
      "Epoch 1038/1500\n",
      "11/11 [==============================] - 0s 601us/step - loss: 0.4282 - accuracy: 0.7871\n",
      "Epoch 1039/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.4273 - accuracy: 0.7771\n",
      "Epoch 1040/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4374 - accuracy: 0.7829\n",
      "Epoch 1041/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4345 - accuracy: 0.7800\n",
      "Epoch 1042/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.4315 - accuracy: 0.7729\n",
      "Epoch 1043/1500\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.4389 - accuracy: 0.7700\n",
      "Epoch 1044/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4305 - accuracy: 0.7871\n",
      "Epoch 1045/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4279 - accuracy: 0.7829\n",
      "Epoch 1046/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4291 - accuracy: 0.7900\n",
      "Epoch 1047/1500\n",
      "11/11 [==============================] - 0s 696us/step - loss: 0.4248 - accuracy: 0.7843\n",
      "Epoch 1048/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4265 - accuracy: 0.7914\n",
      "Epoch 1049/1500\n",
      "11/11 [==============================] - 0s 724us/step - loss: 0.4254 - accuracy: 0.7814\n",
      "Epoch 1050/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4287 - accuracy: 0.7971\n",
      "Epoch 1051/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4409 - accuracy: 0.7857\n",
      "Epoch 1052/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4400 - accuracy: 0.7829\n",
      "Epoch 1053/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4320 - accuracy: 0.7871\n",
      "Epoch 1054/1500\n",
      "11/11 [==============================] - 0s 657us/step - loss: 0.4309 - accuracy: 0.7871\n",
      "Epoch 1055/1500\n",
      "11/11 [==============================] - 0s 726us/step - loss: 0.4347 - accuracy: 0.7871\n",
      "Epoch 1056/1500\n",
      "11/11 [==============================] - 0s 649us/step - loss: 0.4287 - accuracy: 0.7886\n",
      "Epoch 1057/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4304 - accuracy: 0.7871\n",
      "Epoch 1058/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4356 - accuracy: 0.7843\n",
      "Epoch 1059/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4266 - accuracy: 0.7829\n",
      "Epoch 1060/1500\n",
      "11/11 [==============================] - 0s 513us/step - loss: 0.4245 - accuracy: 0.7857\n",
      "Epoch 1061/1500\n",
      "11/11 [==============================] - 0s 597us/step - loss: 0.4402 - accuracy: 0.7829\n",
      "Epoch 1062/1500\n",
      "11/11 [==============================] - 0s 593us/step - loss: 0.4386 - accuracy: 0.7871\n",
      "Epoch 1063/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4285 - accuracy: 0.7886\n",
      "Epoch 1064/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4281 - accuracy: 0.7829\n",
      "Epoch 1065/1500\n",
      "11/11 [==============================] - 0s 573us/step - loss: 0.4283 - accuracy: 0.7900\n",
      "Epoch 1066/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4287 - accuracy: 0.7857\n",
      "Epoch 1067/1500\n",
      "11/11 [==============================] - 0s 652us/step - loss: 0.4270 - accuracy: 0.7843\n",
      "Epoch 1068/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4365 - accuracy: 0.7829\n",
      "Epoch 1069/1500\n",
      "11/11 [==============================] - 0s 687us/step - loss: 0.4254 - accuracy: 0.7971\n",
      "Epoch 1070/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4242 - accuracy: 0.7857\n",
      "Epoch 1071/1500\n",
      "11/11 [==============================] - 0s 583us/step - loss: 0.4345 - accuracy: 0.7971\n",
      "Epoch 1072/1500\n",
      "11/11 [==============================] - 0s 749us/step - loss: 0.4320 - accuracy: 0.7843\n",
      "Epoch 1073/1500\n",
      "11/11 [==============================] - 0s 550us/step - loss: 0.4343 - accuracy: 0.7786\n",
      "Epoch 1074/1500\n",
      "11/11 [==============================] - 0s 717us/step - loss: 0.4241 - accuracy: 0.7871\n",
      "Epoch 1075/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4259 - accuracy: 0.7900\n",
      "Epoch 1076/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4641 - accuracy: 0.7757\n",
      "Epoch 1077/1500\n",
      "11/11 [==============================] - 0s 735us/step - loss: 0.4674 - accuracy: 0.7757\n",
      "Epoch 1078/1500\n",
      "11/11 [==============================] - 0s 661us/step - loss: 0.4404 - accuracy: 0.7757\n",
      "Epoch 1079/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4428 - accuracy: 0.7786\n",
      "Epoch 1080/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4310 - accuracy: 0.7857\n",
      "Epoch 1081/1500\n",
      "11/11 [==============================] - 0s 548us/step - loss: 0.4235 - accuracy: 0.7914\n",
      "Epoch 1082/1500\n",
      "11/11 [==============================] - 0s 652us/step - loss: 0.4259 - accuracy: 0.7857\n",
      "Epoch 1083/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4234 - accuracy: 0.7871\n",
      "Epoch 1084/1500\n",
      "11/11 [==============================] - 0s 673us/step - loss: 0.4231 - accuracy: 0.7943\n",
      "Epoch 1085/1500\n",
      "11/11 [==============================] - 0s 724us/step - loss: 0.4235 - accuracy: 0.7857\n",
      "Epoch 1086/1500\n",
      "11/11 [==============================] - 0s 616us/step - loss: 0.4361 - accuracy: 0.7829\n",
      "Epoch 1087/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4314 - accuracy: 0.7971\n",
      "Epoch 1088/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4306 - accuracy: 0.7857\n",
      "Epoch 1089/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4226 - accuracy: 0.7929\n",
      "Epoch 1090/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4199 - accuracy: 0.7814\n",
      "Epoch 1091/1500\n",
      "11/11 [==============================] - 0s 733us/step - loss: 0.4401 - accuracy: 0.7643\n",
      "Epoch 1092/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4321 - accuracy: 0.7843\n",
      "Epoch 1093/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4314 - accuracy: 0.7757\n",
      "Epoch 1094/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4252 - accuracy: 0.7886\n",
      "Epoch 1095/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 639us/step - loss: 0.4278 - accuracy: 0.7857\n",
      "Epoch 1096/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4295 - accuracy: 0.7800\n",
      "Epoch 1097/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4346 - accuracy: 0.7886\n",
      "Epoch 1098/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.4265 - accuracy: 0.7857\n",
      "Epoch 1099/1500\n",
      "11/11 [==============================] - 0s 555us/step - loss: 0.4347 - accuracy: 0.7657\n",
      "Epoch 1100/1500\n",
      "11/11 [==============================] - 0s 649us/step - loss: 0.4336 - accuracy: 0.7914\n",
      "Epoch 1101/1500\n",
      "11/11 [==============================] - 0s 704us/step - loss: 0.4236 - accuracy: 0.7829\n",
      "Epoch 1102/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4251 - accuracy: 0.7943\n",
      "Epoch 1103/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4258 - accuracy: 0.7886\n",
      "Epoch 1104/1500\n",
      "11/11 [==============================] - 0s 655us/step - loss: 0.4231 - accuracy: 0.7986\n",
      "Epoch 1105/1500\n",
      "11/11 [==============================] - 0s 810us/step - loss: 0.4194 - accuracy: 0.7857\n",
      "Epoch 1106/1500\n",
      "11/11 [==============================] - 0s 536us/step - loss: 0.4236 - accuracy: 0.7829\n",
      "Epoch 1107/1500\n",
      "11/11 [==============================] - 0s 650us/step - loss: 0.4217 - accuracy: 0.7814\n",
      "Epoch 1108/1500\n",
      "11/11 [==============================] - 0s 550us/step - loss: 0.4191 - accuracy: 0.7986\n",
      "Epoch 1109/1500\n",
      "11/11 [==============================] - 0s 638us/step - loss: 0.4374 - accuracy: 0.7714\n",
      "Epoch 1110/1500\n",
      "11/11 [==============================] - 0s 646us/step - loss: 0.4268 - accuracy: 0.7757\n",
      "Epoch 1111/1500\n",
      "11/11 [==============================] - 0s 678us/step - loss: 0.4381 - accuracy: 0.7786\n",
      "Epoch 1112/1500\n",
      "11/11 [==============================] - 0s 650us/step - loss: 0.4244 - accuracy: 0.7886\n",
      "Epoch 1113/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4218 - accuracy: 0.7871\n",
      "Epoch 1114/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4220 - accuracy: 0.7900\n",
      "Epoch 1115/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4212 - accuracy: 0.7929\n",
      "Epoch 1116/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4334 - accuracy: 0.7800\n",
      "Epoch 1117/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4412 - accuracy: 0.7743\n",
      "Epoch 1118/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4258 - accuracy: 0.7843\n",
      "Epoch 1119/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4401 - accuracy: 0.7757\n",
      "Epoch 1120/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4213 - accuracy: 0.7986\n",
      "Epoch 1121/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4255 - accuracy: 0.8014\n",
      "Epoch 1122/1500\n",
      "11/11 [==============================] - 0s 716us/step - loss: 0.4221 - accuracy: 0.7943\n",
      "Epoch 1123/1500\n",
      "11/11 [==============================] - 0s 669us/step - loss: 0.4212 - accuracy: 0.7814\n",
      "Epoch 1124/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4258 - accuracy: 0.7843\n",
      "Epoch 1125/1500\n",
      "11/11 [==============================] - 0s 621us/step - loss: 0.4228 - accuracy: 0.7771\n",
      "Epoch 1126/1500\n",
      "11/11 [==============================] - 0s 673us/step - loss: 0.4240 - accuracy: 0.7857\n",
      "Epoch 1127/1500\n",
      "11/11 [==============================] - 0s 619us/step - loss: 0.4408 - accuracy: 0.7757\n",
      "Epoch 1128/1500\n",
      "11/11 [==============================] - 0s 643us/step - loss: 0.4326 - accuracy: 0.7829\n",
      "Epoch 1129/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4228 - accuracy: 0.7957\n",
      "Epoch 1130/1500\n",
      "11/11 [==============================] - 0s 680us/step - loss: 0.4281 - accuracy: 0.7886\n",
      "Epoch 1131/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4185 - accuracy: 0.7943\n",
      "Epoch 1132/1500\n",
      "11/11 [==============================] - 0s 652us/step - loss: 0.4192 - accuracy: 0.7971\n",
      "Epoch 1133/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4218 - accuracy: 0.7857\n",
      "Epoch 1134/1500\n",
      "11/11 [==============================] - 0s 716us/step - loss: 0.4206 - accuracy: 0.7771\n",
      "Epoch 1135/1500\n",
      "11/11 [==============================] - 0s 728us/step - loss: 0.4246 - accuracy: 0.7914\n",
      "Epoch 1136/1500\n",
      "11/11 [==============================] - 0s 647us/step - loss: 0.4212 - accuracy: 0.7886\n",
      "Epoch 1137/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4254 - accuracy: 0.7914\n",
      "Epoch 1138/1500\n",
      "11/11 [==============================] - 0s 622us/step - loss: 0.4365 - accuracy: 0.7886\n",
      "Epoch 1139/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4307 - accuracy: 0.7829\n",
      "Epoch 1140/1500\n",
      "11/11 [==============================] - 0s 671us/step - loss: 0.4211 - accuracy: 0.7843\n",
      "Epoch 1141/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4244 - accuracy: 0.7814\n",
      "Epoch 1142/1500\n",
      "11/11 [==============================] - 0s 575us/step - loss: 0.4209 - accuracy: 0.7800\n",
      "Epoch 1143/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.4208 - accuracy: 0.7929\n",
      "Epoch 1144/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.4192 - accuracy: 0.7914\n",
      "Epoch 1145/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4358 - accuracy: 0.7871\n",
      "Epoch 1146/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4261 - accuracy: 0.7886\n",
      "Epoch 1147/1500\n",
      "11/11 [==============================] - 0s 650us/step - loss: 0.4305 - accuracy: 0.7786\n",
      "Epoch 1148/1500\n",
      "11/11 [==============================] - 0s 693us/step - loss: 0.4193 - accuracy: 0.7871\n",
      "Epoch 1149/1500\n",
      "11/11 [==============================] - 0s 696us/step - loss: 0.4224 - accuracy: 0.7843\n",
      "Epoch 1150/1500\n",
      "11/11 [==============================] - 0s 539us/step - loss: 0.4186 - accuracy: 0.7914\n",
      "Epoch 1151/1500\n",
      "11/11 [==============================] - 0s 653us/step - loss: 0.4316 - accuracy: 0.7871\n",
      "Epoch 1152/1500\n",
      "11/11 [==============================] - 0s 716us/step - loss: 0.4228 - accuracy: 0.7871\n",
      "Epoch 1153/1500\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.4338 - accuracy: 0.7843\n",
      "Epoch 1154/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4340 - accuracy: 0.7829\n",
      "Epoch 1155/1500\n",
      "11/11 [==============================] - 0s 583us/step - loss: 0.4193 - accuracy: 0.7957\n",
      "Epoch 1156/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4214 - accuracy: 0.7843\n",
      "Epoch 1157/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4199 - accuracy: 0.7843\n",
      "Epoch 1158/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4255 - accuracy: 0.7786\n",
      "Epoch 1159/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4298 - accuracy: 0.7900\n",
      "Epoch 1160/1500\n",
      "11/11 [==============================] - 0s 712us/step - loss: 0.4183 - accuracy: 0.7886\n",
      "Epoch 1161/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4275 - accuracy: 0.7857\n",
      "Epoch 1162/1500\n",
      "11/11 [==============================] - 0s 660us/step - loss: 0.4129 - accuracy: 0.7900\n",
      "Epoch 1163/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4214 - accuracy: 0.7857\n",
      "Epoch 1164/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.4247 - accuracy: 0.7886\n",
      "Epoch 1165/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4483 - accuracy: 0.7657\n",
      "Epoch 1166/1500\n",
      "11/11 [==============================] - 0s 741us/step - loss: 0.4489 - accuracy: 0.7686\n",
      "Epoch 1167/1500\n",
      "11/11 [==============================] - 0s 550us/step - loss: 0.4347 - accuracy: 0.7743\n",
      "Epoch 1168/1500\n",
      "11/11 [==============================] - 0s 679us/step - loss: 0.4228 - accuracy: 0.7914\n",
      "Epoch 1169/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4272 - accuracy: 0.7829\n",
      "Epoch 1170/1500\n",
      "11/11 [==============================] - 0s 655us/step - loss: 0.4200 - accuracy: 0.7943\n",
      "Epoch 1171/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4257 - accuracy: 0.7843\n",
      "Epoch 1172/1500\n",
      "11/11 [==============================] - 0s 662us/step - loss: 0.4238 - accuracy: 0.7786\n",
      "Epoch 1173/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 635us/step - loss: 0.4394 - accuracy: 0.7729\n",
      "Epoch 1174/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4238 - accuracy: 0.7886\n",
      "Epoch 1175/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4437 - accuracy: 0.7714\n",
      "Epoch 1176/1500\n",
      "11/11 [==============================] - 0s 649us/step - loss: 0.4425 - accuracy: 0.7743\n",
      "Epoch 1177/1500\n",
      "11/11 [==============================] - 0s 601us/step - loss: 0.4257 - accuracy: 0.7771\n",
      "Epoch 1178/1500\n",
      "11/11 [==============================] - 0s 744us/step - loss: 0.4257 - accuracy: 0.7843\n",
      "Epoch 1179/1500\n",
      "11/11 [==============================] - 0s 551us/step - loss: 0.4320 - accuracy: 0.7829\n",
      "Epoch 1180/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4239 - accuracy: 0.7900\n",
      "Epoch 1181/1500\n",
      "11/11 [==============================] - 0s 549us/step - loss: 0.4197 - accuracy: 0.7914\n",
      "Epoch 1182/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4230 - accuracy: 0.7829\n",
      "Epoch 1183/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4280 - accuracy: 0.7829\n",
      "Epoch 1184/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4199 - accuracy: 0.7857\n",
      "Epoch 1185/1500\n",
      "11/11 [==============================] - 0s 552us/step - loss: 0.4192 - accuracy: 0.7900\n",
      "Epoch 1186/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4158 - accuracy: 0.7900\n",
      "Epoch 1187/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4152 - accuracy: 0.7943\n",
      "Epoch 1188/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4166 - accuracy: 0.7914\n",
      "Epoch 1189/1500\n",
      "11/11 [==============================] - 0s 611us/step - loss: 0.4160 - accuracy: 0.7900\n",
      "Epoch 1190/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4124 - accuracy: 0.7900\n",
      "Epoch 1191/1500\n",
      "11/11 [==============================] - 0s 616us/step - loss: 0.4275 - accuracy: 0.7814\n",
      "Epoch 1192/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.4430 - accuracy: 0.7829\n",
      "Epoch 1193/1500\n",
      "11/11 [==============================] - 0s 554us/step - loss: 0.4304 - accuracy: 0.7814\n",
      "Epoch 1194/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.4296 - accuracy: 0.7857\n",
      "Epoch 1195/1500\n",
      "11/11 [==============================] - 0s 606us/step - loss: 0.4268 - accuracy: 0.7871\n",
      "Epoch 1196/1500\n",
      "11/11 [==============================] - 0s 674us/step - loss: 0.4158 - accuracy: 0.7900\n",
      "Epoch 1197/1500\n",
      "11/11 [==============================] - 0s 687us/step - loss: 0.4186 - accuracy: 0.7900\n",
      "Epoch 1198/1500\n",
      "11/11 [==============================] - 0s 689us/step - loss: 0.4206 - accuracy: 0.8000\n",
      "Epoch 1199/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4191 - accuracy: 0.7900\n",
      "Epoch 1200/1500\n",
      "11/11 [==============================] - 0s 681us/step - loss: 0.4335 - accuracy: 0.7843\n",
      "Epoch 1201/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4164 - accuracy: 0.7886\n",
      "Epoch 1202/1500\n",
      "11/11 [==============================] - 0s 601us/step - loss: 0.4227 - accuracy: 0.7857\n",
      "Epoch 1203/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4239 - accuracy: 0.7786\n",
      "Epoch 1204/1500\n",
      "11/11 [==============================] - 0s 713us/step - loss: 0.4192 - accuracy: 0.7886\n",
      "Epoch 1205/1500\n",
      "11/11 [==============================] - 0s 746us/step - loss: 0.4155 - accuracy: 0.8014\n",
      "Epoch 1206/1500\n",
      "11/11 [==============================] - 0s 562us/step - loss: 0.4209 - accuracy: 0.7943\n",
      "Epoch 1207/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4371 - accuracy: 0.7786\n",
      "Epoch 1208/1500\n",
      "11/11 [==============================] - 0s 648us/step - loss: 0.4365 - accuracy: 0.7643\n",
      "Epoch 1209/1500\n",
      "11/11 [==============================] - 0s 730us/step - loss: 0.4338 - accuracy: 0.7971\n",
      "Epoch 1210/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4238 - accuracy: 0.7929\n",
      "Epoch 1211/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4268 - accuracy: 0.7829\n",
      "Epoch 1212/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.4196 - accuracy: 0.7800\n",
      "Epoch 1213/1500\n",
      "11/11 [==============================] - 0s 708us/step - loss: 0.4369 - accuracy: 0.7743\n",
      "Epoch 1214/1500\n",
      "11/11 [==============================] - 0s 810us/step - loss: 0.4207 - accuracy: 0.7957\n",
      "Epoch 1215/1500\n",
      "11/11 [==============================] - 0s 613us/step - loss: 0.4275 - accuracy: 0.7771\n",
      "Epoch 1216/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4252 - accuracy: 0.7800\n",
      "Epoch 1217/1500\n",
      "11/11 [==============================] - 0s 661us/step - loss: 0.4254 - accuracy: 0.7871\n",
      "Epoch 1218/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4235 - accuracy: 0.7800\n",
      "Epoch 1219/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4118 - accuracy: 0.7871\n",
      "Epoch 1220/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.4118 - accuracy: 0.7914\n",
      "Epoch 1221/1500\n",
      "11/11 [==============================] - 0s 646us/step - loss: 0.4196 - accuracy: 0.7943\n",
      "Epoch 1222/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4162 - accuracy: 0.7886\n",
      "Epoch 1223/1500\n",
      "11/11 [==============================] - 0s 638us/step - loss: 0.4199 - accuracy: 0.7971\n",
      "Epoch 1224/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4281 - accuracy: 0.7943\n",
      "Epoch 1225/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4313 - accuracy: 0.7771\n",
      "Epoch 1226/1500\n",
      "11/11 [==============================] - 0s 695us/step - loss: 0.4161 - accuracy: 0.7914\n",
      "Epoch 1227/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4179 - accuracy: 0.7871\n",
      "Epoch 1228/1500\n",
      "11/11 [==============================] - 0s 594us/step - loss: 0.4330 - accuracy: 0.7800\n",
      "Epoch 1229/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4198 - accuracy: 0.7771\n",
      "Epoch 1230/1500\n",
      "11/11 [==============================] - 0s 682us/step - loss: 0.4208 - accuracy: 0.7929\n",
      "Epoch 1231/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4149 - accuracy: 0.8014\n",
      "Epoch 1232/1500\n",
      "11/11 [==============================] - 0s 517us/step - loss: 0.4213 - accuracy: 0.7914\n",
      "Epoch 1233/1500\n",
      "11/11 [==============================] - 0s 623us/step - loss: 0.4158 - accuracy: 0.7914\n",
      "Epoch 1234/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4153 - accuracy: 0.7914\n",
      "Epoch 1235/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4220 - accuracy: 0.7929\n",
      "Epoch 1236/1500\n",
      "11/11 [==============================] - 0s 547us/step - loss: 0.4234 - accuracy: 0.7843\n",
      "Epoch 1237/1500\n",
      "11/11 [==============================] - 0s 676us/step - loss: 0.4224 - accuracy: 0.7786\n",
      "Epoch 1238/1500\n",
      "11/11 [==============================] - 0s 599us/step - loss: 0.4147 - accuracy: 0.7957\n",
      "Epoch 1239/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4135 - accuracy: 0.7900\n",
      "Epoch 1240/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4212 - accuracy: 0.7971\n",
      "Epoch 1241/1500\n",
      "11/11 [==============================] - 0s 651us/step - loss: 0.4309 - accuracy: 0.7829\n",
      "Epoch 1242/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4236 - accuracy: 0.7786\n",
      "Epoch 1243/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4120 - accuracy: 0.7871\n",
      "Epoch 1244/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.4151 - accuracy: 0.7857\n",
      "Epoch 1245/1500\n",
      "11/11 [==============================] - 0s 590us/step - loss: 0.4228 - accuracy: 0.7843\n",
      "Epoch 1246/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4261 - accuracy: 0.7800\n",
      "Epoch 1247/1500\n",
      "11/11 [==============================] - 0s 660us/step - loss: 0.4263 - accuracy: 0.7757\n",
      "Epoch 1248/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4211 - accuracy: 0.7900\n",
      "Epoch 1249/1500\n",
      "11/11 [==============================] - 0s 588us/step - loss: 0.4350 - accuracy: 0.7786\n",
      "Epoch 1250/1500\n",
      "11/11 [==============================] - 0s 538us/step - loss: 0.4157 - accuracy: 0.7843\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 712us/step - loss: 0.4199 - accuracy: 0.7886\n",
      "Epoch 1252/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4188 - accuracy: 0.7857\n",
      "Epoch 1253/1500\n",
      "11/11 [==============================] - 0s 597us/step - loss: 0.4159 - accuracy: 0.7943\n",
      "Epoch 1254/1500\n",
      "11/11 [==============================] - 0s 673us/step - loss: 0.4130 - accuracy: 0.7900\n",
      "Epoch 1255/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4165 - accuracy: 0.7900\n",
      "Epoch 1256/1500\n",
      "11/11 [==============================] - 0s 821us/step - loss: 0.4136 - accuracy: 0.7814\n",
      "Epoch 1257/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4182 - accuracy: 0.7800\n",
      "Epoch 1258/1500\n",
      "11/11 [==============================] - 0s 543us/step - loss: 0.4164 - accuracy: 0.7857\n",
      "Epoch 1259/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4135 - accuracy: 0.7914\n",
      "Epoch 1260/1500\n",
      "11/11 [==============================] - 0s 578us/step - loss: 0.4088 - accuracy: 0.7871\n",
      "Epoch 1261/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4127 - accuracy: 0.7943\n",
      "Epoch 1262/1500\n",
      "11/11 [==============================] - 0s 559us/step - loss: 0.4105 - accuracy: 0.7843\n",
      "Epoch 1263/1500\n",
      "11/11 [==============================] - 0s 613us/step - loss: 0.4185 - accuracy: 0.7857\n",
      "Epoch 1264/1500\n",
      "11/11 [==============================] - 0s 732us/step - loss: 0.4104 - accuracy: 0.7957\n",
      "Epoch 1265/1500\n",
      "11/11 [==============================] - 0s 776us/step - loss: 0.4164 - accuracy: 0.7886\n",
      "Epoch 1266/1500\n",
      "11/11 [==============================] - 0s 585us/step - loss: 0.4106 - accuracy: 0.7857\n",
      "Epoch 1267/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4187 - accuracy: 0.7771\n",
      "Epoch 1268/1500\n",
      "11/11 [==============================] - 0s 620us/step - loss: 0.4217 - accuracy: 0.7829\n",
      "Epoch 1269/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4243 - accuracy: 0.7843\n",
      "Epoch 1270/1500\n",
      "11/11 [==============================] - 0s 582us/step - loss: 0.4149 - accuracy: 0.7971\n",
      "Epoch 1271/1500\n",
      "11/11 [==============================] - 0s 728us/step - loss: 0.4210 - accuracy: 0.7786\n",
      "Epoch 1272/1500\n",
      "11/11 [==============================] - 0s 548us/step - loss: 0.4125 - accuracy: 0.7814\n",
      "Epoch 1273/1500\n",
      "11/11 [==============================] - 0s 703us/step - loss: 0.4113 - accuracy: 0.7871\n",
      "Epoch 1274/1500\n",
      "11/11 [==============================] - 0s 657us/step - loss: 0.4162 - accuracy: 0.7871\n",
      "Epoch 1275/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4146 - accuracy: 0.8029\n",
      "Epoch 1276/1500\n",
      "11/11 [==============================] - 0s 549us/step - loss: 0.4224 - accuracy: 0.7786\n",
      "Epoch 1277/1500\n",
      "11/11 [==============================] - 0s 624us/step - loss: 0.4161 - accuracy: 0.7857\n",
      "Epoch 1278/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4215 - accuracy: 0.7786\n",
      "Epoch 1279/1500\n",
      "11/11 [==============================] - 0s 567us/step - loss: 0.4219 - accuracy: 0.7886\n",
      "Epoch 1280/1500\n",
      "11/11 [==============================] - 0s 663us/step - loss: 0.4125 - accuracy: 0.7971\n",
      "Epoch 1281/1500\n",
      "11/11 [==============================] - 0s 652us/step - loss: 0.4096 - accuracy: 0.7943\n",
      "Epoch 1282/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4100 - accuracy: 0.7914\n",
      "Epoch 1283/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.4095 - accuracy: 0.7857\n",
      "Epoch 1284/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4064 - accuracy: 0.7943\n",
      "Epoch 1285/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4132 - accuracy: 0.7857\n",
      "Epoch 1286/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4148 - accuracy: 0.7886\n",
      "Epoch 1287/1500\n",
      "11/11 [==============================] - 0s 659us/step - loss: 0.4070 - accuracy: 0.7986\n",
      "Epoch 1288/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4075 - accuracy: 0.7886\n",
      "Epoch 1289/1500\n",
      "11/11 [==============================] - 0s 627us/step - loss: 0.4095 - accuracy: 0.7914\n",
      "Epoch 1290/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4091 - accuracy: 0.7914\n",
      "Epoch 1291/1500\n",
      "11/11 [==============================] - 0s 624us/step - loss: 0.4068 - accuracy: 0.7929\n",
      "Epoch 1292/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4080 - accuracy: 0.7986\n",
      "Epoch 1293/1500\n",
      "11/11 [==============================] - 0s 622us/step - loss: 0.4132 - accuracy: 0.7814\n",
      "Epoch 1294/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4079 - accuracy: 0.7929\n",
      "Epoch 1295/1500\n",
      "11/11 [==============================] - 0s 703us/step - loss: 0.4086 - accuracy: 0.7871\n",
      "Epoch 1296/1500\n",
      "11/11 [==============================] - 0s 656us/step - loss: 0.4073 - accuracy: 0.7986\n",
      "Epoch 1297/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4119 - accuracy: 0.7857\n",
      "Epoch 1298/1500\n",
      "11/11 [==============================] - 0s 603us/step - loss: 0.4160 - accuracy: 0.7929\n",
      "Epoch 1299/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4121 - accuracy: 0.7871\n",
      "Epoch 1300/1500\n",
      "11/11 [==============================] - 0s 758us/step - loss: 0.4199 - accuracy: 0.7800\n",
      "Epoch 1301/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.4101 - accuracy: 0.7929\n",
      "Epoch 1302/1500\n",
      "11/11 [==============================] - 0s 581us/step - loss: 0.4106 - accuracy: 0.7843\n",
      "Epoch 1303/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4092 - accuracy: 0.7900\n",
      "Epoch 1304/1500\n",
      "11/11 [==============================] - 0s 732us/step - loss: 0.4064 - accuracy: 0.7771\n",
      "Epoch 1305/1500\n",
      "11/11 [==============================] - 0s 809us/step - loss: 0.4208 - accuracy: 0.7871\n",
      "Epoch 1306/1500\n",
      "11/11 [==============================] - 0s 558us/step - loss: 0.4176 - accuracy: 0.7886\n",
      "Epoch 1307/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4327 - accuracy: 0.7786\n",
      "Epoch 1308/1500\n",
      "11/11 [==============================] - 0s 574us/step - loss: 0.4193 - accuracy: 0.7871\n",
      "Epoch 1309/1500\n",
      "11/11 [==============================] - 0s 647us/step - loss: 0.4347 - accuracy: 0.7871\n",
      "Epoch 1310/1500\n",
      "11/11 [==============================] - 0s 645us/step - loss: 0.4248 - accuracy: 0.7700\n",
      "Epoch 1311/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4213 - accuracy: 0.7986\n",
      "Epoch 1312/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4108 - accuracy: 0.7886\n",
      "Epoch 1313/1500\n",
      "11/11 [==============================] - 0s 724us/step - loss: 0.4120 - accuracy: 0.7929\n",
      "Epoch 1314/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4174 - accuracy: 0.7929\n",
      "Epoch 1315/1500\n",
      "11/11 [==============================] - 0s 584us/step - loss: 0.4132 - accuracy: 0.7943\n",
      "Epoch 1316/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4161 - accuracy: 0.7900\n",
      "Epoch 1317/1500\n",
      "11/11 [==============================] - 0s 652us/step - loss: 0.4170 - accuracy: 0.7814\n",
      "Epoch 1318/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4078 - accuracy: 0.7914\n",
      "Epoch 1319/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.4170 - accuracy: 0.7914\n",
      "Epoch 1320/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4231 - accuracy: 0.7843\n",
      "Epoch 1321/1500\n",
      "11/11 [==============================] - 0s 565us/step - loss: 0.4122 - accuracy: 0.7871\n",
      "Epoch 1322/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4157 - accuracy: 0.7886\n",
      "Epoch 1323/1500\n",
      "11/11 [==============================] - 0s 600us/step - loss: 0.4200 - accuracy: 0.7829\n",
      "Epoch 1324/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4278 - accuracy: 0.7814\n",
      "Epoch 1325/1500\n",
      "11/11 [==============================] - 0s 647us/step - loss: 0.4162 - accuracy: 0.7771\n",
      "Epoch 1326/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4156 - accuracy: 0.7886\n",
      "Epoch 1327/1500\n",
      "11/11 [==============================] - 0s 532us/step - loss: 0.4087 - accuracy: 0.7943\n",
      "Epoch 1328/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4276 - accuracy: 0.7771\n",
      "Epoch 1329/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 684us/step - loss: 0.4146 - accuracy: 0.7786\n",
      "Epoch 1330/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.4077 - accuracy: 0.7871\n",
      "Epoch 1331/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4128 - accuracy: 0.7943\n",
      "Epoch 1332/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.4082 - accuracy: 0.7914\n",
      "Epoch 1333/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4110 - accuracy: 0.7843\n",
      "Epoch 1334/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.4155 - accuracy: 0.7843\n",
      "Epoch 1335/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4204 - accuracy: 0.7900\n",
      "Epoch 1336/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4124 - accuracy: 0.7971\n",
      "Epoch 1337/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4160 - accuracy: 0.7843\n",
      "Epoch 1338/1500\n",
      "11/11 [==============================] - 0s 613us/step - loss: 0.4131 - accuracy: 0.7871\n",
      "Epoch 1339/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4186 - accuracy: 0.7871\n",
      "Epoch 1340/1500\n",
      "11/11 [==============================] - 0s 542us/step - loss: 0.4335 - accuracy: 0.7757\n",
      "Epoch 1341/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4143 - accuracy: 0.7900\n",
      "Epoch 1342/1500\n",
      "11/11 [==============================] - 0s 643us/step - loss: 0.4124 - accuracy: 0.7871\n",
      "Epoch 1343/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.4142 - accuracy: 0.7786\n",
      "Epoch 1344/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4057 - accuracy: 0.7900\n",
      "Epoch 1345/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4104 - accuracy: 0.7843\n",
      "Epoch 1346/1500\n",
      "11/11 [==============================] - 0s 677us/step - loss: 0.4176 - accuracy: 0.7971\n",
      "Epoch 1347/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4103 - accuracy: 0.7929\n",
      "Epoch 1348/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4120 - accuracy: 0.7943\n",
      "Epoch 1349/1500\n",
      "11/11 [==============================] - 0s 653us/step - loss: 0.4071 - accuracy: 0.7886\n",
      "Epoch 1350/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4106 - accuracy: 0.7986\n",
      "Epoch 1351/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.4117 - accuracy: 0.7886\n",
      "Epoch 1352/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4121 - accuracy: 0.7886\n",
      "Epoch 1353/1500\n",
      "11/11 [==============================] - 0s 576us/step - loss: 0.4216 - accuracy: 0.7800\n",
      "Epoch 1354/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4119 - accuracy: 0.8043\n",
      "Epoch 1355/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4106 - accuracy: 0.7886\n",
      "Epoch 1356/1500\n",
      "11/11 [==============================] - 0s 668us/step - loss: 0.4193 - accuracy: 0.7914\n",
      "Epoch 1357/1500\n",
      "11/11 [==============================] - 0s 652us/step - loss: 0.4113 - accuracy: 0.7857\n",
      "Epoch 1358/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4124 - accuracy: 0.7986\n",
      "Epoch 1359/1500\n",
      "11/11 [==============================] - 0s 645us/step - loss: 0.4075 - accuracy: 0.7957\n",
      "Epoch 1360/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.4064 - accuracy: 0.7914\n",
      "Epoch 1361/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4121 - accuracy: 0.7957\n",
      "Epoch 1362/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.4052 - accuracy: 0.7971\n",
      "Epoch 1363/1500\n",
      "11/11 [==============================] - 0s 723us/step - loss: 0.4110 - accuracy: 0.7957\n",
      "Epoch 1364/1500\n",
      "11/11 [==============================] - 0s 532us/step - loss: 0.4175 - accuracy: 0.7943\n",
      "Epoch 1365/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4229 - accuracy: 0.7771\n",
      "Epoch 1366/1500\n",
      "11/11 [==============================] - 0s 526us/step - loss: 0.4291 - accuracy: 0.7814\n",
      "Epoch 1367/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4292 - accuracy: 0.7771\n",
      "Epoch 1368/1500\n",
      "11/11 [==============================] - 0s 563us/step - loss: 0.4098 - accuracy: 0.7943\n",
      "Epoch 1369/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4060 - accuracy: 0.7943\n",
      "Epoch 1370/1500\n",
      "11/11 [==============================] - 0s 769us/step - loss: 0.4153 - accuracy: 0.7886\n",
      "Epoch 1371/1500\n",
      "11/11 [==============================] - 0s 680us/step - loss: 0.4097 - accuracy: 0.7986\n",
      "Epoch 1372/1500\n",
      "11/11 [==============================] - 0s 633us/step - loss: 0.4058 - accuracy: 0.7929\n",
      "Epoch 1373/1500\n",
      "11/11 [==============================] - 0s 538us/step - loss: 0.4135 - accuracy: 0.7843\n",
      "Epoch 1374/1500\n",
      "11/11 [==============================] - 0s 542us/step - loss: 0.4060 - accuracy: 0.8000\n",
      "Epoch 1375/1500\n",
      "11/11 [==============================] - 0s 623us/step - loss: 0.4110 - accuracy: 0.7929\n",
      "Epoch 1376/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4108 - accuracy: 0.7843\n",
      "Epoch 1377/1500\n",
      "11/11 [==============================] - 0s 676us/step - loss: 0.4261 - accuracy: 0.7843\n",
      "Epoch 1378/1500\n",
      "11/11 [==============================] - 0s 650us/step - loss: 0.4027 - accuracy: 0.8014\n",
      "Epoch 1379/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4153 - accuracy: 0.7900\n",
      "Epoch 1380/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4119 - accuracy: 0.7943\n",
      "Epoch 1381/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4031 - accuracy: 0.7914\n",
      "Epoch 1382/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4238 - accuracy: 0.7843\n",
      "Epoch 1383/1500\n",
      "11/11 [==============================] - 0s 621us/step - loss: 0.4155 - accuracy: 0.7900\n",
      "Epoch 1384/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.4120 - accuracy: 0.7914\n",
      "Epoch 1385/1500\n",
      "11/11 [==============================] - 0s 578us/step - loss: 0.4065 - accuracy: 0.7871\n",
      "Epoch 1386/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4103 - accuracy: 0.7957\n",
      "Epoch 1387/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4099 - accuracy: 0.7929\n",
      "Epoch 1388/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4131 - accuracy: 0.7943\n",
      "Epoch 1389/1500\n",
      "11/11 [==============================] - 0s 599us/step - loss: 0.4027 - accuracy: 0.7986\n",
      "Epoch 1390/1500\n",
      "11/11 [==============================] - 0s 623us/step - loss: 0.4104 - accuracy: 0.7957\n",
      "Epoch 1391/1500\n",
      "11/11 [==============================] - 0s 673us/step - loss: 0.4061 - accuracy: 0.7929\n",
      "Epoch 1392/1500\n",
      "11/11 [==============================] - 0s 659us/step - loss: 0.3988 - accuracy: 0.8000\n",
      "Epoch 1393/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4325 - accuracy: 0.7814\n",
      "Epoch 1394/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4194 - accuracy: 0.7929\n",
      "Epoch 1395/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4181 - accuracy: 0.7829\n",
      "Epoch 1396/1500\n",
      "11/11 [==============================] - 0s 614us/step - loss: 0.4100 - accuracy: 0.7871\n",
      "Epoch 1397/1500\n",
      "11/11 [==============================] - 0s 727us/step - loss: 0.4064 - accuracy: 0.7957\n",
      "Epoch 1398/1500\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4137 - accuracy: 0.7914\n",
      "Epoch 1399/1500\n",
      "11/11 [==============================] - 0s 720us/step - loss: 0.4059 - accuracy: 0.8014\n",
      "Epoch 1400/1500\n",
      "11/11 [==============================] - 0s 556us/step - loss: 0.4041 - accuracy: 0.8014\n",
      "Epoch 1401/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4012 - accuracy: 0.7929\n",
      "Epoch 1402/1500\n",
      "11/11 [==============================] - 0s 618us/step - loss: 0.4049 - accuracy: 0.8000\n",
      "Epoch 1403/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4050 - accuracy: 0.7957\n",
      "Epoch 1404/1500\n",
      "11/11 [==============================] - 0s 542us/step - loss: 0.4017 - accuracy: 0.8029\n",
      "Epoch 1405/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4048 - accuracy: 0.7886\n",
      "Epoch 1406/1500\n",
      "11/11 [==============================] - 0s 666us/step - loss: 0.4013 - accuracy: 0.7957\n",
      "Epoch 1407/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 630us/step - loss: 0.4083 - accuracy: 0.7914\n",
      "Epoch 1408/1500\n",
      "11/11 [==============================] - 0s 622us/step - loss: 0.4025 - accuracy: 0.7929\n",
      "Epoch 1409/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4013 - accuracy: 0.7957\n",
      "Epoch 1410/1500\n",
      "11/11 [==============================] - 0s 647us/step - loss: 0.4022 - accuracy: 0.7943\n",
      "Epoch 1411/1500\n",
      "11/11 [==============================] - 0s 581us/step - loss: 0.4077 - accuracy: 0.7986\n",
      "Epoch 1412/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4172 - accuracy: 0.7900\n",
      "Epoch 1413/1500\n",
      "11/11 [==============================] - 0s 599us/step - loss: 0.4066 - accuracy: 0.7843\n",
      "Epoch 1414/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4182 - accuracy: 0.7929\n",
      "Epoch 1415/1500\n",
      "11/11 [==============================] - 0s 547us/step - loss: 0.4188 - accuracy: 0.7857\n",
      "Epoch 1416/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4135 - accuracy: 0.7914\n",
      "Epoch 1417/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.4100 - accuracy: 0.8014\n",
      "Epoch 1418/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4086 - accuracy: 0.7943\n",
      "Epoch 1419/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4386 - accuracy: 0.7700\n",
      "Epoch 1420/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4101 - accuracy: 0.8014\n",
      "Epoch 1421/1500\n",
      "11/11 [==============================] - 0s 615us/step - loss: 0.4069 - accuracy: 0.7929\n",
      "Epoch 1422/1500\n",
      "11/11 [==============================] - 0s 638us/step - loss: 0.4075 - accuracy: 0.7871\n",
      "Epoch 1423/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4027 - accuracy: 0.8000\n",
      "Epoch 1424/1500\n",
      "11/11 [==============================] - 0s 721us/step - loss: 0.4230 - accuracy: 0.7786\n",
      "Epoch 1425/1500\n",
      "11/11 [==============================] - 0s 538us/step - loss: 0.4310 - accuracy: 0.7814\n",
      "Epoch 1426/1500\n",
      "11/11 [==============================] - 0s 681us/step - loss: 0.4134 - accuracy: 0.7900\n",
      "Epoch 1427/1500\n",
      "11/11 [==============================] - 0s 648us/step - loss: 0.4090 - accuracy: 0.8014\n",
      "Epoch 1428/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4109 - accuracy: 0.8000\n",
      "Epoch 1429/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4060 - accuracy: 0.7929\n",
      "Epoch 1430/1500\n",
      "11/11 [==============================] - 0s 561us/step - loss: 0.4011 - accuracy: 0.7986\n",
      "Epoch 1431/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4044 - accuracy: 0.8000\n",
      "Epoch 1432/1500\n",
      "11/11 [==============================] - 0s 654us/step - loss: 0.4072 - accuracy: 0.7900\n",
      "Epoch 1433/1500\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.4078 - accuracy: 0.7986\n",
      "Epoch 1434/1500\n",
      "11/11 [==============================] - 0s 568us/step - loss: 0.4007 - accuracy: 0.7986\n",
      "Epoch 1435/1500\n",
      "11/11 [==============================] - 0s 625us/step - loss: 0.3997 - accuracy: 0.7929\n",
      "Epoch 1436/1500\n",
      "11/11 [==============================] - 0s 673us/step - loss: 0.4012 - accuracy: 0.7957\n",
      "Epoch 1437/1500\n",
      "11/11 [==============================] - 0s 646us/step - loss: 0.4002 - accuracy: 0.7943\n",
      "Epoch 1438/1500\n",
      "11/11 [==============================] - 0s 666us/step - loss: 0.4002 - accuracy: 0.8057\n",
      "Epoch 1439/1500\n",
      "11/11 [==============================] - 0s 729us/step - loss: 0.4084 - accuracy: 0.7971\n",
      "Epoch 1440/1500\n",
      "11/11 [==============================] - 0s 617us/step - loss: 0.4064 - accuracy: 0.7957\n",
      "Epoch 1441/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4114 - accuracy: 0.7971\n",
      "Epoch 1442/1500\n",
      "11/11 [==============================] - 0s 587us/step - loss: 0.4084 - accuracy: 0.7871\n",
      "Epoch 1443/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4071 - accuracy: 0.8029\n",
      "Epoch 1444/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4093 - accuracy: 0.7957\n",
      "Epoch 1445/1500\n",
      "11/11 [==============================] - 0s 832us/step - loss: 0.4013 - accuracy: 0.7971\n",
      "Epoch 1446/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4190 - accuracy: 0.7857\n",
      "Epoch 1447/1500\n",
      "11/11 [==============================] - 0s 692us/step - loss: 0.4101 - accuracy: 0.8014\n",
      "Epoch 1448/1500\n",
      "11/11 [==============================] - 0s 629us/step - loss: 0.4237 - accuracy: 0.7871\n",
      "Epoch 1449/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4021 - accuracy: 0.7986\n",
      "Epoch 1450/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4144 - accuracy: 0.7914\n",
      "Epoch 1451/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4044 - accuracy: 0.8043\n",
      "Epoch 1452/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4097 - accuracy: 0.7914\n",
      "Epoch 1453/1500\n",
      "11/11 [==============================] - 0s 647us/step - loss: 0.3983 - accuracy: 0.8086\n",
      "Epoch 1454/1500\n",
      "11/11 [==============================] - 0s 640us/step - loss: 0.4047 - accuracy: 0.7914\n",
      "Epoch 1455/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4070 - accuracy: 0.7914\n",
      "Epoch 1456/1500\n",
      "11/11 [==============================] - 0s 688us/step - loss: 0.4044 - accuracy: 0.7929\n",
      "Epoch 1457/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4102 - accuracy: 0.7871\n",
      "Epoch 1458/1500\n",
      "11/11 [==============================] - 0s 710us/step - loss: 0.4099 - accuracy: 0.7986\n",
      "Epoch 1459/1500\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4096 - accuracy: 0.7986\n",
      "Epoch 1460/1500\n",
      "11/11 [==============================] - 0s 593us/step - loss: 0.4031 - accuracy: 0.8029\n",
      "Epoch 1461/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.3985 - accuracy: 0.7900\n",
      "Epoch 1462/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4162 - accuracy: 0.7843\n",
      "Epoch 1463/1500\n",
      "11/11 [==============================] - 0s 807us/step - loss: 0.4177 - accuracy: 0.7829\n",
      "Epoch 1464/1500\n",
      "11/11 [==============================] - 0s 585us/step - loss: 0.4366 - accuracy: 0.7814\n",
      "Epoch 1465/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4111 - accuracy: 0.8043\n",
      "Epoch 1466/1500\n",
      "11/11 [==============================] - 0s 597us/step - loss: 0.4135 - accuracy: 0.7929\n",
      "Epoch 1467/1500\n",
      "11/11 [==============================] - 0s 641us/step - loss: 0.4132 - accuracy: 0.7986\n",
      "Epoch 1468/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.3998 - accuracy: 0.8086\n",
      "Epoch 1469/1500\n",
      "11/11 [==============================] - 0s 537us/step - loss: 0.4162 - accuracy: 0.7857\n",
      "Epoch 1470/1500\n",
      "11/11 [==============================] - 0s 534us/step - loss: 0.4034 - accuracy: 0.7914\n",
      "Epoch 1471/1500\n",
      "11/11 [==============================] - 0s 623us/step - loss: 0.3979 - accuracy: 0.7929\n",
      "Epoch 1472/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4054 - accuracy: 0.7971\n",
      "Epoch 1473/1500\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4124 - accuracy: 0.7843\n",
      "Epoch 1474/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4135 - accuracy: 0.8014\n",
      "Epoch 1475/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4163 - accuracy: 0.7971\n",
      "Epoch 1476/1500\n",
      "11/11 [==============================] - 0s 631us/step - loss: 0.3999 - accuracy: 0.7843\n",
      "Epoch 1477/1500\n",
      "11/11 [==============================] - 0s 619us/step - loss: 0.3994 - accuracy: 0.8000\n",
      "Epoch 1478/1500\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.4117 - accuracy: 0.7971\n",
      "Epoch 1479/1500\n",
      "11/11 [==============================] - 0s 697us/step - loss: 0.4055 - accuracy: 0.7914\n",
      "Epoch 1480/1500\n",
      "11/11 [==============================] - 0s 723us/step - loss: 0.3986 - accuracy: 0.7986\n",
      "Epoch 1481/1500\n",
      "11/11 [==============================] - 0s 596us/step - loss: 0.4035 - accuracy: 0.8057\n",
      "Epoch 1482/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.3977 - accuracy: 0.7986\n",
      "Epoch 1483/1500\n",
      "11/11 [==============================] - 0s 681us/step - loss: 0.4032 - accuracy: 0.8000\n",
      "Epoch 1484/1500\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.4027 - accuracy: 0.7943\n",
      "Epoch 1485/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 725us/step - loss: 0.3989 - accuracy: 0.8043\n",
      "Epoch 1486/1500\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4087 - accuracy: 0.7900\n",
      "Epoch 1487/1500\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4059 - accuracy: 0.8014\n",
      "Epoch 1488/1500\n",
      "11/11 [==============================] - 0s 773us/step - loss: 0.4138 - accuracy: 0.7886\n",
      "Epoch 1489/1500\n",
      "11/11 [==============================] - 0s 628us/step - loss: 0.4092 - accuracy: 0.7914\n",
      "Epoch 1490/1500\n",
      "11/11 [==============================] - 0s 609us/step - loss: 0.4085 - accuracy: 0.7929\n",
      "Epoch 1491/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.4010 - accuracy: 0.8014\n",
      "Epoch 1492/1500\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.4014 - accuracy: 0.7971\n",
      "Epoch 1493/1500\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.4181 - accuracy: 0.7929\n",
      "Epoch 1494/1500\n",
      "11/11 [==============================] - 0s 590us/step - loss: 0.4141 - accuracy: 0.7900\n",
      "Epoch 1495/1500\n",
      "11/11 [==============================] - 0s 642us/step - loss: 0.4094 - accuracy: 0.7943\n",
      "Epoch 1496/1500\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4141 - accuracy: 0.7843\n",
      "Epoch 1497/1500\n",
      "11/11 [==============================] - 0s 547us/step - loss: 0.4185 - accuracy: 0.7886\n",
      "Epoch 1498/1500\n",
      "11/11 [==============================] - 0s 674us/step - loss: 0.4029 - accuracy: 0.7943\n",
      "Epoch 1499/1500\n",
      "11/11 [==============================] - 0s 630us/step - loss: 0.4119 - accuracy: 0.7929\n",
      "Epoch 1500/1500\n",
      "11/11 [==============================] - 0s 626us/step - loss: 0.3983 - accuracy: 0.7986\n",
      "3/3 [==============================] - 0s 665us/step - loss: 0.5654 - accuracy: 0.7164\n",
      "accuracy : 71.64%\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# df = pd.read_csv('housing2.csv')   ## 엑셀로 직접 나눈 데이터\n",
    "df = pd.read_csv('pima-indians-diabetes.csv', delimiter = ',', dtype = np.float32)\n",
    "dataset = df.values\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]    # 가격 (단위 : $1.000)\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3,\n",
    "#                                                   random_state = seed)\n",
    "\n",
    "X_train = dataset[:700, 0:8]\n",
    "Y_train = dataset[:700, 8]\n",
    "X_test = dataset[700:, 0:8]\n",
    "Y_test = dataset[700:, 8]   \n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',    #손실함수 : 최소 제곱법 -> 선형 회귀이기 때문에\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "# 모델 저장 폴더 만들기\n",
    "import os\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1,\n",
    "                              save_best_only = True)\n",
    "\n",
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 100)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs = 1500, batch_size = 64)\n",
    "\n",
    "# 모델 평가하기\n",
    "scores = model.evaluate(X_test, Y_test) \n",
    "print(\"%s : %.2f%%\" %(model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-00447f201d23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_vloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# y_acc에 학습셋으로 측정한 정확도의 값을 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc = history.history['accuracy']\n",
    "\n",
    "# x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = numpy.arange(len(y_acc))\n",
    "plt.plot(x_len, y_acc, \"o\", c = 'blue', markersize = 3, label = 'train_accuracy')\n",
    "plt.plot(x_len, y_vloss, \"o\", c = 'red', markersize = 3, label = 'test_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# => 오차는 떨어지고 정확도는 올라감 => 학습이 잘되었다는 것\n",
    "# => 어느 순간 학습셋 정확도가 계속 올라가는데, 테스트셋 오차가 다시 올라가면 => 과적합이 일어났다는 증거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ CNN (컨볼루션 신경망) ✨\n",
    "👉 이미지 => 2차원 배열 => 1차원 배열로 늘림 => 실수형 => 정규화         \n",
    "👉 클래스 => one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋 이미지 수 : 60000 개\n",
      "테스트셋 이미지 수 : 10000 개\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOaElEQVR4nO3de4xc9XnG8eexYwcDDgHWdlywzCWowVBq0IaLjCiUQDAN4lKBcNrIlSgGBStJi9RYNCioVSraXCgBSmvAitMaaCqwQC0JEJOUklDixTHGlzZ2jA12fdkNLZimCdi8/WOHaIGd365nzlzY9/uRRjNz3jlzXo322TNzfnPm54gQgLFvXKcbANAehB1IgrADSRB2IAnCDiTxvnZurKenJ2bOPKqdmwRS2bp1iwYGBjxcramw275A0q2Sxku6OyJuLj1+5syj9INn+prZJICCOaf11q01/Dbe9nhJd0iaK2mWpHm2ZzX6fABaq5nP7KdK2hQRmyPidUn3S7q4mrYAVK2ZsB8h6aUh97fVlr2N7QW2+2z39Q/0N7E5AM1o+dH4iFgcEb0R0TulZ0qrNwegjmbCvl3SjCH3j6wtA9CFmgn7SknH2T7a9kRJV0p6uJq2AFSt4aG3iNhre6GkRzU49LYkItZV1hmASjU1zh4Rj0h6pKJeALQQX5cFkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiaZmcUX32/dmFOuv/WJvS7f/pSc21a3t+b83ius+t3GgWH9o4Zxifd6SH9WtPbvsH4vr6oCDi+Wr/mR+sf6Vi44vP38HNBV221sk7ZG0T9LeiOitoikA1atiz35ORJT/BQPoOD6zA0k0G/aQ9JjtZ20vGO4BthfY7rPd1z/Q3+TmADSq2bCfGRGnSJor6TrbZ73zARGxOCJ6I6J3Ss+UJjcHoFFNhT0itteud0taLunUKpoCUL2Gw277INuT37ot6XxJa6tqDEC1mjkaP03ScttvPc+9EfGdSroaY3b+zy+K9Tf2vVms//DF8mDH/X076tb++5Xytp/7pweL9Y6acUKxfNmd5X3V2geX1y9OPry47tTZ5VHkT574oWK9GzUc9ojYLOk3K+wFQAsx9AYkQdiBJAg7kARhB5Ig7EASnOJagZ/s2FOsnzb/tvITvLKrwm7eQ8aNL5b/7gtzi/UPTBzhz/eiRXVLR04+sLjq5EkTivWZPeX1uxF7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2Ckw75IBifXzPrxXr+7p4nP3w088p1g/5YHm8efMTT9QvTpxUXPeK2TOKdewf9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7BU45MDyuc/33nhBsX7Hkx8p1s87cWqxfuMf31qsl3zg5DOL9ee/fFGxPmli+Zz0zdfVn1b5+oeYZqCd2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs7fB+ceXp/edc3RPsX7g+8tj2Sv+8JN1a9+/+97iurd8+oxifaRx9JEcM/WgurXlV5/W1HNj/4y4Z7e9xPZu22uHLDvM9uO2N9auD21tmwCaNZq38d+Q9M6vgC2StCIijpO0onYfQBcbMewR8aSkl9+x+GJJS2u3l0q6pNq2AFSt0QN00yJiR+32TknT6j3Q9gLbfbb7+gf6G9wcgGY1fTQ+IkJSFOqLI6I3Inqn9ExpdnMAGtRo2HfZni5Jtevd1bUEoBUaDfvDkubXbs+X9FA17QBolRHH2W3fJ+lsST22t0n6oqSbJX3L9lWStkq6opVNjnUHHdDc1x16Jpd/t77kxmVrivVLTjyiWB83zg1vG+014l9ZRMyrUzq34l4AtBBflwWSIOxAEoQdSIKwA0kQdiAJTnEdA75+2Yl1az/88ceL6/7X9x8t1p/ZXD4N9YwPH16so3uwZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnHwNKP/f86OfPKa77G30ri/ULFz1QrJ/x2/XH+CVp7kl1f7FMC+ccU1zX5vTZKrFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGcf4448bFKxfv9t1xTrV37mrmL96aXryvVC7eU//3Rx3evOOKpY75n8/mIdb8eeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJw9uY/P+lCx3rfsj4r1y77+VLH+4ne/Xbf21zf+TXHd9df+frF+2++eVKxP/QDj8EONuGe3vcT2bttrhyy7yfZ226trlwtb2yaAZo3mbfw3JF0wzPJbImJ27fJItW0BqNqIYY+IJyW93IZeALRQMwfoFtpeU3ubf2i9B9leYLvPdl//QH8TmwPQjEbDfqekYyXNlrRD0lfrPTAiFkdEb0T0TumZ0uDmADSrobBHxK6I2BcRb0q6S9Kp1bYFoGoNhd329CF3L5W0tt5jAXSHEcfZbd8n6WxJPba3SfqipLNtz5YUkrZIKp8UjfesY6cdXKw/9YVzi/VvX35C3do119b99CdJeuxv/6FY/9jGucX6mr8YbhAprxHDHhHzhll8Twt6AdBCfF0WSIKwA0kQdiAJwg4kQdiBJDjFFU2ZPGlCsX7F7Bl1a9eML6+rva8Xyy/964pifdULp9WtnXJ03W94j1ns2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZUbRp52vF+u3/vrVYf3LV9vrFEcbRR3LwCb3F+uyZH2zq+cca9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7GPc1oGfF+uL/nl9sf6d5U+XN7Bz0/62NHrjy3+eU6eXz0kfN85VdvOex54dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnP094Gd7flms373yxbq1v1z8b8V144XnGuqpCod+9LeK9bsWzinWz/3ItCrbGfNG3LPbnmH7e7bX215n+7O15YfZftz2xtp1vl/dB95DRvM2fq+k6yNilqTTJV1ne5akRZJWRMRxklbU7gPoUiOGPSJ2RMSq2u09kjZIOkLSxZKW1h62VNIlLeoRQAX26wCd7aMknSzpGUnTImJHrbRT0rAfoGwvsN1nu69/oL+ZXgE0YdRht32wpAckfS4iXh1ai4iQFMOtFxGLI6I3Inqn9ExpqlkAjRtV2G1P0GDQl0XEg7XFu2xPr9WnS9rdmhYBVGHEoTfblnSPpA0R8bUhpYclzZd0c+36oZZ0OAb87LXyTya/sPt/i/VP/Nm/FOu/3LByv3uqyuGnn1Os33HN6XVr540wdMYpqtUazTj7HEmfkvS87dW1ZTdoMOTfsn2VpK2SrmhJhwAqMWLYI+IpSfX+xZ5bbTsAWoWvywJJEHYgCcIOJEHYgSQIO5AEp7iO0is/f6Nu7aLbf1Bcd/3qLcX6vp/+uJGWKjF1zseK9duu/mixftaHy9+KPGDC+P3uCa3Bnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkkgzzr5u26vF+rXLVhXra3/0H/WL2zY00lJ1Jk2uW/q9z1xZXPXLnzi+/NQTGScfK9izA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASacbZb396S7G+9sHlLdv2AbNOLdYv/Z2TivX3jS//fvqXLvj1urXJkyYU10Ue7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IInRzM8+Q9I3JU2TFJIWR8Sttm+SdLWk/tpDb4iIR1rVaLPuvLw8ln3n5be2qROgM0bzpZq9kq6PiFW2J0t61vbjtdotEfGV1rUHoCqjmZ99h6Qdtdt7bG+QdESrGwNQrf36zG77KEknS3qmtmih7TW2l9g+tM46C2z32e7rH+gf7iEA2mDUYbd9sKQHJH0uIl6VdKekYyXN1uCe/6vDrRcRiyOiNyJ6p/SU5wUD0DqjCrvtCRoM+rKIeFCSImJXROyLiDcl3SWpfLYHgI4aMey2LekeSRsi4mtDlk8f8rBLJa2tvj0AVRnN0fg5kj4l6Xnbq2vLbpA0z/ZsDQ7HbZF0TQv6A1CR0RyNf0rScCdUd+2YOoB34xt0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBwR7duY3S9p65BFPZIG2tbA/unW3rq1L4neGlVlbzMjYtjff2tr2N+1cbsvIno71kBBt/bWrX1J9NaodvXG23ggCcIOJNHpsC/u8PZLurW3bu1LordGtaW3jn5mB9A+nd6zA2gTwg4k0ZGw277A9n/a3mR7USd6qMf2FtvP215tu6/DvSyxvdv22iHLDrP9uO2Nteth59jrUG832d5ee+1W276wQ73NsP092+ttr7P92dryjr52hb7a8rq1/TO77fGSfiLpPEnbJK2UNC8i1re1kTpsb5HUGxEd/wKG7bMkvSbpmxFxYm3ZX0l6OSJurv2jPDQiPt8lvd0k6bVOT+Ndm61o+tBpxiVdIukP1MHXrtDXFWrD69aJPfupkjZFxOaIeF3S/ZIu7kAfXS8inpT08jsWXyxpae32Ug3+sbRdnd66QkTsiIhVtdt7JL01zXhHX7tCX23RibAfIemlIfe3qbvmew9Jj9l+1vaCTjczjGkRsaN2e6ekaZ1sZhgjTuPdTu+YZrxrXrtGpj9vFgfo3u3MiDhF0lxJ19XernalGPwM1k1jp6Oaxrtdhplm/Fc6+do1Ov15szoR9u2SZgy5f2RtWVeIiO21692Slqv7pqLe9dYMurXr3R3u51e6aRrv4aYZVxe8dp2c/rwTYV8p6TjbR9ueKOlKSQ93oI93sX1Q7cCJbB8k6Xx131TUD0uaX7s9X9JDHezlbbplGu9604yrw69dx6c/j4i2XyRdqMEj8j+V9Ked6KFOX8dIeq52Wdfp3iTdp8G3dW9o8NjGVZIOl7RC0kZJ35V0WBf19veSnpe0RoPBmt6h3s7U4Fv0NZJW1y4Xdvq1K/TVlteNr8sCSXCADkiCsANJEHYgCcIOJEHYgSQIO5AEYQeS+H8/MRvwx76DpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist   ## mnist 데이터를 불러옴\n",
    "\n",
    "(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()\n",
    "# 이 때 불러온 이미지 데이터를 X로, 이 이미지에 0~9까지 붙인 이름표를 Y_class로!!\n",
    "\n",
    "print(\"학습셋 이미지 수 : %d 개\" % (X_train.shape[0]))\n",
    "print(\"테스트셋 이미지 수 : %d 개\" % (X_test.shape[0]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap = 'Blues')   # cmap = 'Greys' : 흑백으로 출력되게 함\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  3 18 18 18126136175 26166255247127  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 30 36 94154170253253253253253225172253242195 64  0  0  0  0\n",
      "  0  0  0  0  0  0  0 49238253253253253253253253253251 93 82 82 56 39  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0 18219253253253253253198182247241  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 80156107253253205 11  0 43154  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 14  1154253 90  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0139253190  2  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 11190253 70  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 35241225160108  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0 81240253253119 25  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 45186253253150 27  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16 93252253187  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0249253249 64  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 46130183253253207  2  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 39148229253253253250182  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 24114221253253253253201 78  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 23 66213253253253253198 81  2  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 18171219253253253253195 80  9  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 55172226253253253253244133 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0136253253253212135132 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "for x in X_train[0]:\n",
    "    for i in x:\n",
    "        sys.stdout.write('%3d' % i)\n",
    "    sys.stdout.write('\\n')\n",
    "\n",
    "# 이렇게 이미지는 다시 숫자의 집합으로 바뀌어 학습셋으로 사용됨\n",
    "# 28 * 28 = 784 개의 속성을 이용해 (0~9) 10개 클래스 중 하나를 맞히는 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 784)\n",
    "X_train\n",
    "\n",
    "# 주어진 가로 28, 세로 28의 2차원 배열을 784개의 1차원 배열로 바꿔 줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0~255 사이의 값으로 이루어진 값을 0~1 사이의 값으로 바꿔야 함\n",
    "# 바꾸는 방법은 각 값을 255로 나누는 것\n",
    "# 이렇게 데이터의 폭이 클 때 적절한 값으로 분산의 정도를 바꾸는 과정을 ⭐데이터 정규화⭐ 라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float64')   ## 실수형으로 바꿔줘야 나누기 가능\n",
    "X_train = X_train / 255\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float64') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class : 5\n"
     ]
    }
   ],
   "source": [
    "print(\"class : %d\" % (Y_class_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## class => one-hot encoding 해준다 => 0~9까지의 값을 0,1로 이루어지게 바꾸자\n",
    "## ex) class : 5 => [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_class_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_class_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[0])    # one-hot encoding이 적용된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋 이미지 수 : 60000 개\n",
      "테스트셋 이미지 수 : 10000 개\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  3 18 18 18126136175 26166255247127  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 30 36 94154170253253253253253225172253242195 64  0  0  0  0\n",
      "  0  0  0  0  0  0  0 49238253253253253253253253253251 93 82 82 56 39  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0 18219253253253253253198182247241  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 80156107253253205 11  0 43154  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 14  1154253 90  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0139253190  2  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 11190253 70  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 35241225160108  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0 81240253253119 25  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 45186253253150 27  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16 93252253187  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0249253249 64  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 46130183253253207  2  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 39148229253253253250182  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 24114221253253253253201 78  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 23 66213253253253253198 81  2  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 18171219253253253253195 80  9  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 55172226253253253253244133 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0136253253253212135132 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "class : 5\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding : utf-8 -*\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# MNIST 데이터셋 불러오기\n",
    "(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()\n",
    "# 이 때 불러온 이미지 데이터를 X로, 이 이미지에 0~9까지 붙인 이름표를 Y_class로!!\n",
    "\n",
    "print(\"학습셋 이미지 수 : %d 개\" % (X_train.shape[0]))\n",
    "print(\"테스트셋 이미지 수 : %d 개\" % (X_test.shape[0]))\n",
    "\n",
    "\n",
    "# 그래프로 확인\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap = 'Blues')   # cmap = 'Greys' : 흑백으로 출력되게 함\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 코드로 확인\n",
    "import sys\n",
    "for x in X_train[0]:\n",
    "    for i in x:\n",
    "        sys.stdout.write('%3d' % i)\n",
    "    sys.stdout.write('\\n')\n",
    "\n",
    "    \n",
    "# 차원 변환 과정\n",
    "X_train = X_train.reshape(X_train.shape[0], 784).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float32') / 255\n",
    "\n",
    "\n",
    "# 클래스 값 확인\n",
    "print(\"class : %d\" % (Y_class_train[0]))\n",
    "\n",
    "\n",
    "# 바이너리화 과정\n",
    "Y_train = np_utils.to_categorical(Y_class_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_class_test, 10)\n",
    "\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15533, saving model to ./model\\01-0.1553.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15533 to 0.10623, saving model to ./model\\02-0.1062.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10623 to 0.08204, saving model to ./model\\03-0.0820.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08204 to 0.07681, saving model to ./model\\04-0.0768.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07681 to 0.06882, saving model to ./model\\05-0.0688.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06882 to 0.06567, saving model to ./model\\06-0.0657.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06567 to 0.06195, saving model to ./model\\07-0.0620.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06195 to 0.05934, saving model to ./model\\08-0.0593.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05934\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05934\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.05934\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.05934\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.05934\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.05934\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.05934\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.05934\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05934\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05934\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9801\n",
      "\n",
      " Accuracy : 0.9801\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim = 784, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',  \n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "# 모델 저장 폴더 만들기\n",
    "import os\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1,\n",
    "                              save_best_only = True)   # 앞서 저장한 모델보다 나아졌을 때만 모델 저장 \n",
    "\n",
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "# 10번 이상 loss가 좋아지지 않으면 중단\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    validation_data = (X_test, Y_test), epochs = 30, batch_size = 200, verbose = 0,\n",
    "                   callbacks = [early_stopping_callback, checkpointer])\n",
    "               ## validation = 검증 : 검증 데이터에 test set을 지정한다.\n",
    "               ## validation_data 를 지정안하면 validation_split 을 지정해주어야 한다!!\n",
    "\n",
    "print(\"\\n Accuracy : %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#테스트셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker = '.', c = 'red', label = 'Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker = '.', c = 'blue', label = 'Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "# plt.axis([0, 20, 0, 0.35])\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ CNN (컨볼루션 신경망) 실행하기 ✨\n",
    "-> 더 빨리, 더 정확하게 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "## 학습이 진행되어도 테스트셋 오차가 줄지 않으면 학습을 멈추게 하는 함수\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "from tensorflow.keras.datasets import mnist   ## mnist 데이터를 불러옴\n",
    "\n",
    "(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()\n",
    "\n",
    "# 데이터 불러오기\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "# one-hot encoding 적용\n",
    "Y_train = np_utils.to_categorical(Y_class_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_class_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.9160\n",
      "Epoch 00001: val_loss improved from inf to 0.05740, saving model to ./model\\01-0.0574.hdf5\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.2771 - accuracy: 0.9160 - val_loss: 0.0574 - val_accuracy: 0.9815\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9725\n",
      "Epoch 00002: val_loss improved from 0.05740 to 0.04747, saving model to ./model\\02-0.0475.hdf5\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 0.0911 - accuracy: 0.9725 - val_loss: 0.0475 - val_accuracy: 0.9833\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9797\n",
      "Epoch 00003: val_loss improved from 0.04747 to 0.03501, saving model to ./model\\03-0.0350.hdf5\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 0.0689 - accuracy: 0.9797 - val_loss: 0.0350 - val_accuracy: 0.9881\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9829\n",
      "Epoch 00004: val_loss improved from 0.03501 to 0.03418, saving model to ./model\\04-0.0342.hdf5\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0558 - accuracy: 0.9829 - val_loss: 0.0342 - val_accuracy: 0.9882\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9857\n",
      "Epoch 00005: val_loss improved from 0.03418 to 0.03207, saving model to ./model\\05-0.0321.hdf5\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.0321 - val_accuracy: 0.9899\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9871\n",
      "Epoch 00006: val_loss improved from 0.03207 to 0.02987, saving model to ./model\\06-0.0299.hdf5\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 0.0410 - accuracy: 0.9871 - val_loss: 0.0299 - val_accuracy: 0.9914\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9891\n",
      "Epoch 00007: val_loss improved from 0.02987 to 0.02867, saving model to ./model\\07-0.0287.hdf5\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 0.0352 - accuracy: 0.9891 - val_loss: 0.0287 - val_accuracy: 0.9908\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9895\n",
      "Epoch 00008: val_loss did not improve from 0.02867\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0314 - val_accuracy: 0.9905\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9910\n",
      "Epoch 00009: val_loss improved from 0.02867 to 0.02773, saving model to ./model\\09-0.0277.hdf5\n",
      "300/300 [==============================] - 39s 129ms/step - loss: 0.0290 - accuracy: 0.9910 - val_loss: 0.0277 - val_accuracy: 0.9909\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9917\n",
      "Epoch 00010: val_loss did not improve from 0.02773\n",
      "300/300 [==============================] - 36s 120ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.0299 - val_accuracy: 0.9911\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9915\n",
      "Epoch 00011: val_loss did not improve from 0.02773\n",
      "300/300 [==============================] - 36s 119ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0312 - val_accuracy: 0.9908\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9928\n",
      "Epoch 00012: val_loss did not improve from 0.02773\n",
      "300/300 [==============================] - 36s 120ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.0298 - val_accuracy: 0.9925\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9928\n",
      "Epoch 00013: val_loss did not improve from 0.02773\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.0326 - val_accuracy: 0.9914\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9931\n",
      "Epoch 00014: val_loss did not improve from 0.02773\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0308 - val_accuracy: 0.9910\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9939\n",
      "Epoch 00015: val_loss did not improve from 0.02773\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0316 - val_accuracy: 0.9918\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9934\n",
      "Epoch 00016: val_loss did not improve from 0.02773\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 0.0183 - accuracy: 0.9934 - val_loss: 0.0302 - val_accuracy: 0.9929\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9947\n",
      "Epoch 00017: val_loss did not improve from 0.02773\n",
      "300/300 [==============================] - 37s 124ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0358 - val_accuracy: 0.9909\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9949\n",
      "Epoch 00018: val_loss did not improve from 0.02773\n",
      "300/300 [==============================] - 37s 124ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0287 - val_accuracy: 0.9924\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9948\n",
      "Epoch 00019: val_loss did not improve from 0.02773\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.0289 - val_accuracy: 0.9930\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0289 - accuracy: 0.9930\n",
      "\n",
      " Accuracy : 0.9930\n"
     ]
    }
   ],
   "source": [
    "# 컨볼루션 신경망 설정\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))    # 맥스 풀링 -> 간추림\n",
    "model.add(Dropout(0.25))   # 학습이 진행 될 때 랜덤하게 은닉층의 노드를 계산하지 않음\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "# 모델 최적화 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1,\n",
    "                              save_best_only = True)   # 앞서 저장한 모델보다 나아졌을 때만 모델 저장 \n",
    "\n",
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "# 10번 이상 loss가 좋아지지 않으면 중단\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    validation_data = (X_test, Y_test), epochs = 30, batch_size = 200, verbose = 1,\n",
    "                   callbacks = [early_stopping_callback, checkpointer])\n",
    "\n",
    "# model 저장\n",
    "model.save('./model/my_model_cnn_use.h5')\n",
    "\n",
    "print(\"\\n Accuracy : %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "## 정확도가 전보다 훨씬 좋아짐 : 99.3%\n",
    "## => but, 100%가 아닌 이유 : 데이터 안에 사람의 눈으로도 확인할 수 없는 글씨가 들어있었기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker = '.', c = 'red', label = 'Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker = '.', c = 'blue', label = 'Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "# plt.axis([0, 20, 0, 0.35])\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
