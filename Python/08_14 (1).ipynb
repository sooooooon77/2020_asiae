{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 다중 로지스틱 회귀 실습 ✨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 당뇨 데이터를 활용한 당뇨 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5000, W1 = -0.7133, W2 = -2.1019, W3 = 0.1283, W4 = -0.5249, W5 = -0.2082, W6 = -0.9658, W7 = -0.3619, W8 = 0.0189, b = 0.4189, cost = 0.4995\n",
      "step = 10000, W1 = -0.8332, W2 = -2.8493, W3 = 0.0250, W4 = -0.6205, W5 = -0.2910, W6 = -1.4362, W7 = -0.6406, W8 = -0.0420, b = 0.3123, cost = 0.4800\n",
      "step = 15000, W1 = -0.8625, W2 = -3.1866, W3 = 0.0331, W4 = -0.6444, W5 = -0.2972, W6 = -1.7349, W7 = -0.7983, W8 = -0.0409, b = 0.2743, cost = 0.4753\n",
      "step = 20000, W1 = -0.8749, W2 = -3.3604, W3 = 0.0724, W4 = -0.6459, W5 = -0.2970, W6 = -1.9434, W7 = -0.8841, W8 = -0.0411, b = 0.2498, cost = 0.4736\n",
      "step = 25000, W1 = -0.8820, W2 = -3.4553, W3 = 0.1204, W4 = -0.6383, W5 = -0.2991, W6 = -2.0968, W7 = -0.9307, W8 = -0.0464, b = 0.2301, cost = 0.4728\n",
      "step = 30000, W1 = -0.8866, W2 = -3.5088, W3 = 0.1687, W4 = -0.6267, W5 = -0.3034, W6 = -2.2134, W7 = -0.9562, W8 = -0.0544, b = 0.2134, cost = 0.4724\n",
      "step = 35000, W1 = -0.8898, W2 = -3.5395, W3 = 0.2138, W4 = -0.6138, W5 = -0.3089, W6 = -2.3042, W7 = -0.9702, W8 = -0.0633, b = 0.1991, cost = 0.4722\n",
      "step = 40000, W1 = -0.8921, W2 = -3.5573, W3 = 0.2542, W4 = -0.6007, W5 = -0.3149, W6 = -2.3761, W7 = -0.9779, W8 = -0.0720, b = 0.1869, cost = 0.4720\n",
      "step = 45000, W1 = -0.8938, W2 = -3.5679, W3 = 0.2897, W4 = -0.5884, W5 = -0.3209, W6 = -2.4339, W7 = -0.9821, W8 = -0.0800, b = 0.1765, cost = 0.4719\n",
      "step = 50000, W1 = -0.8951, W2 = -3.5743, W3 = 0.3203, W4 = -0.5770, W5 = -0.3265, W6 = -2.4807, W7 = -0.9844, W8 = -0.0870, b = 0.1677, cost = 0.4718\n",
      "\n",
      "Accuracy : 0.7681159420289855\n"
     ]
    }
   ],
   "source": [
    "Data_set = np.loadtxt(\"data-03-diabetes.csv\", delimiter = \",\")\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "x_data = Data_set[: , 0 : -1]\n",
    "y_data = Data_set[: , [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape = [None, 8])  # 개수가 정확하지 않을 때 : None 사용!\n",
    "Y = tf.placeholder(tf.float64, shape = [None, 1])\n",
    "\n",
    "# 기울기 a와 바이어스 b의 값을 임의로 정함\n",
    "W = tf.Variable(tf.random_uniform([8, 1], dtype = tf.float64), name = 'Weight')\n",
    "# [8, 1] 의미 : 들어오는 값은 8개, 나가는 값은 1개\n",
    "\n",
    "b = tf.Variable(tf.random_uniform([1], dtype = tf.float64), name = 'bias')\n",
    "\n",
    "# y 시그모이드 함수의 방정식을 세움\n",
    "y = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# 오차를 구하는 함수\n",
    "cost = -tf.reduce_mean(Y * tf.log(y) + (1 - Y) * tf.log(1 - y))\n",
    "\n",
    "# 학습률 값\n",
    "learning_rate = 0.01\n",
    "\n",
    "# 오차를 최소로 하는 값 찾기\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "# 💥🚫⛔우리가 만든 모델의 정밀도를 측정하기 위해!💥🚫⛔\n",
    "predicted = tf.cast(y > 0.5, dtype = tf.float64)   ## 0.5 를 기준으로 0, 1을 반환해준다.\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float64))  ## predicted 와 Y가 같은지, 다른지\n",
    "# => reduce_mean : 배열의 평균 (predicted(예측값)와 Y(실제값)를 비교했을 때 결과의 평균 = 정확도)\n",
    "\n",
    "\n",
    "# 학습\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(50001):\n",
    "        W_, b_, cost_, _ = sess.run([W, b, cost, gradient_decent], feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if (i + 1) % 5000 == 0:\n",
    "            print(\"step = %d, W1 = %.4f, W2 = %.4f, W3 = %.4f, W4 = %.4f, W5 = %.4f, W6 = %.4f, W7 = %.4f, W8 = %.4f, b = %.4f, cost = %.4f\" \n",
    "                 % (i + 1, W_[0], W_[1], W_[2], W_[3], W_[4], W_[5], W_[6], W_[7], b_, cost_))\n",
    "    \n",
    "    \n",
    "    # 추가 코드\n",
    "    #print(\"predicted = \", sess.run(predicted, feed_dict={X:x_data}))   # => y를 구하려면 X를 지정해줘야한다.\n",
    "\n",
    "    # 다른 값 테스트\n",
    "    #p_val, h_val = sess.run([predicted, y], feed_dict = {X:[[1, 5], [10, 5], [4, 5]]})\n",
    "    #print(\"check predicted =\", p_val)   # 연산된 값을 bool로 변환한 값\n",
    "    #print(\"check hypothesis =\", h_val)  # 계산값\n",
    "    \n",
    "    # 정확도 측정\n",
    "    #h, c, a = sess.run([y, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    #print(\"\\nHypothesis :\", h, \"\\nCorrect (Y) :\", c, \"\\nAccuracy :\", a)        \n",
    "    \n",
    "    # 정확도 측정\n",
    "    _, _, a = sess.run([y, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print(\"\\nAccuracy :\", a)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 퍼셉트론 ✨\n",
    "🐶 신경망을 이루는 가장 중요한 기본 단위\n",
    "\n",
    "🐱 y = ax + b ( a는 기울기, b는 y 절편 ) 👉 y = Wx + b ( W는 가중치, b는 바이어스 )\n",
    "\n",
    "🦊 가중합 : W1x1+ W2x2 + b      \n",
    "🦊 활성화 함수  ex) 시그모이드\n",
    "\n",
    "🐰 XOR (exclusive OR) 문제를 해결하지 못 함! ([1,1] : 0, [0,0] : 0, [1,0] : 1, [0,1] : 1)             \n",
    "\n",
    "🤓 기존처럼 하나의 선이 아닌 두 개의 선을 그어 교집합을 찾자        \n",
    " x1 XOR x2 == NOT (x1 AND x2) AND (x1 OR x2) == (x1 NAND x2) AND (x1 OR x2)    \n",
    "\n",
    "🧐 Hidden Layer(은닉층)에는 두 개의 직선을 만들기 위해 두 개의 뉴런이 필요 => 이 둘 교차시키는 연산 필요 => ⭐다중 퍼셉트론⭐\n",
    "\n",
    "🐨오차 역전파는 경사 하강법의 확장 개념     \n",
    "신경망 내부의 가중치는 오차 역전파를 이용하여 수정하여 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1️⃣ single neural network AND 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 cost = 0.70660204 W = [[2.4511883 ]\n",
      " [0.39721212]] b = [-0.8031659]\n",
      "step = 100 cost = 0.3377292 W = [[1.8987201]\n",
      " [0.7005495]] b = [-2.2825046]\n",
      "step = 200 cost = 0.2782881 W = [[2.015758 ]\n",
      " [1.2689223]] b = [-2.786027]\n",
      "step = 300 cost = 0.23981419 W = [[2.1807175]\n",
      " [1.7022659]] b = [-3.1967237]\n",
      "step = 400 cost = 0.21204533 W = [[2.3562264]\n",
      " [2.0417883]] b = [-3.5589411]\n",
      "step = 500 cost = 0.19060236 W = [[2.5321186]\n",
      " [2.3203743]] b = [-3.8840754]\n",
      "step = 600 cost = 0.17331824 W = [[2.7033732]\n",
      " [2.5575235]] b = [-4.1793666]\n",
      "step = 700 cost = 0.1589841 W = [[2.8676171]\n",
      " [2.7650511]] b = [-4.4500313]\n",
      "step = 800 cost = 0.14685471 W = [[3.023933 ]\n",
      " [2.9504292]] b = [-4.699982]\n",
      "step = 900 cost = 0.1364345 W = [[3.1721797]\n",
      " [3.1185846]] b = [-4.9322295]\n",
      "step = 1000 cost = 0.127375 W = [[3.312608 ]\n",
      " [3.2729087]] b = [-5.14915]\n",
      "step = 1100 cost = 0.119420886 W = [[3.4456546]\n",
      " [3.4158213]] b = [-5.3526554]\n",
      "step = 1200 cost = 0.11237925 W = [[3.5718274]\n",
      " [3.5491076]] b = [-5.5443096]\n",
      "step = 1300 cost = 0.10610096 W = [[3.6916459]\n",
      " [3.6741312]] b = [-5.725408]\n",
      "step = 1400 cost = 0.10046807 W = [[3.8056078]\n",
      " [3.7919543]] b = [-5.8970494]\n",
      "step = 1500 cost = 0.09538638 W = [[3.914183 ]\n",
      " [3.9034286]] b = [-6.060157]\n",
      "step = 1600 cost = 0.09077913 W = [[4.0178   ]\n",
      " [4.0092483]] b = [-6.215527]\n",
      "step = 1700 cost = 0.086583376 W = [[4.1168504]\n",
      " [4.1099906]] b = [-6.3638525]\n",
      "step = 1800 cost = 0.08274685 W = [[4.211688]\n",
      " [4.206138]] b = [-6.5057297]\n",
      "step = 1900 cost = 0.07922585 W = [[4.302631]\n",
      " [4.298105]] b = [-6.6416845]\n",
      "step = 2000 cost = 0.07598341 W = [[4.389967 ]\n",
      " [4.3862476]] b = [-6.772182]\n",
      "step = 2100 cost = 0.072988175 W = [[4.473953 ]\n",
      " [4.4708786]] b = [-6.897634]\n",
      "step = 2200 cost = 0.0702132 W = [[4.5548267]\n",
      " [4.5522695]] b = [-7.018409]\n",
      "step = 2300 cost = 0.06763549 W = [[4.6328   ]\n",
      " [4.6306586]] b = [-7.134835]\n",
      "step = 2400 cost = 0.06523481 W = [[4.708065]\n",
      " [4.706262]] b = [-7.2472053]\n",
      "step = 2500 cost = 0.06299399 W = [[4.7807965]\n",
      " [4.779269 ]] b = [-7.355789]\n",
      "step = 2600 cost = 0.060897723 W = [[4.851152]\n",
      " [4.849851]] b = [-7.460826]\n",
      "step = 2700 cost = 0.058932684 W = [[4.9192753]\n",
      " [4.918164 ]] b = [-7.562534]\n",
      "step = 2800 cost = 0.05708702 W = [[4.9853005]\n",
      " [4.9843464]] b = [-7.661115]\n",
      "step = 2900 cost = 0.05535041 W = [[5.0493493]\n",
      " [5.0485272]] b = [-7.75675]\n",
      "step = 3000 cost = 0.05371357 W = [[5.1115327]\n",
      " [5.1108217]] b = [-7.849606]\n",
      "step = 3100 cost = 0.052168332 W = [[5.171953 ]\n",
      " [5.1713357]] b = [-7.9398365]\n",
      "step = 3200 cost = 0.050707236 W = [[5.230704]\n",
      " [5.230167]] b = [-8.027581]\n",
      "step = 3300 cost = 0.049323674 W = [[5.287874 ]\n",
      " [5.2874055]] b = [-8.112971]\n",
      "step = 3400 cost = 0.04801185 W = [[5.343545]\n",
      " [5.343133]] b = [-8.196127]\n",
      "step = 3500 cost = 0.0467662 W = [[5.3977895]\n",
      " [5.3974266]] b = [-8.277162]\n",
      "step = 3600 cost = 0.04558204 W = [[5.4506783]\n",
      " [5.450358 ]] b = [-8.356176]\n",
      "step = 3700 cost = 0.044454984 W = [[5.5022745]\n",
      " [5.5019913]] b = [-8.433269]\n",
      "step = 3800 cost = 0.043381058 W = [[5.5526414]\n",
      " [5.5523863]] b = [-8.508526]\n",
      "step = 3900 cost = 0.042356588 W = [[5.6018305]\n",
      " [5.601604 ]] b = [-8.582033]\n",
      "step = 4000 cost = 0.04137838 W = [[5.6498966]\n",
      " [5.6496944]] b = [-8.653868]\n",
      "step = 4100 cost = 0.0404433 W = [[5.6968884]\n",
      " [5.6967077]] b = [-8.724101]\n",
      "step = 4200 cost = 0.03954865 W = [[5.7428527]\n",
      " [5.7426896]] b = [-8.792805]\n",
      "step = 4300 cost = 0.0386919 W = [[5.7878327]\n",
      " [5.787684 ]] b = [-8.860041]\n",
      "step = 4400 cost = 0.03787069 W = [[5.8318667]\n",
      " [5.831732 ]] b = [-8.925867]\n",
      "step = 4500 cost = 0.037082918 W = [[5.8749943]\n",
      " [5.874872 ]] b = [-8.990344]\n",
      "step = 4600 cost = 0.036326565 W = [[5.91725]\n",
      " [5.91714]] b = [-9.053524]\n",
      "step = 4700 cost = 0.03559988 W = [[5.95867  ]\n",
      " [5.9585705]] b = [-9.115456]\n",
      "step = 4800 cost = 0.034901068 W = [[5.999284 ]\n",
      " [5.9991937]] b = [-9.1761875]\n",
      "step = 4900 cost = 0.034228697 W = [[6.039123]\n",
      " [6.039041]] b = [-9.2357645]\n",
      "step = 5000 cost = 0.03358121 W = [[6.078216]\n",
      " [6.078142]] b = [-9.29423]\n",
      "step = 5100 cost = 0.032957297 W = [[6.11659  ]\n",
      " [6.1165223]] b = [-9.351622]\n",
      "step = 5200 cost = 0.032355692 W = [[6.15427 ]\n",
      " [6.154209]] b = [-9.407978]\n",
      "step = 5300 cost = 0.03177531 W = [[6.1912794]\n",
      " [6.1912236]] b = [-9.463337]\n",
      "step = 5400 cost = 0.031214967 W = [[6.227643]\n",
      " [6.227591]] b = [-9.51773]\n",
      "step = 5500 cost = 0.030673733 W = [[6.263381 ]\n",
      " [6.2633333]] b = [-9.571191]\n",
      "step = 5600 cost = 0.030150615 W = [[6.298515 ]\n",
      " [6.2984705]] b = [-9.623751]\n",
      "step = 5700 cost = 0.029644724 W = [[6.3330646]\n",
      " [6.333024 ]] b = [-9.675439]\n",
      "step = 5800 cost = 0.029155215 W = [[6.367048 ]\n",
      " [6.3670106]] b = [-9.726282]\n",
      "step = 5900 cost = 0.028681394 W = [[6.400484 ]\n",
      " [6.4004498]] b = [-9.776309]\n",
      "step = 6000 cost = 0.028222457 W = [[6.4333897]\n",
      " [6.4333572]] b = [-9.825544]\n",
      "step = 6100 cost = 0.027777687 W = [[6.4657807]\n",
      " [6.4657507]] b = [-9.874012]\n",
      "step = 6200 cost = 0.027346509 W = [[6.497673]\n",
      " [6.497646]] b = [-9.921737]\n",
      "step = 6300 cost = 0.02692834 W = [[6.5290823]\n",
      " [6.5290556]] b = [-9.968736]\n",
      "step = 6400 cost = 0.02652252 W = [[6.560021]\n",
      " [6.559996]] b = [-10.015036]\n",
      "step = 6500 cost = 0.026128605 W = [[6.590504 ]\n",
      " [6.5904813]] b = [-10.060655]\n",
      "step = 6600 cost = 0.025746018 W = [[6.6205435]\n",
      " [6.620523 ]] b = [-10.105613]\n",
      "step = 6700 cost = 0.025374305 W = [[6.650153]\n",
      " [6.650134]] b = [-10.149929]\n",
      "step = 6800 cost = 0.025012989 W = [[6.6793437]\n",
      " [6.679326 ]] b = [-10.193619]\n",
      "step = 6900 cost = 0.0246617 W = [[6.7081275]\n",
      " [6.7081122]] b = [-10.236702]\n",
      "step = 7000 cost = 0.024319945 W = [[6.7365155]\n",
      " [6.7365007]] b = [-10.279194]\n",
      "step = 7100 cost = 0.023987481 W = [[6.764518]\n",
      " [6.764505]] b = [-10.321109]\n",
      "step = 7200 cost = 0.023663776 W = [[6.7921457]\n",
      " [6.7921343]] b = [-10.362463]\n",
      "step = 7300 cost = 0.023348628 W = [[6.8194065]\n",
      " [6.819397 ]] b = [-10.403272]\n",
      "step = 7400 cost = 0.023041613 W = [[6.8463135]\n",
      " [6.846304 ]] b = [-10.44355]\n",
      "step = 7500 cost = 0.02274246 W = [[6.8728733]\n",
      " [6.872864 ]] b = [-10.483309]\n",
      "step = 7600 cost = 0.022450881 W = [[6.899094]\n",
      " [6.899085]] b = [-10.522563]\n",
      "step = 7700 cost = 0.022166576 W = [[6.9249854]\n",
      " [6.9249763]] b = [-10.561324]\n",
      "step = 7800 cost = 0.021889277 W = [[6.9505544]\n",
      " [6.9505453]] b = [-10.599605]\n",
      "step = 7900 cost = 0.021618746 W = [[6.97581 ]\n",
      " [6.975802]] b = [-10.637417]\n",
      "step = 8000 cost = 0.021354757 W = [[7.000758 ]\n",
      " [7.0007505]] b = [-10.674772]\n",
      "step = 8100 cost = 0.021097044 W = [[7.025408 ]\n",
      " [7.0254006]] b = [-10.711679]\n",
      "step = 8200 cost = 0.020845372 W = [[7.0497656]\n",
      " [7.0497584]] b = [-10.748148]\n",
      "step = 8300 cost = 0.020599551 W = [[7.0738373]\n",
      " [7.0738316]] b = [-10.784192]\n",
      "step = 8400 cost = 0.02035939 W = [[7.097631 ]\n",
      " [7.0976253]] b = [-10.819821]\n",
      "step = 8500 cost = 0.020124745 W = [[7.121153]\n",
      " [7.121147]] b = [-10.85504]\n",
      "step = 8600 cost = 0.019895323 W = [[7.1444063]\n",
      " [7.1444006]] b = [-10.88986]\n",
      "step = 8700 cost = 0.01967102 W = [[7.1674013]\n",
      " [7.1673956]] b = [-10.924292]\n",
      "step = 8800 cost = 0.019451685 W = [[7.1901393]\n",
      " [7.1901336]] b = [-10.958343]\n",
      "step = 8900 cost = 0.019237146 W = [[7.212629]\n",
      " [7.212623]] b = [-10.9920225]\n",
      "step = 9000 cost = 0.019027162 W = [[7.2348742]\n",
      " [7.2348685]] b = [-11.025337]\n",
      "step = 9100 cost = 0.01882172 W = [[7.2568808]\n",
      " [7.2568755]] b = [-11.058292]\n",
      "step = 9200 cost = 0.018620603 W = [[7.278654]\n",
      " [7.278649]] b = [-11.0908985]\n",
      "step = 9300 cost = 0.01842365 W = [[7.300199 ]\n",
      " [7.3001943]] b = [-11.123166]\n",
      "step = 9400 cost = 0.018230814 W = [[7.321518 ]\n",
      " [7.3215137]] b = [-11.155093]\n",
      "step = 9500 cost = 0.018041896 W = [[7.342618 ]\n",
      " [7.3426137]] b = [-11.186695]\n",
      "step = 9600 cost = 0.017856842 W = [[7.363503 ]\n",
      " [7.3634987]] b = [-11.217973]\n",
      "step = 9700 cost = 0.017675499 W = [[7.384177]\n",
      " [7.384173]] b = [-11.248935]\n",
      "step = 9800 cost = 0.017497743 W = [[7.404643 ]\n",
      " [7.4046392]] b = [-11.27959]\n",
      "step = 9900 cost = 0.017323509 W = [[7.4249077]\n",
      " [7.424904 ]] b = [-11.309942]\n",
      "step = 10000 cost = 0.017152626 W = [[7.4449735]\n",
      " [7.4449697]] b = [-11.339997]\n",
      "\\hypothesis : [[1.1831522e-05]\n",
      " [1.9937217e-02]\n",
      " [1.9937277e-02]\n",
      " [9.7207594e-01]] \n",
      "Correct : [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]] \n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype = np.float32)\n",
    "y_data = np.array([[0], [0], [0], [1]], dtype = np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name = 'x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name = 'y-input')\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#활성화 함수(hypothesis : 가설)\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost / loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# 예측값 결과 계산 및 정밀도 계산\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(\"step =\", step, \"cost =\", sess.run(cost, feed_dict={X:x_data, Y:y_data}),\n",
    "                 \"W =\", sess.run(W), \"b =\", sess.run(b))\n",
    "            \n",
    "    # Accuracy\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print(\"\\nHypothesis :\", h, \"\\nCorrect :\", c, \"\\nAccuracy :\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2️⃣ single neural network NAND 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 cost = 0.68160236 W = [[ 1.0457289]\n",
      " [-0.6151815]] b = [1.6071373]\n",
      "step = 100 cost = 0.41311142 W = [[-0.2684953]\n",
      " [-1.3226477]] b = [1.7036629]\n",
      "step = 200 cost = 0.3289925 W = [[-0.94491595]\n",
      " [-1.5826888 ]] b = [2.2606018]\n",
      "step = 300 cost = 0.27684397 W = [[-1.4247683]\n",
      " [-1.8200564]] b = [2.7436142]\n",
      "step = 400 cost = 0.2405568 W = [[-1.7951871]\n",
      " [-2.0471635]] b = [3.1601415]\n",
      "step = 500 cost = 0.21336022 W = [[-2.096842 ]\n",
      " [-2.2618775]] b = [3.5270488]\n",
      "step = 600 cost = 0.19196668 W = [[-2.3523986]\n",
      " [-2.4632437]] b = [3.8556275]\n",
      "step = 700 cost = 0.17457573 W = [[-2.5752487]\n",
      " [-2.6514344]] b = [4.153577]\n",
      "step = 800 cost = 0.16010071 W = [[-2.7737365]\n",
      " [-2.8272102]] b = [4.426387]\n",
      "step = 900 cost = 0.14783579 W = [[-2.9533134]\n",
      " [-2.9915717]] b = [4.6781197]\n",
      "step = 1000 cost = 0.13729614 W = [[-3.1177135]\n",
      " [-3.145565 ]] b = [4.911886]\n",
      "step = 1100 cost = 0.12813455 W = [[-3.2695944]\n",
      " [-3.2901967]] b = [5.1301184]\n",
      "step = 1200 cost = 0.12009388 W = [[-3.4109237]\n",
      " [-3.426386 ]] b = [5.334774]\n",
      "step = 1300 cost = 0.11297895 W = [[-3.543198 ]\n",
      " [-3.5549595]] b = [5.5274453]\n",
      "step = 1400 cost = 0.10663821 W = [[-3.6675894]\n",
      " [-3.6766477]] b = [5.7094517]\n",
      "step = 1500 cost = 0.10095194 W = [[-3.7850416]\n",
      " [-3.7920961]] b = [5.881908]\n",
      "step = 1600 cost = 0.09582424 W = [[-3.8963215]\n",
      " [-3.9018729]] b = [6.045753]\n",
      "step = 1700 cost = 0.09117718 W = [[-4.002067]\n",
      " [-4.006477]] b = [6.2017927]\n",
      "step = 1800 cost = 0.086946696 W = [[-4.102815 ]\n",
      " [-4.1063523]] b = [6.3507266]\n",
      "step = 1900 cost = 0.083079755 W = [[-4.1990275]\n",
      " [-4.2018876]] b = [6.493162]\n",
      "step = 2000 cost = 0.07953198 W = [[-4.291097 ]\n",
      " [-4.2934275]] b = [6.6296315]\n",
      "step = 2100 cost = 0.07626576 W = [[-4.3793683]\n",
      " [-4.3812823]] b = [6.7606044]\n",
      "step = 2200 cost = 0.07324938 W = [[-4.4641423]\n",
      " [-4.4657254]] b = [6.886496]\n",
      "step = 2300 cost = 0.07045549 W = [[-4.545684 ]\n",
      " [-4.5470014]] b = [7.00768]\n",
      "step = 2400 cost = 0.06786079 W = [[-4.6242313]\n",
      " [-4.625333 ]] b = [7.1244855]\n",
      "step = 2500 cost = 0.06544495 W = [[-4.699992]\n",
      " [-4.70092 ]] b = [7.2372117]\n",
      "step = 2600 cost = 0.06319031 W = [[-4.773157]\n",
      " [-4.773941]] b = [7.346128]\n",
      "step = 2700 cost = 0.061081532 W = [[-4.8438993]\n",
      " [-4.8445597]] b = [7.4514766]\n",
      "step = 2800 cost = 0.05910512 W = [[-4.912363]\n",
      " [-4.912927]] b = [7.553476]\n",
      "step = 2900 cost = 0.057249106 W = [[-4.978693]\n",
      " [-4.979177]] b = [7.652332]\n",
      "step = 3000 cost = 0.05550307 W = [[-5.0430174]\n",
      " [-5.0434327]] b = [7.7482257]\n",
      "step = 3100 cost = 0.053857602 W = [[-5.105449]\n",
      " [-5.105808]] b = [7.841326]\n",
      "step = 3200 cost = 0.052304365 W = [[-5.1660957]\n",
      " [-5.1664076]] b = [7.9317875]\n",
      "step = 3300 cost = 0.050835926 W = [[-5.225055 ]\n",
      " [-5.2253265]] b = [8.019752]\n",
      "step = 3400 cost = 0.049445648 W = [[-5.2824173]\n",
      " [-5.282654 ]] b = [8.1053505]\n",
      "step = 3500 cost = 0.04812749 W = [[-5.3382635]\n",
      " [-5.3384714]] b = [8.1887045]\n",
      "step = 3600 cost = 0.046876106 W = [[-5.3926716]\n",
      " [-5.3928547]] b = [8.269926]\n",
      "step = 3700 cost = 0.04568662 W = [[-5.445712 ]\n",
      " [-5.4458737]] b = [8.349119]\n",
      "step = 3800 cost = 0.044554554 W = [[-5.497451 ]\n",
      " [-5.4975934]] b = [8.426381]\n",
      "step = 3900 cost = 0.04347598 W = [[-5.5479507]\n",
      " [-5.5480733]] b = [8.5018015]\n",
      "step = 4000 cost = 0.042447206 W = [[-5.5972652]\n",
      " [-5.5973735]] b = [8.575463]\n",
      "step = 4100 cost = 0.041464955 W = [[-5.6454487]\n",
      " [-5.645545 ]] b = [8.647445]\n",
      "step = 4200 cost = 0.040526096 W = [[-5.6925516]\n",
      " [-5.6926374]] b = [8.717819]\n",
      "step = 4300 cost = 0.039627854 W = [[-5.7386203]\n",
      " [-5.738697 ]] b = [8.786658]\n",
      "step = 4400 cost = 0.03876779 W = [[-5.7836986]\n",
      " [-5.7837663]] b = [8.854024]\n",
      "step = 4500 cost = 0.03794348 W = [[-5.827827 ]\n",
      " [-5.8278875]] b = [8.919975]\n",
      "step = 4600 cost = 0.037152775 W = [[-5.871044 ]\n",
      " [-5.8710985]] b = [8.984572]\n",
      "step = 4700 cost = 0.036393687 W = [[-5.913386]\n",
      " [-5.913436]] b = [9.047867]\n",
      "step = 4800 cost = 0.035664342 W = [[-5.954888 ]\n",
      " [-5.9549327]] b = [9.10991]\n",
      "step = 4900 cost = 0.03496314 W = [[-5.9955792]\n",
      " [-5.9956226]] b = [9.170748]\n",
      "step = 5000 cost = 0.034288384 W = [[-6.035494]\n",
      " [-6.035533]] b = [9.230429]\n",
      "step = 5100 cost = 0.033638738 W = [[-6.074659]\n",
      " [-6.074694]] b = [9.288993]\n",
      "step = 5200 cost = 0.033012707 W = [[-6.113101 ]\n",
      " [-6.1131334]] b = [9.34648]\n",
      "step = 5300 cost = 0.0324092 W = [[-6.1508474]\n",
      " [-6.150876 ]] b = [9.402928]\n",
      "step = 5400 cost = 0.03182689 W = [[-6.1879206]\n",
      " [-6.1879473]] b = [9.458375]\n",
      "step = 5500 cost = 0.031264827 W = [[-6.2243447]\n",
      " [-6.224369 ]] b = [9.512854]\n",
      "step = 5600 cost = 0.030721908 W = [[-6.2601414]\n",
      " [-6.260164 ]] b = [9.566398]\n",
      "step = 5700 cost = 0.03019714 W = [[-6.295332 ]\n",
      " [-6.2953544]] b = [9.619038]\n",
      "step = 5800 cost = 0.029689776 W = [[-6.3299356]\n",
      " [-6.329956 ]] b = [9.670803]\n",
      "step = 5900 cost = 0.02919883 W = [[-6.3639717]\n",
      " [-6.363991 ]] b = [9.721723]\n",
      "step = 6000 cost = 0.028723598 W = [[-6.3974586]\n",
      " [-6.3974767]] b = [9.771822]\n",
      "step = 6100 cost = 0.028263316 W = [[-6.430413]\n",
      " [-6.43043 ]] b = [9.821128]\n",
      "step = 6200 cost = 0.027817346 W = [[-6.4628515]\n",
      " [-6.4628673]] b = [9.869663]\n",
      "step = 6300 cost = 0.027384983 W = [[-6.49479 ]\n",
      " [-6.494806]] b = [9.917454]\n",
      "step = 6400 cost = 0.026965614 W = [[-6.5262427]\n",
      " [-6.526258 ]] b = [9.964518]\n",
      "step = 6500 cost = 0.026558697 W = [[-6.5572243]\n",
      " [-6.5572386]] b = [10.010881]\n",
      "step = 6600 cost = 0.026163757 W = [[-6.5877495]\n",
      " [-6.587763 ]] b = [10.0565605]\n",
      "step = 6700 cost = 0.025780147 W = [[-6.6178293]\n",
      " [-6.6178417]] b = [10.101577]\n",
      "step = 6800 cost = 0.025407428 W = [[-6.6474786]\n",
      " [-6.6474905]] b = [10.14595]\n",
      "step = 6900 cost = 0.025045218 W = [[-6.676708]\n",
      " [-6.676719]] b = [10.189698]\n",
      "step = 7000 cost = 0.024693035 W = [[-6.7055297]\n",
      " [-6.7055407]] b = [10.232833]\n",
      "step = 7100 cost = 0.024350481 W = [[-6.733954]\n",
      " [-6.733965]] b = [10.275376]\n",
      "step = 7200 cost = 0.024017155 W = [[-6.761992]\n",
      " [-6.762002]] b = [10.317344]\n",
      "step = 7300 cost = 0.023692697 W = [[-6.7896547]\n",
      " [-6.789663 ]] b = [10.358749]\n",
      "step = 7400 cost = 0.023376781 W = [[-6.816951]\n",
      " [-6.816958]] b = [10.399609]\n",
      "step = 7500 cost = 0.023069002 W = [[-6.8438888]\n",
      " [-6.843896 ]] b = [10.439933]\n",
      "step = 7600 cost = 0.022769175 W = [[-6.8704796]\n",
      " [-6.8704863]] b = [10.479739]\n",
      "step = 7700 cost = 0.022476899 W = [[-6.896731 ]\n",
      " [-6.8967376]] b = [10.519039]\n",
      "step = 7800 cost = 0.022191968 W = [[-6.922652 ]\n",
      " [-6.9226584]] b = [10.557844]\n",
      "step = 7900 cost = 0.021914046 W = [[-6.948251 ]\n",
      " [-6.9482574]] b = [10.596168]\n",
      "step = 8000 cost = 0.02164289 W = [[-6.9735336]\n",
      " [-6.97354  ]] b = [10.634023]\n",
      "step = 8100 cost = 0.021378323 W = [[-6.998511 ]\n",
      " [-6.9985166]] b = [10.671416]\n",
      "step = 8200 cost = 0.021120008 W = [[-7.0231876]\n",
      " [-7.0231934]] b = [10.708363]\n",
      "step = 8300 cost = 0.020867838 W = [[-7.0475717]\n",
      " [-7.047577 ]] b = [10.744873]\n",
      "step = 8400 cost = 0.020621516 W = [[-7.0716705]\n",
      " [-7.071676 ]] b = [10.780954]\n",
      "step = 8500 cost = 0.020380871 W = [[-7.095489 ]\n",
      " [-7.0954943]] b = [10.81662]\n",
      "step = 8600 cost = 0.0201457 W = [[-7.119034]\n",
      " [-7.119039]] b = [10.851877]\n",
      "step = 8700 cost = 0.019915812 W = [[-7.1423125]\n",
      " [-7.142318 ]] b = [10.886735]\n",
      "step = 8800 cost = 0.01969106 W = [[-7.165329]\n",
      " [-7.165334]] b = [10.921201]\n",
      "step = 8900 cost = 0.01947129 W = [[-7.1880913]\n",
      " [-7.188096 ]] b = [10.955286]\n",
      "step = 9000 cost = 0.019256284 W = [[-7.2106037]\n",
      " [-7.2106085]] b = [10.988997]\n",
      "step = 9100 cost = 0.01904593 W = [[-7.2328715]\n",
      " [-7.232876 ]] b = [11.022343]\n",
      "step = 9200 cost = 0.018840056 W = [[-7.2549005]\n",
      " [-7.254904 ]] b = [11.05533]\n",
      "step = 9300 cost = 0.01863858 W = [[-7.276694]\n",
      " [-7.276697]] b = [11.087971]\n",
      "step = 9400 cost = 0.018441286 W = [[-7.2982583]\n",
      " [-7.298261 ]] b = [11.120264]\n",
      "step = 9500 cost = 0.018248033 W = [[-7.3195987]\n",
      " [-7.3196015]] b = [11.152225]\n",
      "step = 9600 cost = 0.018058788 W = [[-7.3407187]\n",
      " [-7.3407216]] b = [11.183853]\n",
      "step = 9700 cost = 0.01787341 W = [[-7.3616223]\n",
      " [-7.361625 ]] b = [11.215163]\n",
      "step = 9800 cost = 0.017691696 W = [[-7.382315]\n",
      " [-7.382318]] b = [11.246154]\n",
      "step = 9900 cost = 0.017513616 W = [[-7.402802 ]\n",
      " [-7.4028044]] b = [11.2768345]\n",
      "step = 10000 cost = 0.017339103 W = [[-7.423084]\n",
      " [-7.423086]] b = [11.307213]\n",
      "\\hypothesis : [[0.99998766]\n",
      " [0.9798486 ]\n",
      " [0.97984874]\n",
      " [0.0282239 ]] \n",
      "Correct : [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype = np.float32)\n",
    "y_data = np.array([[1], [1], [1], [0]], dtype = np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name = 'x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name = 'y-input')\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#활성화 함수(hypothesis : 가설)\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost / loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# 예측값 결과 계산 및 정밀도 계산\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(\"step =\", step, \"cost =\", sess.run(cost, feed_dict={X:x_data, Y:y_data}),\n",
    "                 \"W =\", sess.run(W), \"b =\", sess.run(b))\n",
    "            \n",
    "    # Accuracy\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print(\"\\nHypothesis :\", h, \"\\nCorrect :\", c, \"\\nAccuracy :\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3️⃣ single neural network OR 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 cost = 0.9201837 W = [[-0.5642119]\n",
      " [ 0.7443477]] b = [-0.76706487]\n",
      "step = 100 cost = 0.3114297 W = [[0.95614994]\n",
      " [1.7542955 ]] b = [0.08526676]\n",
      "step = 200 cost = 0.24459726 W = [[1.6062078]\n",
      " [2.1677344]] b = [-0.1765819]\n",
      "step = 300 cost = 0.20122166 W = [[2.097698]\n",
      " [2.50998 ]] b = [-0.4489475]\n",
      "step = 400 cost = 0.1703693 W = [[2.502319]\n",
      " [2.813876]] b = [-0.67706275]\n",
      "step = 500 cost = 0.14736432 W = [[2.8464632]\n",
      " [3.087842 ]] b = [-0.86770064]\n",
      "step = 600 cost = 0.12958482 W = [[3.1453795]\n",
      " [3.336548 ]] b = [-1.03041]\n",
      "step = 700 cost = 0.11545509 W = [[3.4092102]\n",
      " [3.5635688]] b = [-1.1721374]\n",
      "step = 800 cost = 0.10397346 W = [[3.645096 ]\n",
      " [3.7718577]] b = [-1.2976443]\n",
      "step = 900 cost = 0.09447248 W = [[3.8582392]\n",
      " [3.9638906]] b = [-1.4102535]\n",
      "step = 1000 cost = 0.08649027 W = [[4.052537 ]\n",
      " [4.1417418]] b = [-1.5123588]\n",
      "step = 1100 cost = 0.07969707 W = [[4.230974]\n",
      " [4.307163]] b = [-1.6057395]\n",
      "step = 1200 cost = 0.0738512 W = [[4.395892]\n",
      " [4.461624]] b = [-1.6917537]\n",
      "step = 1300 cost = 0.06877154 W = [[4.5491514]\n",
      " [4.6063704]] b = [-1.7714636]\n",
      "step = 1400 cost = 0.064319864 W = [[4.692256]\n",
      " [4.74247 ]] b = [-1.8457161]\n",
      "step = 1500 cost = 0.06038892 W = [[4.8264427]\n",
      " [4.870827 ]] b = [-1.9151986]\n",
      "step = 1600 cost = 0.056894198 W = [[4.952737]\n",
      " [4.992222]] b = [-1.9804755]\n",
      "step = 1700 cost = 0.05376844 W = [[5.0719905]\n",
      " [5.107328 ]] b = [-2.042018]\n",
      "step = 1800 cost = 0.050957296 W = [[5.184935 ]\n",
      " [5.2167277]] b = [-2.1002207]\n",
      "step = 1900 cost = 0.04841636 W = [[5.29219 ]\n",
      " [5.320939]] b = [-2.15542]\n",
      "step = 2000 cost = 0.04610932 W = [[5.394292]\n",
      " [5.420402]] b = [-2.2079053]\n",
      "step = 2100 cost = 0.04400578 W = [[5.4917006]\n",
      " [5.515513 ]] b = [-2.2579238]\n",
      "step = 2200 cost = 0.04208045 W = [[5.5848236]\n",
      " [5.606621 ]] b = [-2.3056943]\n",
      "step = 2300 cost = 0.040311962 W = [[5.6740136]\n",
      " [5.694036 ]] b = [-2.3514054]\n",
      "step = 2400 cost = 0.038682293 W = [[5.7595835]\n",
      " [5.778036 ]] b = [-2.3952234]\n",
      "step = 2500 cost = 0.037175898 W = [[5.8418097]\n",
      " [5.8588676]] b = [-2.4372964]\n",
      "step = 2600 cost = 0.03577953 W = [[5.92094  ]\n",
      " [5.9367514]] b = [-2.4777558]\n",
      "step = 2700 cost = 0.03448182 W = [[5.9971933]\n",
      " [6.0118895]] b = [-2.5167165]\n",
      "step = 2800 cost = 0.033272706 W = [[6.07077  ]\n",
      " [6.0844617]] b = [-2.5542846]\n",
      "step = 2900 cost = 0.032143656 W = [[6.141848 ]\n",
      " [6.1546316]] b = [-2.5905547]\n",
      "step = 3000 cost = 0.031087052 W = [[6.210587]\n",
      " [6.22255 ]] b = [-2.6256099]\n",
      "step = 3100 cost = 0.030096207 W = [[6.2771344]\n",
      " [6.288353 ]] b = [-2.6595302]\n",
      "step = 3200 cost = 0.029165275 W = [[6.341624 ]\n",
      " [6.3521624]] b = [-2.6923842]\n",
      "step = 3300 cost = 0.028289078 W = [[6.404176 ]\n",
      " [6.4140954]] b = [-2.724236]\n",
      "step = 3400 cost = 0.027462875 W = [[6.464903 ]\n",
      " [6.4742546]] b = [-2.7551432]\n",
      "step = 3500 cost = 0.026682677 W = [[6.5239058]\n",
      " [6.5327363]] b = [-2.78516]\n",
      "step = 3600 cost = 0.025944786 W = [[6.5812783]\n",
      " [6.5896297]] b = [-2.8143358]\n",
      "step = 3700 cost = 0.025245853 W = [[6.637108 ]\n",
      " [6.6450176]] b = [-2.8427155]\n",
      "step = 3800 cost = 0.024582861 W = [[6.6914735]\n",
      " [6.6989746]] b = [-2.8703387]\n",
      "step = 3900 cost = 0.023953252 W = [[6.744448]\n",
      " [6.751572]] b = [-2.8972456]\n",
      "step = 4000 cost = 0.023354491 W = [[6.7961006]\n",
      " [6.8028746]] b = [-2.9234724]\n",
      "step = 4100 cost = 0.022784479 W = [[6.846494 ]\n",
      " [6.8529444]] b = [-2.9490514]\n",
      "step = 4200 cost = 0.022241168 W = [[6.8956885]\n",
      " [6.9018354]] b = [-2.9740145]\n",
      "step = 4300 cost = 0.021722686 W = [[6.9437385]\n",
      " [6.9496036]] b = [-2.9983883]\n",
      "step = 4400 cost = 0.021227527 W = [[6.990695]\n",
      " [6.996298]] b = [-3.0222003]\n",
      "step = 4500 cost = 0.020754065 W = [[7.036607]\n",
      " [7.041963]] b = [-3.0454764]\n",
      "step = 4600 cost = 0.020300912 W = [[7.081518 ]\n",
      " [7.0866423]] b = [-3.0682387]\n",
      "step = 4700 cost = 0.019866906 W = [[7.125471]\n",
      " [7.13038 ]] b = [-3.09051]\n",
      "step = 4800 cost = 0.01945072 W = [[7.1685057]\n",
      " [7.173211 ]] b = [-3.1123097]\n",
      "step = 4900 cost = 0.01905141 W = [[7.2106586]\n",
      " [7.2151737]] b = [-3.133658]\n",
      "step = 5000 cost = 0.018667912 W = [[7.2519655]\n",
      " [7.256301 ]] b = [-3.1545725]\n",
      "step = 5100 cost = 0.018299397 W = [[7.2924576]\n",
      " [7.296626 ]] b = [-3.1750703]\n",
      "step = 5200 cost = 0.017944887 W = [[7.3321676]\n",
      " [7.3361764]] b = [-3.1951673]\n",
      "step = 5300 cost = 0.017603667 W = [[7.3711247]\n",
      " [7.3749833]] b = [-3.2148795]\n",
      "step = 5400 cost = 0.017275088 W = [[7.409356]\n",
      " [7.413073]] b = [-3.234221]\n",
      "step = 5500 cost = 0.016958328 W = [[7.446888]\n",
      " [7.45047 ]] b = [-3.2532043]\n",
      "step = 5600 cost = 0.016652869 W = [[7.4837456]\n",
      " [7.4872007]] b = [-3.2718437]\n",
      "step = 5700 cost = 0.016358016 W = [[7.5199523]\n",
      " [7.523286 ]] b = [-3.29015]\n",
      "step = 5800 cost = 0.016073313 W = [[7.5555305]\n",
      " [7.5587497]] b = [-3.308135]\n",
      "step = 5900 cost = 0.015798269 W = [[7.5905004]\n",
      " [7.593612 ]] b = [-3.3258104]\n",
      "step = 6000 cost = 0.015532368 W = [[7.624884 ]\n",
      " [7.6278925]] b = [-3.3431861]\n",
      "step = 6100 cost = 0.015275156 W = [[7.6587005]\n",
      " [7.6616096]] b = [-3.360272]\n",
      "step = 6200 cost = 0.015026238 W = [[7.6919665]\n",
      " [7.694781 ]] b = [-3.3770773]\n",
      "step = 6300 cost = 0.014785193 W = [[7.724701]\n",
      " [7.727425]] b = [-3.3936117]\n",
      "step = 6400 cost = 0.014551692 W = [[7.7569194]\n",
      " [7.759558 ]] b = [-3.4098825]\n",
      "step = 6500 cost = 0.014325356 W = [[7.788637]\n",
      " [7.791195]] b = [-3.4258993]\n",
      "step = 6600 cost = 0.014105909 W = [[7.81987  ]\n",
      " [7.8223515]] b = [-3.4416683]\n",
      "step = 6700 cost = 0.013892972 W = [[7.8506336]\n",
      " [7.8530407]] b = [-3.4571977]\n",
      "step = 6800 cost = 0.013686268 W = [[7.8809404]\n",
      " [7.883277 ]] b = [-3.4724946]\n",
      "step = 6900 cost = 0.0134856645 W = [[7.9108033]\n",
      " [7.9130726]] b = [-3.4875662]\n",
      "step = 7000 cost = 0.013290717 W = [[7.9402356]\n",
      " [7.9424405]] b = [-3.5024185]\n",
      "step = 7100 cost = 0.013101313 W = [[7.9692497]\n",
      " [7.9713917]] b = [-3.517058]\n",
      "step = 7200 cost = 0.012917127 W = [[7.997857 ]\n",
      " [7.9999394]] b = [-3.5314898]\n",
      "step = 7300 cost = 0.012738065 W = [[8.026067]\n",
      " [8.028094]] b = [-3.5457213]\n",
      "step = 7400 cost = 0.012563785 W = [[8.053893]\n",
      " [8.055866]] b = [-3.5597568]\n",
      "step = 7500 cost = 0.012394178 W = [[8.081345]\n",
      " [8.083267]] b = [-3.5736017]\n",
      "step = 7600 cost = 0.012229072 W = [[8.108432]\n",
      " [8.110303]] b = [-3.5872602]\n",
      "step = 7700 cost = 0.012068221 W = [[8.135167]\n",
      " [8.136984]] b = [-3.6007392]\n",
      "step = 7800 cost = 0.011911576 W = [[8.1615505]\n",
      " [8.163324 ]] b = [-3.6140423]\n",
      "step = 7900 cost = 0.011758905 W = [[8.1876  ]\n",
      " [8.189326]] b = [-3.627174]\n",
      "step = 8000 cost = 0.011609994 W = [[8.213317]\n",
      " [8.215006]] b = [-3.6401381]\n",
      "step = 8100 cost = 0.011464808 W = [[8.238717]\n",
      " [8.24036 ]] b = [-3.6529396]\n",
      "step = 8200 cost = 0.011323165 W = [[8.2638035]\n",
      " [8.265405 ]] b = [-3.6655815]\n",
      "step = 8300 cost = 0.011184953 W = [[8.288581]\n",
      " [8.290146]] b = [-3.6780689]\n",
      "step = 8400 cost = 0.011050081 W = [[8.313062]\n",
      " [8.314591]] b = [-3.6904042]\n",
      "step = 8500 cost = 0.010918393 W = [[8.337252]\n",
      " [8.338745]] b = [-3.7025921]\n",
      "step = 8600 cost = 0.010789707 W = [[8.361158]\n",
      " [8.362616]] b = [-3.714636]\n",
      "step = 8700 cost = 0.010664064 W = [[8.384788]\n",
      " [8.38621 ]] b = [-3.7265391]\n",
      "step = 8800 cost = 0.010541239 W = [[8.408147]\n",
      " [8.409535]] b = [-3.7383041]\n",
      "step = 8900 cost = 0.010421226 W = [[8.431235]\n",
      " [8.432598]] b = [-3.7499347]\n",
      "step = 9000 cost = 0.010303904 W = [[8.454067]\n",
      " [8.455398]] b = [-3.761434]\n",
      "step = 9100 cost = 0.010189181 W = [[8.47665 ]\n",
      " [8.477946]] b = [-3.7728043]\n",
      "step = 9200 cost = 0.010076873 W = [[8.498977]\n",
      " [8.500252]] b = [-3.7840483]\n",
      "step = 9300 cost = 0.00996713 W = [[8.521067]\n",
      " [8.522307]] b = [-3.7951698]\n",
      "step = 9400 cost = 0.0098596625 W = [[8.542914]\n",
      " [8.544133]] b = [-3.8061707]\n",
      "step = 9500 cost = 0.009754456 W = [[8.564536]\n",
      " [8.565722]] b = [-3.8170538]\n",
      "step = 9600 cost = 0.0096514765 W = [[8.585921]\n",
      " [8.587087]] b = [-3.827822]\n",
      "step = 9700 cost = 0.00955065 W = [[8.607088 ]\n",
      " [8.6082325]] b = [-3.8384774]\n",
      "step = 9800 cost = 0.009451836 W = [[8.62804 ]\n",
      " [8.629154]] b = [-3.8490214]\n",
      "step = 9900 cost = 0.009355037 W = [[8.648771]\n",
      " [8.649864]] b = [-3.8594575]\n",
      "step = 10000 cost = 0.009260265 W = [[8.669294]\n",
      " [8.670366]] b = [-3.8697865]\n",
      "\\hypothesis : [[0.02043647]\n",
      " [0.9918421 ]\n",
      " [0.99183345]\n",
      " [0.99999857]] \n",
      "Correct : [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype = np.float32)\n",
    "y_data = np.array([[0], [1], [1], [1]], dtype = np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name = 'x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name = 'y-input')\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#활성화 함수(hypothesis : 가설)\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost / loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# 예측값 결과 계산 및 정밀도 계산\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(\"step =\", step, \"cost =\", sess.run(cost, feed_dict={X:x_data, Y:y_data}),\n",
    "                 \"W =\", sess.run(W), \"b =\", sess.run(b))\n",
    "            \n",
    "    # Accuracy\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print(\"\\nHypothesis :\", h, \"\\nCorrect :\", c, \"\\nAccuracy :\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4️⃣ single neural network XOR 연산 💥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 cost = 1.147689 W = [[0.54303825]\n",
      " [0.22509597]] b = [1.6586293]\n",
      "step = 100 cost = 0.6977366 W = [[-0.13235211]\n",
      " [-0.31579468]] b = [0.31076336]\n",
      "step = 200 cost = 0.69505054 W = [[-0.1127404 ]\n",
      " [-0.21080059]] b = [0.19272244]\n",
      "step = 300 cost = 0.69399035 W = [[-0.08325413]\n",
      " [-0.13564825]] b = [0.12985343]\n",
      "step = 400 cost = 0.69352436 W = [[-0.05990801]\n",
      " [-0.08789951]] b = [0.08766488]\n",
      "step = 500 cost = 0.693317 W = [[-0.04241316]\n",
      " [-0.05736698]] b = [0.05917792]\n",
      "step = 600 cost = 0.69322395 W = [[-0.02968203]\n",
      " [-0.03767065]] b = [0.03994525]\n",
      "step = 700 cost = 0.693182 W = [[-0.02059721]\n",
      " [-0.02486487]] b = [0.02696234]\n",
      "step = 800 cost = 0.693163 W = [[-0.01420295]\n",
      " [-0.01648277]] b = [0.01819881]\n",
      "step = 900 cost = 0.69315445 W = [[-0.00974699]\n",
      " [-0.0109649 ]] b = [0.01228362]\n",
      "step = 1000 cost = 0.69315046 W = [[-0.0066646 ]\n",
      " [-0.00731522]] b = [0.00829102]\n",
      "step = 1100 cost = 0.6931487 W = [[-0.00454415]\n",
      " [-0.00489172]] b = [0.00559614]\n",
      "step = 1200 cost = 0.69314784 W = [[-0.0030916 ]\n",
      " [-0.00327728]] b = [0.00377721]\n",
      "step = 1300 cost = 0.6931475 W = [[-0.00209979]\n",
      " [-0.00219899]] b = [0.00254949]\n",
      "step = 1400 cost = 0.6931473 W = [[-0.00142427]\n",
      " [-0.00147727]] b = [0.00172084]\n",
      "step = 1500 cost = 0.6931473 W = [[-0.00096507]\n",
      " [-0.00099339]] b = [0.00116152]\n",
      "step = 1600 cost = 0.6931472 W = [[-0.0006534 ]\n",
      " [-0.00066852]] b = [0.00078401]\n",
      "step = 1700 cost = 0.6931472 W = [[-0.00044209]\n",
      " [-0.00045017]] b = [0.00052917]\n",
      "step = 1800 cost = 0.6931472 W = [[-0.00029897]\n",
      " [-0.0003033 ]] b = [0.00035724]\n",
      "step = 1900 cost = 0.6931472 W = [[-0.00020211]\n",
      " [-0.00020442]] b = [0.00024111]\n",
      "step = 2000 cost = 0.6931472 W = [[-0.00013658]\n",
      " [-0.00013781]] b = [0.00016274]\n",
      "step = 2100 cost = 0.6931472 W = [[-9.226608e-05]\n",
      " [-9.292497e-05]] b = [0.00010984]\n",
      "step = 2200 cost = 0.6931472 W = [[-6.2319232e-05]\n",
      " [-6.2669635e-05]] b = [7.413744e-05]\n",
      "step = 2300 cost = 0.6931472 W = [[-4.2083451e-05]\n",
      " [-4.2266965e-05]] b = [5.00363e-05]\n",
      "step = 2400 cost = 0.6931472 W = [[-2.8414612e-05]\n",
      " [-2.8508723e-05]] b = [3.377318e-05]\n",
      "step = 2500 cost = 0.6931472 W = [[-1.9182600e-05]\n",
      " [-1.9230512e-05]] b = [2.2796245e-05]\n",
      "step = 2600 cost = 0.6931472 W = [[-1.2946463e-05]\n",
      " [-1.2970533e-05]] b = [1.538739e-05]\n",
      "step = 2700 cost = 0.6931472 W = [[-8.734650e-06]\n",
      " [-8.746798e-06]] b = [1.0387308e-05]\n",
      "step = 2800 cost = 0.6931472 W = [[-5.8952332e-06]\n",
      " [-5.9044014e-06]] b = [7.0039987e-06]\n",
      "step = 2900 cost = 0.6931472 W = [[-3.9699994e-06]\n",
      " [-3.9702277e-06]] b = [4.744983e-06]\n",
      "step = 3000 cost = 0.6931472 W = [[-2.6706193e-06]\n",
      " [-2.6693576e-06]] b = [3.2131416e-06]\n",
      "step = 3100 cost = 0.6931472 W = [[-1.8063497e-06]\n",
      " [-1.8050880e-06]] b = [2.1626088e-06]\n",
      "step = 3200 cost = 0.6931472 W = [[-1.2192434e-06]\n",
      " [-1.2179817e-06]] b = [1.468216e-06]\n",
      "step = 3300 cost = 0.6931472 W = [[-8.3926136e-07]\n",
      " [-8.3799966e-07]] b = [9.571029e-07]\n",
      "step = 3400 cost = 0.6931472 W = [[-5.5390365e-07]\n",
      " [-5.5264195e-07]] b = [6.702566e-07]\n",
      "step = 3500 cost = 0.6931472 W = [[-3.5869797e-07]\n",
      " [-3.5743628e-07]] b = [4.7654268e-07]\n",
      "step = 3600 cost = 0.6931472 W = [[-2.4619447e-07]\n",
      " [-2.4493278e-07]] b = [3.3423674e-07]\n",
      "step = 3700 cost = 0.6931472 W = [[-1.7168853e-07]\n",
      " [-1.7042680e-07]] b = [2.5973208e-07]\n",
      "step = 3800 cost = 0.6931472 W = [[-1.1431884e-07]\n",
      " [-1.1305711e-07]] b = [1.6808998e-07]\n",
      "step = 3900 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 4000 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 4100 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 4200 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 4300 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 4400 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 4500 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 4600 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 4700 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 4800 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 4900 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 5000 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 5100 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 5200 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 5300 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 5400 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 5500 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 5600 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 5700 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 5800 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 5900 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 6000 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 6100 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 6200 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 6300 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 6400 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 6500 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 6600 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 6700 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 6800 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 6900 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 7000 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 7100 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 7200 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 7300 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 7400 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 7500 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 7600 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 7700 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 7800 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 7900 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 8000 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 8100 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 8200 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 8300 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 8400 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 8500 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 8600 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 8700 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 8800 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 8900 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 9000 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 9100 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 9200 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 9300 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 9400 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 9500 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 9600 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 9700 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 9800 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 9900 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n",
      "step = 10000 cost = 0.6931472 W = [[-8.8986766e-08]\n",
      " [-8.7725041e-08]] b = [1.1891597e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\hypothesis : [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct : [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy : 0.5\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype = np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype = np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name = 'x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name = 'y-input')\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#활성화 함수(hypothesis : 가설)\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost / loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# 예측값 결과 계산 및 정밀도 계산\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(\"step =\", step, \"cost =\", sess.run(cost, feed_dict={X:x_data, Y:y_data}),\n",
    "                 \"W =\", sess.run(W), \"b =\", sess.run(b))\n",
    "            \n",
    "    # Accuracy\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print(\"\\nHypothesis :\", h, \"\\nCorrect :\", c, \"\\nAccuracy :\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4️⃣ single neural network XOR 연산  => 해결!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 값 :(0, 0)출력 값 :0\n",
      "입력 값 :(1, 0)출력 값 :1\n",
      "입력 값 :(0, 1)출력 값 :1\n",
      "입력 값 :(1, 1)출력 값 :0\n"
     ]
    }
   ],
   "source": [
    "# 가중치와 바이어스\n",
    "w11 = np.array([-2, -2])\n",
    "w12 = np.array([2, 2])\n",
    "w2 = np.array([1, 1])\n",
    "b1 = 3\n",
    "b2 = -1\n",
    "b3 = -1\n",
    "\n",
    "# 퍼셉트론\n",
    "def MLP(x, w, b):\n",
    "    y = np.sum(w * x) + b\n",
    "    if y <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "# NAND 게이트\n",
    "def NAND(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w11, b1)\n",
    "\n",
    "# OR 게이트\n",
    "def OR(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w12, b2)\n",
    "\n",
    "# AND 게이트\n",
    "def AND(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w2, b3)\n",
    "\n",
    "# XOR 게이트\n",
    "def XOR(x1, x2):\n",
    "    return AND(NAND(x1, x2), OR(x1, x2))\n",
    "\n",
    "# x1, x2 값을 번갈아 대입해 가며 최종값 출력\n",
    "if __name__ == '__main__':\n",
    "    for x in [(0,0), (1,0), (0,1), (1,1)]:\n",
    "        y = XOR(x[0], x[1])\n",
    "        print(\"입력 값 :\" + str(x) + \"출력 값 :\" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 값 :(0, 0)출력 값 :0\n",
      "입력 값 :(1, 0)출력 값 :1\n",
      "입력 값 :(0, 1)출력 값 :1\n",
      "입력 값 :(1, 1)출력 값 :0\n"
     ]
    }
   ],
   "source": [
    "# 가중치와 바이어스\n",
    "w11 = np.array([-7.40, -7.40])\n",
    "w12 = np.array([8.67, 8.67])\n",
    "w2 = np.array([7.41, 7.41])\n",
    "b1 = 11.28\n",
    "b2 = -3.87\n",
    "b3 = -11.29\n",
    "\n",
    "# 퍼셉트론\n",
    "def MLP(x, w, b):\n",
    "    y = np.sum(w * x) + b\n",
    "    if y <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "# NAND 게이트\n",
    "def NAND(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w11, b1)\n",
    "\n",
    "# OR 게이트\n",
    "def OR(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w12, b2)\n",
    "\n",
    "# AND 게이트\n",
    "def AND(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w2, b3)\n",
    "\n",
    "# XOR 게이트\n",
    "def XOR(x1, x2):\n",
    "    return AND(NAND(x1, x2), OR(x1, x2))\n",
    "\n",
    "# x1, x2 값을 번갈아 대입해 가며 최종값 출력\n",
    "if __name__ == '__main__':\n",
    "    for x in [(0,0), (1,0), (0,1), (1,1)]:\n",
    "        y = XOR(x[0], x[1])\n",
    "        print(\"입력 값 :\" + str(x) + \"출력 값 :\" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 cost = 0.7127425 W2 = [[-1.0439962 ]\n",
      " [-0.35504904]]\n",
      "step = 100 cost = 0.6919861 W2 = [[-0.9733313 ]\n",
      " [-0.27967462]]\n",
      "step = 200 cost = 0.69140023 W2 = [[-0.9719322 ]\n",
      " [-0.30612385]]\n",
      "step = 300 cost = 0.69072264 W2 = [[-0.9758814 ]\n",
      " [-0.34338722]]\n",
      "step = 400 cost = 0.6898404 W2 = [[-0.9823105 ]\n",
      " [-0.38849455]]\n",
      "step = 500 cost = 0.68866503 W2 = [[-0.9914159 ]\n",
      " [-0.44299483]]\n",
      "step = 600 cost = 0.6870754 W2 = [[-1.003686  ]\n",
      " [-0.50899225]]\n",
      "step = 700 cost = 0.6849079 W2 = [[-1.0197763 ]\n",
      " [-0.58894217]]\n",
      "step = 800 cost = 0.681951 W2 = [[-1.040517  ]\n",
      " [-0.68554235]]\n",
      "step = 900 cost = 0.6779443 W2 = [[-1.0669235]\n",
      " [-0.8015172]]\n",
      "step = 1000 cost = 0.67258817 W2 = [[-1.1001972 ]\n",
      " [-0.93929684]]\n",
      "step = 1100 cost = 0.66555375 W2 = [[-1.1417398]\n",
      " [-1.1006715]]\n",
      "step = 1200 cost = 0.6564859 W2 = [[-1.1932102]\n",
      " [-1.2865418]]\n",
      "step = 1300 cost = 0.64499897 W2 = [[-1.2566508]\n",
      " [-1.4968084]]\n",
      "step = 1400 cost = 0.63068587 W2 = [[-1.3346751]\n",
      " [-1.7303244]]\n",
      "step = 1500 cost = 0.6131715 W2 = [[-1.4306113]\n",
      " [-1.9848126]]\n",
      "step = 1600 cost = 0.5922049 W2 = [[-1.5484424]\n",
      " [-2.2567928]]\n",
      "step = 1700 cost = 0.56773436 W2 = [[-1.6923742]\n",
      " [-2.5417266]]\n",
      "step = 1800 cost = 0.5399105 W2 = [[-1.8660336]\n",
      " [-2.8345401]]\n",
      "step = 1900 cost = 0.5090352 W2 = [[-2.0715158]\n",
      " [-3.1303196]]\n",
      "step = 2000 cost = 0.47553682 W2 = [[-2.3086033]\n",
      " [-3.4248438]]\n",
      "step = 2100 cost = 0.4400118 W2 = [[-2.5744014]\n",
      " [-3.714758 ]]\n",
      "step = 2200 cost = 0.40328586 W2 = [[-2.863473 ]\n",
      " [-3.9974873]]\n",
      "step = 2300 cost = 0.3664013 W2 = [[-3.1685035]\n",
      " [-4.2710614]]\n",
      "step = 2400 cost = 0.33048907 W2 = [[-3.4813542]\n",
      " [-4.533979 ]]\n",
      "step = 2500 cost = 0.29657137 W2 = [[-3.794229]\n",
      " [-4.785163]]\n",
      "step = 2600 cost = 0.26539743 W2 = [[-4.1005917]\n",
      " [-5.023929 ]]\n",
      "step = 2700 cost = 0.2373738 W2 = [[-4.395633]\n",
      " [-5.249983]]\n",
      "step = 2800 cost = 0.21259509 W2 = [[-4.6763034]\n",
      " [-5.463371 ]]\n",
      "step = 2900 cost = 0.19092818 W2 = [[-4.9410453]\n",
      " [-5.664417 ]]\n",
      "step = 3000 cost = 0.17210585 W2 = [[-5.18942 ]\n",
      " [-5.853656]]\n",
      "step = 3100 cost = 0.15580197 W2 = [[-5.421743 ]\n",
      " [-6.0317507]]\n",
      "step = 3200 cost = 0.14168252 W2 = [[-5.6387835]\n",
      " [-6.1994343]]\n",
      "step = 3300 cost = 0.12943412 W2 = [[-5.841547 ]\n",
      " [-6.3574605]]\n",
      "step = 3400 cost = 0.11877716 W2 = [[-6.0311365]\n",
      " [-6.5065694]]\n",
      "step = 3500 cost = 0.109469846 W2 = [[-6.20866 ]\n",
      " [-6.647471]]\n",
      "step = 3600 cost = 0.10130652 W2 = [[-6.3751826]\n",
      " [-6.7808313]]\n",
      "step = 3700 cost = 0.094114214 W2 = [[-6.5316978]\n",
      " [-6.9072666]]\n",
      "step = 3800 cost = 0.0877487 W2 = [[-6.6791058]\n",
      " [-7.027338 ]]\n",
      "step = 3900 cost = 0.0820892 W2 = [[-6.818233]\n",
      " [-7.14156 ]]\n",
      "step = 4000 cost = 0.07703528 W2 = [[-6.9498177]\n",
      " [-7.250397 ]]\n",
      "step = 4100 cost = 0.07250261 W2 = [[-7.074522 ]\n",
      " [-7.3542767]]\n",
      "step = 4200 cost = 0.06842106 W2 = [[-7.192939]\n",
      " [-7.453567]]\n",
      "step = 4300 cost = 0.06473121 W2 = [[-7.305597]\n",
      " [-7.548618]]\n",
      "step = 4400 cost = 0.061383184 W2 = [[-7.412969]\n",
      " [-7.639743]]\n",
      "step = 4500 cost = 0.058334563 W2 = [[-7.5154843]\n",
      " [-7.727222 ]]\n",
      "step = 4600 cost = 0.055549502 W2 = [[-7.6135116]\n",
      " [-7.811311 ]]\n",
      "step = 4700 cost = 0.05299708 W2 = [[-7.7073965]\n",
      " [-7.89224  ]]\n",
      "step = 4800 cost = 0.05065101 W2 = [[-7.797446 ]\n",
      " [-7.9702225]]\n",
      "step = 4900 cost = 0.048488416 W2 = [[-7.8839355]\n",
      " [-8.045448 ]]\n",
      "step = 5000 cost = 0.04648981 W2 = [[-7.967117]\n",
      " [-8.118092]]\n",
      "step = 5100 cost = 0.044638045 W2 = [[-8.047212]\n",
      " [-8.188314]]\n",
      "step = 5200 cost = 0.04291825 W2 = [[-8.124426]\n",
      " [-8.256263]]\n",
      "step = 5300 cost = 0.041317515 W2 = [[-8.198948]\n",
      " [-8.322069]]\n",
      "step = 5400 cost = 0.039824344 W2 = [[-8.270946]\n",
      " [-8.385859]]\n",
      "step = 5500 cost = 0.038428664 W2 = [[-8.340577]\n",
      " [-8.447744]]\n",
      "step = 5600 cost = 0.037121706 W2 = [[-8.407981]\n",
      " [-8.507831]]\n",
      "step = 5700 cost = 0.035895515 W2 = [[-8.4732895]\n",
      " [-8.566216 ]]\n",
      "step = 5800 cost = 0.03474316 W2 = [[-8.536624]\n",
      " [-8.622985]]\n",
      "step = 5900 cost = 0.033658393 W2 = [[-8.598089]\n",
      " [-8.678225]]\n",
      "step = 6000 cost = 0.032635648 W2 = [[-8.657789]\n",
      " [-8.73201 ]]\n",
      "step = 6100 cost = 0.03166993 W2 = [[-8.715816]\n",
      " [-8.784416]]\n",
      "step = 6200 cost = 0.030756745 W2 = [[-8.772258]\n",
      " [-8.835503]]\n",
      "step = 6300 cost = 0.029892094 W2 = [[-8.827198]\n",
      " [-8.885335]]\n",
      "step = 6400 cost = 0.029072367 W2 = [[-8.880706 ]\n",
      " [-8.9339695]]\n",
      "step = 6500 cost = 0.02829421 W2 = [[-8.932855]\n",
      " [-8.981463]]\n",
      "step = 6600 cost = 0.027554613 W2 = [[-8.983706 ]\n",
      " [-9.0278635]]\n",
      "step = 6700 cost = 0.026850903 W2 = [[-9.033323]\n",
      " [-9.073221]]\n",
      "step = 6800 cost = 0.026180599 W2 = [[-9.081762]\n",
      " [-9.117578]]\n",
      "step = 6900 cost = 0.025541432 W2 = [[-9.129075]\n",
      " [-9.160975]]\n",
      "step = 7000 cost = 0.024931353 W2 = [[-9.175312]\n",
      " [-9.203456]]\n",
      "step = 7100 cost = 0.024348505 W2 = [[-9.220517]\n",
      " [-9.245052]]\n",
      "step = 7200 cost = 0.0237911 W2 = [[-9.264733]\n",
      " [-9.285802]]\n",
      "step = 7300 cost = 0.023257522 W2 = [[-9.308002]\n",
      " [-9.325738]]\n",
      "step = 7400 cost = 0.022746423 W2 = [[-9.350366]\n",
      " [-9.36489 ]]\n",
      "step = 7500 cost = 0.02225641 W2 = [[-9.391856]\n",
      " [-9.403286]]\n",
      "step = 7600 cost = 0.02178614 W2 = [[-9.432506]\n",
      " [-9.440958]]\n",
      "step = 7700 cost = 0.02133461 W2 = [[-9.472351]\n",
      " [-9.477928]]\n",
      "step = 7800 cost = 0.020900674 W2 = [[-9.51142 ]\n",
      " [-9.514225]]\n",
      "step = 7900 cost = 0.020483375 W2 = [[-9.549741]\n",
      " [-9.549871]]\n",
      "step = 8000 cost = 0.020081762 W2 = [[-9.587345]\n",
      " [-9.584886]]\n",
      "step = 8100 cost = 0.019695 W2 = [[-9.624254]\n",
      " [-9.619293]]\n",
      "step = 8200 cost = 0.019322325 W2 = [[-9.660494]\n",
      " [-9.653112]]\n",
      "step = 8300 cost = 0.01896299 W2 = [[-9.696087]\n",
      " [-9.686364]]\n",
      "step = 8400 cost = 0.018616287 W2 = [[-9.731058]\n",
      " [-9.719064]]\n",
      "step = 8500 cost = 0.018281605 W2 = [[-9.765422]\n",
      " [-9.751233]]\n",
      "step = 8600 cost = 0.017958298 W2 = [[-9.799204]\n",
      " [-9.782884]]\n",
      "step = 8700 cost = 0.017645836 W2 = [[-9.832424]\n",
      " [-9.814035]]\n",
      "step = 8800 cost = 0.017343711 W2 = [[-9.865094]\n",
      " [-9.844703]]\n",
      "step = 8900 cost = 0.017051382 W2 = [[-9.897237]\n",
      " [-9.874901]]\n",
      "step = 9000 cost = 0.016768461 W2 = [[-9.928865]\n",
      " [-9.904644]]\n",
      "step = 9100 cost = 0.016494483 W2 = [[-9.959999]\n",
      " [-9.933941]]\n",
      "step = 9200 cost = 0.016228978 W2 = [[-9.99065 ]\n",
      " [-9.962812]]\n",
      "step = 9300 cost = 0.01597158 W2 = [[-10.020835]\n",
      " [ -9.991261]]\n",
      "step = 9400 cost = 0.015721992 W2 = [[-10.050568]\n",
      " [-10.019304]]\n",
      "step = 9500 cost = 0.015479866 W2 = [[-10.079857]\n",
      " [-10.046954]]\n",
      "step = 9600 cost = 0.015244822 W2 = [[-10.108722]\n",
      " [-10.07422 ]]\n",
      "step = 9700 cost = 0.0150166275 W2 = [[-10.137167]\n",
      " [-10.10111 ]]\n",
      "step = 9800 cost = 0.014794883 W2 = [[-10.165209]\n",
      " [-10.12764 ]]\n",
      "step = 9900 cost = 0.014579467 W2 = [[-10.192858]\n",
      " [-10.153813]]\n",
      "step = 10000 cost = 0.014369993 W2 = [[-10.220124]\n",
      " [-10.179639]]\n",
      "\n",
      "Hypothesis : \n",
      " [[0.01183227]\n",
      " [0.9844234 ]\n",
      " [0.98441565]\n",
      " [0.01407099]] \n",
      "Correct : \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy : \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y_data = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name = 'weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name = 'bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name = 'weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name = 'bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(\"step =\", step, \"cost =\", sess.run(cost, feed_dict={X:x_data, Y:y_data}),\n",
    "                 \"W2 =\", sess.run(W2))\n",
    "            \n",
    "    # Accuracy\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print(\"\\nHypothesis : \\n\", h, \"\\nCorrect : \\n\", c, \"\\nAccuracy : \\n\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.1.0-cp37-cp37m-win_amd64.whl (9.4 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from pandas) (1.19.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.1.0 pytz-2020.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "서울    9904312\n",
       "부산    3448737\n",
       "인천    2890451\n",
       "대구    2466052\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([9904312, 3448737, 2890451, 2466052],    # numpy는 np.array\n",
    "             index = ['서울', '부산', '인천', '대구'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['서울', '부산', '인천', '대구'], dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9904312, 3448737, 2890451, 2466052], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "도시\n",
       "서울    9904312\n",
       "부산    3448737\n",
       "인천    2890451\n",
       "대구    2466052\n",
       "Name: 인구, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.name = \"인구\"\n",
    "s.index.name = \"도시\"\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "도시\n",
       "서울    9.904312\n",
       "부산    3.448737\n",
       "인천    2.890451\n",
       "대구    2.466052\n",
       "Name: 인구, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3448737, 3448737)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1], s['부산']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2890451, 2890451)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[2], s['인천']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "도시\n",
       "서울    9904312\n",
       "대구    2466052\n",
       "부산    3448737\n",
       "Name: 인구, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[[0, 3, 1]]  # numpy 1차원 array(vector)와 동일함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9904312"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "도시\n",
       "부산    3448737\n",
       "인천    2890451\n",
       "Name: 인구, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[(250e4 < s) & (s < 500e4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "도시\n",
       "부산    3448737\n",
       "인천    2890451\n",
       "Name: 인구, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "도시\n",
       "부산    3448737\n",
       "인천    2890451\n",
       "대구    2466052\n",
       "Name: 인구, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"부산\":\"대구\"]   ## 문자로 인덱싱할 때는 마지막 인덱스도 포함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0\n",
       "b    1\n",
       "c    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0 = pd.Series(range(3), index = [\"a\", \"b\", \"c\"])\n",
    "s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from matplotlib) (1.19.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Windows\\\\Fonts\\\\HMKBP.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LEELAWDB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMFMPYUN.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MEIRYOB.TTC',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PERB____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\palabi.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\JOKERMAN.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GOUDOS.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENOCRA.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GARABD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\seguibli.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKBS.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LeelUIsl.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BAUHS93.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\H2GTRM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GILSANUB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENGDOS.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\msjh.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YGGE05.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\segoeuib.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYNAML.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\H2MJRE.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ahn_l.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LeelaUIb.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CENTURY.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FRADMIT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENMUHB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YSHN05.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENCSCHI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FREESCPT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ebrimabd.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENGARMB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CALIFR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CALIFB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CALISTBI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ROCCB___.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ONYX.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ARIALNI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LeelawUI.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Inkfree.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YSOS07.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FRSCRIPT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\trebucbi.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\constan.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\bahnschrift.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\constanb.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\arial.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MISTRAL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANSaleM.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANYGO230.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANCooljazzB.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\\\x7f\\x7f\\x7f\\x7fBOLD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\corbelli.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BELLB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\NIAGSOL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BKANT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\comic.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GOTHIC.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\AGENCYR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYKANB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\corbelb.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MK.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYWULB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GOUDOSI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\REFSAN.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\UNI_HSR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ARIALUNI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\palab.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\OCRAEXT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\RAGE.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\georgiai.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENBLBK.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YDWM05.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MSUIGHUB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\POORICH.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GILC____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MG.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\simsunb.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FRAHVIT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\TAENMR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANBatangExt.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\mmrtext.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKMOLD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANSomaB.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKBA.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANSomaM.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENORAT10.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ERASDEMI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\cambriab.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GARAIT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\tahoma.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\taileb.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\framdit.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HTOWERT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\himalaya.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FRABK.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYDNKM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BASKVILL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENGDOSBI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\calibrib.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\georgia.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYNAMM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GOUDOSB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ELEPHNTI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\timesbi.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\calibril.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\segoeui.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\H2GSRB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYBDAM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYPORM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYSANB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\msjhbd.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BRADHITC.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\segoesc.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LBRITE.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MOD20.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\trebucit.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\georgiaz.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LHANDW.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BRLNSB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\segoepr.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\seguisb.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\TCM_____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LFAXI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LBRITEI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YBUU02.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ERASMD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BERNHC.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYSUPB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FRAHV.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANBaekM.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOD_PSTC.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\arialbi.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\wingding.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENGARMI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\TCBI____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LEELAWAD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MJ.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\malgunsl.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\H2PORL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ALGER.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\SNAP____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKMRHD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PAPYRUS.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANCooljazzM.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\seguisym.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\comicz.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENSTEN.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\IMPRISHA.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENCOBKI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENSW721L.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANBatangB.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ARIALNB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\H2PORM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYSNRL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ntailu.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENGDOSI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANBatang.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\DUBAI-LIGHT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYNAMB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\seguibl.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Sol.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENOCRB10.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\trebucbd.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ROCKEB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\SCHLBKBI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GOTHICBI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MEIRYO.TTC',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\tahomabd.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BRLNSDB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\calibrii.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\couri.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CALISTB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\georgiab.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOOKOS.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\mingliub.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MTEXTRA.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FRADMCN.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENITCNBK.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKLA.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\DUBAI-REGULAR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ariali.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PENHL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\H2GTRE.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BRUSHSCI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LTYPEBO.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOD_BI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKLS.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKMS.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\gadugi.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\msgothic.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\TCCEB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\consolaz.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\msjhl.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LFAXDI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOD_R.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANSaleB.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YuGothM.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOD_CR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\VIVALDII.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BELL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ROCC____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\H2MJSM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\DUBAI-BOLD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\\\x7f\\x7f\\x7f\\x7fEXTRABOLD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENBRODWY.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\TEMPSITC.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CURLZ___.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\cambriai.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GILB____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ANTQUAB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\marlett.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\arialbd.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MATURASC.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\H2GPRM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\gadugib.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\framd.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\SCRIPTBL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\lucon.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\timesi.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENHOBO.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Candarali.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LSANSDI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\corbeli.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Candarab.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\RAVIE.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YBLO05.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENCOSCPT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENLIBRTY.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CALIST.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ELEPHNT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\H2HDRM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LFAX.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\TCMI____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOD_CI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ITCEDSCR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\H2SA1M.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYSUPM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\comici.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\javatext.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\mvboli.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\malgun.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOOKOSB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\NirmalaB.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LTYPE.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LSANSD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENBODBK.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BROADW.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYTBRB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYMJRE.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HBATANG.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YINJ05.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYBSRB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\taile.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\comicbd.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\timesbd.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\KUNSTLER.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ROCKB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENFREEHD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Art.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PER_____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ANTQUAI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GIGI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYMPRL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CHILLER.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENPKAV.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\INFROMAN.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PALSCRI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\seguiemj.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\segoescb.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYCYSM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\courbd.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\corbelz.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\pala.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENCR10B.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENCSCHB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\WINGDNG3.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GILI____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PERTILI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GILLUBCD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\VINERITC.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\H2MKPB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PARCHM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ITCKRIST.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\SitkaZ.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENGDOSB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PERI____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LBRITED.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\msyh.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\OLDENGL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOD_BLAI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\holomdl2.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GARA.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANDotum.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENBODBI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYGTRE.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANYGO240.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\mmrtextb.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\simsun.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Candara.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LBRITEDI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HDOTUM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HARNGTON.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\corbell.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\segoeuii.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\cambriaz.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKMM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MN.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GLSNECB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CALISTI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\COPRGTB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ARIALN.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANYGO250.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\micross.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MP.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\msyhl.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\phagspab.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LFAXD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\SitkaI.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\NGULIM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOD_B.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\REFSPCL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENBASKVL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENS721LI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CASTELAR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\palai.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENCSCHBI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANSolM.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YNCH05.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\calibrili.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYDNKB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YuGothL.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YBMG05.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Nirmala.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\calibri.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Gabriola.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYGSRB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ROCK.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\COOPBL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GLECB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GILBI___.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\seguisli.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PERBI___.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BELLI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MSUIGHUR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MAGNETOB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FELIXTI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YWDA05.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Gaesung.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LSANSI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\segoeprb.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\SCHLBKB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CENTAUR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\SCHLBKI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YDOO08.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOOKOSI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYKANM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ahn_m.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FTLTLT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LSANS.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENCSCH.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MAIAN.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\consola.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LTYPEB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FRABKIT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENGARMBI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKMP.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYGPRM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYBDAL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\impact.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYWULM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LCALLIG.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CENSCBK.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANDotumExt.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\verdanai.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANCooljazzL.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\corbel.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\times.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\SitkaB.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\JUICE___.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKLP.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ROCKBI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\consolai.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GIL_____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ROCKI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\verdanab.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\msyhbd.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ntailub.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\COPRGTL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FZSong_Super.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PRISTINA.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\courbi.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HATTEN.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKMMAG.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Candaral.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Candarai.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOD_CBI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\cambria.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANBaekB.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GOUDYSTO.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MH.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENBODBKI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\segmdl2.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMFMOLD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\seguisbi.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Candaraz.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GOTHICI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\phagspa.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOD_I.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENGARM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ariblk.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENGR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BRITANIC.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Sitka.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANYheadM.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\trebuc.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YBLA05.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANYheadB.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANDotumB.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\MTCORSVA.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\constani.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YCHM08.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\cour.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENCOBK.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\webdings.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LATINWD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ARIALNBI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YINP05.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YuGothB.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FRAMDCN.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKMAMI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\seguili.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YTTE08.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ANTQUABI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\STENCIL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\WINGDNG2.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENDOMCA.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FORTE.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ERASBD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\DUBAI-MEDIUM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\segoeuisl.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\calibriz.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOD_CB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENBERNF.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\constanz.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\malgunbd.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENBODB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PERTIBD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\NirmalaS.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENORBITB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMFMMUEX.TTC',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\TCCB____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\consolab.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\TCCM____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\OUTLOOK.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\batang.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENCR10BI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\PLAYBILL.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\verdanaz.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\VLADIMIR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\\\x7f\\x7f\\x7f\\x7f.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\TCB_____.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\verdana.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Easop.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\LTYPEO.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\sylfaen.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENBRUSH.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\Along.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\SHOWG.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ERASLGHT.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YMAE07.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANSolB.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\l_10646.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HARLOWSI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\CALIFI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKMA.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\symbol.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\monbaiti.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOD_BLAR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BSSYM7.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BOOKOSBI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\FRADM.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\NIAGENG.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\gulim.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\msyi.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HANYheadL.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YuGothR.ttc',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ITCBLKAD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ebrima.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\seguihis.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HMKMG.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\COLONNA.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HYHWPEQ.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\GOTHICB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ENFUTUBK.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\BRLNSR.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\HTOWERTI.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YGBI08.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ARLRDBD.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\segoeuiz.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\segoeuil.ttf',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\AGENCYB.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\YDUG05.TTF',\n",
       " 'C:\\\\Windows\\\\Fonts\\\\ahn_b.ttf']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "\n",
    "font_list = fm.findSystemFonts(fontpaths= None, fontext = \"ttf\")\n",
    "\n",
    "font_list[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'? ??',\n",
       " '???',\n",
       " '????',\n",
       " '??????',\n",
       " 'Agency FB',\n",
       " 'Algerian',\n",
       " 'AmeriGarmnd BT',\n",
       " 'Ami R',\n",
       " 'Arial',\n",
       " 'Arial Rounded MT Bold',\n",
       " 'Arial Unicode MS',\n",
       " 'Bahnschrift',\n",
       " 'Baskerville BT',\n",
       " 'Baskerville Old Face',\n",
       " 'Batang',\n",
       " 'Bauhaus 93',\n",
       " 'Bell MT',\n",
       " 'Berlin Sans FB',\n",
       " 'Berlin Sans FB Demi',\n",
       " 'Bernard MT Condensed',\n",
       " 'BernhardFashion BT',\n",
       " 'Blackadder ITC',\n",
       " 'Blippo Blk BT',\n",
       " 'Bodoni Bd BT',\n",
       " 'Bodoni Bk BT',\n",
       " 'Bodoni MT',\n",
       " 'Book Antiqua',\n",
       " 'Bookman Old Style',\n",
       " 'Bookshelf Symbol 7',\n",
       " 'Bradley Hand ITC',\n",
       " 'Britannic Bold',\n",
       " 'Broadway',\n",
       " 'BroadwayEngraved BT',\n",
       " 'Brush Script MT',\n",
       " 'BrushScript BT',\n",
       " 'Calibri',\n",
       " 'Californian FB',\n",
       " 'Calisto MT',\n",
       " 'Cambria',\n",
       " 'Candara',\n",
       " 'Castellar',\n",
       " 'CentSchbook BT',\n",
       " 'Centaur',\n",
       " 'Century',\n",
       " 'Century Gothic',\n",
       " 'Century Schoolbook',\n",
       " 'Chiller',\n",
       " 'Colonna MT',\n",
       " 'Comic Sans MS',\n",
       " 'CommercialScript BT',\n",
       " 'Consolas',\n",
       " 'Constantia',\n",
       " 'Cooper Black',\n",
       " 'Cooper Blk BT',\n",
       " 'Copperplate Gothic Bold',\n",
       " 'Copperplate Gothic Light',\n",
       " 'Corbel',\n",
       " 'Courier New',\n",
       " 'Courier10 BT',\n",
       " 'Curlz MT',\n",
       " 'DejaVu Sans',\n",
       " 'DejaVu Sans Display',\n",
       " 'DejaVu Sans Mono',\n",
       " 'DejaVu Serif',\n",
       " 'DejaVu Serif Display',\n",
       " 'DomCasual BT',\n",
       " 'Dubai',\n",
       " 'Ebrima',\n",
       " 'Edwardian Script ITC',\n",
       " 'Elephant',\n",
       " 'Engravers MT',\n",
       " 'Eras Bold ITC',\n",
       " 'Eras Demi ITC',\n",
       " 'Eras Light ITC',\n",
       " 'Eras Medium ITC',\n",
       " 'FZSong_Superfont',\n",
       " 'Felix Titling',\n",
       " 'Footlight MT Light',\n",
       " 'Forte',\n",
       " 'Franklin Gothic Book',\n",
       " 'Franklin Gothic Demi',\n",
       " 'Franklin Gothic Demi Cond',\n",
       " 'Franklin Gothic Heavy',\n",
       " 'Franklin Gothic Medium',\n",
       " 'Franklin Gothic Medium Cond',\n",
       " 'Freehand591 BT',\n",
       " 'Freestyle Script',\n",
       " 'French Script MT',\n",
       " 'FuturaBlack BT',\n",
       " 'Gabriola',\n",
       " 'Gadugi',\n",
       " 'Garamond',\n",
       " 'Georgia',\n",
       " 'Gigi',\n",
       " 'Gill Sans MT',\n",
       " 'Gill Sans MT Condensed',\n",
       " 'Gill Sans MT Ext Condensed Bold',\n",
       " 'Gill Sans Ultra Bold',\n",
       " 'Gill Sans Ultra Bold Condensed',\n",
       " 'Gloucester MT Extra Condensed',\n",
       " 'Goudy Old Style',\n",
       " 'Goudy Stout',\n",
       " 'GoudyOlSt BT',\n",
       " 'Gulim',\n",
       " 'HCR Batang',\n",
       " 'HCR Batang Ext',\n",
       " 'HCR Dotum',\n",
       " 'HCR Dotum Ext',\n",
       " 'HYGothic-Extra',\n",
       " 'HYGothic-Medium',\n",
       " 'HYGraphic-Medium',\n",
       " 'HYGungSo-Bold',\n",
       " 'HYHeadLine M',\n",
       " 'HYMyeongJo-Extra',\n",
       " 'HYPMokGak-Bold',\n",
       " 'HYPost-Light',\n",
       " 'HYPost-Medium',\n",
       " 'HYShortSamul-Medium',\n",
       " 'HYSinMyeongJo-Medium',\n",
       " 'HYbdaL',\n",
       " 'HYbdaM',\n",
       " 'HYbsrB',\n",
       " 'HYcysM',\n",
       " 'HYdnkB',\n",
       " 'HYdnkM',\n",
       " 'HYgprM',\n",
       " 'HYgsrB',\n",
       " 'HYgtrE',\n",
       " 'HYhaeseo',\n",
       " 'HYkanB',\n",
       " 'HYkanM',\n",
       " 'HYmjrE',\n",
       " 'HYmprL',\n",
       " 'HYnamB',\n",
       " 'HYnamL',\n",
       " 'HYnamM',\n",
       " 'HYporM',\n",
       " 'HYsanB',\n",
       " 'HYsnrL',\n",
       " 'HYsupB',\n",
       " 'HYsupM',\n",
       " 'HYtbrB',\n",
       " 'HYwulB',\n",
       " 'HYwulM',\n",
       " 'Haan Baekje B',\n",
       " 'Haan Baekje M',\n",
       " 'Haan Cooljazz B',\n",
       " 'Haan Cooljazz L',\n",
       " 'Haan Cooljazz M',\n",
       " 'Haan Sale B',\n",
       " 'Haan Sale M',\n",
       " 'Haan Sollip B',\n",
       " 'Haan Sollip M',\n",
       " 'Haan Somang B',\n",
       " 'Haan Somang M',\n",
       " 'Haan YGodic 230',\n",
       " 'Haan YGodic 240',\n",
       " 'Haan YGodic 250',\n",
       " 'Haan YHead B',\n",
       " 'Haan YHead L',\n",
       " 'Haan YHead M',\n",
       " 'Haansoft Batang',\n",
       " 'Haansoft Dotum',\n",
       " 'Haettenschweiler',\n",
       " 'Harlow Solid Italic',\n",
       " 'Harrington',\n",
       " 'Headline R',\n",
       " 'High Tower Text',\n",
       " 'Hobo BT',\n",
       " 'HoloLens MDL2 Assets',\n",
       " 'HyhwpEQ',\n",
       " 'Impact',\n",
       " 'Imprint MT Shadow',\n",
       " 'Informal Roman',\n",
       " 'Ink Free',\n",
       " 'Javanese Text',\n",
       " 'Jokerman',\n",
       " 'Juice ITC',\n",
       " 'Kristen ITC',\n",
       " 'Kunstler Script',\n",
       " 'Leelawadee',\n",
       " 'Leelawadee UI',\n",
       " 'Liberty BT',\n",
       " 'Lucida Bright',\n",
       " 'Lucida Calligraphy',\n",
       " 'Lucida Console',\n",
       " 'Lucida Fax',\n",
       " 'Lucida Handwriting',\n",
       " 'Lucida Sans',\n",
       " 'Lucida Sans Typewriter',\n",
       " 'Lucida Sans Unicode',\n",
       " 'MBatang',\n",
       " 'MDAlong',\n",
       " 'MDArt',\n",
       " 'MDEasop',\n",
       " 'MDGaesung',\n",
       " 'MDSol',\n",
       " 'MDotum',\n",
       " 'MGungHeulim',\n",
       " 'MGungJeong',\n",
       " 'MHunmin',\n",
       " 'MJemokBatang',\n",
       " 'MJemokGothic',\n",
       " 'MS Gothic',\n",
       " 'MS Outlook',\n",
       " 'MS Reference Sans Serif',\n",
       " 'MS Reference Specialty',\n",
       " 'MSugiHeulim',\n",
       " 'MSugiJeong',\n",
       " 'MT Extra',\n",
       " 'MV Boli',\n",
       " 'Magic R',\n",
       " 'Magneto',\n",
       " 'Maiandra GD',\n",
       " 'Malgun Gothic',\n",
       " 'Marlett',\n",
       " 'Matura MT Script Capitals',\n",
       " 'Meiryo',\n",
       " 'Microsoft Himalaya',\n",
       " 'Microsoft JhengHei',\n",
       " 'Microsoft New Tai Lue',\n",
       " 'Microsoft PhagsPa',\n",
       " 'Microsoft Sans Serif',\n",
       " 'Microsoft Tai Le',\n",
       " 'Microsoft Uighur',\n",
       " 'Microsoft YaHei',\n",
       " 'Microsoft Yi Baiti',\n",
       " 'MingLiU-ExtB',\n",
       " 'Mistral',\n",
       " 'Modern No. 20',\n",
       " 'MoeumT R',\n",
       " 'Mongolian Baiti',\n",
       " 'Monotype Corsiva',\n",
       " 'MurrayHill Bd BT',\n",
       " 'Myanmar Text',\n",
       " 'NanumGothic',\n",
       " 'New Gulim',\n",
       " 'Newtext Bk BT',\n",
       " 'Niagara Engraved',\n",
       " 'Niagara Solid',\n",
       " 'Nirmala UI',\n",
       " 'OCR A Extended',\n",
       " 'OCR-A BT',\n",
       " 'OCR-B-10 BT',\n",
       " 'Old English Text MT',\n",
       " 'Onyx',\n",
       " 'Orator10 BT',\n",
       " 'Orbit-B BT',\n",
       " 'Palace Script MT',\n",
       " 'Palatino Linotype',\n",
       " 'Papyrus',\n",
       " 'Parchment',\n",
       " 'ParkAvenue BT',\n",
       " 'Perpetua',\n",
       " 'Perpetua Titling MT',\n",
       " 'Playbill',\n",
       " 'Poor Richard',\n",
       " 'Pristina',\n",
       " 'Pyunji R',\n",
       " 'Rage Italic',\n",
       " 'Ravie',\n",
       " 'Rockwell',\n",
       " 'Rockwell Condensed',\n",
       " 'Rockwell Extra Bold',\n",
       " 'STIXGeneral',\n",
       " 'STIXNonUnicode',\n",
       " 'STIXSizeFiveSym',\n",
       " 'STIXSizeFourSym',\n",
       " 'STIXSizeOneSym',\n",
       " 'STIXSizeThreeSym',\n",
       " 'STIXSizeTwoSym',\n",
       " 'Script MT Bold',\n",
       " 'Segoe MDL2 Assets',\n",
       " 'Segoe Print',\n",
       " 'Segoe Script',\n",
       " 'Segoe UI',\n",
       " 'Segoe UI Emoji',\n",
       " 'Segoe UI Historic',\n",
       " 'Segoe UI Symbol',\n",
       " 'Showcard Gothic',\n",
       " 'SimSun',\n",
       " 'SimSun-ExtB',\n",
       " 'Sitka Small',\n",
       " 'Snap ITC',\n",
       " 'Stencil',\n",
       " 'Stencil BT',\n",
       " 'Swis721 BT',\n",
       " 'Sylfaen',\n",
       " 'Symbol',\n",
       " 'Tahoma',\n",
       " 'Tempus Sans ITC',\n",
       " 'Times New Roman',\n",
       " 'Trebuchet MS',\n",
       " 'Tw Cen MT',\n",
       " 'Tw Cen MT Condensed',\n",
       " 'Tw Cen MT Condensed Extra Bold',\n",
       " 'Verdana',\n",
       " 'Viner Hand ITC',\n",
       " 'Vivaldi',\n",
       " 'Vladimir Script',\n",
       " 'Webdings',\n",
       " 'Wide Latin',\n",
       " 'Wingdings',\n",
       " 'Wingdings 2',\n",
       " 'Wingdings 3',\n",
       " 'YJ BELLA Medium',\n",
       " 'YJ INJANG Medium',\n",
       " 'Yet R',\n",
       " 'Yj BACDOO Bold ',\n",
       " 'Yj BLOCK Medium',\n",
       " 'Yj BONMOKGAK Medium ',\n",
       " 'Yj BUTGOT Light ',\n",
       " 'Yj CHMSOOT Bold',\n",
       " 'Yj DOOLGI Medium',\n",
       " 'Yj DWMMOOGJO',\n",
       " 'Yj GABI',\n",
       " 'Yj GOTGAE Medium',\n",
       " 'Yj INITIALPOSITIVE Medium',\n",
       " 'Yj MAEHWA  SemiBold',\n",
       " 'Yj NANCHO Medium',\n",
       " 'Yj SHANALL Medium ',\n",
       " 'Yj SOSEL SemiBold',\n",
       " 'Yj TEUNTEUN Bold',\n",
       " 'Yj WADAG Medium',\n",
       " 'Yu Gothic',\n",
       " 'ahn2006-B',\n",
       " 'ahn2006-L',\n",
       " 'ahn2006-M',\n",
       " 'cmb10',\n",
       " 'cmex10',\n",
       " 'cmmi10',\n",
       " 'cmr10',\n",
       " 'cmss10',\n",
       " 'cmsy10',\n",
       " 'cmtt10'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sorted([f.name for f in mpl.font_manager.fontManager.ttflist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폰트 설정\n",
    "mpl.rc(\"font\", family = 'NanumGothic')\n",
    "\n",
    "# 유니코드에서 음수 부호설정\n",
    "mpl.rc('axes', unicode_minus = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('한글 제목')\n",
    "plt.plot([1, 4, 9, 16])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('x ticks')\n",
    "plt.plot([10, 20, 30, 40], [1, 4, 9, 16])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"한글 제목\")\n",
    "plt.plot([10, 20, 30, 40], [1, 4, 9, 16])\n",
    "plt.xlabel('엑스축 라벨')\n",
    "plt.ylabel('와이축 라벨')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"한글 제목\", fontdict = font1)\n",
    "plt.plot([10, 20, 30, 40], [1, 4, 9, 16])\n",
    "plt.xlabel('엑스축 라벨', fontdict = font2)\n",
    "plt.ylabel('와이축 라벨', fontdict = font3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"타이틀\")\n",
    "plt.plot([10, 20, 30, 40], [1, 4, 9, 16], 'rs--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
