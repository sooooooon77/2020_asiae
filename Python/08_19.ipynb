{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 피마 인디언의 당뇨병 데이터 ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] 액세스가 거부되었습니다: 'c:\\\\programdata\\\\anaconda3\\\\envs\\\\new_env\\\\lib\\\\site-packages\\\\numpy-1.19.1.dist-info\\\\direct_url.json'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached tensorflow-2.3.0-cp37-cp37m-win_amd64.whl (342.5 MB)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (3.12.3)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.27.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting astunparse==1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Using cached tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Collecting scipy==1.4.1\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9 MB)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Using cached numpy-1.18.5-cp37-cp37m-win_amd64.whl (12.7 MB)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Using cached tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from protobuf>=3.9.2->tensorflow) (49.2.1.post20200807)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.20.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.16.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Installing collected packages: astunparse, numpy, keras-preprocessing, tensorflow-estimator, scipy, gast, tensorboard, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pima-indians-diabetes.csv\", \n",
    "                 names = [\"pregnant\", \"plasma\", \"pressure\", \"thickness\", \n",
    "                          \"insulin\", \"BMI\", \"pedigree\", \"age\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  class\n",
       "0         6     148        72         35        0  33.6     0.627   50      1\n",
       "1         1      85        66         29        0  26.6     0.351   31      0\n",
       "2         8     183        64          0        0  23.3     0.672   32      1\n",
       "3         1      89        66         23       94  28.1     0.167   21      0\n",
       "4         0     137        40         35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  \\\n",
       "763        10     101        76         48      180  32.9     0.171   63   \n",
       "764         2     122        70         27        0  36.8     0.340   27   \n",
       "765         5     121        72         23      112  26.2     0.245   30   \n",
       "766         1     126        60          0        0  30.1     0.349   47   \n",
       "767         1      93        70         31        0  30.4     0.315   23   \n",
       "\n",
       "     class  \n",
       "763      0  \n",
       "764      0  \n",
       "765      0  \n",
       "766      1  \n",
       "767      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pregnant   768 non-null    int64  \n",
      " 1   plasma     768 non-null    int64  \n",
      " 2   pressure   768 non-null    int64  \n",
      " 3   thickness  768 non-null    int64  \n",
      " 4   insulin    768 non-null    int64  \n",
      " 5   BMI        768 non-null    float64\n",
      " 6   pedigree   768 non-null    float64\n",
      " 7   age        768 non-null    int64  \n",
      " 8   class      768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pregnant      plasma    pressure   thickness     insulin         BMI  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "         pedigree         age       class  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  class\n",
       "0           6      1\n",
       "1           1      0\n",
       "2           8      1\n",
       "3           1      0\n",
       "4           0      1\n",
       "..        ...    ...\n",
       "763        10      0\n",
       "764         2      0\n",
       "765         5      0\n",
       "766         1      1\n",
       "767         1      0\n",
       "\n",
       "[768 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['pregnant', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.342342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.214815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.184466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.338235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pregnant     class\n",
       "0          0  0.342342\n",
       "1          1  0.214815\n",
       "2          2  0.184466\n",
       "3          3  0.360000\n",
       "4          4  0.338235\n",
       "5          5  0.368421\n",
       "6          6  0.320000\n",
       "7          7  0.555556\n",
       "8          8  0.578947\n",
       "9          9  0.642857\n",
       "10        10  0.416667\n",
       "11        11  0.636364\n",
       "12        12  0.444444\n",
       "13        13  0.500000\n",
       "14        14  1.000000\n",
       "15        15  1.000000\n",
       "16        17  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임신 횟수당 당뇨병 발병 횟수\n",
    "df[['pregnant', 'class']].groupby(['pregnant'], \n",
    "                                  as_index = False).mean().sort_values(by = 'pregnant', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.1-cp37-cp37m-win_amd64.whl (8.5 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.2.0-cp37-none-win_amd64.whl (57 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-7.2.0-cp37-cp37m-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib) (1.19.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib) (2020.6.20)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Installing collected packages: kiwisolver, pillow, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.3.1 pillow-7.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (7, 5))\n",
    "\n",
    "sns.heatmap(df.corr(), linewidths = 0.1, vmax = 0.5, cmap = plt.cm.Set3,\n",
    "           linecolor = 'white', annot = True)\n",
    "# annot : data 값을 각 셀에 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANAAAADNCAYAAADJ7P4xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAK8UlEQVR4nO3dX4wddRnG8e9jkRKxYmtL05Q2LaTRFIOVbGoMBlEiLCVaMIEUb3pRUxMhERMSl3BBuWhSjWi8kIYCTRv/UBuRtFiCkAZD5EKoUPqXSikbunTTba0B1Fhteb2YWTg2Z/ecnPf8mV2eT3JyZn7nNzPvTvfpzM75zTmKCMysNR/pdQFmE5kDZJbgAJklOEBmCQ6QWYIDZJZQiQD19/cH4IcfVXs0VIkAnTx5stclmLWkEgEym6gcILMEB8gswQEyS3CAzBIcILOE83pdgLXPgoEdLS87uO7GNlby4eEjkFmCA2SW4ACZJThAZgkOkFmCA2SW4ACZJThAZgkOkFmCA2SW0DBAkjZKGpG0r6ZtjaS3JO0uH8tqXrtb0mFJhyRd36nCzaqgmSPQJqC/TvtPI2JJ+XgSQNJiYAVwebnMA5KmtKtYs6ppGKCIeA441eT6lgNbIuJ0RLwBHAaWJuozq7TM30B3SNpTnuJNL9vmAkdr+gyVbWaTUqsBWg9cBiwBhoH7y3bV6Vv344EkrZa0S9KuEydOtFiGWW+1FKCIOB4RZyPiPeAhPjhNGwLm1XS9BDg2xjo2RERfRPTNmjWrlTLMeq6lAEmaUzN7MzB6hW47sELSVEkLgUXAC7kSzaqr4R2pkh4FrgFmShoC7gWukbSE4vRsEPgOQETsl7QVOACcAW6PiLMdqdysAhoGKCJuq9P8yDj91wJrM0WZTRQeiWCW4ACZJThAZgkOkFmCA2SW4ACZJThAZgkOkFmCA2SW4ACZJThAZgkOkFmCA2SW4ACZJfgb6iom8y1z1n0+ApklOEBmCQ6QWYIDZJbgAJklOEBmCQ6QWYIDZJbgAJklOEBmCQ6QWYIDZJbgAJklOEBmCQ6QWYIDZJbgAJklOEBmCQ6QWYIDZJbgAJklOEBmCQ0DJGmjpBFJ+2raZkh6RtJr5fP0mtfulnRY0iFJ13eqcLMqaOYItAnoP6dtANgZEYuAneU8khYDK4DLy2UekDSlbdWaVUzDAEXEc8Cpc5qXA5vL6c3ATTXtWyLidES8ARwGlranVLPqafVvoNkRMQxQPl9cts8Fjtb0GyrbzCaldl9EUJ22qNtRWi1pl6RdJ06caHMZZt3R6mdjH5c0JyKGJc0BRsr2IWBeTb9LgGP1VhARG4ANAH19fXVDZt2T+UzuwXU3trGSiaXVI9B2YGU5vRLYVtO+QtJUSQuBRcALuRLNqqvhEUjSo8A1wExJQ8C9wDpgq6RVwJvALQARsV/SVuAAcAa4PSLOdqh2s55rGKCIuG2Ml64do/9aYG2mKLOJwiMRzBIcILMEB8gswQEyS3CAzBIcILMEB8gswQEyS3CAzBIcILMEB8gswQEyS3CAzBIcILMEB8gswQEyS3CAzBIcILMEB8gswQEyS3CAzBIcILMEB8gswQEyS3CAzBIcILMEB8gswQEyS2j1+4FsEhq84FutLbgGWPN2O0uZMHwEMktwgMwSHCCzBAfILMEBMktwgMwSHCCzhNT7QJIGgXeBs8CZiOiTNAP4DbAAGARujYi/58o0q6Z2vJH6lYg4WTM/AOyMiHWSBsr5H7RhO9aElt8MtZZ04hRuObC5nN4M3NSBbZhVQvYIFMDTkgJ4MCI2ALMjYhggIoYlXZwt0iaANRcllp24w4CyAboqIo6VIXlG0qvNLihpNbAaYP78+ckyzHojdQoXEcfK5xHgcWApcFzSHIDyeWSMZTdERF9E9M2aNStThlnPtBwgSRdKmjY6DVwH7AO2AyvLbiuBbdkizaoqcwo3G3hc0uh6fh0RT0l6EdgqaRXwJnBLvkyzamo5QBFxBPhcnfa/AddmijKbKHxDnfXeBL6C56E8ZgkOkFmCA2SW4ACZJfgigk1sPb4A4SOQWYIDZJbgAJklOEBmCQ6QWYIDZJbgAJklOEBmCQ6QWYJHInTAgoEdvS7BusRHILMEB8gswQEyS3CAzBIcILMEB8gswQEyS3CAzBIcILMEB8gswQEyS3CAzBIcILMEj8auIH9R8MThI5BZggNkluAAmSU4QGYJDpBZggNkluAAmSV07H0gSf3Az4ApwMMRsa5T2+oUf7qONdKRAEmaAvwc+BowBLwoaXtEHGhlfZlf5MF1N7a8rFkjnToCLQUOR8QRAElbgOVASwHKvTPf269Bt8mtUwGaCxytmR8CvtChbVWSh+N8OHQqQKrTFv/XQVoNrC5n/yHp0DjrmwmcbKmS++qV0jZj1tXRrY6v9X3VWdWrq/jdGK+upyKif7xVdCpAQ8C8mvlLgGO1HSJiA7ChmZVJ2hURfe0rrz2qWFcVa4LJW1enLmO/CCyStFDS+cAKYHuHtmXWMx05AkXEGUl3AH+guIy9MSL2d2JbZr3UsfeBIuJJ4Mk2ra6pU70eqGJdVawJJmldiojGvcysLg/lMUuodIAk9Us6JOmwpIEe1zIoaa+k3ZJ2lW0zJD0j6bXyeXoX6tgoaUTSvpq2MeuQdHe5/w5Jur7Lda2R9Fa5z3ZLWtbNuiTNk/SspIOS9kv6Xtnevv0VEZV8UFx8eB24FDgfeAVY3MN6BoGZ57T9CBgopweAH3ahjquBK4F9jeoAFpf7bSqwsNyfU7pY1xrgrjp9u1IXMAe4spyeBvy13Hbb9leVj0DvDweKiP8Ao8OBqmQ5sLmc3gzc1OkNRsRzwKkm61gObImI0xHxBnCYYr92q66xdKWuiBiOiJfK6XeBgxSjZNq2v6ocoHrDgeb2qBYoRlI8Lekv5SgKgNkRMQzFPxZwcY9qG6uOKuzDOyTtKU/xRk+Vul6XpAXA54E/08b9VeUANRwO1GVXRcSVwA3A7ZKu7mEtzer1PlwPXAYsAYaB+8v2rtYl6ePAY8CdEfHOeF3rtI1bV5UD1HA4UDdFxLHyeQR4nOLQflzSHIDyeaRH5Y1VR0/3YUQcj4izEfEe8BAfnA51rS5JH6UIz68i4ndlc9v2V5UDVJnhQJIulDRtdBq4DthX1rOy7LYS2NaL+sapYzuwQtJUSQuBRcAL3Spq9Je0dDPFPutaXZIEPAIcjIif1LzUvv3V6atGyasoyyiunLwO3NPDOi6luDrzCrB/tBbgU8BO4LXyeUYXanmU4nTovxT/Y64arw7gnnL/HQJu6HJdvwD2AnvKX8453awL+BLFKdgeYHf5WNbO/eWRCGYJVT6FM6s8B8gswQEyS3CAzBIcILMEB2gCkPRHSZX7PAFzgMxSHKAKkbRA0quSNpcDMH8r6WPn9FkvaVd5f8t9Ne3rJB0ol/tx2bap7P+spCOSvlwO6jwoaVOjdVpj/o7U6vk0sCoinpe0EfjuOa/fExGnyo9P3inpCop3/m8GPhMRIemTNf2nA18FvgE8AVwFfJvi45aXRMTueuuMiD2d/CEnCx+BqudoRDxfTv+SYjhKrVslvQS8DFxOcRPYO8C/gYclfRP4V03/J6IYbrIXOB4Re6MY3LkfWDDOOq0JDlD1nDu26v35coDjXcC1EXEFsAO4ICLOUIx0fozi5rCnapY/XT6/VzM9On/eWOts208zyTlA1TNf0hfL6duAP9W89gngn8DbkmZT3Js0er/LRVF8lNidFPffNKvuOq05/huoeg4CKyU9SDFaeD3wdYCIeEXSyxSnX0eA0VO9acA2SRdQ3BT2/WY3Ns46rQkejV0h5W3Hv4+Iz/a6FmuOT+HMEnwEMkvwEcgswQEyS3CAzBIcILMEB8gswQEyS/gf4RFoHffJpLwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 다중 그리드를 만들어줌\n",
    "#grid = sns.FacetGrid(df, col = 'class')\n",
    "#grid = sns.FacetGrid(df, row = 'class')\n",
    "grid = sns.FacetGrid(df, hue = 'class')\n",
    "\n",
    "grid.map(plt.hist, 'plasma', bins = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 피마 인디언의 당뇨병 예측 실행 ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from keras) (1.19.1)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from keras) (1.5.0)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-5.3.1-cp37-cp37m-win_amd64.whl (216 kB)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\tf_v1\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: pyyaml, keras\n",
      "Successfully installed keras-2.4.3 pyyaml-5.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__   # 2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter = ',')\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "768/768 [==============================] - 0s 187us/step - loss: 5.5959 - accuracy: 0.5898\n",
      "Epoch 2/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 1.3267 - accuracy: 0.5872\n",
      "Epoch 3/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 1.0256 - accuracy: 0.6198\n",
      "Epoch 4/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.9482 - accuracy: 0.6367\n",
      "Epoch 5/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.8585 - accuracy: 0.6146\n",
      "Epoch 6/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.8077 - accuracy: 0.6406\n",
      "Epoch 7/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.7945 - accuracy: 0.6289\n",
      "Epoch 8/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.7512 - accuracy: 0.6497\n",
      "Epoch 9/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.7215 - accuracy: 0.6393\n",
      "Epoch 10/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.6936 - accuracy: 0.6549\n",
      "Epoch 11/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.7000 - accuracy: 0.6419\n",
      "Epoch 12/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.6882 - accuracy: 0.6341\n",
      "Epoch 13/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.6743 - accuracy: 0.6758\n",
      "Epoch 14/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.6596 - accuracy: 0.6693\n",
      "Epoch 15/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.6368 - accuracy: 0.6654\n",
      "Epoch 16/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.6342 - accuracy: 0.6836\n",
      "Epoch 17/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.6157 - accuracy: 0.6888\n",
      "Epoch 18/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.6316 - accuracy: 0.6836\n",
      "Epoch 19/200\n",
      "768/768 [==============================] - 0s 76us/step - loss: 0.6151 - accuracy: 0.6849\n",
      "Epoch 20/200\n",
      "768/768 [==============================] - 0s 76us/step - loss: 0.6199 - accuracy: 0.6888\n",
      "Epoch 21/200\n",
      "768/768 [==============================] - 0s 78us/step - loss: 0.6083 - accuracy: 0.6849\n",
      "Epoch 22/200\n",
      "768/768 [==============================] - 0s 76us/step - loss: 0.5943 - accuracy: 0.7031\n",
      "Epoch 23/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.6055 - accuracy: 0.6797\n",
      "Epoch 24/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.6415 - accuracy: 0.6706\n",
      "Epoch 25/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5899 - accuracy: 0.7161\n",
      "Epoch 26/200\n",
      "768/768 [==============================] - 0s 76us/step - loss: 0.5884 - accuracy: 0.6914\n",
      "Epoch 27/200\n",
      "768/768 [==============================] - 0s 76us/step - loss: 0.5896 - accuracy: 0.6966\n",
      "Epoch 28/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.5808 - accuracy: 0.7031\n",
      "Epoch 29/200\n",
      "768/768 [==============================] - 0s 76us/step - loss: 0.5967 - accuracy: 0.6927\n",
      "Epoch 30/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5855 - accuracy: 0.6862\n",
      "Epoch 31/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5826 - accuracy: 0.6992\n",
      "Epoch 32/200\n",
      "768/768 [==============================] - 0s 78us/step - loss: 0.5824 - accuracy: 0.6888\n",
      "Epoch 33/200\n",
      "768/768 [==============================] - 0s 84us/step - loss: 0.6140 - accuracy: 0.6875\n",
      "Epoch 34/200\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.5751 - accuracy: 0.7031\n",
      "Epoch 35/200\n",
      "768/768 [==============================] - 0s 77us/step - loss: 0.5693 - accuracy: 0.7122\n",
      "Epoch 36/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.5971 - accuracy: 0.7070\n",
      "Epoch 37/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5792 - accuracy: 0.7083\n",
      "Epoch 38/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.5832 - accuracy: 0.7201\n",
      "Epoch 39/200\n",
      "768/768 [==============================] - 0s 78us/step - loss: 0.5670 - accuracy: 0.7214\n",
      "Epoch 40/200\n",
      "768/768 [==============================] - 0s 81us/step - loss: 0.5740 - accuracy: 0.7044\n",
      "Epoch 41/200\n",
      "768/768 [==============================] - 0s 79us/step - loss: 0.6552 - accuracy: 0.6706\n",
      "Epoch 42/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.5678 - accuracy: 0.7161\n",
      "Epoch 43/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5685 - accuracy: 0.7292\n",
      "Epoch 44/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.5680 - accuracy: 0.6966\n",
      "Epoch 45/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5805 - accuracy: 0.7057\n",
      "Epoch 46/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5720 - accuracy: 0.7031\n",
      "Epoch 47/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5869 - accuracy: 0.6810\n",
      "Epoch 48/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5734 - accuracy: 0.7253\n",
      "Epoch 49/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5681 - accuracy: 0.7240\n",
      "Epoch 50/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.5777 - accuracy: 0.7109\n",
      "Epoch 51/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5772 - accuracy: 0.7083\n",
      "Epoch 52/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.5636 - accuracy: 0.7096\n",
      "Epoch 53/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5599 - accuracy: 0.7396\n",
      "Epoch 54/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5835 - accuracy: 0.6914\n",
      "Epoch 55/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5626 - accuracy: 0.7227\n",
      "Epoch 56/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.5567 - accuracy: 0.7240\n",
      "Epoch 57/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5679 - accuracy: 0.7109\n",
      "Epoch 58/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.5649 - accuracy: 0.7292\n",
      "Epoch 59/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5605 - accuracy: 0.7109\n",
      "Epoch 60/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5572 - accuracy: 0.7214\n",
      "Epoch 61/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5649 - accuracy: 0.7188\n",
      "Epoch 62/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5694 - accuracy: 0.7070\n",
      "Epoch 63/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5570 - accuracy: 0.7148\n",
      "Epoch 64/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5530 - accuracy: 0.7214\n",
      "Epoch 65/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5503 - accuracy: 0.7214\n",
      "Epoch 66/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5534 - accuracy: 0.7344\n",
      "Epoch 67/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5442 - accuracy: 0.7279\n",
      "Epoch 68/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5741 - accuracy: 0.7122\n",
      "Epoch 69/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5842 - accuracy: 0.7044\n",
      "Epoch 70/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5579 - accuracy: 0.7227\n",
      "Epoch 71/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5498 - accuracy: 0.7174\n",
      "Epoch 72/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5513 - accuracy: 0.7096\n",
      "Epoch 73/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5447 - accuracy: 0.7370\n",
      "Epoch 74/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5524 - accuracy: 0.7214\n",
      "Epoch 75/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5496 - accuracy: 0.7161\n",
      "Epoch 76/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5625 - accuracy: 0.7214\n",
      "Epoch 77/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5487 - accuracy: 0.7227\n",
      "Epoch 78/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5477 - accuracy: 0.7266\n",
      "Epoch 79/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5640 - accuracy: 0.7253\n",
      "Epoch 80/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5797 - accuracy: 0.7031\n",
      "Epoch 81/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.5433 - accuracy: 0.7383\n",
      "Epoch 82/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5380 - accuracy: 0.7357\n",
      "Epoch 83/200\n",
      "768/768 [==============================] - 0s 68us/step - loss: 0.5613 - accuracy: 0.7188\n",
      "Epoch 84/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5504 - accuracy: 0.7096\n",
      "Epoch 85/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5324 - accuracy: 0.7409\n",
      "Epoch 86/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5468 - accuracy: 0.7266\n",
      "Epoch 87/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5382 - accuracy: 0.7409\n",
      "Epoch 88/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5313 - accuracy: 0.7201\n",
      "Epoch 89/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5352 - accuracy: 0.7292\n",
      "Epoch 90/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5583 - accuracy: 0.7161\n",
      "Epoch 91/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5365 - accuracy: 0.7174\n",
      "Epoch 92/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5598 - accuracy: 0.7070\n",
      "Epoch 93/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5425 - accuracy: 0.7161\n",
      "Epoch 94/200\n",
      "768/768 [==============================] - 0s 68us/step - loss: 0.5363 - accuracy: 0.7318\n",
      "Epoch 95/200\n",
      "768/768 [==============================] - 0s 68us/step - loss: 0.5320 - accuracy: 0.7474\n",
      "Epoch 96/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5349 - accuracy: 0.7240\n",
      "Epoch 97/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5261 - accuracy: 0.7318\n",
      "Epoch 98/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5335 - accuracy: 0.7292\n",
      "Epoch 99/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5520 - accuracy: 0.7122\n",
      "Epoch 100/200\n",
      "768/768 [==============================] - 0s 76us/step - loss: 0.5273 - accuracy: 0.7396\n",
      "Epoch 101/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.5243 - accuracy: 0.7253\n",
      "Epoch 102/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.5306 - accuracy: 0.7292\n",
      "Epoch 103/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.5218 - accuracy: 0.7448\n",
      "Epoch 104/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5249 - accuracy: 0.7370\n",
      "Epoch 105/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5368 - accuracy: 0.7331\n",
      "Epoch 106/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5233 - accuracy: 0.7357\n",
      "Epoch 107/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5529 - accuracy: 0.7344\n",
      "Epoch 108/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5206 - accuracy: 0.7344\n",
      "Epoch 109/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.5255 - accuracy: 0.7331\n",
      "Epoch 110/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.5201 - accuracy: 0.7422\n",
      "Epoch 111/200\n",
      "768/768 [==============================] - 0s 77us/step - loss: 0.5252 - accuracy: 0.7539\n",
      "Epoch 112/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.5226 - accuracy: 0.7383\n",
      "Epoch 113/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5276 - accuracy: 0.7240\n",
      "Epoch 114/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5231 - accuracy: 0.7435\n",
      "Epoch 115/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5200 - accuracy: 0.7357\n",
      "Epoch 116/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5318 - accuracy: 0.7214\n",
      "Epoch 117/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5194 - accuracy: 0.7370\n",
      "Epoch 118/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5131 - accuracy: 0.7500\n",
      "Epoch 119/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5066 - accuracy: 0.7448\n",
      "Epoch 120/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5232 - accuracy: 0.7448\n",
      "Epoch 121/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5316 - accuracy: 0.7331\n",
      "Epoch 122/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5316 - accuracy: 0.7409\n",
      "Epoch 123/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5164 - accuracy: 0.7474\n",
      "Epoch 124/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5145 - accuracy: 0.7539\n",
      "Epoch 125/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5049 - accuracy: 0.7474\n",
      "Epoch 126/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5161 - accuracy: 0.7409\n",
      "Epoch 127/200\n",
      "768/768 [==============================] - 0s 68us/step - loss: 0.5296 - accuracy: 0.7396\n",
      "Epoch 128/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5189 - accuracy: 0.7357\n",
      "Epoch 129/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5182 - accuracy: 0.7435\n",
      "Epoch 130/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5193 - accuracy: 0.7409\n",
      "Epoch 131/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5126 - accuracy: 0.7396\n",
      "Epoch 132/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5100 - accuracy: 0.7526\n",
      "Epoch 133/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5132 - accuracy: 0.7435\n",
      "Epoch 134/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5208 - accuracy: 0.7422\n",
      "Epoch 135/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5208 - accuracy: 0.7279\n",
      "Epoch 136/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5200 - accuracy: 0.7266\n",
      "Epoch 137/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5063 - accuracy: 0.7292\n",
      "Epoch 138/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5044 - accuracy: 0.7513\n",
      "Epoch 139/200\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.5292 - accuracy: 0.7331\n",
      "Epoch 140/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5002 - accuracy: 0.7396\n",
      "Epoch 141/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5016 - accuracy: 0.7552\n",
      "Epoch 142/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5054 - accuracy: 0.7591\n",
      "Epoch 143/200\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.5008 - accuracy: 0.7591\n",
      "Epoch 144/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5339 - accuracy: 0.7266\n",
      "Epoch 145/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4937 - accuracy: 0.7591\n",
      "Epoch 146/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.4967 - accuracy: 0.7448\n",
      "Epoch 147/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5025 - accuracy: 0.7487\n",
      "Epoch 148/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5094 - accuracy: 0.7331\n",
      "Epoch 149/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5066 - accuracy: 0.7552\n",
      "Epoch 150/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4987 - accuracy: 0.7526\n",
      "Epoch 151/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.5060 - accuracy: 0.7526\n",
      "Epoch 152/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.4969 - accuracy: 0.7526\n",
      "Epoch 153/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4942 - accuracy: 0.7513\n",
      "Epoch 154/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.4966 - accuracy: 0.7604\n",
      "Epoch 155/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5011 - accuracy: 0.7526\n",
      "Epoch 156/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4894 - accuracy: 0.7539\n",
      "Epoch 157/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4928 - accuracy: 0.7604\n",
      "Epoch 158/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.4914 - accuracy: 0.7526\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 72us/step - loss: 0.4966 - accuracy: 0.7513\n",
      "Epoch 160/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.4885 - accuracy: 0.7708\n",
      "Epoch 161/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4908 - accuracy: 0.7565\n",
      "Epoch 162/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.4859 - accuracy: 0.7474\n",
      "Epoch 163/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4968 - accuracy: 0.7539\n",
      "Epoch 164/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5055 - accuracy: 0.7474\n",
      "Epoch 165/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5118 - accuracy: 0.7552\n",
      "Epoch 166/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4820 - accuracy: 0.7630\n",
      "Epoch 167/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4970 - accuracy: 0.7591\n",
      "Epoch 168/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5025 - accuracy: 0.7578\n",
      "Epoch 169/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.5055 - accuracy: 0.7604\n",
      "Epoch 170/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5143 - accuracy: 0.7539\n",
      "Epoch 171/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4958 - accuracy: 0.7682\n",
      "Epoch 172/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4908 - accuracy: 0.7539\n",
      "Epoch 173/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4994 - accuracy: 0.7708\n",
      "Epoch 174/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4984 - accuracy: 0.7591\n",
      "Epoch 175/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4976 - accuracy: 0.7565\n",
      "Epoch 176/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4919 - accuracy: 0.7591\n",
      "Epoch 177/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4822 - accuracy: 0.7617\n",
      "Epoch 178/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4803 - accuracy: 0.7708\n",
      "Epoch 179/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4956 - accuracy: 0.7565\n",
      "Epoch 180/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4835 - accuracy: 0.7578\n",
      "Epoch 181/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4864 - accuracy: 0.7552\n",
      "Epoch 182/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4956 - accuracy: 0.7578\n",
      "Epoch 183/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.5041 - accuracy: 0.7513\n",
      "Epoch 184/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4941 - accuracy: 0.7669\n",
      "Epoch 185/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4875 - accuracy: 0.7448\n",
      "Epoch 186/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5013 - accuracy: 0.7370\n",
      "Epoch 187/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4799 - accuracy: 0.7656\n",
      "Epoch 188/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.4858 - accuracy: 0.7721\n",
      "Epoch 189/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4757 - accuracy: 0.7734\n",
      "Epoch 190/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.5094 - accuracy: 0.7448\n",
      "Epoch 191/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.4833 - accuracy: 0.7617\n",
      "Epoch 192/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4754 - accuracy: 0.7695\n",
      "Epoch 193/200\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.4799 - accuracy: 0.7734\n",
      "Epoch 194/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4956 - accuracy: 0.7591\n",
      "Epoch 195/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4849 - accuracy: 0.7721\n",
      "Epoch 196/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4901 - accuracy: 0.7617\n",
      "Epoch 197/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4778 - accuracy: 0.7591\n",
      "Epoch 198/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4913 - accuracy: 0.7617\n",
      "Epoch 199/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4846 - accuracy: 0.7643\n",
      "Epoch 200/200\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4814 - accuracy: 0.7656\n",
      "768/768 [==============================] - 0s 28us/step\n",
      "\n",
      " Accuracy : 0.7539\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#히든레이어 2개\n",
    "model.add(Dense(12, input_dim = 8, activation = 'relu'))  #입력 뉴런 8개, 출력 뉴런 12개   #히든레이어\n",
    "model.add(Dense(8, activation = 'relu'))                  #입력 뉴런 12개, 출력 뉴런 8개   #히든레이어\n",
    "model.add(Dense(1, activation = 'sigmoid'))               #입력 뉴런 8개, 출력 뉴런 1개\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',   #손실함수 : 이진분류 (최소 제곱법 사용할 경우, 로컬 미니엄을 찾을 위험이 있음)\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs = 200, batch_size = 10)   #batch_size : 10개씩 결과를 보고 가중치를 갱신 (숫자 작으면 시간 오래걸림)\n",
    "                                                 #10개(batch_size)씩 200번(epochs) 훈련\n",
    "\n",
    "print(\"\\n Accuracy : %.4f\" % (model.evaluate(X, Y)[1]))\n",
    "\n",
    "# 모두 음성인 경우가 65% 정도 이므로 정확도가 65% 보다 낮게 나오면 모두 음성으로 판단하는 것보다 낮은 확률인 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "768/768 [==============================] - 0s 292us/step - loss: 1.1839 - accuracy: 0.5898\n",
      "Epoch 2/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.7276 - accuracy: 0.6289\n",
      "Epoch 3/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.6480 - accuracy: 0.6380\n",
      "Epoch 4/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.6497 - accuracy: 0.6445\n",
      "Epoch 5/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.6437 - accuracy: 0.6419\n",
      "Epoch 6/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.6265 - accuracy: 0.6667\n",
      "Epoch 7/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.6131 - accuracy: 0.6693\n",
      "Epoch 8/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.6107 - accuracy: 0.6823\n",
      "Epoch 9/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5988 - accuracy: 0.6628\n",
      "Epoch 10/200\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.6093 - accuracy: 0.6888\n",
      "Epoch 11/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.6318 - accuracy: 0.6589\n",
      "Epoch 12/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.6198 - accuracy: 0.6771\n",
      "Epoch 13/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.6259 - accuracy: 0.6654\n",
      "Epoch 14/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5886 - accuracy: 0.6992\n",
      "Epoch 15/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5928 - accuracy: 0.7057\n",
      "Epoch 16/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5841 - accuracy: 0.6953\n",
      "Epoch 17/200\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5693 - accuracy: 0.7070\n",
      "Epoch 18/200\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5986 - accuracy: 0.6654\n",
      "Epoch 19/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5793 - accuracy: 0.6966\n",
      "Epoch 20/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5780 - accuracy: 0.6953\n",
      "Epoch 21/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5598 - accuracy: 0.7201\n",
      "Epoch 22/200\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.5538 - accuracy: 0.7240\n",
      "Epoch 23/200\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5636 - accuracy: 0.7122\n",
      "Epoch 24/200\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.5560 - accuracy: 0.7188\n",
      "Epoch 25/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5456 - accuracy: 0.7135\n",
      "Epoch 26/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5343 - accuracy: 0.7253\n",
      "Epoch 27/200\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5435 - accuracy: 0.7214\n",
      "Epoch 28/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5380 - accuracy: 0.7435\n",
      "Epoch 29/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5291 - accuracy: 0.7370\n",
      "Epoch 30/200\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5246 - accuracy: 0.7292\n",
      "Epoch 31/200\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.5620 - accuracy: 0.7070\n",
      "Epoch 32/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5280 - accuracy: 0.7279\n",
      "Epoch 33/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5463 - accuracy: 0.7331\n",
      "Epoch 34/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5235 - accuracy: 0.7370\n",
      "Epoch 35/200\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5093 - accuracy: 0.7656\n",
      "Epoch 36/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5122 - accuracy: 0.7578\n",
      "Epoch 37/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5244 - accuracy: 0.7266\n",
      "Epoch 38/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5177 - accuracy: 0.7474\n",
      "Epoch 39/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5135 - accuracy: 0.7331\n",
      "Epoch 40/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5182 - accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5010 - accuracy: 0.7344\n",
      "Epoch 42/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4867 - accuracy: 0.7578\n",
      "Epoch 43/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4919 - accuracy: 0.7617\n",
      "Epoch 44/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5013 - accuracy: 0.7396\n",
      "Epoch 45/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5042 - accuracy: 0.7513\n",
      "Epoch 46/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4995 - accuracy: 0.7565\n",
      "Epoch 47/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5265 - accuracy: 0.7448\n",
      "Epoch 48/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5023 - accuracy: 0.7513\n",
      "Epoch 49/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4997 - accuracy: 0.7656\n",
      "Epoch 50/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4862 - accuracy: 0.7552\n",
      "Epoch 51/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4924 - accuracy: 0.7526\n",
      "Epoch 52/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4916 - accuracy: 0.7643\n",
      "Epoch 53/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4954 - accuracy: 0.7656\n",
      "Epoch 54/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4899 - accuracy: 0.7461\n",
      "Epoch 55/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4696 - accuracy: 0.7760\n",
      "Epoch 56/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5108 - accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4864 - accuracy: 0.7721\n",
      "Epoch 58/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4820 - accuracy: 0.7539\n",
      "Epoch 59/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4801 - accuracy: 0.7708\n",
      "Epoch 60/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4895 - accuracy: 0.7539\n",
      "Epoch 61/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4726 - accuracy: 0.7721\n",
      "Epoch 62/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4850 - accuracy: 0.7565\n",
      "Epoch 63/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4667 - accuracy: 0.7708\n",
      "Epoch 64/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4712 - accuracy: 0.7656\n",
      "Epoch 65/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4654 - accuracy: 0.7630\n",
      "Epoch 66/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4704 - accuracy: 0.7669\n",
      "Epoch 67/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4719 - accuracy: 0.7591\n",
      "Epoch 68/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4820 - accuracy: 0.7565\n",
      "Epoch 69/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4692 - accuracy: 0.7708\n",
      "Epoch 70/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4711 - accuracy: 0.7682\n",
      "Epoch 71/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4597 - accuracy: 0.7786\n",
      "Epoch 72/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4771 - accuracy: 0.7539\n",
      "Epoch 73/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4592 - accuracy: 0.7721\n",
      "Epoch 74/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4544 - accuracy: 0.7708\n",
      "Epoch 75/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4451 - accuracy: 0.7956\n",
      "Epoch 76/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4577 - accuracy: 0.7604\n",
      "Epoch 77/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4677 - accuracy: 0.7669\n",
      "Epoch 78/200\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4727 - accuracy: 0.7708\n",
      "Epoch 79/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4537 - accuracy: 0.7786\n",
      "Epoch 80/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4604 - accuracy: 0.7695\n",
      "Epoch 81/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4457 - accuracy: 0.7747\n",
      "Epoch 82/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4501 - accuracy: 0.7708\n",
      "Epoch 83/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4423 - accuracy: 0.7839\n",
      "Epoch 84/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4612 - accuracy: 0.7617\n",
      "Epoch 85/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4579 - accuracy: 0.7812\n",
      "Epoch 86/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4428 - accuracy: 0.7839\n",
      "Epoch 87/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4532 - accuracy: 0.7773\n",
      "Epoch 88/200\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4471 - accuracy: 0.7799\n",
      "Epoch 89/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4274 - accuracy: 0.7956\n",
      "Epoch 90/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4573 - accuracy: 0.7786\n",
      "Epoch 91/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4394 - accuracy: 0.7878\n",
      "Epoch 92/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4249 - accuracy: 0.8086\n",
      "Epoch 93/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4344 - accuracy: 0.7773\n",
      "Epoch 94/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4221 - accuracy: 0.8021\n",
      "Epoch 95/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4680 - accuracy: 0.7721\n",
      "Epoch 96/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4269 - accuracy: 0.7943\n",
      "Epoch 97/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4447 - accuracy: 0.7852\n",
      "Epoch 98/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4300 - accuracy: 0.7904\n",
      "Epoch 99/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4280 - accuracy: 0.7969\n",
      "Epoch 100/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4187 - accuracy: 0.7930\n",
      "Epoch 101/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4089 - accuracy: 0.8060\n",
      "Epoch 102/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4227 - accuracy: 0.7956\n",
      "Epoch 103/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4307 - accuracy: 0.7917\n",
      "Epoch 104/200\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4306 - accuracy: 0.7891\n",
      "Epoch 105/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4198 - accuracy: 0.7956\n",
      "Epoch 106/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4108 - accuracy: 0.8151\n",
      "Epoch 107/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4036 - accuracy: 0.8099\n",
      "Epoch 108/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4137 - accuracy: 0.8203\n",
      "Epoch 109/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4086 - accuracy: 0.8099\n",
      "Epoch 110/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4244 - accuracy: 0.8060\n",
      "Epoch 111/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4137 - accuracy: 0.8060\n",
      "Epoch 112/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4160 - accuracy: 0.7995\n",
      "Epoch 113/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4056 - accuracy: 0.8008\n",
      "Epoch 114/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4069 - accuracy: 0.8190\n",
      "Epoch 115/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4397 - accuracy: 0.8008\n",
      "Epoch 116/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4107 - accuracy: 0.8073\n",
      "Epoch 117/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4024 - accuracy: 0.8112\n",
      "Epoch 118/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4111 - accuracy: 0.7956\n",
      "Epoch 119/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4074 - accuracy: 0.7995\n",
      "Epoch 120/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3963 - accuracy: 0.8138\n",
      "Epoch 121/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3812 - accuracy: 0.8281\n",
      "Epoch 122/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.3827 - accuracy: 0.8242\n",
      "Epoch 123/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3925 - accuracy: 0.8151\n",
      "Epoch 124/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3751 - accuracy: 0.8216\n",
      "Epoch 125/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3890 - accuracy: 0.8177\n",
      "Epoch 126/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4153 - accuracy: 0.7969\n",
      "Epoch 127/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3860 - accuracy: 0.8164\n",
      "Epoch 128/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.3983 - accuracy: 0.8125\n",
      "Epoch 129/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.3817 - accuracy: 0.8255\n",
      "Epoch 130/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.3877 - accuracy: 0.8242\n",
      "Epoch 131/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4013 - accuracy: 0.8125\n",
      "Epoch 132/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.3667 - accuracy: 0.8229\n",
      "Epoch 133/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3699 - accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.3776 - accuracy: 0.8190\n",
      "Epoch 135/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3674 - accuracy: 0.8385\n",
      "Epoch 136/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.3912 - accuracy: 0.8151\n",
      "Epoch 137/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.3735 - accuracy: 0.8229\n",
      "Epoch 138/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.3674 - accuracy: 0.8372\n",
      "Epoch 139/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.3724 - accuracy: 0.8216\n",
      "Epoch 140/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.3536 - accuracy: 0.8438\n",
      "Epoch 141/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3709 - accuracy: 0.8307\n",
      "Epoch 142/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.3627 - accuracy: 0.8255\n",
      "Epoch 143/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.3361 - accuracy: 0.8568\n",
      "Epoch 144/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3531 - accuracy: 0.8359\n",
      "Epoch 145/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3602 - accuracy: 0.8229\n",
      "Epoch 146/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.3972 - accuracy: 0.8307\n",
      "Epoch 147/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.3568 - accuracy: 0.8385\n",
      "Epoch 148/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.3731 - accuracy: 0.8255\n",
      "Epoch 149/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.3443 - accuracy: 0.8555\n",
      "Epoch 150/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.3967 - accuracy: 0.8164\n",
      "Epoch 151/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.3463 - accuracy: 0.8464\n",
      "Epoch 152/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.3620 - accuracy: 0.8320\n",
      "Epoch 153/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.3695 - accuracy: 0.8307\n",
      "Epoch 154/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.3518 - accuracy: 0.8294\n",
      "Epoch 155/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.3497 - accuracy: 0.8503\n",
      "Epoch 156/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.3729 - accuracy: 0.8268\n",
      "Epoch 157/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.3328 - accuracy: 0.8359\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 104us/step - loss: 0.3470 - accuracy: 0.8229\n",
      "Epoch 159/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.3404 - accuracy: 0.8359\n",
      "Epoch 160/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.3619 - accuracy: 0.8281\n",
      "Epoch 161/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.3140 - accuracy: 0.8633\n",
      "Epoch 162/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.3813 - accuracy: 0.8177\n",
      "Epoch 163/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.3306 - accuracy: 0.8607\n",
      "Epoch 164/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.3163 - accuracy: 0.8581\n",
      "Epoch 165/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.3277 - accuracy: 0.8542\n",
      "Epoch 166/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.3167 - accuracy: 0.8516\n",
      "Epoch 167/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.3120 - accuracy: 0.8516\n",
      "Epoch 168/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.3207 - accuracy: 0.8542\n",
      "Epoch 169/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.3107 - accuracy: 0.8477\n",
      "Epoch 170/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.3327 - accuracy: 0.8477\n",
      "Epoch 171/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.3211 - accuracy: 0.8672\n",
      "Epoch 172/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.3056 - accuracy: 0.8776\n",
      "Epoch 173/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.3065 - accuracy: 0.8633\n",
      "Epoch 174/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.3471 - accuracy: 0.8359\n",
      "Epoch 175/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.3285 - accuracy: 0.8659\n",
      "Epoch 176/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.3103 - accuracy: 0.8672\n",
      "Epoch 177/200\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.2924 - accuracy: 0.8698\n",
      "Epoch 178/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.3512 - accuracy: 0.8490\n",
      "Epoch 179/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.3141 - accuracy: 0.8568\n",
      "Epoch 180/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.2969 - accuracy: 0.8750\n",
      "Epoch 181/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.3311 - accuracy: 0.8607\n",
      "Epoch 182/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.2917 - accuracy: 0.8750\n",
      "Epoch 183/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.2924 - accuracy: 0.8724\n",
      "Epoch 184/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.2919 - accuracy: 0.8711\n",
      "Epoch 185/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.2886 - accuracy: 0.8750\n",
      "Epoch 186/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.2954 - accuracy: 0.8802\n",
      "Epoch 187/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.2882 - accuracy: 0.8841\n",
      "Epoch 188/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.2774 - accuracy: 0.8763\n",
      "Epoch 189/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.3281 - accuracy: 0.8620\n",
      "Epoch 190/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.3446 - accuracy: 0.8438\n",
      "Epoch 191/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.3410 - accuracy: 0.8372\n",
      "Epoch 192/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.2859 - accuracy: 0.8789\n",
      "Epoch 193/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.2907 - accuracy: 0.8724\n",
      "Epoch 194/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.2655 - accuracy: 0.8841\n",
      "Epoch 195/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.2720 - accuracy: 0.8906\n",
      "Epoch 196/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.2793 - accuracy: 0.8815\n",
      "Epoch 197/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.2619 - accuracy: 0.8880\n",
      "Epoch 198/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.2724 - accuracy: 0.8737\n",
      "Epoch 199/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.2787 - accuracy: 0.8867\n",
      "Epoch 200/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.2694 - accuracy: 0.8815\n",
      "768/768 [==============================] - 0s 35us/step\n",
      "\n",
      " Accuracy : 0.8672\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#히든레이어 2개\n",
    "model.add(Dense(35, input_dim = 8, activation = 'relu'))  #입력 뉴런 8개, 출력 뉴런 12개   #히든레이어\n",
    "model.add(Dense(35, activation = 'relu'))                  #입력 뉴런 12개, 출력 뉴런 8개   #히든레이어\n",
    "model.add(Dense(35, activation = 'relu'))                  #입력 뉴런 12개, 출력 뉴런 8개   #히든레이어\n",
    "model.add(Dense(35, activation = 'relu'))                  #입력 뉴런 12개, 출력 뉴런 8개   #히든레이어\n",
    "model.add(Dense(35, activation = 'relu'))                  #입력 뉴런 12개, 출력 뉴런 8개   #히든레이어\n",
    "model.add(Dense(35, activation = 'relu'))                  #입력 뉴런 12개, 출력 뉴런 8개   #히든레이어\n",
    "model.add(Dense(1, activation = 'sigmoid'))               #입력 뉴런 8개, 출력 뉴런 1개\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',   #손실함수 : 이진분류 (최소 제곱법 사용할 경우, 로컬 미니엄을 찾을 위험이 있음)\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs = 200, batch_size = 10)   #batch_size : 10개씩 결과를 보고 가중치를 갱신 (숫자 작으면 시간 오래걸림)\n",
    "                                                 #10개(batch_size)씩 200번(epochs) 훈련\n",
    "\n",
    "print(\"\\n Accuracy : %.4f\" % (model.evaluate(X, Y)[1]))\n",
    "\n",
    "# 모두 음성인 경우가 65% 정도 이므로 정확도가 65% 보다 낮게 나오면 모두 음성으로 판단하는 것보다 낮은 확률인 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 아이리스 품종 데이터 ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\", names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n",
    "# 꽃받침 길이, 꽃받침 넓이, 꽃잎 길이, 꽃잎 넓이 (단위 : cm) , 품종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.10.1-py3-none-any.whl (215 kB)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from seaborn) (1.5.0)\n",
      "Requirement already satisfied: pandas>=0.22.0 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from seaborn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from seaborn) (1.19.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from seaborn) (3.3.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from pandas>=0.22.0->seaborn) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from pandas>=0.22.0->seaborn) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (7.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\new_env\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.22.0->seaborn) (1.15.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 823.25x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(df, hue = 'species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Iris-setosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c2506e7fc80e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mY_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# one-hot encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Iris-setosa'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"iris.csv\", names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n",
    "\n",
    "#sns.pairplot(df, hue = 'species')\n",
    "#plt.show()\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:, 0:4].astype(float)\n",
    "Y = dataset[:, 4].astype(float)\n",
    "\n",
    "Y_encoded = np_utils.to_categorical(Y)  # one-hot encoding\n",
    "#???????\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#히든레이어 2개\n",
    "model.add(Dense(16, input_dim = 8, activation = 'relu'))  #입력 뉴런 8개, 출력 뉴런 16개   #히든레이어\n",
    "model.add(Dense(3, activation = 'softmax'))                  #입력 뉴런 16개, 출력 뉴런 3개(품종이 3개)\n",
    "\n",
    "# 다중분류를 위해 softmax 사용 : 총합이 1인 형태로 변환 -> 큰 값이 두드러지게, 작은 값은 더 작아지게\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',   #손실함수 : 다중분류 (최소 제곱법 사용할 경우, 로컬 미니엄을 찾을 위험이 있음)\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X, Y_encoded, epochs = 50, batch_size = 1)  \n",
    "\n",
    "print(\"\\n Accuracy : %.4f\" % (model.evaluate(X, Y_encoded)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 과적합 피하기 ✨\n",
    "🐶 과적합 : 층이 너무 많거나 변수가 복잡해서 발생하기도 하고 테스트셋과 학습셋이 중복될 때 생기기도 함\n",
    "\n",
    "🦊 학습셋과 테스트셋의 비율을 나누자          \n",
    "🦊 학습셋(70), 테스트셋(30)\n",
    "        \n",
    "🐱 학습을 진행해도 테스트 결과가 더 이상 좋아지지 않는 지점에서 학습을 멈춰야 함.           \n",
    "🐱 이 때의 학습 정도가 가장 적절한 것으로 볼 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\46\\ef\\c3\\157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\\sklearn-0.0-py2.py3-none-any.whl\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.23.2-cp37-cp37m-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\user\\anaconda3\\envs\\new_env\\lib\\site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\user\\anaconda3\\envs\\new_env\\lib\\site-packages (from scikit-learn->sklearn) (1.19.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.16.0 scikit-learn-0.23.2 sklearn-0.0 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "145/145 [==============================] - 0s 574us/step - loss: 0.2550 - accuracy: 0.4690\n",
      "Epoch 2/130\n",
      "145/145 [==============================] - 0s 158us/step - loss: 0.2488 - accuracy: 0.5241\n",
      "Epoch 3/130\n",
      "145/145 [==============================] - 0s 172us/step - loss: 0.2452 - accuracy: 0.5793\n",
      "Epoch 4/130\n",
      "145/145 [==============================] - 0s 129us/step - loss: 0.2439 - accuracy: 0.6138\n",
      "Epoch 5/130\n",
      "145/145 [==============================] - 0s 157us/step - loss: 0.2392 - accuracy: 0.6414\n",
      "Epoch 6/130\n",
      "145/145 [==============================] - 0s 141us/step - loss: 0.2345 - accuracy: 0.7103\n",
      "Epoch 7/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.2294 - accuracy: 0.6897\n",
      "Epoch 8/130\n",
      "145/145 [==============================] - 0s 157us/step - loss: 0.2226 - accuracy: 0.7586\n",
      "Epoch 9/130\n",
      "145/145 [==============================] - 0s 150us/step - loss: 0.2158 - accuracy: 0.7448\n",
      "Epoch 10/130\n",
      "145/145 [==============================] - 0s 141us/step - loss: 0.2087 - accuracy: 0.7517\n",
      "Epoch 11/130\n",
      "145/145 [==============================] - 0s 151us/step - loss: 0.2001 - accuracy: 0.7448\n",
      "Epoch 12/130\n",
      "145/145 [==============================] - 0s 151us/step - loss: 0.1909 - accuracy: 0.7793\n",
      "Epoch 13/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.1815 - accuracy: 0.7724\n",
      "Epoch 14/130\n",
      "145/145 [==============================] - 0s 150us/step - loss: 0.1714 - accuracy: 0.7724\n",
      "Epoch 15/130\n",
      "145/145 [==============================] - 0s 146us/step - loss: 0.1644 - accuracy: 0.7586\n",
      "Epoch 16/130\n",
      "145/145 [==============================] - 0s 144us/step - loss: 0.1569 - accuracy: 0.8207\n",
      "Epoch 17/130\n",
      "145/145 [==============================] - 0s 157us/step - loss: 0.1485 - accuracy: 0.8069\n",
      "Epoch 18/130\n",
      "145/145 [==============================] - 0s 160us/step - loss: 0.1489 - accuracy: 0.8069\n",
      "Epoch 19/130\n",
      "145/145 [==============================] - 0s 151us/step - loss: 0.1390 - accuracy: 0.8276\n",
      "Epoch 20/130\n",
      "145/145 [==============================] - 0s 151us/step - loss: 0.1335 - accuracy: 0.8414\n",
      "Epoch 21/130\n",
      "145/145 [==============================] - 0s 131us/step - loss: 0.1338 - accuracy: 0.8207\n",
      "Epoch 22/130\n",
      "145/145 [==============================] - 0s 151us/step - loss: 0.1282 - accuracy: 0.8483\n",
      "Epoch 23/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.1272 - accuracy: 0.8483\n",
      "Epoch 24/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.1340 - accuracy: 0.7931\n",
      "Epoch 25/130\n",
      "145/145 [==============================] - 0s 158us/step - loss: 0.1233 - accuracy: 0.8276\n",
      "Epoch 26/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.1151 - accuracy: 0.8690\n",
      "Epoch 27/130\n",
      "145/145 [==============================] - 0s 150us/step - loss: 0.1111 - accuracy: 0.8621\n",
      "Epoch 28/130\n",
      "145/145 [==============================] - 0s 158us/step - loss: 0.1080 - accuracy: 0.8828\n",
      "Epoch 29/130\n",
      "145/145 [==============================] - 0s 151us/step - loss: 0.1082 - accuracy: 0.8552\n",
      "Epoch 30/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.1038 - accuracy: 0.8759\n",
      "Epoch 31/130\n",
      "145/145 [==============================] - 0s 158us/step - loss: 0.1020 - accuracy: 0.8759\n",
      "Epoch 32/130\n",
      "145/145 [==============================] - 0s 151us/step - loss: 0.1018 - accuracy: 0.8759\n",
      "Epoch 33/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0987 - accuracy: 0.8690\n",
      "Epoch 34/130\n",
      "145/145 [==============================] - 0s 158us/step - loss: 0.0991 - accuracy: 0.8621\n",
      "Epoch 35/130\n",
      "145/145 [==============================] - 0s 151us/step - loss: 0.0955 - accuracy: 0.8690\n",
      "Epoch 36/130\n",
      "145/145 [==============================] - 0s 151us/step - loss: 0.0938 - accuracy: 0.8759\n",
      "Epoch 37/130\n",
      "145/145 [==============================] - 0s 144us/step - loss: 0.0914 - accuracy: 0.8828\n",
      "Epoch 38/130\n",
      "145/145 [==============================] - 0s 124us/step - loss: 0.0887 - accuracy: 0.8966\n",
      "Epoch 39/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0887 - accuracy: 0.8828\n",
      "Epoch 40/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0863 - accuracy: 0.9034\n",
      "Epoch 41/130\n",
      "145/145 [==============================] - 0s 124us/step - loss: 0.0833 - accuracy: 0.9034\n",
      "Epoch 42/130\n",
      "145/145 [==============================] - 0s 117us/step - loss: 0.0815 - accuracy: 0.8828\n",
      "Epoch 43/130\n",
      "145/145 [==============================] - 0s 117us/step - loss: 0.0840 - accuracy: 0.8966\n",
      "Epoch 44/130\n",
      "145/145 [==============================] - 0s 122us/step - loss: 0.0793 - accuracy: 0.9034\n",
      "Epoch 45/130\n",
      "145/145 [==============================] - 0s 124us/step - loss: 0.0747 - accuracy: 0.9103\n",
      "Epoch 46/130\n",
      "145/145 [==============================] - 0s 124us/step - loss: 0.0731 - accuracy: 0.9034\n",
      "Epoch 47/130\n",
      "145/145 [==============================] - 0s 123us/step - loss: 0.0720 - accuracy: 0.9034\n",
      "Epoch 48/130\n",
      "145/145 [==============================] - 0s 117us/step - loss: 0.0730 - accuracy: 0.8966\n",
      "Epoch 49/130\n",
      "145/145 [==============================] - 0s 131us/step - loss: 0.0674 - accuracy: 0.9241\n",
      "Epoch 50/130\n",
      "145/145 [==============================] - 0s 118us/step - loss: 0.0694 - accuracy: 0.9103\n",
      "Epoch 51/130\n",
      "145/145 [==============================] - 0s 117us/step - loss: 0.0670 - accuracy: 0.9172\n",
      "Epoch 52/130\n",
      "145/145 [==============================] - 0s 134us/step - loss: 0.0649 - accuracy: 0.9241\n",
      "Epoch 53/130\n",
      "145/145 [==============================] - 0s 131us/step - loss: 0.0659 - accuracy: 0.9241\n",
      "Epoch 54/130\n",
      "145/145 [==============================] - 0s 124us/step - loss: 0.0693 - accuracy: 0.9103\n",
      "Epoch 55/130\n",
      "145/145 [==============================] - 0s 131us/step - loss: 0.0642 - accuracy: 0.9103\n",
      "Epoch 56/130\n",
      "145/145 [==============================] - 0s 139us/step - loss: 0.0599 - accuracy: 0.9379\n",
      "Epoch 57/130\n",
      "145/145 [==============================] - 0s 129us/step - loss: 0.0580 - accuracy: 0.9241\n",
      "Epoch 58/130\n",
      "145/145 [==============================] - 0s 134us/step - loss: 0.0573 - accuracy: 0.9448\n",
      "Epoch 59/130\n",
      "145/145 [==============================] - 0s 129us/step - loss: 0.0568 - accuracy: 0.9379\n",
      "Epoch 60/130\n",
      "145/145 [==============================] - 0s 132us/step - loss: 0.0572 - accuracy: 0.9379\n",
      "Epoch 61/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0555 - accuracy: 0.9379\n",
      "Epoch 62/130\n",
      "145/145 [==============================] - 0s 142us/step - loss: 0.0519 - accuracy: 0.9517\n",
      "Epoch 63/130\n",
      "145/145 [==============================] - 0s 137us/step - loss: 0.0499 - accuracy: 0.9724\n",
      "Epoch 64/130\n",
      "145/145 [==============================] - 0s 143us/step - loss: 0.0488 - accuracy: 0.9517\n",
      "Epoch 65/130\n",
      "145/145 [==============================] - 0s 132us/step - loss: 0.0466 - accuracy: 0.9517\n",
      "Epoch 66/130\n",
      "145/145 [==============================] - 0s 137us/step - loss: 0.0577 - accuracy: 0.9448\n",
      "Epoch 67/130\n",
      "145/145 [==============================] - 0s 135us/step - loss: 0.0450 - accuracy: 0.9655\n",
      "Epoch 68/130\n",
      "145/145 [==============================] - 0s 135us/step - loss: 0.0491 - accuracy: 0.9586\n",
      "Epoch 69/130\n",
      "145/145 [==============================] - 0s 139us/step - loss: 0.0464 - accuracy: 0.9655\n",
      "Epoch 70/130\n",
      "145/145 [==============================] - 0s 142us/step - loss: 0.0486 - accuracy: 0.9379\n",
      "Epoch 71/130\n",
      "145/145 [==============================] - 0s 142us/step - loss: 0.0497 - accuracy: 0.9379\n",
      "Epoch 72/130\n",
      "145/145 [==============================] - 0s 130us/step - loss: 0.0422 - accuracy: 0.9586\n",
      "Epoch 73/130\n",
      "145/145 [==============================] - 0s 132us/step - loss: 0.0412 - accuracy: 0.9517\n",
      "Epoch 74/130\n",
      "145/145 [==============================] - 0s 130us/step - loss: 0.0402 - accuracy: 0.9586\n",
      "Epoch 75/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0384 - accuracy: 0.9655\n",
      "Epoch 76/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0372 - accuracy: 0.9724\n",
      "Epoch 77/130\n",
      "145/145 [==============================] - 0s 139us/step - loss: 0.0413 - accuracy: 0.9586\n",
      "Epoch 78/130\n",
      "145/145 [==============================] - 0s 130us/step - loss: 0.0367 - accuracy: 0.9724\n",
      "Epoch 79/130\n",
      "145/145 [==============================] - 0s 148us/step - loss: 0.0336 - accuracy: 0.9793\n",
      "Epoch 80/130\n",
      "145/145 [==============================] - 0s 141us/step - loss: 0.0360 - accuracy: 0.9793\n",
      "Epoch 81/130\n",
      "145/145 [==============================] - 0s 135us/step - loss: 0.0335 - accuracy: 0.9724\n",
      "Epoch 82/130\n",
      "145/145 [==============================] - 0s 145us/step - loss: 0.0317 - accuracy: 0.9862\n",
      "Epoch 83/130\n",
      "145/145 [==============================] - 0s 141us/step - loss: 0.0300 - accuracy: 0.9793\n",
      "Epoch 84/130\n",
      "145/145 [==============================] - 0s 139us/step - loss: 0.0303 - accuracy: 0.9862\n",
      "Epoch 85/130\n",
      "145/145 [==============================] - 0s 131us/step - loss: 0.0295 - accuracy: 0.9862\n",
      "Epoch 86/130\n",
      "145/145 [==============================] - 0s 134us/step - loss: 0.0289 - accuracy: 0.9862\n",
      "Epoch 87/130\n",
      "145/145 [==============================] - 0s 139us/step - loss: 0.0286 - accuracy: 0.9862\n",
      "Epoch 88/130\n",
      "145/145 [==============================] - 0s 141us/step - loss: 0.0293 - accuracy: 0.9724\n",
      "Epoch 89/130\n",
      "145/145 [==============================] - 0s 139us/step - loss: 0.0360 - accuracy: 0.9655\n",
      "Epoch 90/130\n",
      "145/145 [==============================] - 0s 135us/step - loss: 0.0264 - accuracy: 0.9793\n",
      "Epoch 91/130\n",
      "145/145 [==============================] - 0s 134us/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 92/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0276 - accuracy: 0.9724\n",
      "Epoch 93/130\n",
      "145/145 [==============================] - 0s 137us/step - loss: 0.0271 - accuracy: 0.9862\n",
      "Epoch 94/130\n",
      "145/145 [==============================] - 0s 143us/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 95/130\n",
      "145/145 [==============================] - 0s 142us/step - loss: 0.0238 - accuracy: 0.9862\n",
      "Epoch 96/130\n",
      "145/145 [==============================] - 0s 145us/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 97/130\n",
      "145/145 [==============================] - 0s 140us/step - loss: 0.0203 - accuracy: 0.9931\n",
      "Epoch 98/130\n",
      "145/145 [==============================] - 0s 140us/step - loss: 0.0211 - accuracy: 0.9931\n",
      "Epoch 99/130\n",
      "145/145 [==============================] - 0s 135us/step - loss: 0.0223 - accuracy: 0.9862\n",
      "Epoch 100/130\n",
      "145/145 [==============================] - 0s 135us/step - loss: 0.0198 - accuracy: 0.9931\n",
      "Epoch 101/130\n",
      "145/145 [==============================] - 0s 137us/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 102/130\n",
      "145/145 [==============================] - 0s 139us/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 103/130\n",
      "145/145 [==============================] - 0s 137us/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 104/130\n",
      "145/145 [==============================] - 0s 133us/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 105/130\n",
      "145/145 [==============================] - 0s 142us/step - loss: 0.0168 - accuracy: 0.9931\n",
      "Epoch 106/130\n",
      "145/145 [==============================] - 0s 139us/step - loss: 0.0171 - accuracy: 0.9931\n",
      "Epoch 107/130\n",
      "145/145 [==============================] - 0s 144us/step - loss: 0.0155 - accuracy: 0.9931\n",
      "Epoch 108/130\n",
      "145/145 [==============================] - 0s 135us/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 109/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 110/130\n",
      "145/145 [==============================] - 0s 135us/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 111/130\n",
      "145/145 [==============================] - 0s 141us/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 112/130\n",
      "145/145 [==============================] - 0s 144us/step - loss: 0.0147 - accuracy: 0.9862\n",
      "Epoch 113/130\n",
      "145/145 [==============================] - 0s 136us/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 114/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 115/130\n",
      "145/145 [==============================] - 0s 137us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 116/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 117/130\n",
      "145/145 [==============================] - 0s 134us/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 118/130\n",
      "145/145 [==============================] - 0s 148us/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 119/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 120/130\n",
      "145/145 [==============================] - 0s 144us/step - loss: 0.0156 - accuracy: 0.9931\n",
      "Epoch 121/130\n",
      "145/145 [==============================] - 0s 130us/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 122/130\n",
      "145/145 [==============================] - 0s 131us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 123/130\n",
      "145/145 [==============================] - 0s 144us/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 124/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 125/130\n",
      "145/145 [==============================] - 0s 131us/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 126/130\n",
      "145/145 [==============================] - 0s 137us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 127/130\n",
      "145/145 [==============================] - 0s 141us/step - loss: 0.0093 - accuracy: 0.9931\n",
      "Epoch 128/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 129/130\n",
      "145/145 [==============================] - 0s 138us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 130/130\n",
      "145/145 [==============================] - 0s 135us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "63/63 [==============================] - 0s 175us/step\n",
      "\n",
      " Test Accuracy : 0.8254\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sonar.csv\", header = None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[: , 0:60]\n",
    "Y_obj = dataset[:, 60]\n",
    "\n",
    "# 문자열 변환\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "\n",
    "\n",
    "# 학습셋과 테스트셋으로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = seed)\n",
    "\n",
    "\n",
    "# 모델 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim = 60, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss = 'mean_squared_error',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = 130, batch_size = 5)\n",
    "\n",
    "# 테스트셋에 모델 적용\n",
    "print(\"\\n Test Accuracy : %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
    "#print(\"\\n Accuracy : %.4f\" % (model.evaluate(X, Y)[1]))\n",
    "#print(\"\\n Accuracy : %.4f\" % (model.evaluate(X_train, Y_train)[1]))\n",
    "\n",
    "## ⭐⭐ 결과창 ⭐⭐ \n",
    "## epoch마다의 accuracy는 train data의 accuracy => 이건 증가하지만 맨 밑줄 test accuracy는 0.8로 낮다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 재사용\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ K겹 교차 검증 ✨\n",
    "🐶 각각 다른 부분을 테스트셋으로 하는 n개의 테스트셋, 학습셋을 생성하여 검증하기      \n",
    "🦊 데이터 양이 부족할 때 사용 => 앞으로는 사용하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1       2       3       4       5       6       7       8   \\\n",
      "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "\n",
      "       9   ...      51      52      53      54      55      56      57  \\\n",
      "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
      "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
      "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
      "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
      "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
      "\n",
      "       58      59  60  \n",
      "0  0.0090  0.0032   R  \n",
      "1  0.0052  0.0044   R  \n",
      "2  0.0095  0.0078   R  \n",
      "3  0.0040  0.0117   R  \n",
      "4  0.0107  0.0094   R  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "# seed값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df = pd.read_csv('sonar.csv', header = None)\n",
    "print(df.head())\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[: , 0:60]\n",
    "# X = dataset[: , 0:60].astype(float) 라고 쓰는 경우 fit 하기 전 converter를 안해도 됨\n",
    "Y_obj = dataset[:, 60]\n",
    "\n",
    "# 문자열 변환\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "\n",
    "# 10개의 파일로 쪼갬\n",
    "n_fold = 10\n",
    "skf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2395 - accuracy: 0.5789WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.5294\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 808us/step - loss: 0.2402 - accuracy: 0.5775\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.2346 - accuracy: 0.6043\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2298 - accuracy: 0.6257\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2251 - accuracy: 0.6631\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2212 - accuracy: 0.6631\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2174 - accuracy: 0.6952\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2138 - accuracy: 0.7059\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2101 - accuracy: 0.7326\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2066 - accuracy: 0.7487\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 794us/step - loss: 0.2028 - accuracy: 0.7701\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.1988 - accuracy: 0.7754\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1955 - accuracy: 0.7754\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1915 - accuracy: 0.7647\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1877 - accuracy: 0.7914\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1845 - accuracy: 0.8128\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1809 - accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.1778 - accuracy: 0.8182\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 574us/step - loss: 0.1749 - accuracy: 0.7968\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1725 - accuracy: 0.8021\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1689 - accuracy: 0.7968\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.1652 - accuracy: 0.8128\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 737us/step - loss: 0.1624 - accuracy: 0.8075\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.1601 - accuracy: 0.8021\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1574 - accuracy: 0.8021\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1545 - accuracy: 0.8396\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1521 - accuracy: 0.8182\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 820us/step - loss: 0.1495 - accuracy: 0.8182\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1474 - accuracy: 0.8075\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1449 - accuracy: 0.8128\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1428 - accuracy: 0.8235\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1412 - accuracy: 0.8182\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1389 - accuracy: 0.8235\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1371 - accuracy: 0.8289\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1368 - accuracy: 0.8289\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1365 - accuracy: 0.8182\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1343 - accuracy: 0.8235\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1310 - accuracy: 0.8342\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1298 - accuracy: 0.8342\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1301 - accuracy: 0.8289\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1275 - accuracy: 0.8289\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1260 - accuracy: 0.8289\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1252 - accuracy: 0.8289\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1239 - accuracy: 0.8342\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1234 - accuracy: 0.8342\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1222 - accuracy: 0.8342\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1211 - accuracy: 0.8235\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1196 - accuracy: 0.8342\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1193 - accuracy: 0.8289\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1194 - accuracy: 0.8396\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1165 - accuracy: 0.8342\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1163 - accuracy: 0.8396\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.1152 - accuracy: 0.8556\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.1153 - accuracy: 0.8342\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.1128 - accuracy: 0.8503\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1121 - accuracy: 0.8503\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 811us/step - loss: 0.1117 - accuracy: 0.8396\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1104 - accuracy: 0.8503\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1095 - accuracy: 0.8449\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1090 - accuracy: 0.8556\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 608us/step - loss: 0.1091 - accuracy: 0.8503\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1067 - accuracy: 0.8663\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 796us/step - loss: 0.1062 - accuracy: 0.8610\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1057 - accuracy: 0.8556\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1045 - accuracy: 0.8610\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.8663\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1027 - accuracy: 0.8663\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1019 - accuracy: 0.8610\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1017 - accuracy: 0.8556\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0999 - accuracy: 0.8717\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0996 - accuracy: 0.8717\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0990 - accuracy: 0.8663\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0980 - accuracy: 0.8770\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0974 - accuracy: 0.8717\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0972 - accuracy: 0.8770\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.0955 - accuracy: 0.8770\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0951 - accuracy: 0.8824\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0942 - accuracy: 0.8877\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 594us/step - loss: 0.0954 - accuracy: 0.8663\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 598us/step - loss: 0.0936 - accuracy: 0.8930\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0925 - accuracy: 0.8877\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 615us/step - loss: 0.0923 - accuracy: 0.8877\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0907 - accuracy: 0.8824\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0911 - accuracy: 0.8877\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0896 - accuracy: 0.8824\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 630us/step - loss: 0.0892 - accuracy: 0.8930\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 816us/step - loss: 0.0880 - accuracy: 0.8930\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 773us/step - loss: 0.0886 - accuracy: 0.8877\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 596us/step - loss: 0.0863 - accuracy: 0.8877\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 924us/step - loss: 0.0864 - accuracy: 0.8877\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0862 - accuracy: 0.9037\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0844 - accuracy: 0.9037\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 785us/step - loss: 0.0842 - accuracy: 0.8984\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 982us/step - loss: 0.0833 - accuracy: 0.8984\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0830 - accuracy: 0.8984\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0819 - accuracy: 0.9037\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 784us/step - loss: 0.0814 - accuracy: 0.8984\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0805 - accuracy: 0.9091\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 789us/step - loss: 0.0800 - accuracy: 0.9144\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 791us/step - loss: 0.0804 - accuracy: 0.9144\n",
      "1/1 [==============================] - 0s 653us/step - loss: 0.2619 - accuracy: 0.7143\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 813us/step - loss: 0.2515 - accuracy: 0.4866\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2476 - accuracy: 0.5668\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2440 - accuracy: 0.5775\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2410 - accuracy: 0.5882\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.6096\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2359 - accuracy: 0.6150\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2338 - accuracy: 0.6417\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.2318 - accuracy: 0.6684\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2295 - accuracy: 0.6684\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2274 - accuracy: 0.6738\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2251 - accuracy: 0.6738\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2227 - accuracy: 0.6738\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.2207 - accuracy: 0.6791\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 630us/step - loss: 0.2181 - accuracy: 0.6952\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 412us/step - loss: 0.2155 - accuracy: 0.7005\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2133 - accuracy: 0.7005\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2105 - accuracy: 0.7112\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2079 - accuracy: 0.7166\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2054 - accuracy: 0.7059\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 818us/step - loss: 0.2029 - accuracy: 0.7112\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1994 - accuracy: 0.7219\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 595us/step - loss: 0.1958 - accuracy: 0.7166\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1931 - accuracy: 0.7326\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1905 - accuracy: 0.7273\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1875 - accuracy: 0.7326\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1850 - accuracy: 0.7433\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 619us/step - loss: 0.1825 - accuracy: 0.7594\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1800 - accuracy: 0.7433\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1770 - accuracy: 0.7540\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 595us/step - loss: 0.1744 - accuracy: 0.7540\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.1727 - accuracy: 0.7647\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1698 - accuracy: 0.7701\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1673 - accuracy: 0.7807\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1652 - accuracy: 0.7807\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1643 - accuracy: 0.7754\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1622 - accuracy: 0.7701\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1600 - accuracy: 0.7968\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1573 - accuracy: 0.7968\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1560 - accuracy: 0.8021\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1557 - accuracy: 0.7861\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1523 - accuracy: 0.8075\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1516 - accuracy: 0.7968\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1518 - accuracy: 0.7914\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1486 - accuracy: 0.8182\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1478 - accuracy: 0.8021\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1457 - accuracy: 0.8182\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1443 - accuracy: 0.8235\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1430 - accuracy: 0.8235\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1421 - accuracy: 0.8342\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1413 - accuracy: 0.8235\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.1396 - accuracy: 0.8289\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1388 - accuracy: 0.8289\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1380 - accuracy: 0.8342\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 787us/step - loss: 0.1379 - accuracy: 0.8235\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.1349 - accuracy: 0.8449\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.1344 - accuracy: 0.8342\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1339 - accuracy: 0.8182\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1320 - accuracy: 0.8289\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1306 - accuracy: 0.8396\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1304 - accuracy: 0.8396\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 798us/step - loss: 0.1314 - accuracy: 0.8342\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 815us/step - loss: 0.1281 - accuracy: 0.8449\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1286 - accuracy: 0.8396\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1271 - accuracy: 0.8449\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1248 - accuracy: 0.8342\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1244 - accuracy: 0.8396\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 786us/step - loss: 0.1234 - accuracy: 0.8342\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1231 - accuracy: 0.8449\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 400us/step - loss: 0.1219 - accuracy: 0.8556\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1210 - accuracy: 0.8396\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.1202 - accuracy: 0.8289\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1192 - accuracy: 0.8610\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1178 - accuracy: 0.8663\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.1181 - accuracy: 0.8503\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1171 - accuracy: 0.8396\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1155 - accuracy: 0.8503\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 608us/step - loss: 0.1142 - accuracy: 0.8556\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1139 - accuracy: 0.8556\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1146 - accuracy: 0.8610\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1127 - accuracy: 0.8503\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1113 - accuracy: 0.8663\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1102 - accuracy: 0.8663\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1092 - accuracy: 0.8610\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1086 - accuracy: 0.8663\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 796us/step - loss: 0.1078 - accuracy: 0.8717\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1076 - accuracy: 0.8717\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1071 - accuracy: 0.8663\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 813us/step - loss: 0.1077 - accuracy: 0.8663\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1044 - accuracy: 0.8717\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1054 - accuracy: 0.8770\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1038 - accuracy: 0.8556\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.1021 - accuracy: 0.8717\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1015 - accuracy: 0.8770\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1009 - accuracy: 0.8877\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1005 - accuracy: 0.8877\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0996 - accuracy: 0.8717\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0987 - accuracy: 0.8770\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0981 - accuracy: 0.8824\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 603us/step - loss: 0.0969 - accuracy: 0.8930\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0966 - accuracy: 0.8824\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1080 - accuracy: 0.9524\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2487 - accuracy: 0.5348\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.2459 - accuracy: 0.5348\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 608us/step - loss: 0.2443 - accuracy: 0.5348\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.2433 - accuracy: 0.5348\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 656us/step - loss: 0.2420 - accuracy: 0.5348\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 796us/step - loss: 0.2409 - accuracy: 0.5348\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 580us/step - loss: 0.2397 - accuracy: 0.5348\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2385 - accuracy: 0.5348\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2372 - accuracy: 0.5401\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 583us/step - loss: 0.2358 - accuracy: 0.5508\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2341 - accuracy: 0.5668\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2326 - accuracy: 0.5775\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2312 - accuracy: 0.5882\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2297 - accuracy: 0.5882\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 814us/step - loss: 0.2282 - accuracy: 0.5936\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.2269 - accuracy: 0.6203\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2255 - accuracy: 0.6257\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2242 - accuracy: 0.6257\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2227 - accuracy: 0.6257\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2213 - accuracy: 0.6471\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 815us/step - loss: 0.2196 - accuracy: 0.6684\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2177 - accuracy: 0.6738\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 592us/step - loss: 0.2158 - accuracy: 0.6791\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.2134 - accuracy: 0.6845\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2105 - accuracy: 0.6845\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2072 - accuracy: 0.7059\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 789us/step - loss: 0.2036 - accuracy: 0.7112\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2002 - accuracy: 0.7380\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1967 - accuracy: 0.7433\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1932 - accuracy: 0.7540\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 613us/step - loss: 0.1881 - accuracy: 0.7647\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1838 - accuracy: 0.7968\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.8128\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1743 - accuracy: 0.8021\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 808us/step - loss: 0.1709 - accuracy: 0.7968\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1671 - accuracy: 0.8182\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1659 - accuracy: 0.7914\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.1605 - accuracy: 0.8075\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1578 - accuracy: 0.8235\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.8289\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1524 - accuracy: 0.8289\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 783us/step - loss: 0.1519 - accuracy: 0.8021\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1495 - accuracy: 0.8289\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1460 - accuracy: 0.8503\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1444 - accuracy: 0.8449\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1416 - accuracy: 0.8610\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1404 - accuracy: 0.8396\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1380 - accuracy: 0.8610\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1374 - accuracy: 0.8503\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1352 - accuracy: 0.8610\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1335 - accuracy: 0.8449\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1324 - accuracy: 0.8663\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1304 - accuracy: 0.8717\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1289 - accuracy: 0.8663\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1258 - accuracy: 0.8824\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1251 - accuracy: 0.8770\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1254 - accuracy: 0.8770\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1216 - accuracy: 0.8770\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1205 - accuracy: 0.8930\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1191 - accuracy: 0.8930\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1188 - accuracy: 0.8770\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.1160 - accuracy: 0.8824\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1155 - accuracy: 0.8877\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1152 - accuracy: 0.8877\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1130 - accuracy: 0.8877\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 592us/step - loss: 0.1116 - accuracy: 0.8984\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1106 - accuracy: 0.8930\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 806us/step - loss: 0.1092 - accuracy: 0.8984\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.1090 - accuracy: 0.8930\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 791us/step - loss: 0.1082 - accuracy: 0.8984\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1067 - accuracy: 0.8930\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1052 - accuracy: 0.8930\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1036 - accuracy: 0.8984\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1031 - accuracy: 0.8930\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1033 - accuracy: 0.9037\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1008 - accuracy: 0.9091\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1003 - accuracy: 0.8930\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0989 - accuracy: 0.8930\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 603us/step - loss: 0.1001 - accuracy: 0.9144\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0974 - accuracy: 0.9091\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.0965 - accuracy: 0.9037\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0952 - accuracy: 0.9091\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.0946 - accuracy: 0.9144\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0939 - accuracy: 0.9091\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0929 - accuracy: 0.9144\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0927 - accuracy: 0.9144\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0909 - accuracy: 0.9144\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 410us/step - loss: 0.0906 - accuracy: 0.9144\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0898 - accuracy: 0.9144\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0890 - accuracy: 0.9251\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 400us/step - loss: 0.0889 - accuracy: 0.9198\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0869 - accuracy: 0.9198\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0869 - accuracy: 0.9091\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.0856 - accuracy: 0.9198\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0850 - accuracy: 0.9198\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 781us/step - loss: 0.0845 - accuracy: 0.9251\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 785us/step - loss: 0.0833 - accuracy: 0.9251\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 789us/step - loss: 0.0827 - accuracy: 0.9251\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 784us/step - loss: 0.0820 - accuracy: 0.9251\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.0823 - accuracy: 0.9251\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1012 - accuracy: 0.8095\n",
      "Epoch 1/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2747 - accuracy: 0.4211WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "5/5 [==============================] - 0s 802us/step - loss: 0.2599 - accuracy: 0.4813\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2501 - accuracy: 0.5187\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2456 - accuracy: 0.6203\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 782us/step - loss: 0.2431 - accuracy: 0.6257\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.2416 - accuracy: 0.6043\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 617us/step - loss: 0.2393 - accuracy: 0.6203\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 583us/step - loss: 0.2374 - accuracy: 0.6150\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2353 - accuracy: 0.6471\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2331 - accuracy: 0.6845\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2309 - accuracy: 0.6952\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 781us/step - loss: 0.2287 - accuracy: 0.7112\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.2260 - accuracy: 0.7219\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 790us/step - loss: 0.2238 - accuracy: 0.7166\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2209 - accuracy: 0.7273\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.2181 - accuracy: 0.7326\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.2154 - accuracy: 0.7380\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.2125 - accuracy: 0.7433\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.2098 - accuracy: 0.7487\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2071 - accuracy: 0.7326\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 599us/step - loss: 0.2041 - accuracy: 0.7647\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 581us/step - loss: 0.2009 - accuracy: 0.7968\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.1975 - accuracy: 0.7861\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1944 - accuracy: 0.7861\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1913 - accuracy: 0.7861\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 613us/step - loss: 0.1878 - accuracy: 0.7968\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1846 - accuracy: 0.8021\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1814 - accuracy: 0.8021\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1788 - accuracy: 0.7968\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1753 - accuracy: 0.8075\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1719 - accuracy: 0.8128\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 586us/step - loss: 0.1693 - accuracy: 0.8289\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.1667 - accuracy: 0.8396\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.1634 - accuracy: 0.8449\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.1606 - accuracy: 0.8342\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 784us/step - loss: 0.1590 - accuracy: 0.8235\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.1564 - accuracy: 0.8503\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1540 - accuracy: 0.8235\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.1504 - accuracy: 0.8449\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1483 - accuracy: 0.8449\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 608us/step - loss: 0.1473 - accuracy: 0.8610\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.1438 - accuracy: 0.8449\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1424 - accuracy: 0.8556\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1407 - accuracy: 0.8449\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1378 - accuracy: 0.8449\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 576us/step - loss: 0.1366 - accuracy: 0.8556\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 780us/step - loss: 0.1343 - accuracy: 0.8449\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 619us/step - loss: 0.1322 - accuracy: 0.8663\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 791us/step - loss: 0.1302 - accuracy: 0.8663\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 790us/step - loss: 0.1306 - accuracy: 0.8556\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1286 - accuracy: 0.8556\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1259 - accuracy: 0.8717\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 614us/step - loss: 0.1273 - accuracy: 0.8396\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1244 - accuracy: 0.8503\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1224 - accuracy: 0.8717\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1200 - accuracy: 0.8610\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 785us/step - loss: 0.1194 - accuracy: 0.8663\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1196 - accuracy: 0.8610\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 573us/step - loss: 0.1166 - accuracy: 0.8770\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1151 - accuracy: 0.8717\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1140 - accuracy: 0.8717\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 576us/step - loss: 0.1136 - accuracy: 0.8824\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.1116 - accuracy: 0.8824\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1105 - accuracy: 0.8877\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1098 - accuracy: 0.8824\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1080 - accuracy: 0.8877\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1071 - accuracy: 0.8877\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1061 - accuracy: 0.8877\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.1054 - accuracy: 0.8824\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1041 - accuracy: 0.8770\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 406us/step - loss: 0.1039 - accuracy: 0.8824\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1025 - accuracy: 0.8877\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1013 - accuracy: 0.8877\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1000 - accuracy: 0.8877\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 586us/step - loss: 0.0992 - accuracy: 0.8877\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 613us/step - loss: 0.0986 - accuracy: 0.8824\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0977 - accuracy: 0.8877\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0968 - accuracy: 0.8877\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 605us/step - loss: 0.0956 - accuracy: 0.8877\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.0961 - accuracy: 0.8824\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0953 - accuracy: 0.8877\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0938 - accuracy: 0.8930\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 785us/step - loss: 0.0925 - accuracy: 0.8984\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0912 - accuracy: 0.9037\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0905 - accuracy: 0.9037\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0899 - accuracy: 0.9144\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.0890 - accuracy: 0.9091\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.0879 - accuracy: 0.9091\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0885 - accuracy: 0.9091\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.0859 - accuracy: 0.9144\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0862 - accuracy: 0.9091\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.0862 - accuracy: 0.9037\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0840 - accuracy: 0.9037\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0834 - accuracy: 0.9091\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0829 - accuracy: 0.9091\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 784us/step - loss: 0.0820 - accuracy: 0.9091\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0813 - accuracy: 0.9091\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.0805 - accuracy: 0.9144\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0796 - accuracy: 0.9144\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0794 - accuracy: 0.9091\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 416us/step - loss: 0.0796 - accuracy: 0.9144\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1193 - accuracy: 0.7619\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 717us/step - loss: 0.2577 - accuracy: 0.4385\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2512 - accuracy: 0.4652\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.2483 - accuracy: 0.5241\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.5508\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2432 - accuracy: 0.6043\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.2401 - accuracy: 0.5829\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 796us/step - loss: 0.2370 - accuracy: 0.5989\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 693us/step - loss: 0.2336 - accuracy: 0.5829\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 786us/step - loss: 0.2299 - accuracy: 0.6096\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.2263 - accuracy: 0.6417\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2227 - accuracy: 0.6578\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2190 - accuracy: 0.6898\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2154 - accuracy: 0.7005\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2112 - accuracy: 0.7273\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 818us/step - loss: 0.2073 - accuracy: 0.7433\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2034 - accuracy: 0.7594\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 804us/step - loss: 0.2000 - accuracy: 0.7647\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 786us/step - loss: 0.1958 - accuracy: 0.7754\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.1922 - accuracy: 0.7807\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 846us/step - loss: 0.1890 - accuracy: 0.7914\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1847 - accuracy: 0.7968\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1801 - accuracy: 0.8021\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1761 - accuracy: 0.8021\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1724 - accuracy: 0.8075\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.1691 - accuracy: 0.8075\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.8342\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1612 - accuracy: 0.8396\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 788us/step - loss: 0.1577 - accuracy: 0.8396\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1539 - accuracy: 0.8449\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1510 - accuracy: 0.8396\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1479 - accuracy: 0.8396\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 987us/step - loss: 0.1451 - accuracy: 0.8503\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 780us/step - loss: 0.1420 - accuracy: 0.8289\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1400 - accuracy: 0.8556\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 983us/step - loss: 0.1378 - accuracy: 0.8449\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1365 - accuracy: 0.8610\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.1354 - accuracy: 0.8396\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1312 - accuracy: 0.8663\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1285 - accuracy: 0.8610\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 813us/step - loss: 0.1288 - accuracy: 0.8610\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 770us/step - loss: 0.1248 - accuracy: 0.8717\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1248 - accuracy: 0.8663\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1228 - accuracy: 0.8717\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 786us/step - loss: 0.1203 - accuracy: 0.8877\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1190 - accuracy: 0.8877\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1171 - accuracy: 0.8770\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.1152 - accuracy: 0.8824\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.1138 - accuracy: 0.8930\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.1129 - accuracy: 0.8984\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 626us/step - loss: 0.1116 - accuracy: 0.8930\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1092 - accuracy: 0.8984\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 779us/step - loss: 0.1111 - accuracy: 0.8824\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1093 - accuracy: 0.8824\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1075 - accuracy: 0.8877\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1039 - accuracy: 0.8984\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1044 - accuracy: 0.8824\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1040 - accuracy: 0.8984\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1006 - accuracy: 0.8984\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.1002 - accuracy: 0.8930\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0975 - accuracy: 0.9037\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 817us/step - loss: 0.0977 - accuracy: 0.9037\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 787us/step - loss: 0.0951 - accuracy: 0.9037\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0960 - accuracy: 0.8984\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0943 - accuracy: 0.8930\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0934 - accuracy: 0.9037\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0910 - accuracy: 0.9037\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.0898 - accuracy: 0.8984\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0891 - accuracy: 0.9037\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0875 - accuracy: 0.9037\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0865 - accuracy: 0.9037\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0849 - accuracy: 0.9091\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0838 - accuracy: 0.9144\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 811us/step - loss: 0.0828 - accuracy: 0.9091\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0816 - accuracy: 0.9091\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 586us/step - loss: 0.0821 - accuracy: 0.8984\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0797 - accuracy: 0.9037\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0789 - accuracy: 0.9091\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0776 - accuracy: 0.9198\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0761 - accuracy: 0.9198\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0754 - accuracy: 0.9144\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 616us/step - loss: 0.0755 - accuracy: 0.9198\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0754 - accuracy: 0.9251\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 998us/step - loss: 0.0729 - accuracy: 0.9251\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0718 - accuracy: 0.9251\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0704 - accuracy: 0.9305\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0693 - accuracy: 0.9305\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0681 - accuracy: 0.9305\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.0686 - accuracy: 0.9251\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0665 - accuracy: 0.9358\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0651 - accuracy: 0.9519\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0655 - accuracy: 0.9519\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0634 - accuracy: 0.9412\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0626 - accuracy: 0.9572\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0619 - accuracy: 0.9572\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0622 - accuracy: 0.9412\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0594 - accuracy: 0.9626\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0592 - accuracy: 0.9572\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0586 - accuracy: 0.9572\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0571 - accuracy: 0.9626\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0577 - accuracy: 0.9519\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x000002A2EA1875E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1247 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2488 - accuracy: 0.4652\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2441 - accuracy: 0.4706\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2406 - accuracy: 0.4813\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2379 - accuracy: 0.5401\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 786us/step - loss: 0.2360 - accuracy: 0.5882\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 986us/step - loss: 0.2341 - accuracy: 0.6150\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2321 - accuracy: 0.6417\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2301 - accuracy: 0.6684\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2280 - accuracy: 0.6845\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.2261 - accuracy: 0.6631\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 990us/step - loss: 0.2240 - accuracy: 0.6952\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.2215 - accuracy: 0.7112\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2195 - accuracy: 0.7219\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.2168 - accuracy: 0.7219\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 796us/step - loss: 0.2141 - accuracy: 0.7487\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.2113 - accuracy: 0.7433\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 795us/step - loss: 0.2078 - accuracy: 0.7540\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2033 - accuracy: 0.7914\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 792us/step - loss: 0.1991 - accuracy: 0.8021\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1938 - accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.1874 - accuracy: 0.8128\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 808us/step - loss: 0.1797 - accuracy: 0.8396\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 603us/step - loss: 0.1735 - accuracy: 0.8075\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 590us/step - loss: 0.1682 - accuracy: 0.8128\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1642 - accuracy: 0.8128\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1596 - accuracy: 0.8075\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1561 - accuracy: 0.8128\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1530 - accuracy: 0.8235\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1490 - accuracy: 0.8182\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 604us/step - loss: 0.1464 - accuracy: 0.8235\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1439 - accuracy: 0.8342\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 810us/step - loss: 0.1412 - accuracy: 0.8289\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.1387 - accuracy: 0.8396\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 776us/step - loss: 0.1366 - accuracy: 0.8289\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1351 - accuracy: 0.8289\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 614us/step - loss: 0.1331 - accuracy: 0.8396\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 775us/step - loss: 0.1327 - accuracy: 0.8235\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1296 - accuracy: 0.8449\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1277 - accuracy: 0.8503\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1268 - accuracy: 0.8449\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1235 - accuracy: 0.8610\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1235 - accuracy: 0.8396\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1220 - accuracy: 0.8503\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1219 - accuracy: 0.8396\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1199 - accuracy: 0.8396\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1174 - accuracy: 0.8663\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1157 - accuracy: 0.8610\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1145 - accuracy: 0.8556\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1152 - accuracy: 0.8770\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1165 - accuracy: 0.8396\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1113 - accuracy: 0.8503\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 583us/step - loss: 0.1142 - accuracy: 0.8824\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.8556\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1122 - accuracy: 0.8503\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.1084 - accuracy: 0.8663\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 798us/step - loss: 0.1078 - accuracy: 0.8877\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 590us/step - loss: 0.1077 - accuracy: 0.8610\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 583us/step - loss: 0.1047 - accuracy: 0.8556\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1034 - accuracy: 0.8984\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.1034 - accuracy: 0.8877\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1027 - accuracy: 0.8610\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1015 - accuracy: 0.8717\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.1019 - accuracy: 0.8770\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 621us/step - loss: 0.1011 - accuracy: 0.8824\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0991 - accuracy: 0.8663\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0983 - accuracy: 0.9037\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0979 - accuracy: 0.8930\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 983us/step - loss: 0.0966 - accuracy: 0.8930\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.0967 - accuracy: 0.8984\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 777us/step - loss: 0.0956 - accuracy: 0.8930\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 809us/step - loss: 0.0944 - accuracy: 0.8984\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0938 - accuracy: 0.8984\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0937 - accuracy: 0.8877\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 806us/step - loss: 0.0927 - accuracy: 0.8930\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.0930 - accuracy: 0.9037\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0911 - accuracy: 0.9037\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0910 - accuracy: 0.8984\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0894 - accuracy: 0.8984\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 789us/step - loss: 0.0908 - accuracy: 0.8930\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 786us/step - loss: 0.0894 - accuracy: 0.9091\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.0880 - accuracy: 0.8930\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 594us/step - loss: 0.0869 - accuracy: 0.9144\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0863 - accuracy: 0.9037\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0859 - accuracy: 0.9037\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0857 - accuracy: 0.9037\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 796us/step - loss: 0.0853 - accuracy: 0.9198\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0835 - accuracy: 0.9144\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 829us/step - loss: 0.0853 - accuracy: 0.9037\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.0817 - accuracy: 0.9198\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0824 - accuracy: 0.9198\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0811 - accuracy: 0.9198\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.0802 - accuracy: 0.9198\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0794 - accuracy: 0.9251\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.0787 - accuracy: 0.9251\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0781 - accuracy: 0.9251\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0776 - accuracy: 0.9198\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0773 - accuracy: 0.9305\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0762 - accuracy: 0.9305\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0756 - accuracy: 0.9251\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0762 - accuracy: 0.9305\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000002A2EA0A9EE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 710us/step - loss: 0.2423 - accuracy: 0.5348\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.2382 - accuracy: 0.5401\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.2350 - accuracy: 0.5829\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.6203\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 818us/step - loss: 0.2272 - accuracy: 0.6578\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.2236 - accuracy: 0.6845\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2202 - accuracy: 0.6952\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2170 - accuracy: 0.7005\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2136 - accuracy: 0.7059\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.2104 - accuracy: 0.7166\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.2074 - accuracy: 0.7219\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 808us/step - loss: 0.2039 - accuracy: 0.7326\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2014 - accuracy: 0.7166\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1978 - accuracy: 0.7487\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.1945 - accuracy: 0.7594\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1916 - accuracy: 0.7701\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 596us/step - loss: 0.1885 - accuracy: 0.7701\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 811us/step - loss: 0.1854 - accuracy: 0.7701\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.1825 - accuracy: 0.7754\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1799 - accuracy: 0.7968\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1769 - accuracy: 0.7968\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1734 - accuracy: 0.8128\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1710 - accuracy: 0.7914\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1686 - accuracy: 0.8021\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1658 - accuracy: 0.8128\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.1633 - accuracy: 0.8235\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1609 - accuracy: 0.8235\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1582 - accuracy: 0.8182\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 798us/step - loss: 0.1554 - accuracy: 0.8289\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 808us/step - loss: 0.1535 - accuracy: 0.8289\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1511 - accuracy: 0.8449\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1490 - accuracy: 0.8289\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1469 - accuracy: 0.8289\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1448 - accuracy: 0.8342\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1441 - accuracy: 0.8449\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1418 - accuracy: 0.8396\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 809us/step - loss: 0.1403 - accuracy: 0.8342\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1374 - accuracy: 0.8449\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1359 - accuracy: 0.8449\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1357 - accuracy: 0.8449\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.1324 - accuracy: 0.8449\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1319 - accuracy: 0.8449\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 613us/step - loss: 0.1307 - accuracy: 0.8396\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1293 - accuracy: 0.8342\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 810us/step - loss: 0.1280 - accuracy: 0.8396\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1256 - accuracy: 0.8342\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1241 - accuracy: 0.8449\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1229 - accuracy: 0.8449\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1243 - accuracy: 0.8396\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.1229 - accuracy: 0.8503\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 782us/step - loss: 0.1199 - accuracy: 0.8449\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1196 - accuracy: 0.8556\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1176 - accuracy: 0.8610\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1171 - accuracy: 0.8503\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1146 - accuracy: 0.8610\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1149 - accuracy: 0.8717\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1147 - accuracy: 0.8449\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.1117 - accuracy: 0.8556\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1104 - accuracy: 0.8717\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1101 - accuracy: 0.8663\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1102 - accuracy: 0.8717\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1080 - accuracy: 0.8663\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1081 - accuracy: 0.8717\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1063 - accuracy: 0.8770\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1047 - accuracy: 0.8663\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1036 - accuracy: 0.8663\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1025 - accuracy: 0.8663\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1020 - accuracy: 0.8717\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1012 - accuracy: 0.8770\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1003 - accuracy: 0.8770\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0992 - accuracy: 0.8717\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.0981 - accuracy: 0.8717\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0971 - accuracy: 0.8877\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0962 - accuracy: 0.8717\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.0956 - accuracy: 0.8770\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0946 - accuracy: 0.8663\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0940 - accuracy: 0.8824\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0929 - accuracy: 0.8824\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0925 - accuracy: 0.8877\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.0910 - accuracy: 0.8930\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0906 - accuracy: 0.9037\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0909 - accuracy: 0.8770\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0884 - accuracy: 0.8930\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0881 - accuracy: 0.9037\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0866 - accuracy: 0.9037\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0870 - accuracy: 0.8770\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0856 - accuracy: 0.9037\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0869 - accuracy: 0.8930\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0834 - accuracy: 0.9198\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0829 - accuracy: 0.9037\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0821 - accuracy: 0.9091\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0810 - accuracy: 0.9091\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0807 - accuracy: 0.9091\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0788 - accuracy: 0.9144\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0785 - accuracy: 0.9091\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0769 - accuracy: 0.9091\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0762 - accuracy: 0.9144\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0758 - accuracy: 0.9251\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0750 - accuracy: 0.9251\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0752 - accuracy: 0.9144\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x000002A2E87D5798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0965 - accuracy: 0.9524\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2474 - accuracy: 0.5027\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 791us/step - loss: 0.2394 - accuracy: 0.5455\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 606us/step - loss: 0.2327 - accuracy: 0.5722\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2275 - accuracy: 0.6684\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2221 - accuracy: 0.7005\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 785us/step - loss: 0.2172 - accuracy: 0.7380\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 788us/step - loss: 0.2123 - accuracy: 0.7433\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2077 - accuracy: 0.7380\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2031 - accuracy: 0.7380\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 785us/step - loss: 0.1979 - accuracy: 0.7594\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1936 - accuracy: 0.7647\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1889 - accuracy: 0.7647\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1856 - accuracy: 0.7647\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1808 - accuracy: 0.7594\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1769 - accuracy: 0.7807\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1740 - accuracy: 0.7861\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 985us/step - loss: 0.1698 - accuracy: 0.8075\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 595us/step - loss: 0.1669 - accuracy: 0.7807\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 590us/step - loss: 0.1637 - accuracy: 0.7807\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 808us/step - loss: 0.1625 - accuracy: 0.7861\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1585 - accuracy: 0.8235\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1549 - accuracy: 0.8021\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 982us/step - loss: 0.1529 - accuracy: 0.7968\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.1505 - accuracy: 0.8128\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 784us/step - loss: 0.1480 - accuracy: 0.8289\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1458 - accuracy: 0.8235\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 583us/step - loss: 0.1438 - accuracy: 0.8235\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.1426 - accuracy: 0.8128\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1397 - accuracy: 0.8235\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1386 - accuracy: 0.8235\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1365 - accuracy: 0.8289\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 983us/step - loss: 0.1353 - accuracy: 0.8556\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 615us/step - loss: 0.1332 - accuracy: 0.8449\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1321 - accuracy: 0.8235\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 983us/step - loss: 0.1308 - accuracy: 0.8289\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1304 - accuracy: 0.8396\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1290 - accuracy: 0.8396\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1262 - accuracy: 0.8342\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 804us/step - loss: 0.1246 - accuracy: 0.8556\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1261 - accuracy: 0.8717\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.1221 - accuracy: 0.8556\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1229 - accuracy: 0.8235\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.1230 - accuracy: 0.8556\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.1201 - accuracy: 0.8610\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 578us/step - loss: 0.1193 - accuracy: 0.8503\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.1163 - accuracy: 0.8717\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1157 - accuracy: 0.8610\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1140 - accuracy: 0.8663\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 586us/step - loss: 0.1131 - accuracy: 0.8717\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 784us/step - loss: 0.1137 - accuracy: 0.8556\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.1110 - accuracy: 0.8663\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1118 - accuracy: 0.8663\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.1120 - accuracy: 0.8556\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1089 - accuracy: 0.8610\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1067 - accuracy: 0.8717\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.8824\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1083 - accuracy: 0.8556\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1033 - accuracy: 0.8770\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 985us/step - loss: 0.1060 - accuracy: 0.8770\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1013 - accuracy: 0.8984\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 566us/step - loss: 0.1049 - accuracy: 0.8663\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0994 - accuracy: 0.8877\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1007 - accuracy: 0.8930\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0996 - accuracy: 0.8717\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.0979 - accuracy: 0.8877\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.0967 - accuracy: 0.8877\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0961 - accuracy: 0.8930\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 814us/step - loss: 0.0960 - accuracy: 0.8930\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 564us/step - loss: 0.0940 - accuracy: 0.8984\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 567us/step - loss: 0.0945 - accuracy: 0.8877\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0927 - accuracy: 0.8824\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.0926 - accuracy: 0.9091\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0911 - accuracy: 0.8930\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0900 - accuracy: 0.8930\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.0901 - accuracy: 0.8984\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0886 - accuracy: 0.9037\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.0879 - accuracy: 0.8930\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0866 - accuracy: 0.9037\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 790us/step - loss: 0.0867 - accuracy: 0.9037\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0861 - accuracy: 0.8984\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 781us/step - loss: 0.0845 - accuracy: 0.9037\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0836 - accuracy: 0.9037\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0831 - accuracy: 0.9091\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 598us/step - loss: 0.0830 - accuracy: 0.8984\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.0820 - accuracy: 0.9144\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 822us/step - loss: 0.0814 - accuracy: 0.9144\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0802 - accuracy: 0.9091\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0813 - accuracy: 0.9091\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 784us/step - loss: 0.0779 - accuracy: 0.9198\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0793 - accuracy: 0.9305\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0787 - accuracy: 0.9198\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 793us/step - loss: 0.0764 - accuracy: 0.9251\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0763 - accuracy: 0.9144\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.0754 - accuracy: 0.9144\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0755 - accuracy: 0.9198\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0738 - accuracy: 0.9251\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0739 - accuracy: 0.9305\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 613us/step - loss: 0.0728 - accuracy: 0.9198\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0724 - accuracy: 0.9251\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 593us/step - loss: 0.0713 - accuracy: 0.9305\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function at 0x000002A2EB4AF438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1465 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 814us/step - loss: 0.2612 - accuracy: 0.4681\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.2532 - accuracy: 0.4947\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.2496 - accuracy: 0.5372\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2463 - accuracy: 0.5638\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2448 - accuracy: 0.5638\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.5745\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.2406 - accuracy: 0.5904\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2387 - accuracy: 0.6170\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2364 - accuracy: 0.6223\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.2342 - accuracy: 0.6223\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.6543\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 810us/step - loss: 0.2293 - accuracy: 0.6809\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2268 - accuracy: 0.6968\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2241 - accuracy: 0.6755\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2217 - accuracy: 0.6862\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2192 - accuracy: 0.6915\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2154 - accuracy: 0.6968\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 617us/step - loss: 0.2127 - accuracy: 0.6915\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2095 - accuracy: 0.6915\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.2064 - accuracy: 0.6968\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2034 - accuracy: 0.6968\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 981us/step - loss: 0.2001 - accuracy: 0.6915\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 606us/step - loss: 0.1974 - accuracy: 0.7074\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 619us/step - loss: 0.1934 - accuracy: 0.7287\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 808us/step - loss: 0.1901 - accuracy: 0.7394\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1871 - accuracy: 0.7394\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1845 - accuracy: 0.7447\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 835us/step - loss: 0.1819 - accuracy: 0.7872\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1788 - accuracy: 0.7979\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 788us/step - loss: 0.1762 - accuracy: 0.7872\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1732 - accuracy: 0.7926\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 784us/step - loss: 0.1711 - accuracy: 0.8191\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1689 - accuracy: 0.8404\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1657 - accuracy: 0.8404\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1639 - accuracy: 0.8351\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1613 - accuracy: 0.8351\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1593 - accuracy: 0.8298\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 613us/step - loss: 0.1585 - accuracy: 0.8351\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1555 - accuracy: 0.8245\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1555 - accuracy: 0.8191\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1527 - accuracy: 0.8191\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1509 - accuracy: 0.8245\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1495 - accuracy: 0.8351\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1486 - accuracy: 0.8351\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 802us/step - loss: 0.1464 - accuracy: 0.8457\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1451 - accuracy: 0.8457\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1437 - accuracy: 0.8564\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1421 - accuracy: 0.8564\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1408 - accuracy: 0.8457\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1398 - accuracy: 0.8511\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.1388 - accuracy: 0.8564\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1376 - accuracy: 0.8564\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1366 - accuracy: 0.8564\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1356 - accuracy: 0.8564\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1344 - accuracy: 0.8511\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1333 - accuracy: 0.8617\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 598us/step - loss: 0.1326 - accuracy: 0.8564\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1318 - accuracy: 0.8457\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1310 - accuracy: 0.8564\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1300 - accuracy: 0.8617\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1287 - accuracy: 0.8670\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1283 - accuracy: 0.8617\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1277 - accuracy: 0.8617\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1263 - accuracy: 0.8564\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1261 - accuracy: 0.8511\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1256 - accuracy: 0.8564\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1239 - accuracy: 0.8617\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 813us/step - loss: 0.1234 - accuracy: 0.8670\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1243 - accuracy: 0.8617\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1212 - accuracy: 0.8670\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1232 - accuracy: 0.8511\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1205 - accuracy: 0.8564\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1200 - accuracy: 0.8670\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1193 - accuracy: 0.8723\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1185 - accuracy: 0.8670\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1180 - accuracy: 0.8670\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1170 - accuracy: 0.8670\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1164 - accuracy: 0.8670\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1156 - accuracy: 0.8670\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1165 - accuracy: 0.8723\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1149 - accuracy: 0.8723\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.1144 - accuracy: 0.8511\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 808us/step - loss: 0.1137 - accuracy: 0.8723\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1135 - accuracy: 0.8617\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1130 - accuracy: 0.8617\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1121 - accuracy: 0.8777\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1117 - accuracy: 0.8564\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.1118 - accuracy: 0.8457\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1108 - accuracy: 0.8777\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1097 - accuracy: 0.8670\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 596us/step - loss: 0.1103 - accuracy: 0.8617\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 782us/step - loss: 0.1095 - accuracy: 0.8723\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1087 - accuracy: 0.8883\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1114 - accuracy: 0.8457\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1069 - accuracy: 0.8723\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1074 - accuracy: 0.8883\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.1064 - accuracy: 0.8883\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 795us/step - loss: 0.1056 - accuracy: 0.8723\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1061 - accuracy: 0.8777\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1050 - accuracy: 0.8777\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x000002A2E9AFF3A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1175 - accuracy: 0.9000\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2515 - accuracy: 0.5319\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.2476 - accuracy: 0.5319\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 586us/step - loss: 0.2445 - accuracy: 0.5372\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 761us/step - loss: 0.2427 - accuracy: 0.5532\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2410 - accuracy: 0.5585\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2395 - accuracy: 0.5691\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2380 - accuracy: 0.5691\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.5904\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2346 - accuracy: 0.6170\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.2330 - accuracy: 0.6277\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2312 - accuracy: 0.6383\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2295 - accuracy: 0.6330\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.2277 - accuracy: 0.6489\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2262 - accuracy: 0.6489\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2243 - accuracy: 0.6543\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 775us/step - loss: 0.2231 - accuracy: 0.6702\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.6809\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 580us/step - loss: 0.2188 - accuracy: 0.6915\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2167 - accuracy: 0.6968\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2147 - accuracy: 0.7021\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2128 - accuracy: 0.7021\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2107 - accuracy: 0.7021\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2089 - accuracy: 0.7128\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.2062 - accuracy: 0.7128\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.2038 - accuracy: 0.7074\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.2011 - accuracy: 0.7074\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1988 - accuracy: 0.7074\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1957 - accuracy: 0.7234\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1928 - accuracy: 0.7447\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 798us/step - loss: 0.1902 - accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1869 - accuracy: 0.7553\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1840 - accuracy: 0.7766\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1810 - accuracy: 0.7819\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1778 - accuracy: 0.7872\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1751 - accuracy: 0.7926\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1720 - accuracy: 0.7979\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1692 - accuracy: 0.8085\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1667 - accuracy: 0.8138\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1636 - accuracy: 0.8032\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1623 - accuracy: 0.7926\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 400us/step - loss: 0.1590 - accuracy: 0.7979\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 708us/step - loss: 0.1570 - accuracy: 0.7926\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1541 - accuracy: 0.8085\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.1524 - accuracy: 0.8032\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1497 - accuracy: 0.8032\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1481 - accuracy: 0.8191\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1460 - accuracy: 0.8138\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1444 - accuracy: 0.8138\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 794us/step - loss: 0.1419 - accuracy: 0.8138\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1400 - accuracy: 0.8404\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 591us/step - loss: 0.1383 - accuracy: 0.8457\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1366 - accuracy: 0.8457\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1352 - accuracy: 0.8457\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.1334 - accuracy: 0.8511\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1318 - accuracy: 0.8404\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1305 - accuracy: 0.8457\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1290 - accuracy: 0.8351\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.1277 - accuracy: 0.8457\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 814us/step - loss: 0.1262 - accuracy: 0.8457\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1251 - accuracy: 0.8511\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1234 - accuracy: 0.8511\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 796us/step - loss: 0.1231 - accuracy: 0.8351\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1217 - accuracy: 0.8298\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1203 - accuracy: 0.8457\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1191 - accuracy: 0.8457\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1189 - accuracy: 0.8404\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1167 - accuracy: 0.8511\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 785us/step - loss: 0.1166 - accuracy: 0.8404\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1167 - accuracy: 0.8511\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.1135 - accuracy: 0.8564\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.1137 - accuracy: 0.8617\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1118 - accuracy: 0.8457\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.1113 - accuracy: 0.8670\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1103 - accuracy: 0.8670\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1089 - accuracy: 0.8511\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1085 - accuracy: 0.8670\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1072 - accuracy: 0.8617\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1066 - accuracy: 0.8564\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 408us/step - loss: 0.1060 - accuracy: 0.8511\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.1071 - accuracy: 0.8617\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 793us/step - loss: 0.1051 - accuracy: 0.8723\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.1036 - accuracy: 0.8670\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 605us/step - loss: 0.1023 - accuracy: 0.8723\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1017 - accuracy: 0.8723\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.1008 - accuracy: 0.8670\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.1003 - accuracy: 0.8670\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0997 - accuracy: 0.8617\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0987 - accuracy: 0.8777\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0983 - accuracy: 0.8723\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0970 - accuracy: 0.8723\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 792us/step - loss: 0.0972 - accuracy: 0.8723\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 382us/step - loss: 0.0967 - accuracy: 0.8723\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 784us/step - loss: 0.0963 - accuracy: 0.8830\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.0954 - accuracy: 0.8777\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0943 - accuracy: 0.8883\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.0933 - accuracy: 0.8936\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.8936\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 413us/step - loss: 0.0940 - accuracy: 0.8883\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0942 - accuracy: 0.8830\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0911 - accuracy: 0.8989\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x000002A2E8963AF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1403 - accuracy: 0.8000\n",
      "\n",
      " 10 fold accuracy :  ['0.7143', '0.9524', '0.8095', '0.7619', '0.7619', '0.7619', '0.9524', '0.7619', '0.9000', '0.8000']\n"
     ]
    }
   ],
   "source": [
    "# 빈 accuracy 배열\n",
    "accuracy = []\n",
    "\n",
    "# 모델의 설정, 컴파일, 실행\n",
    "for train, test in skf.split(X, Y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim = 60, activation = 'relu'))\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(loss = 'mean_squared_error',\n",
    "                 optimizer = 'adam',\n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    X_train = tf.convert_to_tensor(X[train], dtype = tf.float32)\n",
    "    Y_train = tf.convert_to_tensor(Y[train], dtype = tf.float32)\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs = 100, steps_per_epoch = 5)\n",
    "    #model.fit(X_train, Y_train, epochs = 100)\n",
    "    \n",
    "    X_test = tf.convert_to_tensor(X[test], dtype = tf.float32)\n",
    "    Y_test = tf.convert_to_tensor(Y[test], dtype = tf.float32)\n",
    "    \n",
    "    k_accuracy = \"%.4f\" % (model.evaluate(X_test, Y_test)[1])\n",
    "    accuracy.append(k_accuracy)\n",
    "    \n",
    "# 결과 출력\n",
    "print(\"\\n %.f fold accuracy : \" % n_fold, accuracy)\n",
    "\n",
    "# 실행 후 10번의 테스트 값들이 출력되었음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 와인 데이터 ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = pd.read_csv('wine.csv', header = None)\n",
    "df = df_pre.sample(frac = 1)   ## 100%를 랜덤으로 불러오라는 의미 (0.5 이면 50%를 랜덤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.048</td>\n",
       "      <td>59.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.99178</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.084</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.99672</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.99686</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.50</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.048</td>\n",
       "      <td>36.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.99904</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.29</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.046</td>\n",
       "      <td>82.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1     2     3      4     5      6        7     8     9     10  \\\n",
       "5465  8.4  0.230  0.32   1.3  0.048  59.0  113.0  0.99178  3.10  0.55  11.0   \n",
       "1293  7.5  0.755  0.00   1.9  0.084   6.0   12.0  0.99672  3.34  0.49   9.7   \n",
       "1199  7.9  0.580  0.23   2.3  0.076  23.0   94.0  0.99686  3.21  0.58   9.5   \n",
       "4295  6.5  0.220  0.50  16.4  0.048  36.0  182.0  0.99904  3.02  0.49   8.8   \n",
       "3273  6.8  0.220  0.29   8.9  0.046  82.0  188.0  0.99550  3.30  0.44  10.3   \n",
       "\n",
       "      11  12  \n",
       "5465   6   0  \n",
       "1293   4   1  \n",
       "1199   6   1  \n",
       "4295   6   0  \n",
       "3273   6   0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "130/130 [==============================] - 0s 647us/step - loss: 0.2854 - accuracy: 0.9012\n",
      "Epoch 2/200\n",
      "130/130 [==============================] - 0s 578us/step - loss: 0.2021 - accuracy: 0.9340\n",
      "Epoch 3/200\n",
      "130/130 [==============================] - 0s 573us/step - loss: 0.1888 - accuracy: 0.9341\n",
      "Epoch 4/200\n",
      "130/130 [==============================] - 0s 575us/step - loss: 0.1774 - accuracy: 0.9372\n",
      "Epoch 5/200\n",
      "130/130 [==============================] - 0s 586us/step - loss: 0.1707 - accuracy: 0.9392\n",
      "Epoch 6/200\n",
      "130/130 [==============================] - 0s 595us/step - loss: 0.1537 - accuracy: 0.9443\n",
      "Epoch 7/200\n",
      "130/130 [==============================] - 0s 577us/step - loss: 0.1428 - accuracy: 0.9495\n",
      "Epoch 8/200\n",
      "130/130 [==============================] - 0s 593us/step - loss: 0.1329 - accuracy: 0.9500\n",
      "Epoch 9/200\n",
      "130/130 [==============================] - 0s 577us/step - loss: 0.1242 - accuracy: 0.9552\n",
      "Epoch 10/200\n",
      "130/130 [==============================] - 0s 571us/step - loss: 0.1203 - accuracy: 0.9578\n",
      "Epoch 11/200\n",
      "130/130 [==============================] - 0s 585us/step - loss: 0.1087 - accuracy: 0.9600\n",
      "Epoch 12/200\n",
      "130/130 [==============================] - 0s 557us/step - loss: 0.1086 - accuracy: 0.9648\n",
      "Epoch 13/200\n",
      "130/130 [==============================] - 0s 577us/step - loss: 0.1013 - accuracy: 0.9654\n",
      "Epoch 14/200\n",
      "130/130 [==============================] - 0s 570us/step - loss: 0.0994 - accuracy: 0.9671\n",
      "Epoch 15/200\n",
      "130/130 [==============================] - 0s 572us/step - loss: 0.0942 - accuracy: 0.9704\n",
      "Epoch 16/200\n",
      "130/130 [==============================] - 0s 574us/step - loss: 0.0893 - accuracy: 0.9711\n",
      "Epoch 17/200\n",
      "130/130 [==============================] - 0s 588us/step - loss: 0.0859 - accuracy: 0.9724\n",
      "Epoch 18/200\n",
      "130/130 [==============================] - 0s 616us/step - loss: 0.0834 - accuracy: 0.9732\n",
      "Epoch 19/200\n",
      "130/130 [==============================] - 0s 606us/step - loss: 0.0868 - accuracy: 0.9726\n",
      "Epoch 20/200\n",
      "130/130 [==============================] - 0s 582us/step - loss: 0.0795 - accuracy: 0.9737\n",
      "Epoch 21/200\n",
      "130/130 [==============================] - 0s 585us/step - loss: 0.0777 - accuracy: 0.9758\n",
      "Epoch 22/200\n",
      "130/130 [==============================] - 0s 596us/step - loss: 0.0776 - accuracy: 0.9769\n",
      "Epoch 23/200\n",
      "130/130 [==============================] - 0s 573us/step - loss: 0.0771 - accuracy: 0.9744\n",
      "Epoch 24/200\n",
      "130/130 [==============================] - 0s 572us/step - loss: 0.0749 - accuracy: 0.9760\n",
      "Epoch 25/200\n",
      "130/130 [==============================] - 0s 586us/step - loss: 0.0739 - accuracy: 0.9757\n",
      "Epoch 26/200\n",
      "130/130 [==============================] - 0s 614us/step - loss: 0.0712 - accuracy: 0.9785\n",
      "Epoch 27/200\n",
      "130/130 [==============================] - 0s 563us/step - loss: 0.0698 - accuracy: 0.9789\n",
      "Epoch 28/200\n",
      "130/130 [==============================] - 0s 594us/step - loss: 0.0703 - accuracy: 0.9778\n",
      "Epoch 29/200\n",
      "130/130 [==============================] - 0s 583us/step - loss: 0.0684 - accuracy: 0.9789\n",
      "Epoch 30/200\n",
      "130/130 [==============================] - 0s 598us/step - loss: 0.0677 - accuracy: 0.9795\n",
      "Epoch 31/200\n",
      "130/130 [==============================] - 0s 573us/step - loss: 0.0690 - accuracy: 0.9797\n",
      "Epoch 32/200\n",
      "130/130 [==============================] - 0s 587us/step - loss: 0.0658 - accuracy: 0.9801\n",
      "Epoch 33/200\n",
      "130/130 [==============================] - 0s 578us/step - loss: 0.0643 - accuracy: 0.9817\n",
      "Epoch 34/200\n",
      "130/130 [==============================] - 0s 586us/step - loss: 0.0688 - accuracy: 0.9798\n",
      "Epoch 35/200\n",
      "130/130 [==============================] - 0s 561us/step - loss: 0.0718 - accuracy: 0.9788\n",
      "Epoch 36/200\n",
      "130/130 [==============================] - 0s 579us/step - loss: 0.0630 - accuracy: 0.9821\n",
      "Epoch 37/200\n",
      "130/130 [==============================] - 0s 585us/step - loss: 0.0651 - accuracy: 0.9812\n",
      "Epoch 38/200\n",
      "130/130 [==============================] - 0s 584us/step - loss: 0.0636 - accuracy: 0.9815\n",
      "Epoch 39/200\n",
      "130/130 [==============================] - 0s 566us/step - loss: 0.0633 - accuracy: 0.9820\n",
      "Epoch 40/200\n",
      "130/130 [==============================] - 0s 557us/step - loss: 0.0609 - accuracy: 0.9829\n",
      "Epoch 41/200\n",
      "130/130 [==============================] - 0s 591us/step - loss: 0.0612 - accuracy: 0.9812\n",
      "Epoch 42/200\n",
      "130/130 [==============================] - 0s 585us/step - loss: 0.0635 - accuracy: 0.9806\n",
      "Epoch 43/200\n",
      "130/130 [==============================] - 0s 553us/step - loss: 0.0633 - accuracy: 0.9803\n",
      "Epoch 44/200\n",
      "130/130 [==============================] - 0s 580us/step - loss: 0.0614 - accuracy: 0.9818\n",
      "Epoch 45/200\n",
      "130/130 [==============================] - 0s 597us/step - loss: 0.0603 - accuracy: 0.9815\n",
      "Epoch 46/200\n",
      "130/130 [==============================] - 0s 586us/step - loss: 0.0660 - accuracy: 0.9818\n",
      "Epoch 47/200\n",
      "130/130 [==============================] - 0s 627us/step - loss: 0.0640 - accuracy: 0.9809\n",
      "Epoch 48/200\n",
      "130/130 [==============================] - 0s 652us/step - loss: 0.0587 - accuracy: 0.9817\n",
      "Epoch 49/200\n",
      "130/130 [==============================] - 0s 590us/step - loss: 0.0592 - accuracy: 0.9825\n",
      "Epoch 50/200\n",
      "130/130 [==============================] - 0s 596us/step - loss: 0.0599 - accuracy: 0.9829\n",
      "Epoch 51/200\n",
      "130/130 [==============================] - 0s 588us/step - loss: 0.0641 - accuracy: 0.9809\n",
      "Epoch 52/200\n",
      "130/130 [==============================] - 0s 588us/step - loss: 0.0602 - accuracy: 0.9838\n",
      "Epoch 53/200\n",
      "130/130 [==============================] - 0s 559us/step - loss: 0.0638 - accuracy: 0.9814\n",
      "Epoch 54/200\n",
      "130/130 [==============================] - 0s 576us/step - loss: 0.0610 - accuracy: 0.9831\n",
      "Epoch 55/200\n",
      "130/130 [==============================] - 0s 576us/step - loss: 0.0603 - accuracy: 0.9820\n",
      "Epoch 56/200\n",
      "130/130 [==============================] - 0s 562us/step - loss: 0.0672 - accuracy: 0.9801\n",
      "Epoch 57/200\n",
      "130/130 [==============================] - 0s 559us/step - loss: 0.0580 - accuracy: 0.9825\n",
      "Epoch 58/200\n",
      "130/130 [==============================] - 0s 552us/step - loss: 0.0604 - accuracy: 0.9825\n",
      "Epoch 59/200\n",
      "130/130 [==============================] - 0s 568us/step - loss: 0.0573 - accuracy: 0.9823\n",
      "Epoch 60/200\n",
      "130/130 [==============================] - 0s 578us/step - loss: 0.0586 - accuracy: 0.9828\n",
      "Epoch 61/200\n",
      "130/130 [==============================] - 0s 526us/step - loss: 0.0662 - accuracy: 0.9808\n",
      "Epoch 62/200\n",
      "130/130 [==============================] - 0s 538us/step - loss: 0.0572 - accuracy: 0.9828\n",
      "Epoch 63/200\n",
      "130/130 [==============================] - 0s 564us/step - loss: 0.0623 - accuracy: 0.9815\n",
      "Epoch 64/200\n",
      "130/130 [==============================] - 0s 567us/step - loss: 0.0580 - accuracy: 0.9834\n",
      "Epoch 65/200\n",
      "130/130 [==============================] - 0s 572us/step - loss: 0.0563 - accuracy: 0.9840\n",
      "Epoch 66/200\n",
      "130/130 [==============================] - 0s 568us/step - loss: 0.0592 - accuracy: 0.9828\n",
      "Epoch 67/200\n",
      "130/130 [==============================] - 0s 565us/step - loss: 0.0619 - accuracy: 0.9818\n",
      "Epoch 68/200\n",
      "130/130 [==============================] - 0s 555us/step - loss: 0.0615 - accuracy: 0.9821\n",
      "Epoch 69/200\n",
      "130/130 [==============================] - 0s 565us/step - loss: 0.0603 - accuracy: 0.9831\n",
      "Epoch 70/200\n",
      "130/130 [==============================] - 0s 550us/step - loss: 0.0607 - accuracy: 0.9821\n",
      "Epoch 71/200\n",
      "130/130 [==============================] - 0s 565us/step - loss: 0.0552 - accuracy: 0.9845\n",
      "Epoch 72/200\n",
      "130/130 [==============================] - 0s 553us/step - loss: 0.0590 - accuracy: 0.9832\n",
      "Epoch 73/200\n",
      "130/130 [==============================] - 0s 569us/step - loss: 0.0615 - accuracy: 0.9801\n",
      "Epoch 74/200\n",
      "130/130 [==============================] - 0s 569us/step - loss: 0.0592 - accuracy: 0.9835\n",
      "Epoch 75/200\n",
      "130/130 [==============================] - 0s 545us/step - loss: 0.0604 - accuracy: 0.9829\n",
      "Epoch 76/200\n",
      "130/130 [==============================] - 0s 551us/step - loss: 0.0595 - accuracy: 0.9811\n",
      "Epoch 77/200\n",
      "130/130 [==============================] - 0s 541us/step - loss: 0.0581 - accuracy: 0.9826\n",
      "Epoch 78/200\n",
      "130/130 [==============================] - 0s 554us/step - loss: 0.0581 - accuracy: 0.9854\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 568us/step - loss: 0.0581 - accuracy: 0.9829\n",
      "Epoch 80/200\n",
      "130/130 [==============================] - 0s 580us/step - loss: 0.0577 - accuracy: 0.9831\n",
      "Epoch 81/200\n",
      "130/130 [==============================] - 0s 569us/step - loss: 0.0548 - accuracy: 0.9851\n",
      "Epoch 82/200\n",
      "130/130 [==============================] - 0s 581us/step - loss: 0.0548 - accuracy: 0.9851\n",
      "Epoch 83/200\n",
      "130/130 [==============================] - 0s 556us/step - loss: 0.0580 - accuracy: 0.9838\n",
      "Epoch 84/200\n",
      "130/130 [==============================] - 0s 541us/step - loss: 0.0558 - accuracy: 0.9846\n",
      "Epoch 85/200\n",
      "130/130 [==============================] - 0s 560us/step - loss: 0.0570 - accuracy: 0.9841\n",
      "Epoch 86/200\n",
      "130/130 [==============================] - 0s 577us/step - loss: 0.0546 - accuracy: 0.9846\n",
      "Epoch 87/200\n",
      "130/130 [==============================] - 0s 575us/step - loss: 0.0563 - accuracy: 0.9835\n",
      "Epoch 88/200\n",
      "130/130 [==============================] - 0s 559us/step - loss: 0.0545 - accuracy: 0.9845\n",
      "Epoch 89/200\n",
      "130/130 [==============================] - 0s 556us/step - loss: 0.0566 - accuracy: 0.9831\n",
      "Epoch 90/200\n",
      "130/130 [==============================] - 0s 559us/step - loss: 0.0562 - accuracy: 0.9821\n",
      "Epoch 91/200\n",
      "130/130 [==============================] - 0s 561us/step - loss: 0.0577 - accuracy: 0.9832\n",
      "Epoch 92/200\n",
      "130/130 [==============================] - 0s 548us/step - loss: 0.0573 - accuracy: 0.9837\n",
      "Epoch 93/200\n",
      "130/130 [==============================] - 0s 569us/step - loss: 0.0543 - accuracy: 0.9843\n",
      "Epoch 94/200\n",
      "130/130 [==============================] - 0s 566us/step - loss: 0.0545 - accuracy: 0.9846\n",
      "Epoch 95/200\n",
      "130/130 [==============================] - 0s 572us/step - loss: 0.0568 - accuracy: 0.9832\n",
      "Epoch 96/200\n",
      "130/130 [==============================] - 0s 549us/step - loss: 0.0535 - accuracy: 0.9828\n",
      "Epoch 97/200\n",
      "130/130 [==============================] - 0s 559us/step - loss: 0.0572 - accuracy: 0.9834\n",
      "Epoch 98/200\n",
      "130/130 [==============================] - 0s 547us/step - loss: 0.0582 - accuracy: 0.9831\n",
      "Epoch 99/200\n",
      "130/130 [==============================] - 0s 555us/step - loss: 0.0534 - accuracy: 0.9841\n",
      "Epoch 100/200\n",
      "130/130 [==============================] - 0s 558us/step - loss: 0.0564 - accuracy: 0.9825\n",
      "Epoch 101/200\n",
      "130/130 [==============================] - 0s 564us/step - loss: 0.0552 - accuracy: 0.9823\n",
      "Epoch 102/200\n",
      "130/130 [==============================] - 0s 549us/step - loss: 0.0545 - accuracy: 0.9846\n",
      "Epoch 103/200\n",
      "130/130 [==============================] - 0s 570us/step - loss: 0.0557 - accuracy: 0.9837\n",
      "Epoch 104/200\n",
      "130/130 [==============================] - 0s 561us/step - loss: 0.0546 - accuracy: 0.9834\n",
      "Epoch 105/200\n",
      "130/130 [==============================] - 0s 551us/step - loss: 0.0590 - accuracy: 0.9825\n",
      "Epoch 106/200\n",
      "130/130 [==============================] - 0s 554us/step - loss: 0.0525 - accuracy: 0.9840\n",
      "Epoch 107/200\n",
      "130/130 [==============================] - 0s 549us/step - loss: 0.0511 - accuracy: 0.9855\n",
      "Epoch 108/200\n",
      "130/130 [==============================] - 0s 557us/step - loss: 0.0513 - accuracy: 0.9849\n",
      "Epoch 109/200\n",
      "130/130 [==============================] - 0s 565us/step - loss: 0.0547 - accuracy: 0.9837\n",
      "Epoch 110/200\n",
      "130/130 [==============================] - 0s 561us/step - loss: 0.0519 - accuracy: 0.9852\n",
      "Epoch 111/200\n",
      "130/130 [==============================] - 0s 557us/step - loss: 0.0529 - accuracy: 0.9858\n",
      "Epoch 112/200\n",
      "130/130 [==============================] - 0s 565us/step - loss: 0.0523 - accuracy: 0.9845\n",
      "Epoch 113/200\n",
      "130/130 [==============================] - 0s 562us/step - loss: 0.0525 - accuracy: 0.9843\n",
      "Epoch 114/200\n",
      "130/130 [==============================] - 0s 552us/step - loss: 0.0498 - accuracy: 0.9857\n",
      "Epoch 115/200\n",
      "130/130 [==============================] - 0s 577us/step - loss: 0.0504 - accuracy: 0.9846\n",
      "Epoch 116/200\n",
      "130/130 [==============================] - 0s 568us/step - loss: 0.0566 - accuracy: 0.9837\n",
      "Epoch 117/200\n",
      "130/130 [==============================] - 0s 575us/step - loss: 0.0501 - accuracy: 0.9858\n",
      "Epoch 118/200\n",
      "130/130 [==============================] - 0s 567us/step - loss: 0.0506 - accuracy: 0.9851\n",
      "Epoch 119/200\n",
      "130/130 [==============================] - 0s 559us/step - loss: 0.0521 - accuracy: 0.9854\n",
      "Epoch 120/200\n",
      "130/130 [==============================] - 0s 535us/step - loss: 0.0487 - accuracy: 0.9863\n",
      "Epoch 121/200\n",
      "130/130 [==============================] - 0s 555us/step - loss: 0.0507 - accuracy: 0.9846\n",
      "Epoch 122/200\n",
      "130/130 [==============================] - 0s 569us/step - loss: 0.0522 - accuracy: 0.9851\n",
      "Epoch 123/200\n",
      "130/130 [==============================] - 0s 550us/step - loss: 0.0506 - accuracy: 0.9849\n",
      "Epoch 124/200\n",
      "130/130 [==============================] - 0s 554us/step - loss: 0.0500 - accuracy: 0.9858\n",
      "Epoch 125/200\n",
      "130/130 [==============================] - 0s 559us/step - loss: 0.0494 - accuracy: 0.9858\n",
      "Epoch 126/200\n",
      "130/130 [==============================] - 0s 565us/step - loss: 0.0547 - accuracy: 0.9848\n",
      "Epoch 127/200\n",
      "130/130 [==============================] - 0s 565us/step - loss: 0.0520 - accuracy: 0.9855\n",
      "Epoch 128/200\n",
      "130/130 [==============================] - 0s 562us/step - loss: 0.0526 - accuracy: 0.9863\n",
      "Epoch 129/200\n",
      "130/130 [==============================] - 0s 550us/step - loss: 0.0496 - accuracy: 0.9871\n",
      "Epoch 130/200\n",
      "130/130 [==============================] - 0s 563us/step - loss: 0.0482 - accuracy: 0.9869\n",
      "Epoch 131/200\n",
      "130/130 [==============================] - 0s 567us/step - loss: 0.0486 - accuracy: 0.9863\n",
      "Epoch 132/200\n",
      "130/130 [==============================] - 0s 583us/step - loss: 0.0501 - accuracy: 0.9861\n",
      "Epoch 133/200\n",
      "130/130 [==============================] - 0s 563us/step - loss: 0.0528 - accuracy: 0.9851\n",
      "Epoch 134/200\n",
      "130/130 [==============================] - 0s 553us/step - loss: 0.0505 - accuracy: 0.9860\n",
      "Epoch 135/200\n",
      "130/130 [==============================] - 0s 561us/step - loss: 0.0463 - accuracy: 0.9888\n",
      "Epoch 136/200\n",
      "130/130 [==============================] - 0s 547us/step - loss: 0.0494 - accuracy: 0.9857\n",
      "Epoch 137/200\n",
      "130/130 [==============================] - 0s 612us/step - loss: 0.0481 - accuracy: 0.9863\n",
      "Epoch 138/200\n",
      "130/130 [==============================] - 0s 629us/step - loss: 0.0484 - accuracy: 0.9865\n",
      "Epoch 139/200\n",
      "130/130 [==============================] - 0s 653us/step - loss: 0.0495 - accuracy: 0.9857\n",
      "Epoch 140/200\n",
      "130/130 [==============================] - 0s 634us/step - loss: 0.0487 - accuracy: 0.9868\n",
      "Epoch 141/200\n",
      "130/130 [==============================] - 0s 662us/step - loss: 0.0460 - accuracy: 0.9871\n",
      "Epoch 142/200\n",
      "130/130 [==============================] - 0s 650us/step - loss: 0.0490 - accuracy: 0.9849\n",
      "Epoch 143/200\n",
      "130/130 [==============================] - 0s 587us/step - loss: 0.0494 - accuracy: 0.9872\n",
      "Epoch 144/200\n",
      "130/130 [==============================] - 0s 561us/step - loss: 0.0449 - accuracy: 0.9872\n",
      "Epoch 145/200\n",
      "130/130 [==============================] - 0s 568us/step - loss: 0.0457 - accuracy: 0.9872\n",
      "Epoch 146/200\n",
      "130/130 [==============================] - 0s 554us/step - loss: 0.0458 - accuracy: 0.9875\n",
      "Epoch 147/200\n",
      "130/130 [==============================] - 0s 537us/step - loss: 0.0474 - accuracy: 0.9880\n",
      "Epoch 148/200\n",
      "130/130 [==============================] - 0s 567us/step - loss: 0.0479 - accuracy: 0.9869\n",
      "Epoch 149/200\n",
      "130/130 [==============================] - 0s 557us/step - loss: 0.0478 - accuracy: 0.9860\n",
      "Epoch 150/200\n",
      "130/130 [==============================] - 0s 565us/step - loss: 0.0458 - accuracy: 0.9874\n",
      "Epoch 151/200\n",
      "130/130 [==============================] - 0s 567us/step - loss: 0.0439 - accuracy: 0.9888\n",
      "Epoch 152/200\n",
      "130/130 [==============================] - 0s 570us/step - loss: 0.0436 - accuracy: 0.9885\n",
      "Epoch 153/200\n",
      "130/130 [==============================] - 0s 546us/step - loss: 0.0448 - accuracy: 0.9888\n",
      "Epoch 154/200\n",
      "130/130 [==============================] - 0s 575us/step - loss: 0.0451 - accuracy: 0.9883\n",
      "Epoch 155/200\n",
      "130/130 [==============================] - 0s 551us/step - loss: 0.0444 - accuracy: 0.9897\n",
      "Epoch 156/200\n",
      "130/130 [==============================] - 0s 594us/step - loss: 0.0465 - accuracy: 0.9874\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 571us/step - loss: 0.0486 - accuracy: 0.9877\n",
      "Epoch 158/200\n",
      "130/130 [==============================] - 0s 560us/step - loss: 0.0424 - accuracy: 0.9900\n",
      "Epoch 159/200\n",
      "130/130 [==============================] - 0s 548us/step - loss: 0.0439 - accuracy: 0.9888\n",
      "Epoch 160/200\n",
      "130/130 [==============================] - 0s 559us/step - loss: 0.0455 - accuracy: 0.9877\n",
      "Epoch 161/200\n",
      "130/130 [==============================] - 0s 554us/step - loss: 0.0429 - accuracy: 0.9886\n",
      "Epoch 162/200\n",
      "130/130 [==============================] - 0s 562us/step - loss: 0.0417 - accuracy: 0.9877\n",
      "Epoch 163/200\n",
      "130/130 [==============================] - 0s 549us/step - loss: 0.0460 - accuracy: 0.9886\n",
      "Epoch 164/200\n",
      "130/130 [==============================] - 0s 562us/step - loss: 0.0426 - accuracy: 0.9885\n",
      "Epoch 165/200\n",
      "130/130 [==============================] - 0s 556us/step - loss: 0.0461 - accuracy: 0.9860\n",
      "Epoch 166/200\n",
      "130/130 [==============================] - 0s 551us/step - loss: 0.0419 - accuracy: 0.9880\n",
      "Epoch 167/200\n",
      "130/130 [==============================] - 0s 552us/step - loss: 0.0431 - accuracy: 0.9881\n",
      "Epoch 168/200\n",
      "130/130 [==============================] - 0s 571us/step - loss: 0.0433 - accuracy: 0.9885\n",
      "Epoch 169/200\n",
      "130/130 [==============================] - 0s 566us/step - loss: 0.0441 - accuracy: 0.9885\n",
      "Epoch 170/200\n",
      "130/130 [==============================] - 0s 564us/step - loss: 0.0438 - accuracy: 0.9883\n",
      "Epoch 171/200\n",
      "130/130 [==============================] - 0s 557us/step - loss: 0.0422 - accuracy: 0.9877\n",
      "Epoch 172/200\n",
      "130/130 [==============================] - 0s 558us/step - loss: 0.0404 - accuracy: 0.9898\n",
      "Epoch 173/200\n",
      "130/130 [==============================] - 0s 572us/step - loss: 0.0406 - accuracy: 0.9894\n",
      "Epoch 174/200\n",
      "130/130 [==============================] - 0s 542us/step - loss: 0.0444 - accuracy: 0.9872\n",
      "Epoch 175/200\n",
      "130/130 [==============================] - 0s 568us/step - loss: 0.0408 - accuracy: 0.9891\n",
      "Epoch 176/200\n",
      "130/130 [==============================] - 0s 543us/step - loss: 0.0433 - accuracy: 0.9880\n",
      "Epoch 177/200\n",
      "130/130 [==============================] - 0s 561us/step - loss: 0.0420 - accuracy: 0.9895\n",
      "Epoch 178/200\n",
      "130/130 [==============================] - 0s 548us/step - loss: 0.0451 - accuracy: 0.9886\n",
      "Epoch 179/200\n",
      "130/130 [==============================] - 0s 540us/step - loss: 0.0403 - accuracy: 0.9892\n",
      "Epoch 180/200\n",
      "130/130 [==============================] - 0s 538us/step - loss: 0.0404 - accuracy: 0.9891\n",
      "Epoch 181/200\n",
      "130/130 [==============================] - 0s 545us/step - loss: 0.0408 - accuracy: 0.9891\n",
      "Epoch 182/200\n",
      "130/130 [==============================] - 0s 558us/step - loss: 0.0400 - accuracy: 0.9874\n",
      "Epoch 183/200\n",
      "130/130 [==============================] - 0s 574us/step - loss: 0.0398 - accuracy: 0.9900\n",
      "Epoch 184/200\n",
      "130/130 [==============================] - 0s 545us/step - loss: 0.0411 - accuracy: 0.9881\n",
      "Epoch 185/200\n",
      "130/130 [==============================] - 0s 555us/step - loss: 0.0383 - accuracy: 0.9898\n",
      "Epoch 186/200\n",
      "130/130 [==============================] - 0s 555us/step - loss: 0.0387 - accuracy: 0.9900\n",
      "Epoch 187/200\n",
      "130/130 [==============================] - 0s 593us/step - loss: 0.0416 - accuracy: 0.9888\n",
      "Epoch 188/200\n",
      "130/130 [==============================] - 0s 542us/step - loss: 0.0453 - accuracy: 0.9872\n",
      "Epoch 189/200\n",
      "130/130 [==============================] - 0s 565us/step - loss: 0.0403 - accuracy: 0.9891\n",
      "Epoch 190/200\n",
      "130/130 [==============================] - 0s 552us/step - loss: 0.0388 - accuracy: 0.9903\n",
      "Epoch 191/200\n",
      "130/130 [==============================] - 0s 545us/step - loss: 0.0435 - accuracy: 0.9883\n",
      "Epoch 192/200\n",
      "130/130 [==============================] - 0s 576us/step - loss: 0.0394 - accuracy: 0.9895\n",
      "Epoch 193/200\n",
      "130/130 [==============================] - 0s 557us/step - loss: 0.0393 - accuracy: 0.9881\n",
      "Epoch 194/200\n",
      "130/130 [==============================] - 0s 550us/step - loss: 0.0391 - accuracy: 0.9898\n",
      "Epoch 195/200\n",
      "130/130 [==============================] - 0s 570us/step - loss: 0.0390 - accuracy: 0.9892\n",
      "Epoch 196/200\n",
      "130/130 [==============================] - 0s 552us/step - loss: 0.0406 - accuracy: 0.9880\n",
      "Epoch 197/200\n",
      "130/130 [==============================] - 0s 564us/step - loss: 0.0400 - accuracy: 0.9892\n",
      "Epoch 198/200\n",
      "130/130 [==============================] - 0s 577us/step - loss: 0.0397 - accuracy: 0.9894\n",
      "Epoch 199/200\n",
      "130/130 [==============================] - 0s 574us/step - loss: 0.0463 - accuracy: 0.9869\n",
      "Epoch 200/200\n",
      "130/130 [==============================] - 0s 576us/step - loss: 0.0381 - accuracy: 0.9898\n",
      "204/204 [==============================] - 0s 477us/step - loss: 0.0342 - accuracy: 0.9918\n",
      "\n",
      " Accuracy : 0.9918\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df_pre = pd.read_csv('wine.csv', header = None)\n",
    "df = df_pre.sample(frac = 1) \n",
    "dataset = df.values\n",
    "\n",
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#히든레이어 3개\n",
    "model.add(Dense(30, input_dim = 12, activation = 'relu'))  #히든레이어\n",
    "model.add(Dense(12, activation = 'relu'))                  #히든레이어\n",
    "model.add(Dense(8, activation = 'relu'))                   #히든레이어\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',   \n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs = 200, batch_size = 50)   \n",
    "\n",
    "print(\"\\n Accuracy : %.4f\" % (model.evaluate(X, Y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 모델 업데이트하기 ✨\n",
    "- 에포크마다 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint   # 모델을 저장하기위해 케라스의 콜백 함수 중 이걸 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to ./model\\01-0.0328.hdf5\n",
      "\n",
      "Epoch 00002: saving model to ./model\\02-0.0341.hdf5\n",
      "\n",
      "Epoch 00003: saving model to ./model\\03-0.0370.hdf5\n",
      "\n",
      "Epoch 00004: saving model to ./model\\04-0.0359.hdf5\n",
      "\n",
      "Epoch 00005: saving model to ./model\\05-0.0349.hdf5\n",
      "\n",
      "Epoch 00006: saving model to ./model\\06-0.0344.hdf5\n",
      "\n",
      "Epoch 00007: saving model to ./model\\07-0.0346.hdf5\n",
      "\n",
      "Epoch 00008: saving model to ./model\\08-0.0391.hdf5\n",
      "\n",
      "Epoch 00009: saving model to ./model\\09-0.0355.hdf5\n",
      "\n",
      "Epoch 00010: saving model to ./model\\10-0.0358.hdf5\n",
      "\n",
      "Epoch 00011: saving model to ./model\\11-0.0362.hdf5\n",
      "\n",
      "Epoch 00012: saving model to ./model\\12-0.0349.hdf5\n",
      "\n",
      "Epoch 00013: saving model to ./model\\13-0.0350.hdf5\n",
      "\n",
      "Epoch 00014: saving model to ./model\\14-0.0345.hdf5\n",
      "\n",
      "Epoch 00015: saving model to ./model\\15-0.0352.hdf5\n",
      "\n",
      "Epoch 00016: saving model to ./model\\16-0.0371.hdf5\n",
      "\n",
      "Epoch 00017: saving model to ./model\\17-0.0355.hdf5\n",
      "\n",
      "Epoch 00018: saving model to ./model\\18-0.0350.hdf5\n",
      "\n",
      "Epoch 00019: saving model to ./model\\19-0.0352.hdf5\n",
      "\n",
      "Epoch 00020: saving model to ./model\\20-0.0355.hdf5\n",
      "\n",
      "Epoch 00021: saving model to ./model\\21-0.0362.hdf5\n",
      "\n",
      "Epoch 00022: saving model to ./model\\22-0.0414.hdf5\n",
      "\n",
      "Epoch 00023: saving model to ./model\\23-0.0353.hdf5\n",
      "\n",
      "Epoch 00024: saving model to ./model\\24-0.0359.hdf5\n",
      "\n",
      "Epoch 00025: saving model to ./model\\25-0.0359.hdf5\n",
      "\n",
      "Epoch 00026: saving model to ./model\\26-0.0360.hdf5\n",
      "\n",
      "Epoch 00027: saving model to ./model\\27-0.0350.hdf5\n",
      "\n",
      "Epoch 00028: saving model to ./model\\28-0.0364.hdf5\n",
      "\n",
      "Epoch 00029: saving model to ./model\\29-0.0374.hdf5\n",
      "\n",
      "Epoch 00030: saving model to ./model\\30-0.0356.hdf5\n",
      "\n",
      "Epoch 00031: saving model to ./model\\31-0.0354.hdf5\n",
      "\n",
      "Epoch 00032: saving model to ./model\\32-0.0366.hdf5\n",
      "\n",
      "Epoch 00033: saving model to ./model\\33-0.0363.hdf5\n",
      "\n",
      "Epoch 00034: saving model to ./model\\34-0.0363.hdf5\n",
      "\n",
      "Epoch 00035: saving model to ./model\\35-0.0376.hdf5\n",
      "\n",
      "Epoch 00036: saving model to ./model\\36-0.0361.hdf5\n",
      "\n",
      "Epoch 00037: saving model to ./model\\37-0.0353.hdf5\n",
      "\n",
      "Epoch 00038: saving model to ./model\\38-0.0369.hdf5\n",
      "\n",
      "Epoch 00039: saving model to ./model\\39-0.0348.hdf5\n",
      "\n",
      "Epoch 00040: saving model to ./model\\40-0.0355.hdf5\n",
      "\n",
      "Epoch 00041: saving model to ./model\\41-0.0345.hdf5\n",
      "\n",
      "Epoch 00042: saving model to ./model\\42-0.0366.hdf5\n",
      "\n",
      "Epoch 00043: saving model to ./model\\43-0.0356.hdf5\n",
      "\n",
      "Epoch 00044: saving model to ./model\\44-0.0368.hdf5\n",
      "\n",
      "Epoch 00045: saving model to ./model\\45-0.0355.hdf5\n",
      "\n",
      "Epoch 00046: saving model to ./model\\46-0.0350.hdf5\n",
      "\n",
      "Epoch 00047: saving model to ./model\\47-0.0423.hdf5\n",
      "\n",
      "Epoch 00048: saving model to ./model\\48-0.0346.hdf5\n",
      "\n",
      "Epoch 00049: saving model to ./model\\49-0.0364.hdf5\n",
      "\n",
      "Epoch 00050: saving model to ./model\\50-0.0349.hdf5\n",
      "\n",
      "Epoch 00051: saving model to ./model\\51-0.0381.hdf5\n",
      "\n",
      "Epoch 00052: saving model to ./model\\52-0.0347.hdf5\n",
      "\n",
      "Epoch 00053: saving model to ./model\\53-0.0360.hdf5\n",
      "\n",
      "Epoch 00054: saving model to ./model\\54-0.0348.hdf5\n",
      "\n",
      "Epoch 00055: saving model to ./model\\55-0.0348.hdf5\n",
      "\n",
      "Epoch 00056: saving model to ./model\\56-0.0364.hdf5\n",
      "\n",
      "Epoch 00057: saving model to ./model\\57-0.0343.hdf5\n",
      "\n",
      "Epoch 00058: saving model to ./model\\58-0.0395.hdf5\n",
      "\n",
      "Epoch 00059: saving model to ./model\\59-0.0337.hdf5\n",
      "\n",
      "Epoch 00060: saving model to ./model\\60-0.0394.hdf5\n",
      "\n",
      "Epoch 00061: saving model to ./model\\61-0.0360.hdf5\n",
      "\n",
      "Epoch 00062: saving model to ./model\\62-0.0353.hdf5\n",
      "\n",
      "Epoch 00063: saving model to ./model\\63-0.0420.hdf5\n",
      "\n",
      "Epoch 00064: saving model to ./model\\64-0.0352.hdf5\n",
      "\n",
      "Epoch 00065: saving model to ./model\\65-0.0340.hdf5\n",
      "\n",
      "Epoch 00066: saving model to ./model\\66-0.0369.hdf5\n",
      "\n",
      "Epoch 00067: saving model to ./model\\67-0.0376.hdf5\n",
      "\n",
      "Epoch 00068: saving model to ./model\\68-0.0353.hdf5\n",
      "\n",
      "Epoch 00069: saving model to ./model\\69-0.0346.hdf5\n",
      "\n",
      "Epoch 00070: saving model to ./model\\70-0.0340.hdf5\n",
      "\n",
      "Epoch 00071: saving model to ./model\\71-0.0364.hdf5\n",
      "\n",
      "Epoch 00072: saving model to ./model\\72-0.0351.hdf5\n",
      "\n",
      "Epoch 00073: saving model to ./model\\73-0.0389.hdf5\n",
      "\n",
      "Epoch 00074: saving model to ./model\\74-0.0338.hdf5\n",
      "\n",
      "Epoch 00075: saving model to ./model\\75-0.0354.hdf5\n",
      "\n",
      "Epoch 00076: saving model to ./model\\76-0.0406.hdf5\n",
      "\n",
      "Epoch 00077: saving model to ./model\\77-0.0366.hdf5\n",
      "\n",
      "Epoch 00078: saving model to ./model\\78-0.0370.hdf5\n",
      "\n",
      "Epoch 00079: saving model to ./model\\79-0.0342.hdf5\n",
      "\n",
      "Epoch 00080: saving model to ./model\\80-0.0355.hdf5\n",
      "\n",
      "Epoch 00081: saving model to ./model\\81-0.0372.hdf5\n",
      "\n",
      "Epoch 00082: saving model to ./model\\82-0.0340.hdf5\n",
      "\n",
      "Epoch 00083: saving model to ./model\\83-0.0368.hdf5\n",
      "\n",
      "Epoch 00084: saving model to ./model\\84-0.0354.hdf5\n",
      "\n",
      "Epoch 00085: saving model to ./model\\85-0.0387.hdf5\n",
      "\n",
      "Epoch 00086: saving model to ./model\\86-0.0344.hdf5\n",
      "\n",
      "Epoch 00087: saving model to ./model\\87-0.0368.hdf5\n",
      "\n",
      "Epoch 00088: saving model to ./model\\88-0.0360.hdf5\n",
      "\n",
      "Epoch 00089: saving model to ./model\\89-0.0426.hdf5\n",
      "\n",
      "Epoch 00090: saving model to ./model\\90-0.0367.hdf5\n",
      "\n",
      "Epoch 00091: saving model to ./model\\91-0.0348.hdf5\n",
      "\n",
      "Epoch 00092: saving model to ./model\\92-0.0358.hdf5\n",
      "\n",
      "Epoch 00093: saving model to ./model\\93-0.0338.hdf5\n",
      "\n",
      "Epoch 00094: saving model to ./model\\94-0.0384.hdf5\n",
      "\n",
      "Epoch 00095: saving model to ./model\\95-0.0342.hdf5\n",
      "\n",
      "Epoch 00096: saving model to ./model\\96-0.0354.hdf5\n",
      "\n",
      "Epoch 00097: saving model to ./model\\97-0.0359.hdf5\n",
      "\n",
      "Epoch 00098: saving model to ./model\\98-0.0335.hdf5\n",
      "\n",
      "Epoch 00099: saving model to ./model\\99-0.0392.hdf5\n",
      "\n",
      "Epoch 00100: saving model to ./model\\100-0.0320.hdf5\n",
      "\n",
      "Epoch 00101: saving model to ./model\\101-0.0340.hdf5\n",
      "\n",
      "Epoch 00102: saving model to ./model\\102-0.0349.hdf5\n",
      "\n",
      "Epoch 00103: saving model to ./model\\103-0.0371.hdf5\n",
      "\n",
      "Epoch 00104: saving model to ./model\\104-0.0423.hdf5\n",
      "\n",
      "Epoch 00105: saving model to ./model\\105-0.0340.hdf5\n",
      "\n",
      "Epoch 00106: saving model to ./model\\106-0.0344.hdf5\n",
      "\n",
      "Epoch 00107: saving model to ./model\\107-0.0357.hdf5\n",
      "\n",
      "Epoch 00108: saving model to ./model\\108-0.0354.hdf5\n",
      "\n",
      "Epoch 00109: saving model to ./model\\109-0.0353.hdf5\n",
      "\n",
      "Epoch 00110: saving model to ./model\\110-0.0364.hdf5\n",
      "\n",
      "Epoch 00111: saving model to ./model\\111-0.0390.hdf5\n",
      "\n",
      "Epoch 00112: saving model to ./model\\112-0.0367.hdf5\n",
      "\n",
      "Epoch 00113: saving model to ./model\\113-0.0364.hdf5\n",
      "\n",
      "Epoch 00114: saving model to ./model\\114-0.0359.hdf5\n",
      "\n",
      "Epoch 00115: saving model to ./model\\115-0.0367.hdf5\n",
      "\n",
      "Epoch 00116: saving model to ./model\\116-0.0345.hdf5\n",
      "\n",
      "Epoch 00117: saving model to ./model\\117-0.0374.hdf5\n",
      "\n",
      "Epoch 00118: saving model to ./model\\118-0.0370.hdf5\n",
      "\n",
      "Epoch 00119: saving model to ./model\\119-0.0346.hdf5\n",
      "\n",
      "Epoch 00120: saving model to ./model\\120-0.0350.hdf5\n",
      "\n",
      "Epoch 00121: saving model to ./model\\121-0.0405.hdf5\n",
      "\n",
      "Epoch 00122: saving model to ./model\\122-0.0398.hdf5\n",
      "\n",
      "Epoch 00123: saving model to ./model\\123-0.0327.hdf5\n",
      "\n",
      "Epoch 00124: saving model to ./model\\124-0.0375.hdf5\n",
      "\n",
      "Epoch 00125: saving model to ./model\\125-0.0339.hdf5\n",
      "\n",
      "Epoch 00126: saving model to ./model\\126-0.0335.hdf5\n",
      "\n",
      "Epoch 00127: saving model to ./model\\127-0.0360.hdf5\n",
      "\n",
      "Epoch 00128: saving model to ./model\\128-0.0376.hdf5\n",
      "\n",
      "Epoch 00129: saving model to ./model\\129-0.0345.hdf5\n",
      "\n",
      "Epoch 00130: saving model to ./model\\130-0.0385.hdf5\n",
      "\n",
      "Epoch 00131: saving model to ./model\\131-0.0410.hdf5\n",
      "\n",
      "Epoch 00132: saving model to ./model\\132-0.0420.hdf5\n",
      "\n",
      "Epoch 00133: saving model to ./model\\133-0.0382.hdf5\n",
      "\n",
      "Epoch 00134: saving model to ./model\\134-0.0336.hdf5\n",
      "\n",
      "Epoch 00135: saving model to ./model\\135-0.0369.hdf5\n",
      "\n",
      "Epoch 00136: saving model to ./model\\136-0.0363.hdf5\n",
      "\n",
      "Epoch 00137: saving model to ./model\\137-0.0369.hdf5\n",
      "\n",
      "Epoch 00138: saving model to ./model\\138-0.0342.hdf5\n",
      "\n",
      "Epoch 00139: saving model to ./model\\139-0.0364.hdf5\n",
      "\n",
      "Epoch 00140: saving model to ./model\\140-0.0341.hdf5\n",
      "\n",
      "Epoch 00141: saving model to ./model\\141-0.0334.hdf5\n",
      "\n",
      "Epoch 00142: saving model to ./model\\142-0.0357.hdf5\n",
      "\n",
      "Epoch 00143: saving model to ./model\\143-0.0346.hdf5\n",
      "\n",
      "Epoch 00144: saving model to ./model\\144-0.0389.hdf5\n",
      "\n",
      "Epoch 00145: saving model to ./model\\145-0.0351.hdf5\n",
      "\n",
      "Epoch 00146: saving model to ./model\\146-0.0376.hdf5\n",
      "\n",
      "Epoch 00147: saving model to ./model\\147-0.0362.hdf5\n",
      "\n",
      "Epoch 00148: saving model to ./model\\148-0.0352.hdf5\n",
      "\n",
      "Epoch 00149: saving model to ./model\\149-0.0424.hdf5\n",
      "\n",
      "Epoch 00150: saving model to ./model\\150-0.0389.hdf5\n",
      "\n",
      "Epoch 00151: saving model to ./model\\151-0.0332.hdf5\n",
      "\n",
      "Epoch 00152: saving model to ./model\\152-0.0336.hdf5\n",
      "\n",
      "Epoch 00153: saving model to ./model\\153-0.0368.hdf5\n",
      "\n",
      "Epoch 00154: saving model to ./model\\154-0.0336.hdf5\n",
      "\n",
      "Epoch 00155: saving model to ./model\\155-0.0366.hdf5\n",
      "\n",
      "Epoch 00156: saving model to ./model\\156-0.0353.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00157: saving model to ./model\\157-0.0439.hdf5\n",
      "\n",
      "Epoch 00158: saving model to ./model\\158-0.0369.hdf5\n",
      "\n",
      "Epoch 00159: saving model to ./model\\159-0.0386.hdf5\n",
      "\n",
      "Epoch 00160: saving model to ./model\\160-0.0338.hdf5\n",
      "\n",
      "Epoch 00161: saving model to ./model\\161-0.0396.hdf5\n",
      "\n",
      "Epoch 00162: saving model to ./model\\162-0.0354.hdf5\n",
      "\n",
      "Epoch 00163: saving model to ./model\\163-0.0364.hdf5\n",
      "\n",
      "Epoch 00164: saving model to ./model\\164-0.0343.hdf5\n",
      "\n",
      "Epoch 00165: saving model to ./model\\165-0.0354.hdf5\n",
      "\n",
      "Epoch 00166: saving model to ./model\\166-0.0343.hdf5\n",
      "\n",
      "Epoch 00167: saving model to ./model\\167-0.0346.hdf5\n",
      "\n",
      "Epoch 00168: saving model to ./model\\168-0.0338.hdf5\n",
      "\n",
      "Epoch 00169: saving model to ./model\\169-0.0353.hdf5\n",
      "\n",
      "Epoch 00170: saving model to ./model\\170-0.0358.hdf5\n",
      "\n",
      "Epoch 00171: saving model to ./model\\171-0.0344.hdf5\n",
      "\n",
      "Epoch 00172: saving model to ./model\\172-0.0385.hdf5\n",
      "\n",
      "Epoch 00173: saving model to ./model\\173-0.0355.hdf5\n",
      "\n",
      "Epoch 00174: saving model to ./model\\174-0.0355.hdf5\n",
      "\n",
      "Epoch 00175: saving model to ./model\\175-0.0346.hdf5\n",
      "\n",
      "Epoch 00176: saving model to ./model\\176-0.0379.hdf5\n",
      "\n",
      "Epoch 00177: saving model to ./model\\177-0.0406.hdf5\n",
      "\n",
      "Epoch 00178: saving model to ./model\\178-0.0353.hdf5\n",
      "\n",
      "Epoch 00179: saving model to ./model\\179-0.0353.hdf5\n",
      "\n",
      "Epoch 00180: saving model to ./model\\180-0.0346.hdf5\n",
      "\n",
      "Epoch 00181: saving model to ./model\\181-0.0326.hdf5\n",
      "\n",
      "Epoch 00182: saving model to ./model\\182-0.0381.hdf5\n",
      "\n",
      "Epoch 00183: saving model to ./model\\183-0.0368.hdf5\n",
      "\n",
      "Epoch 00184: saving model to ./model\\184-0.0338.hdf5\n",
      "\n",
      "Epoch 00185: saving model to ./model\\185-0.0382.hdf5\n",
      "\n",
      "Epoch 00186: saving model to ./model\\186-0.0367.hdf5\n",
      "\n",
      "Epoch 00187: saving model to ./model\\187-0.0360.hdf5\n",
      "\n",
      "Epoch 00188: saving model to ./model\\188-0.0339.hdf5\n",
      "\n",
      "Epoch 00189: saving model to ./model\\189-0.0391.hdf5\n",
      "\n",
      "Epoch 00190: saving model to ./model\\190-0.0362.hdf5\n",
      "\n",
      "Epoch 00191: saving model to ./model\\191-0.0359.hdf5\n",
      "\n",
      "Epoch 00192: saving model to ./model\\192-0.0325.hdf5\n",
      "\n",
      "Epoch 00193: saving model to ./model\\193-0.0368.hdf5\n",
      "\n",
      "Epoch 00194: saving model to ./model\\194-0.0392.hdf5\n",
      "\n",
      "Epoch 00195: saving model to ./model\\195-0.0366.hdf5\n",
      "\n",
      "Epoch 00196: saving model to ./model\\196-0.0336.hdf5\n",
      "\n",
      "Epoch 00197: saving model to ./model\\197-0.0366.hdf5\n",
      "\n",
      "Epoch 00198: saving model to ./model\\198-0.0471.hdf5\n",
      "\n",
      "Epoch 00199: saving model to ./model\\199-0.0363.hdf5\n",
      "\n",
      "Epoch 00200: saving model to ./model\\200-0.0355.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a2ece70488>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, validation_split = 0.2, epochs = 200, batch_size = 200, verbose = 0,\n",
    "         callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29722, saving model to ./model\\01-0.2972.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29722 to 0.25425, saving model to ./model\\02-0.2543.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.25425 to 0.23356, saving model to ./model\\03-0.2336.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23356 to 0.21444, saving model to ./model\\04-0.2144.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21444 to 0.19984, saving model to ./model\\05-0.1998.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19984 to 0.19539, saving model to ./model\\06-0.1954.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.19539 to 0.19016, saving model to ./model\\07-0.1902.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19016\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.19016 to 0.18586, saving model to ./model\\09-0.1859.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.18586 to 0.18406, saving model to ./model\\10-0.1841.hdf5\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18406\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18406 to 0.17748, saving model to ./model\\12-0.1775.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.17748 to 0.17532, saving model to ./model\\13-0.1753.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.17532 to 0.17184, saving model to ./model\\14-0.1718.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17184 to 0.16910, saving model to ./model\\15-0.1691.hdf5\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16910\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.16910 to 0.16181, saving model to ./model\\17-0.1618.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16181\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.16181 to 0.15618, saving model to ./model\\19-0.1562.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.15618 to 0.15234, saving model to ./model\\20-0.1523.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.15234 to 0.14853, saving model to ./model\\21-0.1485.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.14853 to 0.14607, saving model to ./model\\22-0.1461.hdf5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.14607\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14607 to 0.14017, saving model to ./model\\24-0.1402.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.14017 to 0.13896, saving model to ./model\\25-0.1390.hdf5\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.13896 to 0.13648, saving model to ./model\\26-0.1365.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.13648 to 0.13404, saving model to ./model\\27-0.1340.hdf5\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.13404\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.13404 to 0.12704, saving model to ./model\\29-0.1270.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.12704 to 0.12473, saving model to ./model\\30-0.1247.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.12473 to 0.12384, saving model to ./model\\31-0.1238.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.12384 to 0.12259, saving model to ./model\\32-0.1226.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.12259 to 0.11661, saving model to ./model\\33-0.1166.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.11661 to 0.11613, saving model to ./model\\34-0.1161.hdf5\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.11613 to 0.11273, saving model to ./model\\35-0.1127.hdf5\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11273\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11273\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.11273 to 0.10735, saving model to ./model\\38-0.1074.hdf5\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.10735 to 0.10549, saving model to ./model\\39-0.1055.hdf5\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10549\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10549\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.10549 to 0.09682, saving model to ./model\\42-0.0968.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.09682 to 0.09665, saving model to ./model\\43-0.0967.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.09665\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.09665 to 0.09266, saving model to ./model\\45-0.0927.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.09266 to 0.09130, saving model to ./model\\46-0.0913.hdf5\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.09130\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.09130\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.09130 to 0.08785, saving model to ./model\\49-0.0879.hdf5\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.08785 to 0.08720, saving model to ./model\\50-0.0872.hdf5\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.08720 to 0.08371, saving model to ./model\\51-0.0837.hdf5\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.08371\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.08371\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.08371\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.08371 to 0.07985, saving model to ./model\\55-0.0798.hdf5\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.07985 to 0.07835, saving model to ./model\\56-0.0784.hdf5\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.07835 to 0.07805, saving model to ./model\\57-0.0781.hdf5\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.07805\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.07805 to 0.07646, saving model to ./model\\59-0.0765.hdf5\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.07646 to 0.07473, saving model to ./model\\60-0.0747.hdf5\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.07473\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.07473\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.07473\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07473 to 0.07291, saving model to ./model\\64-0.0729.hdf5\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.07291\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07291 to 0.07016, saving model to ./model\\66-0.0702.hdf5\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.07016\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07016 to 0.06992, saving model to ./model\\68-0.0699.hdf5\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06992 to 0.06726, saving model to ./model\\71-0.0673.hdf5\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06726 to 0.06652, saving model to ./model\\74-0.0665.hdf5\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06652\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.06652\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06652 to 0.06574, saving model to ./model\\77-0.0657.hdf5\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.06574 to 0.06550, saving model to ./model\\78-0.0655.hdf5\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.06550\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.06550\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.06550\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06550 to 0.06544, saving model to ./model\\82-0.0654.hdf5\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06544 to 0.06391, saving model to ./model\\83-0.0639.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06391 to 0.06286, saving model to ./model\\84-0.0629.hdf5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.06286\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.06286\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.06286\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.06286 to 0.06137, saving model to ./model\\88-0.0614.hdf5\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.06137\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.06137\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.06137\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.06137\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.06137 to 0.06019, saving model to ./model\\93-0.0602.hdf5\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.06019\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.06019\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.06019 to 0.06018, saving model to ./model\\96-0.0602.hdf5\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.06018\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.06018 to 0.05950, saving model to ./model\\98-0.0595.hdf5\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05950\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05950\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.05950 to 0.05810, saving model to ./model\\101-0.0581.hdf5\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.05810\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.05810\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.05810 to 0.05765, saving model to ./model\\104-0.0577.hdf5\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.05765 to 0.05686, saving model to ./model\\105-0.0569.hdf5\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.05686\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.05686\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.05686\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.05686\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.05686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00111: val_loss improved from 0.05686 to 0.05665, saving model to ./model\\111-0.0567.hdf5\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.05665\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.05665 to 0.05583, saving model to ./model\\113-0.0558.hdf5\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.05583\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.05583\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.05583\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.05583 to 0.05531, saving model to ./model\\117-0.0553.hdf5\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.05531 to 0.05483, saving model to ./model\\125-0.0548.hdf5\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.05483\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.05483\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.05483 to 0.05457, saving model to ./model\\128-0.0546.hdf5\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.05457\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.05457 to 0.05359, saving model to ./model\\130-0.0536.hdf5\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.05359\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.05359\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.05359\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.05359\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.05359 to 0.05315, saving model to ./model\\135-0.0532.hdf5\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.05315\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.05315\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.05315\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.05315\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.05315\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.05315 to 0.05294, saving model to ./model\\141-0.0529.hdf5\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.05294\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.05294\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.05294\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.05294\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.05294\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.05294 to 0.05247, saving model to ./model\\147-0.0525.hdf5\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.05247 to 0.05240, saving model to ./model\\156-0.0524.hdf5\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.05240\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.05240\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.05240\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.05240\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.05240\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.05240 to 0.05213, saving model to ./model\\162-0.0521.hdf5\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.05213\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.05213\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.05213\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.05213 to 0.05133, saving model to ./model\\166-0.0513.hdf5\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.05133 to 0.05058, saving model to ./model\\197-0.0506.hdf5\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.05058\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.05058\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.05058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a2ecd000c8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df_pre = pd.read_csv('wine.csv', header = None)\n",
    "df = df_pre.sample(frac = 1) \n",
    "dataset = df.values\n",
    "\n",
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#히든레이어 3개\n",
    "model.add(Dense(30, input_dim = 12, activation = 'relu'))  #히든레이어\n",
    "model.add(Dense(12, activation = 'relu'))                  #히든레이어\n",
    "model.add(Dense(8, activation = 'relu'))                   #히든레이어\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',   #손실함수 : 이진분류 (최소 제곱법 사용할 경우, 로컬 미니엄을 찾을 위험이 있음)\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "model.fit(X, Y, validation_split = 0.2, epochs = 200, batch_size = 200, verbose = 0, \n",
    "         callbacks = [checkpointer])    \n",
    "\n",
    "# validation_split = 0.2 : 20%를 검정용으로 사용한다.\n",
    "\n",
    "# 에포크가 진행되면서 모든 값이 저장되는 것이 아니라 테스트 오차를 실행한 결과값이 향상되었을 때만 저장되는 것을 볼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨ 과적합 그래프 그리기 ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.0835 - val_accuracy: 0.9869\n",
      "Epoch 2/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0879 - val_accuracy: 0.9860\n",
      "Epoch 3/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0844 - val_accuracy: 0.9879\n",
      "Epoch 4/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0862 - val_accuracy: 0.9860\n",
      "Epoch 5/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.0830 - val_accuracy: 0.9869\n",
      "Epoch 6/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0835 - val_accuracy: 0.9879\n",
      "Epoch 7/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.0880 - val_accuracy: 0.9869\n",
      "Epoch 8/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0836 - val_accuracy: 0.9879\n",
      "Epoch 9/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0835 - val_accuracy: 0.9888\n",
      "Epoch 10/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 0.0815 - val_accuracy: 0.9869\n",
      "Epoch 11/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.0840 - val_accuracy: 0.9869\n",
      "Epoch 12/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0824 - val_accuracy: 0.9879\n",
      "Epoch 13/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0831 - val_accuracy: 0.9879\n",
      "Epoch 14/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0835 - val_accuracy: 0.9879\n",
      "Epoch 15/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0831 - val_accuracy: 0.9879\n",
      "Epoch 16/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0894 - val_accuracy: 0.9879\n",
      "Epoch 17/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0849 - val_accuracy: 0.9851\n",
      "Epoch 18/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9936 - val_loss: 0.0883 - val_accuracy: 0.9879\n",
      "Epoch 19/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0822 - val_accuracy: 0.9869\n",
      "Epoch 20/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0853 - val_accuracy: 0.9869\n",
      "Epoch 21/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0835 - val_accuracy: 0.9879\n",
      "Epoch 22/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0840 - val_accuracy: 0.9879\n",
      "Epoch 23/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0843 - val_accuracy: 0.9879\n",
      "Epoch 24/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0839 - val_accuracy: 0.9869\n",
      "Epoch 25/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0852 - val_accuracy: 0.9869\n",
      "Epoch 26/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0840 - val_accuracy: 0.9879\n",
      "Epoch 27/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0850 - val_accuracy: 0.9869\n",
      "Epoch 28/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9949 - val_loss: 0.0840 - val_accuracy: 0.9841\n",
      "Epoch 29/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0845 - val_accuracy: 0.9879\n",
      "Epoch 30/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0869 - val_accuracy: 0.9879\n",
      "Epoch 31/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0836 - val_accuracy: 0.9869\n",
      "Epoch 32/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0907 - val_accuracy: 0.9860\n",
      "Epoch 33/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.0842 - val_accuracy: 0.9832\n",
      "Epoch 34/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 0.1044 - val_accuracy: 0.9851\n",
      "Epoch 35/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0981 - val_accuracy: 0.9757\n",
      "Epoch 36/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9913 - val_loss: 0.0933 - val_accuracy: 0.9860\n",
      "Epoch 37/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0818 - val_accuracy: 0.9832\n",
      "Epoch 38/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9949 - val_loss: 0.0960 - val_accuracy: 0.9860\n",
      "Epoch 39/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0830 - val_accuracy: 0.9860\n",
      "Epoch 40/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0878 - val_accuracy: 0.9879\n",
      "Epoch 41/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.0842 - val_accuracy: 0.9832\n",
      "Epoch 42/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0903 - val_accuracy: 0.9879\n",
      "Epoch 43/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.0834 - val_accuracy: 0.9869\n",
      "Epoch 44/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.0872 - val_accuracy: 0.9860\n",
      "Epoch 45/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0816 - val_accuracy: 0.9869\n",
      "Epoch 46/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0826 - val_accuracy: 0.9879\n",
      "Epoch 47/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.0828 - val_accuracy: 0.9869\n",
      "Epoch 48/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0830 - val_accuracy: 0.9879\n",
      "Epoch 49/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0827 - val_accuracy: 0.9888\n",
      "Epoch 50/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0827 - val_accuracy: 0.9879\n",
      "Epoch 51/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9949 - val_loss: 0.0848 - val_accuracy: 0.9851\n",
      "Epoch 52/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.0832 - val_accuracy: 0.9879\n",
      "Epoch 53/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0834 - val_accuracy: 0.9879\n",
      "Epoch 54/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0847 - val_accuracy: 0.9879\n",
      "Epoch 55/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0825 - val_accuracy: 0.9860\n",
      "Epoch 56/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0859 - val_accuracy: 0.9879\n",
      "Epoch 57/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0848 - val_accuracy: 0.9879\n",
      "Epoch 58/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0902 - val_accuracy: 0.9879\n",
      "Epoch 59/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0851 - val_accuracy: 0.9841\n",
      "Epoch 60/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0897 - val_accuracy: 0.9879\n",
      "Epoch 61/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0839 - val_accuracy: 0.9860\n",
      "Epoch 62/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9940 - val_loss: 0.0886 - val_accuracy: 0.9869\n",
      "Epoch 63/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0828 - val_accuracy: 0.9879\n",
      "Epoch 64/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0828 - val_accuracy: 0.9879\n",
      "Epoch 65/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 0.0833 - val_accuracy: 0.9860\n",
      "Epoch 66/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.0987 - val_accuracy: 0.9860\n",
      "Epoch 67/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0882 - val_accuracy: 0.9823\n",
      "Epoch 68/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9922 - val_loss: 0.1018 - val_accuracy: 0.9869\n",
      "Epoch 69/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0919 - val_accuracy: 0.9804\n",
      "Epoch 70/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 0.1200 - val_accuracy: 0.9841\n",
      "Epoch 71/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.1017 - val_accuracy: 0.9767\n",
      "Epoch 72/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9894 - val_loss: 0.0921 - val_accuracy: 0.9879\n",
      "Epoch 73/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9972 - val_loss: 0.0831 - val_accuracy: 0.9860\n",
      "Epoch 74/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0910 - val_accuracy: 0.9879\n",
      "Epoch 75/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0858 - val_accuracy: 0.9832\n",
      "Epoch 76/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9936 - val_loss: 0.0906 - val_accuracy: 0.9879\n",
      "Epoch 77/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0847 - val_accuracy: 0.9851\n",
      "Epoch 78/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0895 - val_accuracy: 0.9869\n",
      "Epoch 79/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.0866 - val_accuracy: 0.9869\n",
      "Epoch 80/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9940 - val_loss: 0.0860 - val_accuracy: 0.9888\n",
      "Epoch 81/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0854 - val_accuracy: 0.9888\n",
      "Epoch 82/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 0.0844 - val_accuracy: 0.9869\n",
      "Epoch 83/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0866 - val_accuracy: 0.9869\n",
      "Epoch 84/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0851 - val_accuracy: 0.9879\n",
      "Epoch 85/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0874 - val_accuracy: 0.9869\n",
      "Epoch 86/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0879 - val_accuracy: 0.9869\n",
      "Epoch 87/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0856 - val_accuracy: 0.9879\n",
      "Epoch 88/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0839 - val_accuracy: 0.9869\n",
      "Epoch 89/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0860 - val_accuracy: 0.9888\n",
      "Epoch 90/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.0858 - val_accuracy: 0.9841\n",
      "Epoch 91/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9945 - val_loss: 0.0844 - val_accuracy: 0.9879\n",
      "Epoch 92/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.0826 - val_accuracy: 0.9879\n",
      "Epoch 93/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0834 - val_accuracy: 0.9888\n",
      "Epoch 94/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0825 - val_accuracy: 0.9869\n",
      "Epoch 95/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0898 - val_accuracy: 0.9869\n",
      "Epoch 96/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.0833 - val_accuracy: 0.9851\n",
      "Epoch 97/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.0849 - val_accuracy: 0.9879\n",
      "Epoch 98/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0822 - val_accuracy: 0.9879\n",
      "Epoch 99/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0836 - val_accuracy: 0.9888\n",
      "Epoch 100/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0834 - val_accuracy: 0.9841\n",
      "Epoch 101/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0832 - val_accuracy: 0.9888\n",
      "Epoch 102/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0845 - val_accuracy: 0.9879\n",
      "Epoch 103/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0865 - val_accuracy: 0.9879\n",
      "Epoch 104/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0842 - val_accuracy: 0.9869\n",
      "Epoch 105/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0845 - val_accuracy: 0.9879\n",
      "Epoch 106/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0829 - val_accuracy: 0.9879\n",
      "Epoch 107/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0831 - val_accuracy: 0.9869\n",
      "Epoch 108/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0840 - val_accuracy: 0.9888\n",
      "Epoch 109/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0843 - val_accuracy: 0.9879\n",
      "Epoch 110/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0861 - val_accuracy: 0.9851\n",
      "Epoch 111/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9936 - val_loss: 0.0876 - val_accuracy: 0.9869\n",
      "Epoch 112/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0826 - val_accuracy: 0.9879\n",
      "Epoch 113/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0887 - val_accuracy: 0.9869\n",
      "Epoch 114/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0840 - val_accuracy: 0.9869\n",
      "Epoch 115/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0855 - val_accuracy: 0.9897\n",
      "Epoch 116/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0843 - val_accuracy: 0.9879\n",
      "Epoch 117/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0878 - val_accuracy: 0.9869\n",
      "Epoch 118/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0842 - val_accuracy: 0.9879\n",
      "Epoch 119/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0882 - val_accuracy: 0.9879\n",
      "Epoch 120/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0875 - val_accuracy: 0.9832\n",
      "Epoch 121/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9917 - val_loss: 0.1044 - val_accuracy: 0.9860\n",
      "Epoch 122/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0924 - val_accuracy: 0.9804\n",
      "Epoch 123/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9922 - val_loss: 0.0916 - val_accuracy: 0.9888\n",
      "Epoch 124/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0876 - val_accuracy: 0.9813\n",
      "Epoch 125/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0909 - val_accuracy: 0.9888\n",
      "Epoch 126/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.0834 - val_accuracy: 0.9832\n",
      "Epoch 127/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9945 - val_loss: 0.0912 - val_accuracy: 0.9869\n",
      "Epoch 128/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.0846 - val_accuracy: 0.9851\n",
      "Epoch 129/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.0902 - val_accuracy: 0.9879\n",
      "Epoch 130/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0860 - val_accuracy: 0.9832\n",
      "Epoch 131/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 0.0866 - val_accuracy: 0.9869\n",
      "Epoch 132/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0831 - val_accuracy: 0.9860\n",
      "Epoch 133/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0911 - val_accuracy: 0.9879\n",
      "Epoch 134/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.0853 - val_accuracy: 0.9832\n",
      "Epoch 135/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9917 - val_loss: 0.0910 - val_accuracy: 0.9879\n",
      "Epoch 136/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0814 - val_accuracy: 0.9869\n",
      "Epoch 137/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 0.0841 - val_accuracy: 0.9869\n",
      "Epoch 138/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0844 - val_accuracy: 0.9851\n",
      "Epoch 139/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9945 - val_loss: 0.0832 - val_accuracy: 0.9869\n",
      "Epoch 140/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.0870 - val_accuracy: 0.9888\n",
      "Epoch 141/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.0825 - val_accuracy: 0.9879\n",
      "Epoch 142/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0877 - val_accuracy: 0.9860\n",
      "Epoch 143/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.0878 - val_accuracy: 0.9860\n",
      "Epoch 144/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9945 - val_loss: 0.0883 - val_accuracy: 0.9869\n",
      "Epoch 145/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0832 - val_accuracy: 0.9869\n",
      "Epoch 146/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0867 - val_accuracy: 0.9869\n",
      "Epoch 147/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.0839 - val_accuracy: 0.9879\n",
      "Epoch 148/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0830 - val_accuracy: 0.9869\n",
      "Epoch 149/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0827 - val_accuracy: 0.9888\n",
      "Epoch 150/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0829 - val_accuracy: 0.9888\n",
      "Epoch 151/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0864 - val_accuracy: 0.9860\n",
      "Epoch 152/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0864 - val_accuracy: 0.9879\n",
      "Epoch 153/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0893 - val_accuracy: 0.9888\n",
      "Epoch 154/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9949 - val_loss: 0.0887 - val_accuracy: 0.9823\n",
      "Epoch 155/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9894 - val_loss: 0.1031 - val_accuracy: 0.9860\n",
      "Epoch 156/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 0.0862 - val_accuracy: 0.9832\n",
      "Epoch 157/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.0908 - val_accuracy: 0.9879\n",
      "Epoch 158/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0813 - val_accuracy: 0.9860\n",
      "Epoch 159/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 0.0829 - val_accuracy: 0.9888\n",
      "Epoch 160/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0828 - val_accuracy: 0.9879\n",
      "Epoch 161/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0858 - val_accuracy: 0.9860\n",
      "Epoch 162/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0846 - val_accuracy: 0.9869\n",
      "Epoch 163/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0852 - val_accuracy: 0.9888\n",
      "Epoch 164/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0838 - val_accuracy: 0.9879\n",
      "Epoch 165/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0838 - val_accuracy: 0.9879\n",
      "Epoch 166/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0833 - val_accuracy: 0.9869\n",
      "Epoch 167/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0840 - val_accuracy: 0.9879\n",
      "Epoch 168/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0831 - val_accuracy: 0.9888\n",
      "Epoch 169/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0838 - val_accuracy: 0.9869\n",
      "Epoch 170/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0859 - val_accuracy: 0.9879\n",
      "Epoch 171/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0828 - val_accuracy: 0.9869\n",
      "Epoch 172/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9940 - val_loss: 0.0919 - val_accuracy: 0.9879\n",
      "Epoch 173/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0838 - val_accuracy: 0.9869\n",
      "Epoch 174/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0844 - val_accuracy: 0.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0846 - val_accuracy: 0.9879\n",
      "Epoch 176/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9954 - val_loss: 0.0865 - val_accuracy: 0.9869\n",
      "Epoch 177/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0847 - val_accuracy: 0.9869\n",
      "Epoch 178/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.0845 - val_accuracy: 0.9879\n",
      "Epoch 179/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0859 - val_accuracy: 0.9897\n",
      "Epoch 180/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9949 - val_loss: 0.0841 - val_accuracy: 0.9869\n",
      "Epoch 181/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0870 - val_accuracy: 0.9860\n",
      "Epoch 182/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0833 - val_accuracy: 0.9869\n",
      "Epoch 183/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.0847 - val_accuracy: 0.9888\n",
      "Epoch 184/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0836 - val_accuracy: 0.9888\n",
      "Epoch 185/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0855 - val_accuracy: 0.9888\n",
      "Epoch 186/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0863 - val_accuracy: 0.9841\n",
      "Epoch 187/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0854 - val_accuracy: 0.9879\n",
      "Epoch 188/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0842 - val_accuracy: 0.9879\n",
      "Epoch 189/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0843 - val_accuracy: 0.9869\n",
      "Epoch 190/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0956 - val_accuracy: 0.9869\n",
      "Epoch 191/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0862 - val_accuracy: 0.9851\n",
      "Epoch 192/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.0886 - val_accuracy: 0.9888\n",
      "Epoch 193/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0818 - val_accuracy: 0.9888\n",
      "Epoch 194/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0827 - val_accuracy: 0.9888\n",
      "Epoch 195/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0843 - val_accuracy: 0.9869\n",
      "Epoch 196/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0863 - val_accuracy: 0.9879\n",
      "Epoch 197/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0859 - val_accuracy: 0.9888\n",
      "Epoch 198/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.0840 - val_accuracy: 0.9869\n",
      "Epoch 199/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0878 - val_accuracy: 0.9869\n",
      "Epoch 200/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0854 - val_accuracy: 0.9851\n",
      "Epoch 201/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0870 - val_accuracy: 0.9897\n",
      "Epoch 202/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0837 - val_accuracy: 0.9860\n",
      "Epoch 203/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.0986 - val_accuracy: 0.9860\n",
      "Epoch 204/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.0901 - val_accuracy: 0.9813\n",
      "Epoch 205/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9936 - val_loss: 0.0954 - val_accuracy: 0.9869\n",
      "Epoch 206/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.0836 - val_accuracy: 0.9851\n",
      "Epoch 207/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0854 - val_accuracy: 0.9869\n",
      "Epoch 208/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0859 - val_accuracy: 0.9841\n",
      "Epoch 209/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0887 - val_accuracy: 0.9879\n",
      "Epoch 210/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0849 - val_accuracy: 0.9879\n",
      "Epoch 211/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0894 - val_accuracy: 0.9869\n",
      "Epoch 212/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9945 - val_loss: 0.0839 - val_accuracy: 0.9869\n",
      "Epoch 213/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0839 - val_accuracy: 0.9888\n",
      "Epoch 214/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0840 - val_accuracy: 0.9879\n",
      "Epoch 215/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.0896 - val_accuracy: 0.9869\n",
      "Epoch 216/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.0870 - val_accuracy: 0.9860\n",
      "Epoch 217/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9936 - val_loss: 0.1027 - val_accuracy: 0.9869\n",
      "Epoch 218/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0874 - val_accuracy: 0.9841\n",
      "Epoch 219/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.0959 - val_accuracy: 0.9879\n",
      "Epoch 220/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0911 - val_accuracy: 0.9832\n",
      "Epoch 221/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9926 - val_loss: 0.0903 - val_accuracy: 0.9860\n",
      "Epoch 222/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0875 - val_accuracy: 0.9823\n",
      "Epoch 223/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9945 - val_loss: 0.0917 - val_accuracy: 0.9879\n",
      "Epoch 224/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.0839 - val_accuracy: 0.9869\n",
      "Epoch 225/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0877 - val_accuracy: 0.9869\n",
      "Epoch 226/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9977 - val_loss: 0.0888 - val_accuracy: 0.9832\n",
      "Epoch 227/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9949 - val_loss: 0.0896 - val_accuracy: 0.9879\n",
      "Epoch 228/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0835 - val_accuracy: 0.9879\n",
      "Epoch 229/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0859 - val_accuracy: 0.9879\n",
      "Epoch 230/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0876 - val_accuracy: 0.9832\n",
      "Epoch 231/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0878 - val_accuracy: 0.9879\n",
      "Epoch 232/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0846 - val_accuracy: 0.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0852 - val_accuracy: 0.9860\n",
      "Epoch 234/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0867 - val_accuracy: 0.9869\n",
      "Epoch 235/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0848 - val_accuracy: 0.9879\n",
      "Epoch 236/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0851 - val_accuracy: 0.9879\n",
      "Epoch 237/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0872 - val_accuracy: 0.9879\n",
      "Epoch 238/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0845 - val_accuracy: 0.9869\n",
      "Epoch 239/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0855 - val_accuracy: 0.9869\n",
      "Epoch 240/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0859 - val_accuracy: 0.9879\n",
      "Epoch 241/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0855 - val_accuracy: 0.9879\n",
      "Epoch 242/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0860 - val_accuracy: 0.9879\n",
      "Epoch 243/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0861 - val_accuracy: 0.9879\n",
      "Epoch 244/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.0846 - val_accuracy: 0.9869\n",
      "Epoch 245/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0861 - val_accuracy: 0.9879\n",
      "Epoch 246/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0852 - val_accuracy: 0.9879\n",
      "Epoch 247/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0862 - val_accuracy: 0.9879\n",
      "Epoch 248/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0854 - val_accuracy: 0.9888\n",
      "Epoch 249/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.0846 - val_accuracy: 0.9869\n",
      "Epoch 250/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0868 - val_accuracy: 0.9888\n",
      "Epoch 251/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0851 - val_accuracy: 0.9879\n",
      "Epoch 252/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0860 - val_accuracy: 0.9879\n",
      "Epoch 253/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0852 - val_accuracy: 0.9879\n",
      "Epoch 254/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0858 - val_accuracy: 0.9879\n",
      "Epoch 255/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0889 - val_accuracy: 0.9860\n",
      "Epoch 256/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0850 - val_accuracy: 0.9879\n",
      "Epoch 257/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0836 - val_accuracy: 0.9888\n",
      "Epoch 258/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0854 - val_accuracy: 0.9879\n",
      "Epoch 259/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0855 - val_accuracy: 0.9869\n",
      "Epoch 260/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.0895 - val_accuracy: 0.9888\n",
      "Epoch 261/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.0850 - val_accuracy: 0.9860\n",
      "Epoch 262/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0905 - val_accuracy: 0.9860\n",
      "Epoch 263/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0852 - val_accuracy: 0.9869\n",
      "Epoch 264/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0854 - val_accuracy: 0.9888\n",
      "Epoch 265/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0913 - val_accuracy: 0.9869\n",
      "Epoch 266/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0883 - val_accuracy: 0.9851\n",
      "Epoch 267/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0880 - val_accuracy: 0.9888\n",
      "Epoch 268/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0866 - val_accuracy: 0.9879\n",
      "Epoch 269/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0899 - val_accuracy: 0.9851\n",
      "Epoch 270/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0859 - val_accuracy: 0.9860\n",
      "Epoch 271/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0878 - val_accuracy: 0.9897\n",
      "Epoch 272/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0842 - val_accuracy: 0.9879\n",
      "Epoch 273/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0887 - val_accuracy: 0.9860\n",
      "Epoch 274/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.0932 - val_accuracy: 0.9869\n",
      "Epoch 275/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.0871 - val_accuracy: 0.9860\n",
      "Epoch 276/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9945 - val_loss: 0.0874 - val_accuracy: 0.9879\n",
      "Epoch 277/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0835 - val_accuracy: 0.9869\n",
      "Epoch 278/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0862 - val_accuracy: 0.9879\n",
      "Epoch 279/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.0853 - val_accuracy: 0.9869\n",
      "Epoch 280/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0854 - val_accuracy: 0.9879\n",
      "Epoch 281/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0858 - val_accuracy: 0.9888\n",
      "Epoch 282/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0843 - val_accuracy: 0.9851\n",
      "Epoch 283/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.0893 - val_accuracy: 0.9869\n",
      "Epoch 284/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0850 - val_accuracy: 0.9869\n",
      "Epoch 285/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0927 - val_accuracy: 0.9879\n",
      "Epoch 286/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0860 - val_accuracy: 0.9860\n",
      "Epoch 287/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0876 - val_accuracy: 0.9879\n",
      "Epoch 288/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0840 - val_accuracy: 0.9869\n",
      "Epoch 289/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.0898 - val_accuracy: 0.9879\n",
      "Epoch 290/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.0847 - val_accuracy: 0.9851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9917 - val_loss: 0.0962 - val_accuracy: 0.9879\n",
      "Epoch 292/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.0931 - val_accuracy: 0.9813\n",
      "Epoch 293/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 0.0964 - val_accuracy: 0.9879\n",
      "Epoch 294/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0842 - val_accuracy: 0.9841\n",
      "Epoch 295/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0852 - val_accuracy: 0.9888\n",
      "Epoch 296/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9949 - val_loss: 0.0843 - val_accuracy: 0.9869\n",
      "Epoch 297/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0905 - val_accuracy: 0.9879\n",
      "Epoch 298/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0853 - val_accuracy: 0.9869\n",
      "Epoch 299/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9931 - val_loss: 0.0952 - val_accuracy: 0.9879\n",
      "Epoch 300/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9922 - val_loss: 0.0976 - val_accuracy: 0.9776\n",
      "Epoch 301/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9871 - val_loss: 0.1073 - val_accuracy: 0.9841\n",
      "Epoch 302/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0854 - val_accuracy: 0.9832\n",
      "Epoch 303/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.0859 - val_accuracy: 0.9907\n",
      "Epoch 304/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0867 - val_accuracy: 0.9851\n",
      "Epoch 305/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0908 - val_accuracy: 0.9869\n",
      "Epoch 306/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.0834 - val_accuracy: 0.9879\n",
      "Epoch 307/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0841 - val_accuracy: 0.9869\n",
      "Epoch 308/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9949 - val_loss: 0.0836 - val_accuracy: 0.9869\n",
      "Epoch 309/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.0856 - val_accuracy: 0.9879\n",
      "Epoch 310/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0856 - val_accuracy: 0.9879\n",
      "Epoch 311/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0858 - val_accuracy: 0.9869\n",
      "Epoch 312/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0845 - val_accuracy: 0.9869\n",
      "Epoch 313/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0844 - val_accuracy: 0.9888\n",
      "Epoch 314/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0847 - val_accuracy: 0.9879\n",
      "Epoch 315/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0865 - val_accuracy: 0.9888\n",
      "Epoch 316/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0839 - val_accuracy: 0.9879\n",
      "Epoch 317/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0868 - val_accuracy: 0.9879\n",
      "Epoch 318/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.0856 - val_accuracy: 0.9869\n",
      "Epoch 319/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0853 - val_accuracy: 0.9879\n",
      "Epoch 320/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0950 - val_accuracy: 0.9860\n",
      "Epoch 321/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0868 - val_accuracy: 0.9832\n",
      "Epoch 322/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.0915 - val_accuracy: 0.9879\n",
      "Epoch 323/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0851 - val_accuracy: 0.9869\n",
      "Epoch 324/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0896 - val_accuracy: 0.9879\n",
      "Epoch 325/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0866 - val_accuracy: 0.9879\n",
      "Epoch 326/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0863 - val_accuracy: 0.9888\n",
      "Epoch 327/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0855 - val_accuracy: 0.9888\n",
      "Epoch 328/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0851 - val_accuracy: 0.9879\n",
      "Epoch 329/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0846 - val_accuracy: 0.9888\n",
      "Epoch 330/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0855 - val_accuracy: 0.9869\n",
      "Epoch 331/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0870 - val_accuracy: 0.9879\n",
      "Epoch 332/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.0843 - val_accuracy: 0.9888\n",
      "Epoch 333/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0849 - val_accuracy: 0.9888\n",
      "Epoch 334/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0867 - val_accuracy: 0.9888\n",
      "Epoch 335/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.0856 - val_accuracy: 0.9879\n",
      "Epoch 336/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0861 - val_accuracy: 0.9888\n",
      "Epoch 337/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0862 - val_accuracy: 0.9879\n",
      "Epoch 338/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0888 - val_accuracy: 0.9860\n",
      "Epoch 339/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0860 - val_accuracy: 0.9879\n",
      "Epoch 340/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0889 - val_accuracy: 0.9888\n",
      "Epoch 341/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0862 - val_accuracy: 0.9879\n",
      "Epoch 342/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0877 - val_accuracy: 0.9869\n",
      "Epoch 343/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0899 - val_accuracy: 0.9869\n",
      "Epoch 344/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0869 - val_accuracy: 0.9869\n",
      "Epoch 345/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 0.0910 - val_accuracy: 0.9879\n",
      "Epoch 346/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0857 - val_accuracy: 0.9851\n",
      "Epoch 347/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9931 - val_loss: 0.0936 - val_accuracy: 0.9888\n",
      "Epoch 348/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0884 - val_accuracy: 0.9841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0953 - val_accuracy: 0.9879\n",
      "Epoch 350/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0866 - val_accuracy: 0.9860\n",
      "Epoch 351/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0894 - val_accuracy: 0.9869\n",
      "Epoch 352/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0852 - val_accuracy: 0.9860\n",
      "Epoch 353/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0954 - val_accuracy: 0.9879\n",
      "Epoch 354/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0860 - val_accuracy: 0.9860\n",
      "Epoch 355/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9949 - val_loss: 0.0871 - val_accuracy: 0.9888\n",
      "Epoch 356/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0843 - val_accuracy: 0.9869\n",
      "Epoch 357/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0886 - val_accuracy: 0.9879\n",
      "Epoch 358/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0857 - val_accuracy: 0.9860\n",
      "Epoch 359/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0865 - val_accuracy: 0.9888\n",
      "Epoch 360/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0861 - val_accuracy: 0.9869\n",
      "Epoch 361/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0865 - val_accuracy: 0.9879\n",
      "Epoch 362/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0854 - val_accuracy: 0.9869\n",
      "Epoch 363/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0854 - val_accuracy: 0.9888\n",
      "Epoch 364/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0859 - val_accuracy: 0.9879\n",
      "Epoch 365/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0859 - val_accuracy: 0.9869\n",
      "Epoch 366/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0872 - val_accuracy: 0.9869\n",
      "Epoch 367/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0856 - val_accuracy: 0.9888\n",
      "Epoch 368/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0854 - val_accuracy: 0.9879\n",
      "Epoch 369/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0902 - val_accuracy: 0.9869\n",
      "Epoch 370/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.0870 - val_accuracy: 0.9869\n",
      "Epoch 371/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0857 - val_accuracy: 0.9879\n",
      "Epoch 372/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.0877 - val_accuracy: 0.9879\n",
      "Epoch 373/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0843 - val_accuracy: 0.9879\n",
      "Epoch 374/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0845 - val_accuracy: 0.9888\n",
      "Epoch 375/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0855 - val_accuracy: 0.9879\n",
      "Epoch 376/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0869 - val_accuracy: 0.9879\n",
      "Epoch 377/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0895 - val_accuracy: 0.9869\n",
      "Epoch 378/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0848 - val_accuracy: 0.9869\n",
      "Epoch 379/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0902 - val_accuracy: 0.9879\n",
      "Epoch 380/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0870 - val_accuracy: 0.9879\n",
      "Epoch 381/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9940 - val_loss: 0.0904 - val_accuracy: 0.9879\n",
      "Epoch 382/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0858 - val_accuracy: 0.9860\n",
      "Epoch 383/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.0961 - val_accuracy: 0.9879\n",
      "Epoch 384/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0870 - val_accuracy: 0.9851\n",
      "Epoch 385/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.0909 - val_accuracy: 0.9888\n",
      "Epoch 386/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0843 - val_accuracy: 0.9879\n",
      "Epoch 387/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0863 - val_accuracy: 0.9869\n",
      "Epoch 388/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0845 - val_accuracy: 0.9869\n",
      "Epoch 389/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0871 - val_accuracy: 0.9888\n",
      "Epoch 390/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0850 - val_accuracy: 0.9888\n",
      "Epoch 391/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0880 - val_accuracy: 0.9888\n",
      "Epoch 392/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0860 - val_accuracy: 0.9869\n",
      "Epoch 393/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0890 - val_accuracy: 0.9879\n",
      "Epoch 394/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0871 - val_accuracy: 0.9879\n",
      "Epoch 395/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0888 - val_accuracy: 0.9879\n",
      "Epoch 396/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0861 - val_accuracy: 0.9888\n",
      "Epoch 397/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0863 - val_accuracy: 0.9879\n",
      "Epoch 398/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0854 - val_accuracy: 0.9879\n",
      "Epoch 399/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0835 - val_accuracy: 0.9879\n",
      "Epoch 400/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.0851 - val_accuracy: 0.9879\n",
      "Epoch 401/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0836 - val_accuracy: 0.9869\n",
      "Epoch 402/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0909 - val_accuracy: 0.9869\n",
      "Epoch 403/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0902 - val_accuracy: 0.9813\n",
      "Epoch 404/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9931 - val_loss: 0.1011 - val_accuracy: 0.9860\n",
      "Epoch 405/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0876 - val_accuracy: 0.9832\n",
      "Epoch 406/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.0932 - val_accuracy: 0.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0877 - val_accuracy: 0.9841\n",
      "Epoch 408/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0954 - val_accuracy: 0.9869\n",
      "Epoch 409/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.0856 - val_accuracy: 0.9860\n",
      "Epoch 410/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9945 - val_loss: 0.0907 - val_accuracy: 0.9879\n",
      "Epoch 411/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0832 - val_accuracy: 0.9879\n",
      "Epoch 412/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0875 - val_accuracy: 0.9879\n",
      "Epoch 413/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0845 - val_accuracy: 0.9869\n",
      "Epoch 414/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0877 - val_accuracy: 0.9888\n",
      "Epoch 415/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0863 - val_accuracy: 0.9888\n",
      "Epoch 416/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.0863 - val_accuracy: 0.9888\n",
      "Epoch 417/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9959 - val_loss: 0.0876 - val_accuracy: 0.9879\n",
      "Epoch 418/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.0866 - val_accuracy: 0.9869\n",
      "Epoch 419/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0873 - val_accuracy: 0.9879\n",
      "Epoch 420/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0876 - val_accuracy: 0.9879\n",
      "Epoch 421/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0874 - val_accuracy: 0.9888\n",
      "Epoch 422/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.0852 - val_accuracy: 0.9879\n",
      "Epoch 423/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0894 - val_accuracy: 0.9897\n",
      "Epoch 424/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0878 - val_accuracy: 0.9841\n",
      "Epoch 425/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.0948 - val_accuracy: 0.9888\n",
      "Epoch 426/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0863 - val_accuracy: 0.9879\n",
      "Epoch 427/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0861 - val_accuracy: 0.9888\n",
      "Epoch 428/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0872 - val_accuracy: 0.9888\n",
      "Epoch 429/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0864 - val_accuracy: 0.9888\n",
      "Epoch 430/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0864 - val_accuracy: 0.9879\n",
      "Epoch 431/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9954 - val_loss: 0.0884 - val_accuracy: 0.9888\n",
      "Epoch 432/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9949 - val_loss: 0.0883 - val_accuracy: 0.9841\n",
      "Epoch 433/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0994 - val_accuracy: 0.9869\n",
      "Epoch 434/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.0860 - val_accuracy: 0.9879\n",
      "Epoch 435/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0864 - val_accuracy: 0.9897\n",
      "Epoch 436/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9936 - val_loss: 0.0907 - val_accuracy: 0.9907\n",
      "Epoch 437/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0922 - val_accuracy: 0.9832\n",
      "Epoch 438/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9908 - val_loss: 0.1139 - val_accuracy: 0.9832\n",
      "Epoch 439/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.0889 - val_accuracy: 0.9851\n",
      "Epoch 440/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0855 - val_accuracy: 0.9897\n",
      "Epoch 441/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.0839 - val_accuracy: 0.9897\n",
      "Epoch 442/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0876 - val_accuracy: 0.9879\n",
      "Epoch 443/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0870 - val_accuracy: 0.9869\n",
      "Epoch 444/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0946 - val_accuracy: 0.9869\n",
      "Epoch 445/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0883 - val_accuracy: 0.9879\n",
      "Epoch 446/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0877 - val_accuracy: 0.9869\n",
      "Epoch 447/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.0896 - val_accuracy: 0.9860\n",
      "Epoch 448/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0864 - val_accuracy: 0.9860\n",
      "Epoch 449/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.0922 - val_accuracy: 0.9879\n",
      "Epoch 450/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0864 - val_accuracy: 0.9860\n",
      "Epoch 451/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0901 - val_accuracy: 0.9879\n",
      "Epoch 452/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0850 - val_accuracy: 0.9879\n",
      "Epoch 453/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0856 - val_accuracy: 0.9888\n",
      "Epoch 454/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0894 - val_accuracy: 0.9888\n",
      "Epoch 455/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0869 - val_accuracy: 0.9879\n",
      "Epoch 456/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9954 - val_loss: 0.0905 - val_accuracy: 0.9879\n",
      "Epoch 457/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0846 - val_accuracy: 0.9869\n",
      "Epoch 458/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0856 - val_accuracy: 0.9879\n",
      "Epoch 459/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.0836 - val_accuracy: 0.9851\n",
      "Epoch 460/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9945 - val_loss: 0.0858 - val_accuracy: 0.9860\n",
      "Epoch 461/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0826 - val_accuracy: 0.9888\n",
      "Epoch 462/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.0828 - val_accuracy: 0.9860\n",
      "Epoch 463/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9926 - val_loss: 0.1022 - val_accuracy: 0.9851\n",
      "Epoch 464/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9917 - val_loss: 0.1107 - val_accuracy: 0.9757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9899 - val_loss: 0.1332 - val_accuracy: 0.9804\n",
      "Epoch 466/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9903 - val_loss: 0.0920 - val_accuracy: 0.9785\n",
      "Epoch 467/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 0.1032 - val_accuracy: 0.9851\n",
      "Epoch 468/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.0901 - val_accuracy: 0.9832\n",
      "Epoch 469/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0967 - val_accuracy: 0.9860\n",
      "Epoch 470/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0918 - val_accuracy: 0.9841\n",
      "Epoch 471/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9931 - val_loss: 0.0972 - val_accuracy: 0.9879\n",
      "Epoch 472/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0886 - val_accuracy: 0.9879\n",
      "Epoch 473/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0871 - val_accuracy: 0.9869\n",
      "Epoch 474/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0882 - val_accuracy: 0.9879\n",
      "Epoch 475/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0909 - val_accuracy: 0.9888\n",
      "Epoch 476/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0878 - val_accuracy: 0.9879\n",
      "Epoch 477/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.0881 - val_accuracy: 0.9897\n",
      "Epoch 478/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0883 - val_accuracy: 0.9897\n",
      "Epoch 479/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0857 - val_accuracy: 0.9869\n",
      "Epoch 480/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.0893 - val_accuracy: 0.9879\n",
      "Epoch 481/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0881 - val_accuracy: 0.9879\n",
      "Epoch 482/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9959 - val_loss: 0.0907 - val_accuracy: 0.9879\n",
      "Epoch 483/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0873 - val_accuracy: 0.9869\n",
      "Epoch 484/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9940 - val_loss: 0.0933 - val_accuracy: 0.9860\n",
      "Epoch 485/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.0896 - val_accuracy: 0.9879\n",
      "Epoch 486/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9954 - val_loss: 0.0864 - val_accuracy: 0.9869\n",
      "Epoch 487/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9945 - val_loss: 0.0946 - val_accuracy: 0.9879\n",
      "Epoch 488/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.0870 - val_accuracy: 0.9851\n",
      "Epoch 489/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0962 - val_accuracy: 0.9860\n",
      "Epoch 490/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.0857 - val_accuracy: 0.9851\n",
      "Epoch 491/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9936 - val_loss: 0.0904 - val_accuracy: 0.9897\n",
      "Epoch 492/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0851 - val_accuracy: 0.9860\n",
      "Epoch 493/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9940 - val_loss: 0.0879 - val_accuracy: 0.9888\n",
      "Epoch 494/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0866 - val_accuracy: 0.9888\n",
      "Epoch 495/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0883 - val_accuracy: 0.9897\n",
      "Epoch 496/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0876 - val_accuracy: 0.9860\n",
      "Epoch 497/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0884 - val_accuracy: 0.9879\n",
      "Epoch 498/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0888 - val_accuracy: 0.9879\n",
      "Epoch 499/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0906 - val_accuracy: 0.9888\n",
      "Epoch 500/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0868 - val_accuracy: 0.9869\n",
      "Epoch 501/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0877 - val_accuracy: 0.9897\n",
      "Epoch 502/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0877 - val_accuracy: 0.9879\n",
      "Epoch 503/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0895 - val_accuracy: 0.9879\n",
      "Epoch 504/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.0869 - val_accuracy: 0.9879\n",
      "Epoch 505/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0877 - val_accuracy: 0.9879\n",
      "Epoch 506/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0881 - val_accuracy: 0.9860\n",
      "Epoch 507/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0860 - val_accuracy: 0.9879\n",
      "Epoch 508/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 0.0907 - val_accuracy: 0.9888\n",
      "Epoch 509/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0887 - val_accuracy: 0.9879\n",
      "Epoch 510/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0905 - val_accuracy: 0.9860\n",
      "Epoch 511/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0863 - val_accuracy: 0.9869\n",
      "Epoch 512/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9945 - val_loss: 0.0862 - val_accuracy: 0.9888\n",
      "Epoch 513/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0862 - val_accuracy: 0.9888\n",
      "Epoch 514/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0866 - val_accuracy: 0.9888\n",
      "Epoch 515/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.0861 - val_accuracy: 0.9879\n",
      "Epoch 516/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0927 - val_accuracy: 0.9879\n",
      "Epoch 517/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0860 - val_accuracy: 0.9869\n",
      "Epoch 518/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0855 - val_accuracy: 0.9869\n",
      "Epoch 519/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0893 - val_accuracy: 0.9897\n",
      "Epoch 520/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0877 - val_accuracy: 0.9879\n",
      "Epoch 521/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0888 - val_accuracy: 0.9869\n",
      "Epoch 522/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0924 - val_accuracy: 0.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9954 - val_loss: 0.0872 - val_accuracy: 0.9869\n",
      "Epoch 524/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.0994 - val_accuracy: 0.9860\n",
      "Epoch 525/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0868 - val_accuracy: 0.9851\n",
      "Epoch 526/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0908 - val_accuracy: 0.9869\n",
      "Epoch 527/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0864 - val_accuracy: 0.9841\n",
      "Epoch 528/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9940 - val_loss: 0.0925 - val_accuracy: 0.9860\n",
      "Epoch 529/3500\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0841 - val_accuracy: 0.9879\n",
      "Epoch 530/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0851 - val_accuracy: 0.9897\n",
      "Epoch 531/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0851 - val_accuracy: 0.9879\n",
      "Epoch 532/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0862 - val_accuracy: 0.9879\n",
      "Epoch 533/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0863 - val_accuracy: 0.9879\n",
      "Epoch 534/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0885 - val_accuracy: 0.9888\n",
      "Epoch 535/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0861 - val_accuracy: 0.9860\n",
      "Epoch 536/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.0962 - val_accuracy: 0.9879\n",
      "Epoch 537/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.0861 - val_accuracy: 0.9879\n",
      "Epoch 538/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.0916 - val_accuracy: 0.9869\n",
      "Epoch 539/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0861 - val_accuracy: 0.9869\n",
      "Epoch 540/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9949 - val_loss: 0.0864 - val_accuracy: 0.9888\n",
      "Epoch 541/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0862 - val_accuracy: 0.9851\n",
      "Epoch 542/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9922 - val_loss: 0.0936 - val_accuracy: 0.9869\n",
      "Epoch 543/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0864 - val_accuracy: 0.9869\n",
      "Epoch 544/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9931 - val_loss: 0.0901 - val_accuracy: 0.9879\n",
      "Epoch 545/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0854 - val_accuracy: 0.9879\n",
      "Epoch 546/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0884 - val_accuracy: 0.9888\n",
      "Epoch 547/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9945 - val_loss: 0.0859 - val_accuracy: 0.9860\n",
      "Epoch 548/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0896 - val_accuracy: 0.9888\n",
      "Epoch 549/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0860 - val_accuracy: 0.9879\n",
      "Epoch 550/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0916 - val_accuracy: 0.9869\n",
      "Epoch 551/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0881 - val_accuracy: 0.9869\n",
      "Epoch 552/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9949 - val_loss: 0.0935 - val_accuracy: 0.9879\n",
      "Epoch 553/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0889 - val_accuracy: 0.9841\n",
      "Epoch 554/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.0930 - val_accuracy: 0.9869\n",
      "Epoch 555/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0865 - val_accuracy: 0.9879\n",
      "Epoch 556/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.0885 - val_accuracy: 0.9888\n",
      "Epoch 557/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0877 - val_accuracy: 0.9879\n",
      "Epoch 558/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0885 - val_accuracy: 0.9888\n",
      "Epoch 559/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0875 - val_accuracy: 0.9869\n",
      "Epoch 560/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0896 - val_accuracy: 0.9879\n",
      "Epoch 561/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9954 - val_loss: 0.0887 - val_accuracy: 0.9869\n",
      "Epoch 562/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.0928 - val_accuracy: 0.9860\n",
      "Epoch 563/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9954 - val_loss: 0.0887 - val_accuracy: 0.9879\n",
      "Epoch 564/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0871 - val_accuracy: 0.9869\n",
      "Epoch 565/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0946 - val_accuracy: 0.9860\n",
      "Epoch 566/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0941 - val_accuracy: 0.9813\n",
      "Epoch 567/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9899 - val_loss: 0.1120 - val_accuracy: 0.9851\n",
      "Epoch 568/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9922 - val_loss: 0.1107 - val_accuracy: 0.9711\n",
      "Epoch 569/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9890 - val_loss: 0.1275 - val_accuracy: 0.9832\n",
      "Epoch 570/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 0.1209 - val_accuracy: 0.9776\n",
      "Epoch 571/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.1158 - val_accuracy: 0.9832\n",
      "Epoch 572/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0998 - val_accuracy: 0.9785\n",
      "Epoch 573/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.1213 - val_accuracy: 0.9832\n",
      "Epoch 574/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.1308 - val_accuracy: 0.9739\n",
      "Epoch 575/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 0.1003 - val_accuracy: 0.9869\n",
      "Epoch 576/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0906 - val_accuracy: 0.9841\n",
      "Epoch 577/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0916 - val_accuracy: 0.9888\n",
      "Epoch 578/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0831 - val_accuracy: 0.9841\n",
      "Epoch 579/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0883 - val_accuracy: 0.9879\n",
      "Epoch 580/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.0846 - val_accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0933 - val_accuracy: 0.9879\n",
      "Epoch 582/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0872 - val_accuracy: 0.9860\n",
      "Epoch 583/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0910 - val_accuracy: 0.9879\n",
      "Epoch 584/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0869 - val_accuracy: 0.9860\n",
      "Epoch 585/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0912 - val_accuracy: 0.9888\n",
      "Epoch 586/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9949 - val_loss: 0.0867 - val_accuracy: 0.9888\n",
      "Epoch 587/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0849 - val_accuracy: 0.9879\n",
      "Epoch 588/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.0877 - val_accuracy: 0.9897\n",
      "Epoch 589/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0862 - val_accuracy: 0.9869\n",
      "Epoch 590/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0873 - val_accuracy: 0.9888\n",
      "Epoch 591/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0877 - val_accuracy: 0.9888\n",
      "Epoch 592/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0889 - val_accuracy: 0.9879\n",
      "Epoch 593/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0881 - val_accuracy: 0.9879\n",
      "Epoch 594/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0879 - val_accuracy: 0.9879\n",
      "Epoch 595/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.0899 - val_accuracy: 0.9897\n",
      "Epoch 596/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0869 - val_accuracy: 0.9860\n",
      "Epoch 597/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.1008 - val_accuracy: 0.9841\n",
      "Epoch 598/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0879 - val_accuracy: 0.9869\n",
      "Epoch 599/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0882 - val_accuracy: 0.9897\n",
      "Epoch 600/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.0859 - val_accuracy: 0.9869\n",
      "Epoch 601/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0875 - val_accuracy: 0.9879\n",
      "Epoch 602/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0867 - val_accuracy: 0.9879\n",
      "Epoch 603/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0900 - val_accuracy: 0.9888\n",
      "Epoch 604/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.0906 - val_accuracy: 0.9879\n",
      "Epoch 605/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0887 - val_accuracy: 0.9888\n",
      "Epoch 606/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0867 - val_accuracy: 0.9879\n",
      "Epoch 607/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0872 - val_accuracy: 0.9879\n",
      "Epoch 608/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0887 - val_accuracy: 0.9888\n",
      "Epoch 609/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.0881 - val_accuracy: 0.9888\n",
      "Epoch 610/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0894 - val_accuracy: 0.9879\n",
      "Epoch 611/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0891 - val_accuracy: 0.9879\n",
      "Epoch 612/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0918 - val_accuracy: 0.9869\n",
      "Epoch 613/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.0907 - val_accuracy: 0.9832\n",
      "Epoch 614/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9931 - val_loss: 0.0940 - val_accuracy: 0.9888\n",
      "Epoch 615/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0869 - val_accuracy: 0.9860\n",
      "Epoch 616/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0878 - val_accuracy: 0.9897\n",
      "Epoch 617/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0881 - val_accuracy: 0.9897\n",
      "Epoch 618/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0884 - val_accuracy: 0.9860\n",
      "Epoch 619/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0931 - val_accuracy: 0.9860\n",
      "Epoch 620/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0875 - val_accuracy: 0.9869\n",
      "Epoch 621/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.0880 - val_accuracy: 0.9888\n",
      "Epoch 622/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0876 - val_accuracy: 0.9860\n",
      "Epoch 623/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0909 - val_accuracy: 0.9869\n",
      "Epoch 624/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0934 - val_accuracy: 0.9879\n",
      "Epoch 625/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0899 - val_accuracy: 0.9879\n",
      "Epoch 626/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0895 - val_accuracy: 0.9879\n",
      "Epoch 627/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0901 - val_accuracy: 0.9888\n",
      "Epoch 628/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0882 - val_accuracy: 0.9869\n",
      "Epoch 629/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0949 - val_accuracy: 0.9879\n",
      "Epoch 630/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0879 - val_accuracy: 0.9869\n",
      "Epoch 631/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0945 - val_accuracy: 0.9888\n",
      "Epoch 632/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0876 - val_accuracy: 0.9869\n",
      "Epoch 633/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9945 - val_loss: 0.0949 - val_accuracy: 0.9888\n",
      "Epoch 634/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0875 - val_accuracy: 0.9879\n",
      "Epoch 635/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0881 - val_accuracy: 0.9888\n",
      "Epoch 636/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0889 - val_accuracy: 0.9888\n",
      "Epoch 637/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0885 - val_accuracy: 0.9879\n",
      "Epoch 638/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0909 - val_accuracy: 0.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0917 - val_accuracy: 0.9879\n",
      "Epoch 640/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.0911 - val_accuracy: 0.9879\n",
      "Epoch 641/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0875 - val_accuracy: 0.9869\n",
      "Epoch 642/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.0899 - val_accuracy: 0.9888\n",
      "Epoch 643/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0903 - val_accuracy: 0.9879\n",
      "Epoch 644/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0917 - val_accuracy: 0.9879\n",
      "Epoch 645/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0875 - val_accuracy: 0.9869\n",
      "Epoch 646/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0928 - val_accuracy: 0.9879\n",
      "Epoch 647/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9949 - val_loss: 0.0879 - val_accuracy: 0.9879\n",
      "Epoch 648/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0916 - val_accuracy: 0.9869\n",
      "Epoch 649/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0888 - val_accuracy: 0.9841\n",
      "Epoch 650/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.0970 - val_accuracy: 0.9879\n",
      "Epoch 651/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0888 - val_accuracy: 0.9851\n",
      "Epoch 652/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0962 - val_accuracy: 0.9888\n",
      "Epoch 653/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0893 - val_accuracy: 0.9832\n",
      "Epoch 654/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.1021 - val_accuracy: 0.9869\n",
      "Epoch 655/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.0903 - val_accuracy: 0.9851\n",
      "Epoch 656/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.0940 - val_accuracy: 0.9879\n",
      "Epoch 657/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9949 - val_loss: 0.0879 - val_accuracy: 0.9888\n",
      "Epoch 658/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.0894 - val_accuracy: 0.9879\n",
      "Epoch 659/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0885 - val_accuracy: 0.9879\n",
      "Epoch 660/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0927 - val_accuracy: 0.9879\n",
      "Epoch 661/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0894 - val_accuracy: 0.9879\n",
      "Epoch 662/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0911 - val_accuracy: 0.9897\n",
      "Epoch 663/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0888 - val_accuracy: 0.9897\n",
      "Epoch 664/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0890 - val_accuracy: 0.9841\n",
      "Epoch 665/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0950 - val_accuracy: 0.9879\n",
      "Epoch 666/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0920 - val_accuracy: 0.9851\n",
      "Epoch 667/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9936 - val_loss: 0.0932 - val_accuracy: 0.9860\n",
      "Epoch 668/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0865 - val_accuracy: 0.9879\n",
      "Epoch 669/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0882 - val_accuracy: 0.9888\n",
      "Epoch 670/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0882 - val_accuracy: 0.9860\n",
      "Epoch 671/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9959 - val_loss: 0.0952 - val_accuracy: 0.9869\n",
      "Epoch 672/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0891 - val_accuracy: 0.9879\n",
      "Epoch 673/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0903 - val_accuracy: 0.9888\n",
      "Epoch 674/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0887 - val_accuracy: 0.9860\n",
      "Epoch 675/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0902 - val_accuracy: 0.9888\n",
      "Epoch 676/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0889 - val_accuracy: 0.9879\n",
      "Epoch 677/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0919 - val_accuracy: 0.9888\n",
      "Epoch 678/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0893 - val_accuracy: 0.9869\n",
      "Epoch 679/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0932 - val_accuracy: 0.9869\n",
      "Epoch 680/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0881 - val_accuracy: 0.9888\n",
      "Epoch 681/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0875 - val_accuracy: 0.9869\n",
      "Epoch 682/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0933 - val_accuracy: 0.9869\n",
      "Epoch 683/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0894 - val_accuracy: 0.9869\n",
      "Epoch 684/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0913 - val_accuracy: 0.9879\n",
      "Epoch 685/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9949 - val_loss: 0.0878 - val_accuracy: 0.9879\n",
      "Epoch 686/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0915 - val_accuracy: 0.9879\n",
      "Epoch 687/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0890 - val_accuracy: 0.9860\n",
      "Epoch 688/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0955 - val_accuracy: 0.9879\n",
      "Epoch 689/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0878 - val_accuracy: 0.9888\n",
      "Epoch 690/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0883 - val_accuracy: 0.9888\n",
      "Epoch 691/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0940 - val_accuracy: 0.9860\n",
      "Epoch 692/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0882 - val_accuracy: 0.9879\n",
      "Epoch 693/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0909 - val_accuracy: 0.9879\n",
      "Epoch 694/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.0872 - val_accuracy: 0.9879\n",
      "Epoch 695/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0920 - val_accuracy: 0.9879\n",
      "Epoch 696/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9954 - val_loss: 0.0878 - val_accuracy: 0.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0910 - val_accuracy: 0.9888\n",
      "Epoch 698/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0901 - val_accuracy: 0.9888\n",
      "Epoch 699/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0900 - val_accuracy: 0.9888\n",
      "Epoch 700/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0896 - val_accuracy: 0.9879\n",
      "Epoch 701/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0895 - val_accuracy: 0.9879\n",
      "Epoch 702/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0923 - val_accuracy: 0.9879\n",
      "Epoch 703/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0908 - val_accuracy: 0.9879\n",
      "Epoch 704/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0894 - val_accuracy: 0.9869\n",
      "Epoch 705/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0931 - val_accuracy: 0.9888\n",
      "Epoch 706/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0883 - val_accuracy: 0.9869\n",
      "Epoch 707/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9949 - val_loss: 0.0879 - val_accuracy: 0.9888\n",
      "Epoch 708/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0881 - val_accuracy: 0.9888\n",
      "Epoch 709/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0887 - val_accuracy: 0.9888\n",
      "Epoch 710/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0893 - val_accuracy: 0.9888\n",
      "Epoch 711/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0897 - val_accuracy: 0.9879\n",
      "Epoch 712/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0904 - val_accuracy: 0.9879\n",
      "Epoch 713/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.1018 - val_accuracy: 0.9860\n",
      "Epoch 714/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0874 - val_accuracy: 0.9860\n",
      "Epoch 715/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9936 - val_loss: 0.0980 - val_accuracy: 0.9879\n",
      "Epoch 716/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0881 - val_accuracy: 0.9851\n",
      "Epoch 717/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.1039 - val_accuracy: 0.9860\n",
      "Epoch 718/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0873 - val_accuracy: 0.9879\n",
      "Epoch 719/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0916 - val_accuracy: 0.9888\n",
      "Epoch 720/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9940 - val_loss: 0.0873 - val_accuracy: 0.9879\n",
      "Epoch 721/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.0948 - val_accuracy: 0.9888\n",
      "Epoch 722/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0888 - val_accuracy: 0.9869\n",
      "Epoch 723/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0931 - val_accuracy: 0.9897\n",
      "Epoch 724/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0898 - val_accuracy: 0.9832\n",
      "Epoch 725/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9945 - val_loss: 0.0905 - val_accuracy: 0.9897\n",
      "Epoch 726/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0888 - val_accuracy: 0.9897\n",
      "Epoch 727/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0870 - val_accuracy: 0.9897\n",
      "Epoch 728/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0908 - val_accuracy: 0.9888\n",
      "Epoch 729/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0888 - val_accuracy: 0.9860\n",
      "Epoch 730/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0923 - val_accuracy: 0.9897\n",
      "Epoch 731/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0890 - val_accuracy: 0.9879\n",
      "Epoch 732/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0928 - val_accuracy: 0.9888\n",
      "Epoch 733/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.0872 - val_accuracy: 0.9879\n",
      "Epoch 734/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0897 - val_accuracy: 0.9888\n",
      "Epoch 735/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9954 - val_loss: 0.0880 - val_accuracy: 0.9869\n",
      "Epoch 736/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9954 - val_loss: 0.0967 - val_accuracy: 0.9879\n",
      "Epoch 737/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0891 - val_accuracy: 0.9869\n",
      "Epoch 738/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9959 - val_loss: 0.0906 - val_accuracy: 0.9897\n",
      "Epoch 739/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0888 - val_accuracy: 0.9888\n",
      "Epoch 740/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0930 - val_accuracy: 0.9897\n",
      "Epoch 741/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0898 - val_accuracy: 0.9860\n",
      "Epoch 742/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9949 - val_loss: 0.0913 - val_accuracy: 0.9888\n",
      "Epoch 743/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9954 - val_loss: 0.0879 - val_accuracy: 0.9888\n",
      "Epoch 744/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.0966 - val_accuracy: 0.9869\n",
      "Epoch 745/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0919 - val_accuracy: 0.9832\n",
      "Epoch 746/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0954 - val_accuracy: 0.9879\n",
      "Epoch 747/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.0858 - val_accuracy: 0.9879\n",
      "Epoch 748/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0951 - val_accuracy: 0.9869\n",
      "Epoch 749/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0885 - val_accuracy: 0.9879\n",
      "Epoch 750/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.0933 - val_accuracy: 0.9879\n",
      "Epoch 751/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0870 - val_accuracy: 0.9879\n",
      "Epoch 752/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0940 - val_accuracy: 0.9879\n",
      "Epoch 753/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0873 - val_accuracy: 0.9851\n",
      "Epoch 754/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9949 - val_loss: 0.0917 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 755/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0890 - val_accuracy: 0.9841\n",
      "Epoch 756/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9931 - val_loss: 0.1041 - val_accuracy: 0.9851\n",
      "Epoch 757/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.0911 - val_accuracy: 0.9823\n",
      "Epoch 758/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9926 - val_loss: 0.1035 - val_accuracy: 0.9860\n",
      "Epoch 759/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0908 - val_accuracy: 0.9851\n",
      "Epoch 760/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9949 - val_loss: 0.0979 - val_accuracy: 0.9869\n",
      "Epoch 761/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0867 - val_accuracy: 0.9879\n",
      "Epoch 762/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0869 - val_accuracy: 0.9879\n",
      "Epoch 763/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0923 - val_accuracy: 0.9888\n",
      "Epoch 764/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.0915 - val_accuracy: 0.9869\n",
      "Epoch 765/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.0962 - val_accuracy: 0.9888\n",
      "Epoch 766/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.0898 - val_accuracy: 0.9888\n",
      "Epoch 767/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9949 - val_loss: 0.0901 - val_accuracy: 0.9869\n",
      "Epoch 768/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.0929 - val_accuracy: 0.9907\n",
      "Epoch 769/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.0897 - val_accuracy: 0.9851\n",
      "Epoch 770/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.0969 - val_accuracy: 0.9888\n",
      "Epoch 771/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0885 - val_accuracy: 0.9879\n",
      "Epoch 772/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0916 - val_accuracy: 0.9879\n",
      "Epoch 773/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0907 - val_accuracy: 0.9869\n",
      "Epoch 774/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0942 - val_accuracy: 0.9897\n",
      "Epoch 775/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.0895 - val_accuracy: 0.9860\n",
      "Epoch 776/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.1010 - val_accuracy: 0.9869\n",
      "Epoch 777/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0919 - val_accuracy: 0.9832\n",
      "Epoch 778/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.1063 - val_accuracy: 0.9851\n",
      "Epoch 779/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0907 - val_accuracy: 0.9841\n",
      "Epoch 780/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.1117 - val_accuracy: 0.9860\n",
      "Epoch 781/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 0.0953 - val_accuracy: 0.9823\n",
      "Epoch 782/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.0978 - val_accuracy: 0.9869\n",
      "Epoch 783/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0893 - val_accuracy: 0.9888\n",
      "Epoch 784/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0912 - val_accuracy: 0.9888\n",
      "Epoch 785/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0904 - val_accuracy: 0.9888\n",
      "Epoch 786/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0927 - val_accuracy: 0.9879\n",
      "Epoch 787/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9949 - val_loss: 0.0883 - val_accuracy: 0.9888\n",
      "Epoch 788/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0883 - val_accuracy: 0.9888\n",
      "Epoch 789/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.0899 - val_accuracy: 0.9897\n",
      "Epoch 790/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0909 - val_accuracy: 0.9879\n",
      "Epoch 791/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9954 - val_loss: 0.0890 - val_accuracy: 0.9897\n",
      "Epoch 792/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0942 - val_accuracy: 0.9897\n",
      "Epoch 793/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0906 - val_accuracy: 0.9851\n",
      "Epoch 794/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0979 - val_accuracy: 0.9879\n",
      "Epoch 795/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0898 - val_accuracy: 0.9869\n",
      "Epoch 796/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.0972 - val_accuracy: 0.9879\n",
      "Epoch 797/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0897 - val_accuracy: 0.9851\n",
      "Epoch 798/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0957 - val_accuracy: 0.9879\n",
      "Epoch 799/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0899 - val_accuracy: 0.9851\n",
      "Epoch 800/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0954 - val_accuracy: 0.9888\n",
      "Epoch 801/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0879 - val_accuracy: 0.9879\n",
      "Epoch 802/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9954 - val_loss: 0.0897 - val_accuracy: 0.9897\n",
      "Epoch 803/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0917 - val_accuracy: 0.9879\n",
      "Epoch 804/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9945 - val_loss: 0.1028 - val_accuracy: 0.9851\n",
      "Epoch 805/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0909 - val_accuracy: 0.9869\n",
      "Epoch 806/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 0.0979 - val_accuracy: 0.9879\n",
      "Epoch 807/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0903 - val_accuracy: 0.9869\n",
      "Epoch 808/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0958 - val_accuracy: 0.9888\n",
      "Epoch 809/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9959 - val_loss: 0.0908 - val_accuracy: 0.9860\n",
      "Epoch 810/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9949 - val_loss: 0.0917 - val_accuracy: 0.9897\n",
      "Epoch 811/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0903 - val_accuracy: 0.9897\n",
      "Epoch 812/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0886 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 813/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9949 - val_loss: 0.0914 - val_accuracy: 0.9897\n",
      "Epoch 814/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.0894 - val_accuracy: 0.9897\n",
      "Epoch 815/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0888 - val_accuracy: 0.9879\n",
      "Epoch 816/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0905 - val_accuracy: 0.9888\n",
      "Epoch 817/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0901 - val_accuracy: 0.9888\n",
      "Epoch 818/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9945 - val_loss: 0.0890 - val_accuracy: 0.9888\n",
      "Epoch 819/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9954 - val_loss: 0.0914 - val_accuracy: 0.9888\n",
      "Epoch 820/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0925 - val_accuracy: 0.9897\n",
      "Epoch 821/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0893 - val_accuracy: 0.9888\n",
      "Epoch 822/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0933 - val_accuracy: 0.9888\n",
      "Epoch 823/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.0923 - val_accuracy: 0.9832\n",
      "Epoch 824/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9926 - val_loss: 0.0915 - val_accuracy: 0.9879\n",
      "Epoch 825/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9940 - val_loss: 0.0887 - val_accuracy: 0.9888\n",
      "Epoch 826/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0884 - val_accuracy: 0.9860\n",
      "Epoch 827/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0997 - val_accuracy: 0.9869\n",
      "Epoch 828/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0865 - val_accuracy: 0.9888\n",
      "Epoch 829/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0898 - val_accuracy: 0.9897\n",
      "Epoch 830/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0892 - val_accuracy: 0.9888\n",
      "Epoch 831/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0895 - val_accuracy: 0.9869\n",
      "Epoch 832/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.1021 - val_accuracy: 0.9860\n",
      "Epoch 833/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0899 - val_accuracy: 0.9841\n",
      "Epoch 834/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.1008 - val_accuracy: 0.9860\n",
      "Epoch 835/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0918 - val_accuracy: 0.9851\n",
      "Epoch 836/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9949 - val_loss: 0.0997 - val_accuracy: 0.9869\n",
      "Epoch 837/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0880 - val_accuracy: 0.9879\n",
      "Epoch 838/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9949 - val_loss: 0.0966 - val_accuracy: 0.9888\n",
      "Epoch 839/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0890 - val_accuracy: 0.9879\n",
      "Epoch 840/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.0937 - val_accuracy: 0.9888\n",
      "Epoch 841/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0909 - val_accuracy: 0.9888\n",
      "Epoch 842/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0905 - val_accuracy: 0.9888\n",
      "Epoch 843/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0954 - val_accuracy: 0.9869\n",
      "Epoch 844/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.0906 - val_accuracy: 0.9851\n",
      "Epoch 845/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.1019 - val_accuracy: 0.9869\n",
      "Epoch 846/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.0925 - val_accuracy: 0.9832\n",
      "Epoch 847/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.0911 - val_accuracy: 0.9897\n",
      "Epoch 848/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9949 - val_loss: 0.0923 - val_accuracy: 0.9888\n",
      "Epoch 849/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0959 - val_accuracy: 0.9888\n",
      "Epoch 850/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0884 - val_accuracy: 0.9869\n",
      "Epoch 851/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0884 - val_accuracy: 0.9888\n",
      "Epoch 852/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0898 - val_accuracy: 0.9888\n",
      "Epoch 853/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.0919 - val_accuracy: 0.9888\n",
      "Epoch 854/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0910 - val_accuracy: 0.9869\n",
      "Epoch 855/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0967 - val_accuracy: 0.9879\n",
      "Epoch 856/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0897 - val_accuracy: 0.9860\n",
      "Epoch 857/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0915 - val_accuracy: 0.9907\n",
      "Epoch 858/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0925 - val_accuracy: 0.9888\n",
      "Epoch 859/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0922 - val_accuracy: 0.9879\n",
      "Epoch 860/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0895 - val_accuracy: 0.9888\n",
      "Epoch 861/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0934 - val_accuracy: 0.9879\n",
      "Epoch 862/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9954 - val_loss: 0.0902 - val_accuracy: 0.9888\n",
      "Epoch 863/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0935 - val_accuracy: 0.9879\n",
      "Epoch 864/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0885 - val_accuracy: 0.9888\n",
      "Epoch 865/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0903 - val_accuracy: 0.9897\n",
      "Epoch 866/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0893 - val_accuracy: 0.9897\n",
      "Epoch 867/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0930 - val_accuracy: 0.9897\n",
      "Epoch 868/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0900 - val_accuracy: 0.9860\n",
      "Epoch 869/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0897 - val_accuracy: 0.9897\n",
      "Epoch 870/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0885 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0927 - val_accuracy: 0.9888\n",
      "Epoch 872/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0922 - val_accuracy: 0.9888\n",
      "Epoch 873/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9954 - val_loss: 0.0885 - val_accuracy: 0.9897\n",
      "Epoch 874/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0895 - val_accuracy: 0.9897\n",
      "Epoch 875/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0916 - val_accuracy: 0.9897\n",
      "Epoch 876/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0905 - val_accuracy: 0.9879\n",
      "Epoch 877/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0935 - val_accuracy: 0.9907\n",
      "Epoch 878/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0904 - val_accuracy: 0.9888\n",
      "Epoch 879/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9959 - val_loss: 0.0930 - val_accuracy: 0.9888\n",
      "Epoch 880/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0896 - val_accuracy: 0.9888\n",
      "Epoch 881/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.0941 - val_accuracy: 0.9869\n",
      "Epoch 882/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0902 - val_accuracy: 0.9888\n",
      "Epoch 883/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0921 - val_accuracy: 0.9897\n",
      "Epoch 884/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0897 - val_accuracy: 0.9869\n",
      "Epoch 885/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0966 - val_accuracy: 0.9888\n",
      "Epoch 886/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0902 - val_accuracy: 0.9860\n",
      "Epoch 887/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9949 - val_loss: 0.0945 - val_accuracy: 0.9907\n",
      "Epoch 888/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0916 - val_accuracy: 0.9879\n",
      "Epoch 889/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.0943 - val_accuracy: 0.9897\n",
      "Epoch 890/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0900 - val_accuracy: 0.9869\n",
      "Epoch 891/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0952 - val_accuracy: 0.9907\n",
      "Epoch 892/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0891 - val_accuracy: 0.9888\n",
      "Epoch 893/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0926 - val_accuracy: 0.9897\n",
      "Epoch 894/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0911 - val_accuracy: 0.9888\n",
      "Epoch 895/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0907 - val_accuracy: 0.9888\n",
      "Epoch 896/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0905 - val_accuracy: 0.9888\n",
      "Epoch 897/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9959 - val_loss: 0.0919 - val_accuracy: 0.9888\n",
      "Epoch 898/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0913 - val_accuracy: 0.9888\n",
      "Epoch 899/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9959 - val_loss: 0.0915 - val_accuracy: 0.9897\n",
      "Epoch 900/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0898 - val_accuracy: 0.9888\n",
      "Epoch 901/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0919 - val_accuracy: 0.9888\n",
      "Epoch 902/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0901 - val_accuracy: 0.9888\n",
      "Epoch 903/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0962 - val_accuracy: 0.9879\n",
      "Epoch 904/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0920 - val_accuracy: 0.9841\n",
      "Epoch 905/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.1014 - val_accuracy: 0.9869\n",
      "Epoch 906/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0892 - val_accuracy: 0.9851\n",
      "Epoch 907/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9940 - val_loss: 0.0952 - val_accuracy: 0.9869\n",
      "Epoch 908/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0916 - val_accuracy: 0.9851\n",
      "Epoch 909/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0893 - val_accuracy: 0.9897\n",
      "Epoch 910/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0862 - val_accuracy: 0.9897\n",
      "Epoch 911/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0902 - val_accuracy: 0.9907\n",
      "Epoch 912/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9936 - val_loss: 0.0924 - val_accuracy: 0.9907\n",
      "Epoch 913/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.0853 - val_accuracy: 0.9888\n",
      "Epoch 914/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0976 - val_accuracy: 0.9860\n",
      "Epoch 915/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.0871 - val_accuracy: 0.9879\n",
      "Epoch 916/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0966 - val_accuracy: 0.9888\n",
      "Epoch 917/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0883 - val_accuracy: 0.9851\n",
      "Epoch 918/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.1019 - val_accuracy: 0.9860\n",
      "Epoch 919/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0930 - val_accuracy: 0.9832\n",
      "Epoch 920/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9926 - val_loss: 0.1060 - val_accuracy: 0.9841\n",
      "Epoch 921/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0893 - val_accuracy: 0.9860\n",
      "Epoch 922/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.1000 - val_accuracy: 0.9879\n",
      "Epoch 923/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0884 - val_accuracy: 0.9888\n",
      "Epoch 924/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0924 - val_accuracy: 0.9897\n",
      "Epoch 925/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0961 - val_accuracy: 0.9888\n",
      "Epoch 926/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0909 - val_accuracy: 0.9869\n",
      "Epoch 927/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9954 - val_loss: 0.0915 - val_accuracy: 0.9897\n",
      "Epoch 928/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0918 - val_accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 929/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0984 - val_accuracy: 0.9888\n",
      "Epoch 930/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0906 - val_accuracy: 0.9869\n",
      "Epoch 931/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0943 - val_accuracy: 0.9888\n",
      "Epoch 932/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0886 - val_accuracy: 0.9888\n",
      "Epoch 933/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0889 - val_accuracy: 0.9897\n",
      "Epoch 934/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0918 - val_accuracy: 0.9897\n",
      "Epoch 935/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0926 - val_accuracy: 0.9869\n",
      "Epoch 936/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0951 - val_accuracy: 0.9897\n",
      "Epoch 937/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0898 - val_accuracy: 0.9869\n",
      "Epoch 938/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0977 - val_accuracy: 0.9888\n",
      "Epoch 939/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0945 - val_accuracy: 0.9832\n",
      "Epoch 940/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9940 - val_loss: 0.1184 - val_accuracy: 0.9832\n",
      "Epoch 941/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.1019 - val_accuracy: 0.9776\n",
      "Epoch 942/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9899 - val_loss: 0.1015 - val_accuracy: 0.9879\n",
      "Epoch 943/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0956 - val_accuracy: 0.9832\n",
      "Epoch 944/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0965 - val_accuracy: 0.9888\n",
      "Epoch 945/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0874 - val_accuracy: 0.9879\n",
      "Epoch 946/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0927 - val_accuracy: 0.9888\n",
      "Epoch 947/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9949 - val_loss: 0.0930 - val_accuracy: 0.9879\n",
      "Epoch 948/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0926 - val_accuracy: 0.9888\n",
      "Epoch 949/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0891 - val_accuracy: 0.9879\n",
      "Epoch 950/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0909 - val_accuracy: 0.9907\n",
      "Epoch 951/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0930 - val_accuracy: 0.9897\n",
      "Epoch 952/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0944 - val_accuracy: 0.9897\n",
      "Epoch 953/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0932 - val_accuracy: 0.9907\n",
      "Epoch 954/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0907 - val_accuracy: 0.9888\n",
      "Epoch 955/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0895 - val_accuracy: 0.9879\n",
      "Epoch 956/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0920 - val_accuracy: 0.9897\n",
      "Epoch 957/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0925 - val_accuracy: 0.9888\n",
      "Epoch 958/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0914 - val_accuracy: 0.9888\n",
      "Epoch 959/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.0925 - val_accuracy: 0.9888\n",
      "Epoch 960/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0905 - val_accuracy: 0.9860\n",
      "Epoch 961/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9954 - val_loss: 0.1007 - val_accuracy: 0.9879\n",
      "Epoch 962/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0909 - val_accuracy: 0.9869\n",
      "Epoch 963/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9954 - val_loss: 0.0957 - val_accuracy: 0.9907\n",
      "Epoch 964/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0893 - val_accuracy: 0.9888\n",
      "Epoch 965/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0897 - val_accuracy: 0.9888\n",
      "Epoch 966/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.0932 - val_accuracy: 0.9897\n",
      "Epoch 967/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0946 - val_accuracy: 0.9888\n",
      "Epoch 968/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0919 - val_accuracy: 0.9888\n",
      "Epoch 969/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9959 - val_loss: 0.0894 - val_accuracy: 0.9879\n",
      "Epoch 970/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0914 - val_accuracy: 0.9888\n",
      "Epoch 971/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0943 - val_accuracy: 0.9879\n",
      "Epoch 972/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0940 - val_accuracy: 0.9907\n",
      "Epoch 973/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0906 - val_accuracy: 0.9888\n",
      "Epoch 974/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.1002 - val_accuracy: 0.9879\n",
      "Epoch 975/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0920 - val_accuracy: 0.9879\n",
      "Epoch 976/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0925 - val_accuracy: 0.9907\n",
      "Epoch 977/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.0919 - val_accuracy: 0.9888\n",
      "Epoch 978/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9959 - val_loss: 0.0923 - val_accuracy: 0.9888\n",
      "Epoch 979/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.0930 - val_accuracy: 0.9888\n",
      "Epoch 980/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0944 - val_accuracy: 0.9897\n",
      "Epoch 981/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9959 - val_loss: 0.0931 - val_accuracy: 0.9897\n",
      "Epoch 982/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.0919 - val_accuracy: 0.9888\n",
      "Epoch 983/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0929 - val_accuracy: 0.9879\n",
      "Epoch 984/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0910 - val_accuracy: 0.9888\n",
      "Epoch 985/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.0904 - val_accuracy: 0.9888\n",
      "Epoch 986/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0921 - val_accuracy: 0.9888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 987/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9959 - val_loss: 0.0963 - val_accuracy: 0.9888\n",
      "Epoch 988/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0892 - val_accuracy: 0.9869\n",
      "Epoch 989/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0977 - val_accuracy: 0.9879\n",
      "Epoch 990/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0913 - val_accuracy: 0.9869\n",
      "Epoch 991/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0933 - val_accuracy: 0.9897\n",
      "Epoch 992/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9959 - val_loss: 0.0920 - val_accuracy: 0.9907\n",
      "Epoch 993/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0896 - val_accuracy: 0.9879\n",
      "Epoch 994/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0967 - val_accuracy: 0.9869\n",
      "Epoch 995/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0941 - val_accuracy: 0.9879\n",
      "Epoch 996/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0943 - val_accuracy: 0.9888\n",
      "Epoch 997/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0909 - val_accuracy: 0.9888\n",
      "Epoch 998/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.0961 - val_accuracy: 0.9897\n",
      "Epoch 999/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0943 - val_accuracy: 0.9897\n",
      "Epoch 1000/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.0907 - val_accuracy: 0.9897\n",
      "Epoch 1001/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9949 - val_loss: 0.0955 - val_accuracy: 0.9907\n",
      "Epoch 1002/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0908 - val_accuracy: 0.9879\n",
      "Epoch 1003/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0964 - val_accuracy: 0.9879\n",
      "Epoch 1004/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0900 - val_accuracy: 0.9879\n",
      "Epoch 1005/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9954 - val_loss: 0.0960 - val_accuracy: 0.9907\n",
      "Epoch 1006/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0913 - val_accuracy: 0.9869\n",
      "Epoch 1007/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0955 - val_accuracy: 0.9888\n",
      "Epoch 1008/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0898 - val_accuracy: 0.9879\n",
      "Epoch 1009/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9949 - val_loss: 0.0950 - val_accuracy: 0.9897\n",
      "Epoch 1010/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0921 - val_accuracy: 0.9851\n",
      "Epoch 1011/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0960 - val_accuracy: 0.9888\n",
      "Epoch 1012/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0924 - val_accuracy: 0.9897\n",
      "Epoch 1013/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.0925 - val_accuracy: 0.9897\n",
      "Epoch 1014/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.0893 - val_accuracy: 0.9897\n",
      "Epoch 1015/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0969 - val_accuracy: 0.9879\n",
      "Epoch 1016/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0903 - val_accuracy: 0.9879\n",
      "Epoch 1017/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.0947 - val_accuracy: 0.9897\n",
      "Epoch 1018/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.0918 - val_accuracy: 0.9888\n",
      "Epoch 1019/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.0923 - val_accuracy: 0.9888\n",
      "Epoch 1020/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.0916 - val_accuracy: 0.9897\n",
      "Epoch 1021/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.0937 - val_accuracy: 0.9907\n",
      "Epoch 1022/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.0921 - val_accuracy: 0.9869\n",
      "Epoch 1023/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9936 - val_loss: 0.1091 - val_accuracy: 0.9860\n",
      "Epoch 1024/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0994 - val_accuracy: 0.9804\n",
      "Epoch 1025/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9908 - val_loss: 0.1453 - val_accuracy: 0.9795\n",
      "Epoch 1026/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9881 - val_loss: 0.1295 - val_accuracy: 0.9729\n",
      "Epoch 1027/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9881 - val_loss: 0.1211 - val_accuracy: 0.9823\n",
      "Epoch 1028/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9940 - val_loss: 0.1015 - val_accuracy: 0.9748\n",
      "Epoch 1029/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.0889 - val_accuracy: 0.9879\n",
      "Epoch 1030/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9936 - val_loss: 0.0947 - val_accuracy: 0.9897\n",
      "Epoch 1031/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.1021 - val_accuracy: 0.9851\n",
      "Epoch 1032/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0945 - val_accuracy: 0.9851\n",
      "Epoch 1033/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.1021 - val_accuracy: 0.9879\n",
      "Epoch 1034/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0934 - val_accuracy: 0.9888\n",
      "Epoch 1035/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0950 - val_accuracy: 0.9869\n",
      "Epoch 1036/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9922 - val_loss: 0.1114 - val_accuracy: 0.9860\n",
      "Epoch 1037/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 0.0918 - val_accuracy: 0.9851\n",
      "Epoch 1038/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9913 - val_loss: 0.1073 - val_accuracy: 0.9841\n",
      "Epoch 1039/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.0925 - val_accuracy: 0.9869\n",
      "Epoch 1040/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0980 - val_accuracy: 0.9879\n",
      "Epoch 1041/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0909 - val_accuracy: 0.9888\n",
      "Epoch 1042/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0981 - val_accuracy: 0.9888\n",
      "Epoch 1043/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0923 - val_accuracy: 0.9869\n",
      "Epoch 1044/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.0929 - val_accuracy: 0.9907\n",
      "Epoch 1045/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0940 - val_accuracy: 0.9897\n",
      "Epoch 1046/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0969 - val_accuracy: 0.9869\n",
      "Epoch 1047/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0948 - val_accuracy: 0.9888\n",
      "Epoch 1048/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0923 - val_accuracy: 0.9897\n",
      "Epoch 1049/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0923 - val_accuracy: 0.9897\n",
      "Epoch 1050/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0925 - val_accuracy: 0.9888\n",
      "Epoch 1051/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0950 - val_accuracy: 0.9888\n",
      "Epoch 1052/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0933 - val_accuracy: 0.9897\n",
      "Epoch 1053/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0963 - val_accuracy: 0.9907\n",
      "Epoch 1054/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.0928 - val_accuracy: 0.9860\n",
      "Epoch 1055/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9926 - val_loss: 0.1010 - val_accuracy: 0.9888\n",
      "Epoch 1056/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.0924 - val_accuracy: 0.9888\n",
      "Epoch 1057/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0930 - val_accuracy: 0.9888\n",
      "Epoch 1058/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0943 - val_accuracy: 0.9907\n",
      "Epoch 1059/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.0918 - val_accuracy: 0.9879\n",
      "Epoch 1060/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9959 - val_loss: 0.1003 - val_accuracy: 0.9879\n",
      "Epoch 1061/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.0931 - val_accuracy: 0.9869\n",
      "Epoch 1062/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1016 - val_accuracy: 0.9879\n",
      "Epoch 1063/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.0935 - val_accuracy: 0.9841\n",
      "Epoch 1064/3500\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.99 - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9926 - val_loss: 0.1028 - val_accuracy: 0.9879\n",
      "Epoch 1065/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0911 - val_accuracy: 0.9879\n",
      "Epoch 1066/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0923 - val_accuracy: 0.9907\n",
      "Epoch 1067/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0919 - val_accuracy: 0.9879\n",
      "Epoch 1068/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.0956 - val_accuracy: 0.9879\n",
      "Epoch 1069/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0937 - val_accuracy: 0.9907\n",
      "Epoch 1070/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0930 - val_accuracy: 0.9897\n",
      "Epoch 1071/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0940 - val_accuracy: 0.9897\n",
      "Epoch 1072/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0954 - val_accuracy: 0.9888\n",
      "Epoch 1073/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.0943 - val_accuracy: 0.9897\n",
      "Epoch 1074/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0917 - val_accuracy: 0.9879\n",
      "Epoch 1075/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0979 - val_accuracy: 0.9907\n",
      "Epoch 1076/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0915 - val_accuracy: 0.9851\n",
      "Epoch 1077/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.0995 - val_accuracy: 0.9888\n",
      "Epoch 1078/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0928 - val_accuracy: 0.9888\n",
      "Epoch 1079/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0998 - val_accuracy: 0.9888\n",
      "Epoch 1080/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.0896 - val_accuracy: 0.9888\n",
      "Epoch 1081/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0942 - val_accuracy: 0.9916\n",
      "Epoch 1082/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0946 - val_accuracy: 0.9888\n",
      "Epoch 1083/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0932 - val_accuracy: 0.9879\n",
      "Epoch 1084/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0911 - val_accuracy: 0.9879\n",
      "Epoch 1085/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9940 - val_loss: 0.1012 - val_accuracy: 0.9869\n",
      "Epoch 1086/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0944 - val_accuracy: 0.9841\n",
      "Epoch 1087/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9931 - val_loss: 0.0971 - val_accuracy: 0.9907\n",
      "Epoch 1088/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.0905 - val_accuracy: 0.9879\n",
      "Epoch 1089/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0966 - val_accuracy: 0.9897\n",
      "Epoch 1090/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0966 - val_accuracy: 0.9869\n",
      "Epoch 1091/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0938 - val_accuracy: 0.9888\n",
      "Epoch 1092/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0922 - val_accuracy: 0.9907\n",
      "Epoch 1093/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0905 - val_accuracy: 0.9897\n",
      "Epoch 1094/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0936 - val_accuracy: 0.9897\n",
      "Epoch 1095/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0923 - val_accuracy: 0.9897\n",
      "Epoch 1096/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9945 - val_loss: 0.0913 - val_accuracy: 0.9897\n",
      "Epoch 1097/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0954 - val_accuracy: 0.9907\n",
      "Epoch 1098/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0962 - val_accuracy: 0.9860\n",
      "Epoch 1099/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9954 - val_loss: 0.1012 - val_accuracy: 0.9888\n",
      "Epoch 1100/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9954 - val_loss: 0.0912 - val_accuracy: 0.9879\n",
      "Epoch 1101/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9945 - val_loss: 0.0960 - val_accuracy: 0.9907\n",
      "Epoch 1102/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.0921 - val_accuracy: 0.9879\n",
      "Epoch 1103/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.0968 - val_accuracy: 0.9916\n",
      "Epoch 1104/3500\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0912 - val_accuracy: 0.9879\n",
      "Epoch 1105/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0957 - val_accuracy: 0.9907\n",
      "Epoch 1106/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0932 - val_accuracy: 0.9897\n",
      "Epoch 1107/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0971 - val_accuracy: 0.9879\n",
      "Epoch 1108/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0944 - val_accuracy: 0.9888\n",
      "Epoch 1109/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0936 - val_accuracy: 0.9907\n",
      "Epoch 1110/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0945 - val_accuracy: 0.9907\n",
      "Epoch 1111/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.0973 - val_accuracy: 0.9907\n",
      "Epoch 1112/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0928 - val_accuracy: 0.9869\n",
      "Epoch 1113/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.0986 - val_accuracy: 0.9888\n",
      "Epoch 1114/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0907 - val_accuracy: 0.9897\n",
      "Epoch 1115/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9949 - val_loss: 0.0981 - val_accuracy: 0.9869\n",
      "Epoch 1116/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0980 - val_accuracy: 0.9897\n",
      "Epoch 1117/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0891 - val_accuracy: 0.9888\n",
      "Epoch 1118/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0951 - val_accuracy: 0.9907\n",
      "Epoch 1119/3500\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0917 - val_accuracy: 0.9888\n",
      "Epoch 1120/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.0935 - val_accuracy: 0.9897\n",
      "Epoch 1121/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0911 - val_accuracy: 0.9879\n",
      "Epoch 1122/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9945 - val_loss: 0.0934 - val_accuracy: 0.9907\n",
      "Epoch 1123/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.0937 - val_accuracy: 0.9897\n",
      "Epoch 1124/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.0936 - val_accuracy: 0.9888\n",
      "Epoch 1125/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0947 - val_accuracy: 0.9888\n",
      "Epoch 1126/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.0930 - val_accuracy: 0.9888\n",
      "Epoch 1127/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0983 - val_accuracy: 0.9888\n",
      "Epoch 1128/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0921 - val_accuracy: 0.9869\n",
      "Epoch 1129/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9954 - val_loss: 0.0977 - val_accuracy: 0.9907\n",
      "Epoch 1130/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0936 - val_accuracy: 0.9897\n",
      "Epoch 1131/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0916 - val_accuracy: 0.9879\n",
      "Epoch 1132/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0986 - val_accuracy: 0.9869\n",
      "Epoch 1133/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9940 - val_loss: 0.0938 - val_accuracy: 0.9897\n",
      "Epoch 1134/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.0921 - val_accuracy: 0.9888\n",
      "Epoch 1135/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9949 - val_loss: 0.0957 - val_accuracy: 0.9916\n",
      "Epoch 1136/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.0947 - val_accuracy: 0.9897\n",
      "Epoch 1137/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9959 - val_loss: 0.0928 - val_accuracy: 0.9888\n",
      "Epoch 1138/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0938 - val_accuracy: 0.9897\n",
      "Epoch 1139/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0928 - val_accuracy: 0.9888\n",
      "Epoch 1140/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.1008 - val_accuracy: 0.9860\n",
      "Epoch 1141/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0948 - val_accuracy: 0.9879\n",
      "Epoch 1142/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0963 - val_accuracy: 0.9907\n",
      "Epoch 1143/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0926 - val_accuracy: 0.9869\n",
      "Epoch 1144/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9945 - val_loss: 0.0958 - val_accuracy: 0.9907\n",
      "Epoch 1145/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0934 - val_accuracy: 0.9869\n",
      "Epoch 1146/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.1065 - val_accuracy: 0.9851\n",
      "Epoch 1147/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0930 - val_accuracy: 0.9879\n",
      "Epoch 1148/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9949 - val_loss: 0.0926 - val_accuracy: 0.9897\n",
      "Epoch 1149/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0922 - val_accuracy: 0.9879\n",
      "Epoch 1150/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.1012 - val_accuracy: 0.9897\n",
      "Epoch 1151/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0935 - val_accuracy: 0.9879\n",
      "Epoch 1152/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0937 - val_accuracy: 0.9897\n",
      "Epoch 1153/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0943 - val_accuracy: 0.9888\n",
      "Epoch 1154/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0952 - val_accuracy: 0.9907\n",
      "Epoch 1155/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0934 - val_accuracy: 0.9888\n",
      "Epoch 1156/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.0941 - val_accuracy: 0.9888\n",
      "Epoch 1157/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.0931 - val_accuracy: 0.9869\n",
      "Epoch 1158/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9945 - val_loss: 0.0922 - val_accuracy: 0.9897\n",
      "Epoch 1159/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0910 - val_accuracy: 0.9897\n",
      "Epoch 1160/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0991 - val_accuracy: 0.9897\n",
      "Epoch 1161/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.0931 - val_accuracy: 0.9897\n",
      "Epoch 1162/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0927 - val_accuracy: 0.9897\n",
      "Epoch 1163/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0973 - val_accuracy: 0.9897\n",
      "Epoch 1164/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9959 - val_loss: 0.0961 - val_accuracy: 0.9888\n",
      "Epoch 1165/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0930 - val_accuracy: 0.9897\n",
      "Epoch 1166/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0922 - val_accuracy: 0.9888\n",
      "Epoch 1167/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1027 - val_accuracy: 0.9869\n",
      "Epoch 1168/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0959 - val_accuracy: 0.9879\n",
      "Epoch 1169/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0933 - val_accuracy: 0.9888\n",
      "Epoch 1170/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0947 - val_accuracy: 0.9888\n",
      "Epoch 1171/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0966 - val_accuracy: 0.9888\n",
      "Epoch 1172/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0950 - val_accuracy: 0.9888\n",
      "Epoch 1173/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.0957 - val_accuracy: 0.9888\n",
      "Epoch 1174/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.0937 - val_accuracy: 0.9879\n",
      "Epoch 1175/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.0952 - val_accuracy: 0.9888\n",
      "Epoch 1176/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0951 - val_accuracy: 0.9888\n",
      "Epoch 1177/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.0995 - val_accuracy: 0.9907\n",
      "Epoch 1178/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0934 - val_accuracy: 0.9879\n",
      "Epoch 1179/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0981 - val_accuracy: 0.9907\n",
      "Epoch 1180/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0953 - val_accuracy: 0.9888\n",
      "Epoch 1181/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0997 - val_accuracy: 0.9888\n",
      "Epoch 1182/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0939 - val_accuracy: 0.9888\n",
      "Epoch 1183/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.0943 - val_accuracy: 0.9888\n",
      "Epoch 1184/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0989 - val_accuracy: 0.9888\n",
      "Epoch 1185/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0924 - val_accuracy: 0.9888\n",
      "Epoch 1186/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9936 - val_loss: 0.1047 - val_accuracy: 0.9869\n",
      "Epoch 1187/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0930 - val_accuracy: 0.9860\n",
      "Epoch 1188/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.1053 - val_accuracy: 0.9860\n",
      "Epoch 1189/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0907 - val_accuracy: 0.9879\n",
      "Epoch 1190/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9945 - val_loss: 0.0994 - val_accuracy: 0.9888\n",
      "Epoch 1191/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9954 - val_loss: 0.0956 - val_accuracy: 0.9879\n",
      "Epoch 1192/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0974 - val_accuracy: 0.9897\n",
      "Epoch 1193/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0919 - val_accuracy: 0.9879\n",
      "Epoch 1194/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0939 - val_accuracy: 0.9879\n",
      "Epoch 1195/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.1042 - val_accuracy: 0.9869\n",
      "Epoch 1196/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.0975 - val_accuracy: 0.9869\n",
      "Epoch 1197/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9945 - val_loss: 0.0966 - val_accuracy: 0.9879\n",
      "Epoch 1198/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0921 - val_accuracy: 0.9851\n",
      "Epoch 1199/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9954 - val_loss: 0.1033 - val_accuracy: 0.9879\n",
      "Epoch 1200/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.0933 - val_accuracy: 0.9879\n",
      "Epoch 1201/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.1045 - val_accuracy: 0.9869\n",
      "Epoch 1202/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0922 - val_accuracy: 0.9869\n",
      "Epoch 1203/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.0949 - val_accuracy: 0.9897\n",
      "Epoch 1204/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.0936 - val_accuracy: 0.9897\n",
      "Epoch 1205/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.1012 - val_accuracy: 0.9897\n",
      "Epoch 1206/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0943 - val_accuracy: 0.9888\n",
      "Epoch 1207/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.0946 - val_accuracy: 0.9907\n",
      "Epoch 1208/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0940 - val_accuracy: 0.9879\n",
      "Epoch 1209/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1011 - val_accuracy: 0.9888\n",
      "Epoch 1210/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0939 - val_accuracy: 0.9888\n",
      "Epoch 1211/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0957 - val_accuracy: 0.9897\n",
      "Epoch 1212/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0970 - val_accuracy: 0.9897\n",
      "Epoch 1213/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0949 - val_accuracy: 0.9897\n",
      "Epoch 1214/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0982 - val_accuracy: 0.9907\n",
      "Epoch 1215/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0940 - val_accuracy: 0.9888\n",
      "Epoch 1216/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.0958 - val_accuracy: 0.9907\n",
      "Epoch 1217/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.0983 - val_accuracy: 0.9888\n",
      "Epoch 1218/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0959 - val_accuracy: 0.9888\n",
      "Epoch 1219/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.0961 - val_accuracy: 0.9888\n",
      "Epoch 1220/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0931 - val_accuracy: 0.9879\n",
      "Epoch 1221/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.0997 - val_accuracy: 0.9907\n",
      "Epoch 1222/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0939 - val_accuracy: 0.9879\n",
      "Epoch 1223/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1018 - val_accuracy: 0.9888\n",
      "Epoch 1224/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0923 - val_accuracy: 0.9879\n",
      "Epoch 1225/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9954 - val_loss: 0.1108 - val_accuracy: 0.9851\n",
      "Epoch 1226/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0961 - val_accuracy: 0.9841\n",
      "Epoch 1227/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9926 - val_loss: 0.1182 - val_accuracy: 0.9851\n",
      "Epoch 1228/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0940 - val_accuracy: 0.9869\n",
      "Epoch 1229/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9945 - val_loss: 0.1052 - val_accuracy: 0.9841\n",
      "Epoch 1230/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0916 - val_accuracy: 0.9879\n",
      "Epoch 1231/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0958 - val_accuracy: 0.9907\n",
      "Epoch 1232/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0932 - val_accuracy: 0.9879\n",
      "Epoch 1233/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.0932 - val_accuracy: 0.9879\n",
      "Epoch 1234/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0995 - val_accuracy: 0.9897\n",
      "Epoch 1235/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0923 - val_accuracy: 0.9888\n",
      "Epoch 1236/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0951 - val_accuracy: 0.9907\n",
      "Epoch 1237/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0925 - val_accuracy: 0.9897\n",
      "Epoch 1238/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.0979 - val_accuracy: 0.9907\n",
      "Epoch 1239/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0933 - val_accuracy: 0.9869\n",
      "Epoch 1240/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.0946 - val_accuracy: 0.9888\n",
      "Epoch 1241/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9959 - val_loss: 0.0968 - val_accuracy: 0.9907\n",
      "Epoch 1242/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0973 - val_accuracy: 0.9879\n",
      "Epoch 1243/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0951 - val_accuracy: 0.9897\n",
      "Epoch 1244/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.0951 - val_accuracy: 0.9907\n",
      "Epoch 1245/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.0940 - val_accuracy: 0.9879\n",
      "Epoch 1246/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0980 - val_accuracy: 0.9888\n",
      "Epoch 1247/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0978 - val_accuracy: 0.9851\n",
      "Epoch 1248/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.0967 - val_accuracy: 0.9897\n",
      "Epoch 1249/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0920 - val_accuracy: 0.9869\n",
      "Epoch 1250/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9945 - val_loss: 0.0984 - val_accuracy: 0.9907\n",
      "Epoch 1251/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0979 - val_accuracy: 0.9897\n",
      "Epoch 1252/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0935 - val_accuracy: 0.9879\n",
      "Epoch 1253/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9945 - val_loss: 0.0967 - val_accuracy: 0.9897\n",
      "Epoch 1254/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0947 - val_accuracy: 0.9888\n",
      "Epoch 1255/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.1013 - val_accuracy: 0.9897\n",
      "Epoch 1256/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0933 - val_accuracy: 0.9879\n",
      "Epoch 1257/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1048 - val_accuracy: 0.9879\n",
      "Epoch 1258/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.0964 - val_accuracy: 0.9879\n",
      "Epoch 1259/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0995 - val_accuracy: 0.9897\n",
      "Epoch 1260/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.0930 - val_accuracy: 0.9888\n",
      "Epoch 1261/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0961 - val_accuracy: 0.9897\n",
      "Epoch 1262/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0958 - val_accuracy: 0.9869\n",
      "Epoch 1263/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.1012 - val_accuracy: 0.9888\n",
      "Epoch 1264/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0927 - val_accuracy: 0.9879\n",
      "Epoch 1265/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.1047 - val_accuracy: 0.9869\n",
      "Epoch 1266/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0936 - val_accuracy: 0.9888\n",
      "Epoch 1267/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0978 - val_accuracy: 0.9897\n",
      "Epoch 1268/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.0993 - val_accuracy: 0.9869\n",
      "Epoch 1269/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0997 - val_accuracy: 0.9897\n",
      "Epoch 1270/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0916 - val_accuracy: 0.9879\n",
      "Epoch 1271/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0972 - val_accuracy: 0.9907\n",
      "Epoch 1272/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0965 - val_accuracy: 0.9888\n",
      "Epoch 1273/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0970 - val_accuracy: 0.9897\n",
      "Epoch 1274/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.0922 - val_accuracy: 0.9888\n",
      "Epoch 1275/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.1041 - val_accuracy: 0.9879\n",
      "Epoch 1276/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0943 - val_accuracy: 0.9879\n",
      "Epoch 1277/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0975 - val_accuracy: 0.9897\n",
      "Epoch 1278/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9954 - val_loss: 0.1009 - val_accuracy: 0.9907\n",
      "Epoch 1279/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0933 - val_accuracy: 0.9888\n",
      "Epoch 1280/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.1087 - val_accuracy: 0.9869\n",
      "Epoch 1281/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0958 - val_accuracy: 0.9841\n",
      "Epoch 1282/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.1060 - val_accuracy: 0.9879\n",
      "Epoch 1283/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0955 - val_accuracy: 0.9897\n",
      "Epoch 1284/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0958 - val_accuracy: 0.9897\n",
      "Epoch 1285/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9945 - val_loss: 0.0989 - val_accuracy: 0.9888\n",
      "Epoch 1286/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0932 - val_accuracy: 0.9888\n",
      "Epoch 1287/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9954 - val_loss: 0.1021 - val_accuracy: 0.9879\n",
      "Epoch 1288/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0917 - val_accuracy: 0.9888\n",
      "Epoch 1289/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0953 - val_accuracy: 0.9897\n",
      "Epoch 1290/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0989 - val_accuracy: 0.9897\n",
      "Epoch 1291/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0949 - val_accuracy: 0.9879\n",
      "Epoch 1292/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.1000 - val_accuracy: 0.9897\n",
      "Epoch 1293/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0936 - val_accuracy: 0.9879\n",
      "Epoch 1294/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0970 - val_accuracy: 0.9907\n",
      "Epoch 1295/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.0945 - val_accuracy: 0.9897\n",
      "Epoch 1296/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.0992 - val_accuracy: 0.9897\n",
      "Epoch 1297/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0959 - val_accuracy: 0.9888\n",
      "Epoch 1298/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0971 - val_accuracy: 0.9888\n",
      "Epoch 1299/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0944 - val_accuracy: 0.9879\n",
      "Epoch 1300/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.0988 - val_accuracy: 0.9907\n",
      "Epoch 1301/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0958 - val_accuracy: 0.9888\n",
      "Epoch 1302/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0992 - val_accuracy: 0.9897\n",
      "Epoch 1303/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0951 - val_accuracy: 0.9879\n",
      "Epoch 1304/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.0989 - val_accuracy: 0.9897\n",
      "Epoch 1305/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0972 - val_accuracy: 0.9888\n",
      "Epoch 1306/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.1021 - val_accuracy: 0.9897\n",
      "Epoch 1307/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0936 - val_accuracy: 0.9888\n",
      "Epoch 1308/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.1033 - val_accuracy: 0.9897\n",
      "Epoch 1309/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0979 - val_accuracy: 0.9888\n",
      "Epoch 1310/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0956 - val_accuracy: 0.9879\n",
      "Epoch 1311/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.1016 - val_accuracy: 0.9907\n",
      "Epoch 1312/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.0969 - val_accuracy: 0.9851\n",
      "Epoch 1313/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.1040 - val_accuracy: 0.9879\n",
      "Epoch 1314/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9949 - val_loss: 0.0945 - val_accuracy: 0.9888\n",
      "Epoch 1315/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.1039 - val_accuracy: 0.9888\n",
      "Epoch 1316/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9949 - val_loss: 0.0964 - val_accuracy: 0.9869\n",
      "Epoch 1317/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0993 - val_accuracy: 0.9897\n",
      "Epoch 1318/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0959 - val_accuracy: 0.9897\n",
      "Epoch 1319/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0975 - val_accuracy: 0.9897\n",
      "Epoch 1320/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0945 - val_accuracy: 0.9888\n",
      "Epoch 1321/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.0984 - val_accuracy: 0.9897\n",
      "Epoch 1322/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.0978 - val_accuracy: 0.9888\n",
      "Epoch 1323/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0985 - val_accuracy: 0.9897\n",
      "Epoch 1324/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0951 - val_accuracy: 0.9888\n",
      "Epoch 1325/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.1033 - val_accuracy: 0.9897\n",
      "Epoch 1326/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.0987 - val_accuracy: 0.9841\n",
      "Epoch 1327/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9931 - val_loss: 0.1237 - val_accuracy: 0.9832\n",
      "Epoch 1328/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.1018 - val_accuracy: 0.9813\n",
      "Epoch 1329/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9940 - val_loss: 0.1245 - val_accuracy: 0.9841\n",
      "Epoch 1330/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.0957 - val_accuracy: 0.9823\n",
      "Epoch 1331/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 0.1019 - val_accuracy: 0.9879\n",
      "Epoch 1332/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.0979 - val_accuracy: 0.9888\n",
      "Epoch 1333/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0968 - val_accuracy: 0.9888\n",
      "Epoch 1334/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0955 - val_accuracy: 0.9879\n",
      "Epoch 1335/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0982 - val_accuracy: 0.9888\n",
      "Epoch 1336/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.0954 - val_accuracy: 0.9879\n",
      "Epoch 1337/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.1003 - val_accuracy: 0.9897\n",
      "Epoch 1338/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.0941 - val_accuracy: 0.9879\n",
      "Epoch 1339/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.1006 - val_accuracy: 0.9916\n",
      "Epoch 1340/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0959 - val_accuracy: 0.9869\n",
      "Epoch 1341/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0986 - val_accuracy: 0.9907\n",
      "Epoch 1342/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.0971 - val_accuracy: 0.9888\n",
      "Epoch 1343/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0979 - val_accuracy: 0.9888\n",
      "Epoch 1344/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0959 - val_accuracy: 0.9888\n",
      "Epoch 1345/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0974 - val_accuracy: 0.9879\n",
      "Epoch 1346/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0964 - val_accuracy: 0.9888\n",
      "Epoch 1347/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.1028 - val_accuracy: 0.9907\n",
      "Epoch 1348/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0994 - val_accuracy: 0.9869\n",
      "Epoch 1349/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.1020 - val_accuracy: 0.9888\n",
      "Epoch 1350/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.1022 - val_accuracy: 0.9888\n",
      "Epoch 1351/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0962 - val_accuracy: 0.9851\n",
      "Epoch 1352/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.1167 - val_accuracy: 0.9841\n",
      "Epoch 1353/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.0971 - val_accuracy: 0.9860\n",
      "Epoch 1354/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.1059 - val_accuracy: 0.9879\n",
      "Epoch 1355/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0975 - val_accuracy: 0.9879\n",
      "Epoch 1356/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1109 - val_accuracy: 0.9860\n",
      "Epoch 1357/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0988 - val_accuracy: 0.9869\n",
      "Epoch 1358/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0981 - val_accuracy: 0.9888\n",
      "Epoch 1359/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.0979 - val_accuracy: 0.9879\n",
      "Epoch 1360/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1013 - val_accuracy: 0.9897\n",
      "Epoch 1361/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0961 - val_accuracy: 0.9888\n",
      "Epoch 1362/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.1023 - val_accuracy: 0.9888\n",
      "Epoch 1363/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0967 - val_accuracy: 0.9879\n",
      "Epoch 1364/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.1000 - val_accuracy: 0.9888\n",
      "Epoch 1365/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0980 - val_accuracy: 0.9879\n",
      "Epoch 1366/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1020 - val_accuracy: 0.9897\n",
      "Epoch 1367/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0955 - val_accuracy: 0.9879\n",
      "Epoch 1368/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.1068 - val_accuracy: 0.9869\n",
      "Epoch 1369/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0956 - val_accuracy: 0.9869\n",
      "Epoch 1370/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.1086 - val_accuracy: 0.9879\n",
      "Epoch 1371/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0979 - val_accuracy: 0.9888\n",
      "Epoch 1372/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.1029 - val_accuracy: 0.9888\n",
      "Epoch 1373/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0976 - val_accuracy: 0.9879\n",
      "Epoch 1374/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.1028 - val_accuracy: 0.9879\n",
      "Epoch 1375/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9954 - val_loss: 0.1092 - val_accuracy: 0.9869\n",
      "Epoch 1376/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.0935 - val_accuracy: 0.9879\n",
      "Epoch 1377/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 0.1069 - val_accuracy: 0.9869\n",
      "Epoch 1378/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0993 - val_accuracy: 0.9879\n",
      "Epoch 1379/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.1191 - val_accuracy: 0.9832\n",
      "Epoch 1380/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0935 - val_accuracy: 0.9841\n",
      "Epoch 1381/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.1066 - val_accuracy: 0.9888\n",
      "Epoch 1382/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.1003 - val_accuracy: 0.9860\n",
      "Epoch 1383/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.1174 - val_accuracy: 0.9841\n",
      "Epoch 1384/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0990 - val_accuracy: 0.9823\n",
      "Epoch 1385/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.1164 - val_accuracy: 0.9869\n",
      "Epoch 1386/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9926 - val_loss: 0.1004 - val_accuracy: 0.9860\n",
      "Epoch 1387/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9954 - val_loss: 0.1060 - val_accuracy: 0.9869\n",
      "Epoch 1388/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0958 - val_accuracy: 0.9897\n",
      "Epoch 1389/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9959 - val_loss: 0.0984 - val_accuracy: 0.9888\n",
      "Epoch 1390/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9949 - val_loss: 0.1105 - val_accuracy: 0.9860\n",
      "Epoch 1391/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0941 - val_accuracy: 0.9869\n",
      "Epoch 1392/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.1033 - val_accuracy: 0.9879\n",
      "Epoch 1393/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.0975 - val_accuracy: 0.9869\n",
      "Epoch 1394/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.1092 - val_accuracy: 0.9860\n",
      "Epoch 1395/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0977 - val_accuracy: 0.9888\n",
      "Epoch 1396/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.0981 - val_accuracy: 0.9897\n",
      "Epoch 1397/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.1000 - val_accuracy: 0.9888\n",
      "Epoch 1398/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0965 - val_accuracy: 0.9888\n",
      "Epoch 1399/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9959 - val_loss: 0.1017 - val_accuracy: 0.9907\n",
      "Epoch 1400/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0981 - val_accuracy: 0.9860\n",
      "Epoch 1401/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.1001 - val_accuracy: 0.9897\n",
      "Epoch 1402/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.0959 - val_accuracy: 0.9888\n",
      "Epoch 1403/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.1013 - val_accuracy: 0.9879\n",
      "Epoch 1404/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.1021 - val_accuracy: 0.9869\n",
      "Epoch 1405/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0976 - val_accuracy: 0.9888\n",
      "Epoch 1406/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0982 - val_accuracy: 0.9888\n",
      "Epoch 1407/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.1049 - val_accuracy: 0.9888\n",
      "Epoch 1408/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0991 - val_accuracy: 0.9851\n",
      "Epoch 1409/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9945 - val_loss: 0.1226 - val_accuracy: 0.9841\n",
      "Epoch 1410/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.1005 - val_accuracy: 0.9851\n",
      "Epoch 1411/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.1122 - val_accuracy: 0.9888\n",
      "Epoch 1412/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0976 - val_accuracy: 0.9869\n",
      "Epoch 1413/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.1047 - val_accuracy: 0.9888\n",
      "Epoch 1414/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0960 - val_accuracy: 0.9879\n",
      "Epoch 1415/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0998 - val_accuracy: 0.9897\n",
      "Epoch 1416/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.1043 - val_accuracy: 0.9907\n",
      "Epoch 1417/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0969 - val_accuracy: 0.9869\n",
      "Epoch 1418/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9917 - val_loss: 0.1156 - val_accuracy: 0.9851\n",
      "Epoch 1419/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9940 - val_loss: 0.1008 - val_accuracy: 0.9841\n",
      "Epoch 1420/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9940 - val_loss: 0.1081 - val_accuracy: 0.9860\n",
      "Epoch 1421/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9949 - val_loss: 0.0935 - val_accuracy: 0.9888\n",
      "Epoch 1422/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0991 - val_accuracy: 0.9897\n",
      "Epoch 1423/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.1034 - val_accuracy: 0.9888\n",
      "Epoch 1424/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.1012 - val_accuracy: 0.9869\n",
      "Epoch 1425/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1022 - val_accuracy: 0.9897\n",
      "Epoch 1426/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.1005 - val_accuracy: 0.9879\n",
      "Epoch 1427/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1015 - val_accuracy: 0.9897\n",
      "Epoch 1428/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1021 - val_accuracy: 0.9888\n",
      "Epoch 1429/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.0993 - val_accuracy: 0.9888\n",
      "Epoch 1430/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1000 - val_accuracy: 0.9879\n",
      "Epoch 1431/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0993 - val_accuracy: 0.9869\n",
      "Epoch 1432/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1047 - val_accuracy: 0.9907\n",
      "Epoch 1433/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0980 - val_accuracy: 0.9869\n",
      "Epoch 1434/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.1048 - val_accuracy: 0.9888\n",
      "Epoch 1435/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.0983 - val_accuracy: 0.9879\n",
      "Epoch 1436/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.1047 - val_accuracy: 0.9907\n",
      "Epoch 1437/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.0970 - val_accuracy: 0.9879\n",
      "Epoch 1438/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1054 - val_accuracy: 0.9897\n",
      "Epoch 1439/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0990 - val_accuracy: 0.9869\n",
      "Epoch 1440/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1136 - val_accuracy: 0.9860\n",
      "Epoch 1441/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0971 - val_accuracy: 0.9888\n",
      "Epoch 1442/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.1000 - val_accuracy: 0.9879\n",
      "Epoch 1443/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1003 - val_accuracy: 0.9869\n",
      "Epoch 1444/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1026 - val_accuracy: 0.9897\n",
      "Epoch 1445/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9949 - val_loss: 0.0975 - val_accuracy: 0.9879\n",
      "Epoch 1446/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.0975 - val_accuracy: 0.9888\n",
      "Epoch 1447/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.1045 - val_accuracy: 0.9869\n",
      "Epoch 1448/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0983 - val_accuracy: 0.9888\n",
      "Epoch 1449/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9954 - val_loss: 0.0998 - val_accuracy: 0.9888\n",
      "Epoch 1450/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.1008 - val_accuracy: 0.9869\n",
      "Epoch 1451/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.1045 - val_accuracy: 0.9879\n",
      "Epoch 1452/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9954 - val_loss: 0.1011 - val_accuracy: 0.9804\n",
      "Epoch 1453/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9926 - val_loss: 0.1329 - val_accuracy: 0.9832\n",
      "Epoch 1454/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.1030 - val_accuracy: 0.9860\n",
      "Epoch 1455/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1069 - val_accuracy: 0.9897\n",
      "Epoch 1456/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9954 - val_loss: 0.0991 - val_accuracy: 0.9888\n",
      "Epoch 1457/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0975 - val_accuracy: 0.9879\n",
      "Epoch 1458/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.1101 - val_accuracy: 0.9860\n",
      "Epoch 1459/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0971 - val_accuracy: 0.9879\n",
      "Epoch 1460/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.1051 - val_accuracy: 0.9897\n",
      "Epoch 1461/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.0978 - val_accuracy: 0.9879\n",
      "Epoch 1462/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1026 - val_accuracy: 0.9897\n",
      "Epoch 1463/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0964 - val_accuracy: 0.9888\n",
      "Epoch 1464/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.1040 - val_accuracy: 0.9907\n",
      "Epoch 1465/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0976 - val_accuracy: 0.9879\n",
      "Epoch 1466/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.1029 - val_accuracy: 0.9888\n",
      "Epoch 1467/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0979 - val_accuracy: 0.9879\n",
      "Epoch 1468/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.1050 - val_accuracy: 0.9907\n",
      "Epoch 1469/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0970 - val_accuracy: 0.9879\n",
      "Epoch 1470/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.1023 - val_accuracy: 0.9907\n",
      "Epoch 1471/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1005 - val_accuracy: 0.9879\n",
      "Epoch 1472/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1038 - val_accuracy: 0.9907\n",
      "Epoch 1473/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0989 - val_accuracy: 0.9888\n",
      "Epoch 1474/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1001 - val_accuracy: 0.9888\n",
      "Epoch 1475/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1004 - val_accuracy: 0.9879\n",
      "Epoch 1476/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.1073 - val_accuracy: 0.9897\n",
      "Epoch 1477/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0991 - val_accuracy: 0.9879\n",
      "Epoch 1478/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.1016 - val_accuracy: 0.9897\n",
      "Epoch 1479/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0999 - val_accuracy: 0.9888\n",
      "Epoch 1480/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1016 - val_accuracy: 0.9888\n",
      "Epoch 1481/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.0995 - val_accuracy: 0.9888\n",
      "Epoch 1482/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.1013 - val_accuracy: 0.9888\n",
      "Epoch 1483/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1005 - val_accuracy: 0.9869\n",
      "Epoch 1484/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1022 - val_accuracy: 0.9897\n",
      "Epoch 1485/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.1056 - val_accuracy: 0.9907\n",
      "Epoch 1486/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.1008 - val_accuracy: 0.9879\n",
      "Epoch 1487/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.0989 - val_accuracy: 0.9888\n",
      "Epoch 1488/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1021 - val_accuracy: 0.9888\n",
      "Epoch 1489/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1002 - val_accuracy: 0.9879\n",
      "Epoch 1490/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.1004 - val_accuracy: 0.9888\n",
      "Epoch 1491/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.0991 - val_accuracy: 0.9897\n",
      "Epoch 1492/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.1008 - val_accuracy: 0.9888\n",
      "Epoch 1493/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0990 - val_accuracy: 0.9888\n",
      "Epoch 1494/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.1022 - val_accuracy: 0.9907\n",
      "Epoch 1495/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0975 - val_accuracy: 0.9879\n",
      "Epoch 1496/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1033 - val_accuracy: 0.9897\n",
      "Epoch 1497/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0975 - val_accuracy: 0.9879\n",
      "Epoch 1498/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9959 - val_loss: 0.1092 - val_accuracy: 0.9879\n",
      "Epoch 1499/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.1008 - val_accuracy: 0.9888\n",
      "Epoch 1500/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1024 - val_accuracy: 0.9888\n",
      "Epoch 1501/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0992 - val_accuracy: 0.9879\n",
      "Epoch 1502/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0974 - val_accuracy: 0.9869\n",
      "Epoch 1503/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.1061 - val_accuracy: 0.9888\n",
      "Epoch 1504/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0970 - val_accuracy: 0.9879\n",
      "Epoch 1505/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.1046 - val_accuracy: 0.9897\n",
      "Epoch 1506/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.1006 - val_accuracy: 0.9879\n",
      "Epoch 1507/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.1054 - val_accuracy: 0.9879\n",
      "Epoch 1508/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.1020 - val_accuracy: 0.9897\n",
      "Epoch 1509/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.1005 - val_accuracy: 0.9841\n",
      "Epoch 1510/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9899 - val_loss: 0.1398 - val_accuracy: 0.9851\n",
      "Epoch 1511/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.1044 - val_accuracy: 0.9823\n",
      "Epoch 1512/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9926 - val_loss: 0.1093 - val_accuracy: 0.9879\n",
      "Epoch 1513/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.1016 - val_accuracy: 0.9879\n",
      "Epoch 1514/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.1089 - val_accuracy: 0.9860\n",
      "Epoch 1515/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.0977 - val_accuracy: 0.9879\n",
      "Epoch 1516/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1036 - val_accuracy: 0.9897\n",
      "Epoch 1517/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0988 - val_accuracy: 0.9869\n",
      "Epoch 1518/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.1045 - val_accuracy: 0.9888\n",
      "Epoch 1519/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.0991 - val_accuracy: 0.9879\n",
      "Epoch 1520/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1031 - val_accuracy: 0.9907\n",
      "Epoch 1521/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0993 - val_accuracy: 0.9879\n",
      "Epoch 1522/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.1021 - val_accuracy: 0.9879\n",
      "Epoch 1523/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1026 - val_accuracy: 0.9888\n",
      "Epoch 1524/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0994 - val_accuracy: 0.9888\n",
      "Epoch 1525/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0995 - val_accuracy: 0.9888\n",
      "Epoch 1526/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1023 - val_accuracy: 0.9879\n",
      "Epoch 1527/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1059 - val_accuracy: 0.9907\n",
      "Epoch 1528/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0971 - val_accuracy: 0.9869\n",
      "Epoch 1529/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1039 - val_accuracy: 0.9897\n",
      "Epoch 1530/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1011 - val_accuracy: 0.9888\n",
      "Epoch 1531/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1019 - val_accuracy: 0.9879\n",
      "Epoch 1532/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1007 - val_accuracy: 0.9879\n",
      "Epoch 1533/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1068 - val_accuracy: 0.9897\n",
      "Epoch 1534/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.1044 - val_accuracy: 0.9888\n",
      "Epoch 1535/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.1001 - val_accuracy: 0.9879\n",
      "Epoch 1536/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.1075 - val_accuracy: 0.9897\n",
      "Epoch 1537/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0997 - val_accuracy: 0.9879\n",
      "Epoch 1538/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.1042 - val_accuracy: 0.9888\n",
      "Epoch 1539/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.1018 - val_accuracy: 0.9879\n",
      "Epoch 1540/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.1029 - val_accuracy: 0.9879\n",
      "Epoch 1541/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1046 - val_accuracy: 0.9888\n",
      "Epoch 1542/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1013 - val_accuracy: 0.9879\n",
      "Epoch 1543/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1041 - val_accuracy: 0.9888\n",
      "Epoch 1544/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1009 - val_accuracy: 0.9879\n",
      "Epoch 1545/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9936 - val_loss: 0.1074 - val_accuracy: 0.9897\n",
      "Epoch 1546/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.0984 - val_accuracy: 0.9888\n",
      "Epoch 1547/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1035 - val_accuracy: 0.9897\n",
      "Epoch 1548/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.1078 - val_accuracy: 0.9879\n",
      "Epoch 1549/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.1034 - val_accuracy: 0.9879\n",
      "Epoch 1550/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.1007 - val_accuracy: 0.9888\n",
      "Epoch 1551/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.1017 - val_accuracy: 0.9888\n",
      "Epoch 1552/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1040 - val_accuracy: 0.9888\n",
      "Epoch 1553/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1003 - val_accuracy: 0.9841\n",
      "Epoch 1554/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9959 - val_loss: 0.1087 - val_accuracy: 0.9897\n",
      "Epoch 1555/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.1026 - val_accuracy: 0.9879\n",
      "Epoch 1556/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.1025 - val_accuracy: 0.9879\n",
      "Epoch 1557/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0997 - val_accuracy: 0.9888\n",
      "Epoch 1558/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.1004 - val_accuracy: 0.9888\n",
      "Epoch 1559/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.1181 - val_accuracy: 0.9851\n",
      "Epoch 1560/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.1037 - val_accuracy: 0.9841\n",
      "Epoch 1561/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.1264 - val_accuracy: 0.9860\n",
      "Epoch 1562/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9940 - val_loss: 0.1104 - val_accuracy: 0.9823\n",
      "Epoch 1563/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9940 - val_loss: 0.1069 - val_accuracy: 0.9897\n",
      "Epoch 1564/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.0981 - val_accuracy: 0.9897\n",
      "Epoch 1565/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.1011 - val_accuracy: 0.9888\n",
      "Epoch 1566/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.1020 - val_accuracy: 0.9860\n",
      "Epoch 1567/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.1090 - val_accuracy: 0.9907\n",
      "Epoch 1568/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.0978 - val_accuracy: 0.9879\n",
      "Epoch 1569/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9949 - val_loss: 0.1081 - val_accuracy: 0.9897\n",
      "Epoch 1570/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1030 - val_accuracy: 0.9879\n",
      "Epoch 1571/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.1042 - val_accuracy: 0.9879\n",
      "Epoch 1572/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1028 - val_accuracy: 0.9897\n",
      "Epoch 1573/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.1022 - val_accuracy: 0.9888\n",
      "Epoch 1574/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.1041 - val_accuracy: 0.9869\n",
      "Epoch 1575/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1040 - val_accuracy: 0.9888\n",
      "Epoch 1576/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.1030 - val_accuracy: 0.9888\n",
      "Epoch 1577/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1016 - val_accuracy: 0.9888\n",
      "Epoch 1578/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.1016 - val_accuracy: 0.9888\n",
      "Epoch 1579/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1058 - val_accuracy: 0.9869\n",
      "Epoch 1580/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1026 - val_accuracy: 0.9879\n",
      "Epoch 1581/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1045 - val_accuracy: 0.9888\n",
      "Epoch 1582/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1012 - val_accuracy: 0.9888\n",
      "Epoch 1583/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.1021 - val_accuracy: 0.9888\n",
      "Epoch 1584/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1080 - val_accuracy: 0.9897\n",
      "Epoch 1585/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.1027 - val_accuracy: 0.9869\n",
      "Epoch 1586/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1025 - val_accuracy: 0.9888\n",
      "Epoch 1587/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.1021 - val_accuracy: 0.9879\n",
      "Epoch 1588/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1058 - val_accuracy: 0.9888\n",
      "Epoch 1589/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.1012 - val_accuracy: 0.9879\n",
      "Epoch 1590/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9959 - val_loss: 0.1085 - val_accuracy: 0.9897\n",
      "Epoch 1591/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.1013 - val_accuracy: 0.9869\n",
      "Epoch 1592/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1133 - val_accuracy: 0.9869\n",
      "Epoch 1593/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0992 - val_accuracy: 0.9888\n",
      "Epoch 1594/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.1029 - val_accuracy: 0.9888\n",
      "Epoch 1595/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1064 - val_accuracy: 0.9869\n",
      "Epoch 1596/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.1025 - val_accuracy: 0.9860\n",
      "Epoch 1597/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.1132 - val_accuracy: 0.9879\n",
      "Epoch 1598/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0984 - val_accuracy: 0.9888\n",
      "Epoch 1599/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.1152 - val_accuracy: 0.9860\n",
      "Epoch 1600/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.1015 - val_accuracy: 0.9860\n",
      "Epoch 1601/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.1186 - val_accuracy: 0.9851\n",
      "Epoch 1602/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.1042 - val_accuracy: 0.9832\n",
      "Epoch 1603/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9926 - val_loss: 0.1245 - val_accuracy: 0.9851\n",
      "Epoch 1604/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0992 - val_accuracy: 0.9869\n",
      "Epoch 1605/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.1101 - val_accuracy: 0.9879\n",
      "Epoch 1606/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9949 - val_loss: 0.1039 - val_accuracy: 0.9879\n",
      "Epoch 1607/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.1038 - val_accuracy: 0.9897\n",
      "Epoch 1608/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0997 - val_accuracy: 0.9879\n",
      "Epoch 1609/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1109 - val_accuracy: 0.9897\n",
      "Epoch 1610/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.1011 - val_accuracy: 0.9869\n",
      "Epoch 1611/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.1057 - val_accuracy: 0.9897\n",
      "Epoch 1612/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1012 - val_accuracy: 0.9879\n",
      "Epoch 1613/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1056 - val_accuracy: 0.9879\n",
      "Epoch 1614/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1008 - val_accuracy: 0.9879\n",
      "Epoch 1615/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.1065 - val_accuracy: 0.9897\n",
      "Epoch 1616/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.1015 - val_accuracy: 0.9860\n",
      "Epoch 1617/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9936 - val_loss: 0.1296 - val_accuracy: 0.9851\n",
      "Epoch 1618/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.1069 - val_accuracy: 0.9832\n",
      "Epoch 1619/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.1206 - val_accuracy: 0.9841\n",
      "Epoch 1620/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.0988 - val_accuracy: 0.9860\n",
      "Epoch 1621/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.1183 - val_accuracy: 0.9860\n",
      "Epoch 1622/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.1039 - val_accuracy: 0.9841\n",
      "Epoch 1623/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.1158 - val_accuracy: 0.9860\n",
      "Epoch 1624/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.1053 - val_accuracy: 0.9851\n",
      "Epoch 1625/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.1198 - val_accuracy: 0.9851\n",
      "Epoch 1626/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.1012 - val_accuracy: 0.9841\n",
      "Epoch 1627/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9940 - val_loss: 0.1119 - val_accuracy: 0.9879\n",
      "Epoch 1628/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.1024 - val_accuracy: 0.9860\n",
      "Epoch 1629/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.1104 - val_accuracy: 0.9888\n",
      "Epoch 1630/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.1002 - val_accuracy: 0.9888\n",
      "Epoch 1631/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.1025 - val_accuracy: 0.9888\n",
      "Epoch 1632/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1078 - val_accuracy: 0.9888\n",
      "Epoch 1633/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.1025 - val_accuracy: 0.9879\n",
      "Epoch 1634/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1049 - val_accuracy: 0.9897\n",
      "Epoch 1635/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9959 - val_loss: 0.1043 - val_accuracy: 0.9879\n",
      "Epoch 1636/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1067 - val_accuracy: 0.9888\n",
      "Epoch 1637/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.1014 - val_accuracy: 0.9888\n",
      "Epoch 1638/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1066 - val_accuracy: 0.9907\n",
      "Epoch 1639/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1003 - val_accuracy: 0.9879\n",
      "Epoch 1640/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1108 - val_accuracy: 0.9888\n",
      "Epoch 1641/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.1019 - val_accuracy: 0.9879\n",
      "Epoch 1642/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1043 - val_accuracy: 0.9888\n",
      "Epoch 1643/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1045 - val_accuracy: 0.9869\n",
      "Epoch 1644/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.1054 - val_accuracy: 0.9888\n",
      "Epoch 1645/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0992 - val_accuracy: 0.9860\n",
      "Epoch 1646/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9931 - val_loss: 0.1183 - val_accuracy: 0.9860\n",
      "Epoch 1647/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.1020 - val_accuracy: 0.9879\n",
      "Epoch 1648/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9936 - val_loss: 0.1206 - val_accuracy: 0.9851\n",
      "Epoch 1649/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0996 - val_accuracy: 0.9860\n",
      "Epoch 1650/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.1083 - val_accuracy: 0.9897\n",
      "Epoch 1651/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.1031 - val_accuracy: 0.9869\n",
      "Epoch 1652/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.1087 - val_accuracy: 0.9888\n",
      "Epoch 1653/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.1010 - val_accuracy: 0.9888\n",
      "Epoch 1654/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.1084 - val_accuracy: 0.9907\n",
      "Epoch 1655/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1035 - val_accuracy: 0.9888\n",
      "Epoch 1656/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1042 - val_accuracy: 0.9879\n",
      "Epoch 1657/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1043 - val_accuracy: 0.9879\n",
      "Epoch 1658/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1045 - val_accuracy: 0.9888\n",
      "Epoch 1659/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1034 - val_accuracy: 0.9888\n",
      "Epoch 1660/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1080 - val_accuracy: 0.9879\n",
      "Epoch 1661/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.1026 - val_accuracy: 0.9888\n",
      "Epoch 1662/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.1056 - val_accuracy: 0.9897\n",
      "Epoch 1663/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1026 - val_accuracy: 0.9879\n",
      "Epoch 1664/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.1091 - val_accuracy: 0.9907\n",
      "Epoch 1665/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.1060 - val_accuracy: 0.9869\n",
      "Epoch 1666/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.1069 - val_accuracy: 0.9888\n",
      "Epoch 1667/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1082 - val_accuracy: 0.9897\n",
      "Epoch 1668/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1067 - val_accuracy: 0.9888\n",
      "Epoch 1669/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1024 - val_accuracy: 0.9851\n",
      "Epoch 1670/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.1137 - val_accuracy: 0.9897\n",
      "Epoch 1671/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.1035 - val_accuracy: 0.9841\n",
      "Epoch 1672/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9954 - val_loss: 0.1228 - val_accuracy: 0.9851\n",
      "Epoch 1673/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.1036 - val_accuracy: 0.9869\n",
      "Epoch 1674/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9926 - val_loss: 0.1342 - val_accuracy: 0.9832\n",
      "Epoch 1675/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 0.1021 - val_accuracy: 0.9832\n",
      "Epoch 1676/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9931 - val_loss: 0.1194 - val_accuracy: 0.9879\n",
      "Epoch 1677/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.1084 - val_accuracy: 0.9860\n",
      "Epoch 1678/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.1141 - val_accuracy: 0.9869\n",
      "Epoch 1679/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0982 - val_accuracy: 0.9879\n",
      "Epoch 1680/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.1078 - val_accuracy: 0.9897\n",
      "Epoch 1681/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.1041 - val_accuracy: 0.9860\n",
      "Epoch 1682/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9959 - val_loss: 0.1133 - val_accuracy: 0.9879\n",
      "Epoch 1683/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0986 - val_accuracy: 0.9860\n",
      "Epoch 1684/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.1112 - val_accuracy: 0.9897\n",
      "Epoch 1685/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.1026 - val_accuracy: 0.9888\n",
      "Epoch 1686/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.1051 - val_accuracy: 0.9879\n",
      "Epoch 1687/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.1089 - val_accuracy: 0.9907\n",
      "Epoch 1688/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.1015 - val_accuracy: 0.9888\n",
      "Epoch 1689/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1075 - val_accuracy: 0.9897\n",
      "Epoch 1690/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1027 - val_accuracy: 0.9888\n",
      "Epoch 1691/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.1077 - val_accuracy: 0.9907\n",
      "Epoch 1692/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.1001 - val_accuracy: 0.9888\n",
      "Epoch 1693/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9949 - val_loss: 0.1091 - val_accuracy: 0.9897\n",
      "Epoch 1694/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.1014 - val_accuracy: 0.9897\n",
      "Epoch 1695/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1071 - val_accuracy: 0.9907\n",
      "Epoch 1696/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.1010 - val_accuracy: 0.9888\n",
      "Epoch 1697/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1041 - val_accuracy: 0.9879\n",
      "Epoch 1698/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1050 - val_accuracy: 0.9879\n",
      "Epoch 1699/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1043 - val_accuracy: 0.9879\n",
      "Epoch 1700/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1049 - val_accuracy: 0.9888\n",
      "Epoch 1701/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1107 - val_accuracy: 0.9897\n",
      "Epoch 1702/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.1033 - val_accuracy: 0.9879\n",
      "Epoch 1703/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.1072 - val_accuracy: 0.9897\n",
      "Epoch 1704/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1033 - val_accuracy: 0.9879\n",
      "Epoch 1705/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.1116 - val_accuracy: 0.9907\n",
      "Epoch 1706/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.1044 - val_accuracy: 0.9897\n",
      "Epoch 1707/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9949 - val_loss: 0.1116 - val_accuracy: 0.9888\n",
      "Epoch 1708/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.1035 - val_accuracy: 0.9888\n",
      "Epoch 1709/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1083 - val_accuracy: 0.9888\n",
      "Epoch 1710/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.1044 - val_accuracy: 0.9888\n",
      "Epoch 1711/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1039 - val_accuracy: 0.9888\n",
      "Epoch 1712/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.1070 - val_accuracy: 0.9869\n",
      "Epoch 1713/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.1049 - val_accuracy: 0.9888\n",
      "Epoch 1714/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1032 - val_accuracy: 0.9888\n",
      "Epoch 1715/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.1093 - val_accuracy: 0.9888\n",
      "Epoch 1716/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1067 - val_accuracy: 0.9869\n",
      "Epoch 1717/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 0.1083 - val_accuracy: 0.9897\n",
      "Epoch 1718/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1041 - val_accuracy: 0.9888\n",
      "Epoch 1719/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1131 - val_accuracy: 0.9897\n",
      "Epoch 1720/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1026 - val_accuracy: 0.9888\n",
      "Epoch 1721/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1092 - val_accuracy: 0.9897\n",
      "Epoch 1722/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1050 - val_accuracy: 0.9888\n",
      "Epoch 1723/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.1045 - val_accuracy: 0.9888\n",
      "Epoch 1724/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.1050 - val_accuracy: 0.9879\n",
      "Epoch 1725/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.1079 - val_accuracy: 0.9879\n",
      "Epoch 1726/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1039 - val_accuracy: 0.9888\n",
      "Epoch 1727/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1073 - val_accuracy: 0.9897\n",
      "Epoch 1728/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1061 - val_accuracy: 0.9888\n",
      "Epoch 1729/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1081 - val_accuracy: 0.9888\n",
      "Epoch 1730/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1060 - val_accuracy: 0.9897\n",
      "Epoch 1731/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.1025 - val_accuracy: 0.9897\n",
      "Epoch 1732/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.1115 - val_accuracy: 0.9897\n",
      "Epoch 1733/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.1037 - val_accuracy: 0.9851\n",
      "Epoch 1734/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9940 - val_loss: 0.1160 - val_accuracy: 0.9869\n",
      "Epoch 1735/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.1074 - val_accuracy: 0.9851\n",
      "Epoch 1736/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.1152 - val_accuracy: 0.9879\n",
      "Epoch 1737/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.1017 - val_accuracy: 0.9869\n",
      "Epoch 1738/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9949 - val_loss: 0.1170 - val_accuracy: 0.9879\n",
      "Epoch 1739/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.1052 - val_accuracy: 0.9869\n",
      "Epoch 1740/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1064 - val_accuracy: 0.9897\n",
      "Epoch 1741/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.1012 - val_accuracy: 0.9879\n",
      "Epoch 1742/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1054 - val_accuracy: 0.9888\n",
      "Epoch 1743/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.1039 - val_accuracy: 0.9869\n",
      "Epoch 1744/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.1074 - val_accuracy: 0.9888\n",
      "Epoch 1745/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.1028 - val_accuracy: 0.9869\n",
      "Epoch 1746/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1103 - val_accuracy: 0.9897\n",
      "Epoch 1747/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.1054 - val_accuracy: 0.9869\n",
      "Epoch 1748/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.1198 - val_accuracy: 0.9879\n",
      "Epoch 1749/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.1099 - val_accuracy: 0.9869\n",
      "Epoch 1750/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.1187 - val_accuracy: 0.9869\n",
      "Epoch 1751/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9959 - val_loss: 0.1030 - val_accuracy: 0.9869\n",
      "Epoch 1752/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.1190 - val_accuracy: 0.9869\n",
      "Epoch 1753/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.1035 - val_accuracy: 0.9851\n",
      "Epoch 1754/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.1161 - val_accuracy: 0.9869\n",
      "Epoch 1755/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 0.1032 - val_accuracy: 0.9888\n",
      "Epoch 1756/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.1062 - val_accuracy: 0.9879\n",
      "Epoch 1757/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.1115 - val_accuracy: 0.9879\n",
      "Epoch 1758/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.1051 - val_accuracy: 0.9888\n",
      "Epoch 1759/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.1016 - val_accuracy: 0.9888\n",
      "Epoch 1760/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.1019 - val_accuracy: 0.9888\n",
      "Epoch 1761/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.1203 - val_accuracy: 0.9860\n",
      "Epoch 1762/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.1006 - val_accuracy: 0.9888\n",
      "Epoch 1763/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.1110 - val_accuracy: 0.9879\n",
      "Epoch 1764/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.1031 - val_accuracy: 0.9888\n",
      "Epoch 1765/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.1172 - val_accuracy: 0.9869\n",
      "Epoch 1766/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.1040 - val_accuracy: 0.9897\n",
      "Epoch 1767/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.1155 - val_accuracy: 0.9879\n",
      "Epoch 1768/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.1034 - val_accuracy: 0.9860\n",
      "Epoch 1769/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.1175 - val_accuracy: 0.9888\n",
      "Epoch 1770/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.1059 - val_accuracy: 0.9841\n",
      "Epoch 1771/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9959 - val_loss: 0.1263 - val_accuracy: 0.9851\n",
      "Epoch 1772/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.1013 - val_accuracy: 0.9860\n",
      "Epoch 1773/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.1143 - val_accuracy: 0.9888\n",
      "Epoch 1774/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 0.1041 - val_accuracy: 0.9869\n",
      "Epoch 1775/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1152 - val_accuracy: 0.9879\n",
      "Epoch 1776/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1025 - val_accuracy: 0.9879\n",
      "Epoch 1777/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1075 - val_accuracy: 0.9897\n",
      "Epoch 1778/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1070 - val_accuracy: 0.9851\n",
      "Epoch 1779/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1151 - val_accuracy: 0.9888\n",
      "Epoch 1780/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.1034 - val_accuracy: 0.9832\n",
      "Epoch 1781/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.1175 - val_accuracy: 0.9860\n",
      "Epoch 1782/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.1074 - val_accuracy: 0.9888\n",
      "Epoch 1783/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.1091 - val_accuracy: 0.9879\n",
      "Epoch 1784/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1040 - val_accuracy: 0.9879\n",
      "Epoch 1785/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.1040 - val_accuracy: 0.9879\n",
      "Epoch 1786/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 0.1098 - val_accuracy: 0.9888\n",
      "Epoch 1787/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1047 - val_accuracy: 0.9860\n",
      "Epoch 1788/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9931 - val_loss: 0.1222 - val_accuracy: 0.9851\n",
      "Epoch 1789/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.1021 - val_accuracy: 0.9888\n",
      "Epoch 1790/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9954 - val_loss: 0.1181 - val_accuracy: 0.9869\n",
      "Epoch 1791/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.1045 - val_accuracy: 0.9851\n",
      "Epoch 1792/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9954 - val_loss: 0.1107 - val_accuracy: 0.9897\n",
      "Epoch 1793/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.1076 - val_accuracy: 0.9860\n",
      "Epoch 1794/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.1054 - val_accuracy: 0.9879\n",
      "Epoch 1795/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9922 - val_loss: 0.1180 - val_accuracy: 0.9879\n",
      "Epoch 1796/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.1086 - val_accuracy: 0.9879\n",
      "Epoch 1797/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9931 - val_loss: 0.1275 - val_accuracy: 0.9841\n",
      "Epoch 1798/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9954 - val_loss: 0.1037 - val_accuracy: 0.9869\n",
      "Epoch 1799/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9926 - val_loss: 0.1282 - val_accuracy: 0.9869\n",
      "Epoch 1800/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.1136 - val_accuracy: 0.9832\n",
      "Epoch 1801/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9949 - val_loss: 0.1242 - val_accuracy: 0.9860\n",
      "Epoch 1802/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.1017 - val_accuracy: 0.9851\n",
      "Epoch 1803/3500\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.99 - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.1094 - val_accuracy: 0.9888\n",
      "Epoch 1804/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.1084 - val_accuracy: 0.9851\n",
      "Epoch 1805/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9931 - val_loss: 0.1188 - val_accuracy: 0.9869\n",
      "Epoch 1806/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.1039 - val_accuracy: 0.9879\n",
      "Epoch 1807/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.1082 - val_accuracy: 0.9888\n",
      "Epoch 1808/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.1083 - val_accuracy: 0.9851\n",
      "Epoch 1809/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1148 - val_accuracy: 0.9888\n",
      "Epoch 1810/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.1050 - val_accuracy: 0.9869\n",
      "Epoch 1811/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9926 - val_loss: 0.1218 - val_accuracy: 0.9879\n",
      "Epoch 1812/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.1053 - val_accuracy: 0.9851\n",
      "Epoch 1813/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.1262 - val_accuracy: 0.9851\n",
      "Epoch 1814/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.1034 - val_accuracy: 0.9888\n",
      "Epoch 1815/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.1077 - val_accuracy: 0.9907\n",
      "Epoch 1816/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.1058 - val_accuracy: 0.9869\n",
      "Epoch 1817/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.1095 - val_accuracy: 0.9879\n",
      "Epoch 1818/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1076 - val_accuracy: 0.9897\n",
      "Epoch 1819/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1054 - val_accuracy: 0.9879\n",
      "Epoch 1820/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.1114 - val_accuracy: 0.9897\n",
      "Epoch 1821/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1045 - val_accuracy: 0.9888\n",
      "Epoch 1822/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1074 - val_accuracy: 0.9897\n",
      "Epoch 1823/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.1074 - val_accuracy: 0.9879\n",
      "Epoch 1824/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.1072 - val_accuracy: 0.9879\n",
      "Epoch 1825/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1086 - val_accuracy: 0.9897\n",
      "Epoch 1826/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1080 - val_accuracy: 0.9897\n",
      "Epoch 1827/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1051 - val_accuracy: 0.9869\n",
      "Epoch 1828/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9954 - val_loss: 0.1108 - val_accuracy: 0.9907\n",
      "Epoch 1829/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9954 - val_loss: 0.1052 - val_accuracy: 0.9897\n",
      "Epoch 1830/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.1092 - val_accuracy: 0.9897\n",
      "Epoch 1831/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1077 - val_accuracy: 0.9888\n",
      "Epoch 1832/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1056 - val_accuracy: 0.9879\n",
      "Epoch 1833/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.1071 - val_accuracy: 0.9888\n",
      "Epoch 1834/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1058 - val_accuracy: 0.9869\n",
      "Epoch 1835/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1129 - val_accuracy: 0.9907\n",
      "Epoch 1836/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9959 - val_loss: 0.1042 - val_accuracy: 0.9860\n",
      "Epoch 1837/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.1160 - val_accuracy: 0.9888\n",
      "Epoch 1838/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.1063 - val_accuracy: 0.9851\n",
      "Epoch 1839/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9931 - val_loss: 0.1289 - val_accuracy: 0.9851\n",
      "Epoch 1840/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1041 - val_accuracy: 0.9869\n",
      "Epoch 1841/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1091 - val_accuracy: 0.9897\n",
      "Epoch 1842/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.1060 - val_accuracy: 0.9888\n",
      "Epoch 1843/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.1072 - val_accuracy: 0.9879\n",
      "Epoch 1844/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.1089 - val_accuracy: 0.9897\n",
      "Epoch 1845/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1037 - val_accuracy: 0.9897\n",
      "Epoch 1846/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9959 - val_loss: 0.1147 - val_accuracy: 0.9879\n",
      "Epoch 1847/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.1040 - val_accuracy: 0.9869\n",
      "Epoch 1848/3500\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.99 - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9936 - val_loss: 0.1171 - val_accuracy: 0.9888\n",
      "Epoch 1849/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.1058 - val_accuracy: 0.9860\n",
      "Epoch 1850/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9954 - val_loss: 0.1157 - val_accuracy: 0.9888\n",
      "Epoch 1851/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.1030 - val_accuracy: 0.9888\n",
      "Epoch 1852/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.1079 - val_accuracy: 0.9897\n",
      "Epoch 1853/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1090 - val_accuracy: 0.9879\n",
      "Epoch 1854/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.1041 - val_accuracy: 0.9879\n",
      "Epoch 1855/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1088 - val_accuracy: 0.9897\n",
      "Epoch 1856/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1079 - val_accuracy: 0.9888\n",
      "Epoch 1857/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1088 - val_accuracy: 0.9888\n",
      "Epoch 1858/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1054 - val_accuracy: 0.9888\n",
      "Epoch 1859/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1066 - val_accuracy: 0.9888\n",
      "Epoch 1860/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1057 - val_accuracy: 0.9879\n",
      "Epoch 1861/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.1135 - val_accuracy: 0.9888\n",
      "Epoch 1862/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.1061 - val_accuracy: 0.9879\n",
      "Epoch 1863/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9959 - val_loss: 0.1125 - val_accuracy: 0.9897\n",
      "Epoch 1864/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.1071 - val_accuracy: 0.9869\n",
      "Epoch 1865/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.1123 - val_accuracy: 0.9907\n",
      "Epoch 1866/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1094 - val_accuracy: 0.9897\n",
      "Epoch 1867/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1075 - val_accuracy: 0.9888\n",
      "Epoch 1868/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1096 - val_accuracy: 0.9860\n",
      "Epoch 1869/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1070 - val_accuracy: 0.9879\n",
      "Epoch 1870/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1104 - val_accuracy: 0.9888\n",
      "Epoch 1871/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.1058 - val_accuracy: 0.9841\n",
      "Epoch 1872/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9945 - val_loss: 0.1135 - val_accuracy: 0.9907\n",
      "Epoch 1873/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.1061 - val_accuracy: 0.9879\n",
      "Epoch 1874/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1111 - val_accuracy: 0.9888\n",
      "Epoch 1875/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1071 - val_accuracy: 0.9888\n",
      "Epoch 1876/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.1083 - val_accuracy: 0.9888\n",
      "Epoch 1877/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.1084 - val_accuracy: 0.9888\n",
      "Epoch 1878/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.1134 - val_accuracy: 0.9879\n",
      "Epoch 1879/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.1086 - val_accuracy: 0.9888\n",
      "Epoch 1880/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.1064 - val_accuracy: 0.9888\n",
      "Epoch 1881/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1113 - val_accuracy: 0.9879\n",
      "Epoch 1882/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1095 - val_accuracy: 0.9888\n",
      "Epoch 1883/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.1073 - val_accuracy: 0.9888\n",
      "Epoch 1884/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1086 - val_accuracy: 0.9888\n",
      "Epoch 1885/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.1112 - val_accuracy: 0.9879\n",
      "Epoch 1886/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.1059 - val_accuracy: 0.9851\n",
      "Epoch 1887/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9954 - val_loss: 0.1105 - val_accuracy: 0.9897\n",
      "Epoch 1888/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.1037 - val_accuracy: 0.9888\n",
      "Epoch 1889/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.1166 - val_accuracy: 0.9869\n",
      "Epoch 1890/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1060 - val_accuracy: 0.9888\n",
      "Epoch 1891/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1065 - val_accuracy: 0.9897\n",
      "Epoch 1892/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.1062 - val_accuracy: 0.9888\n",
      "Epoch 1893/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1119 - val_accuracy: 0.9888\n",
      "Epoch 1894/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1103 - val_accuracy: 0.9888\n",
      "Epoch 1895/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1061 - val_accuracy: 0.9888\n",
      "Epoch 1896/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.1105 - val_accuracy: 0.9897\n",
      "Epoch 1897/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1062 - val_accuracy: 0.9869\n",
      "Epoch 1898/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1106 - val_accuracy: 0.9888\n",
      "Epoch 1899/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1054 - val_accuracy: 0.9869\n",
      "Epoch 1900/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9949 - val_loss: 0.1178 - val_accuracy: 0.9879\n",
      "Epoch 1901/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.1077 - val_accuracy: 0.9860\n",
      "Epoch 1902/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.1116 - val_accuracy: 0.9888\n",
      "Epoch 1903/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1086 - val_accuracy: 0.9888\n",
      "Epoch 1904/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1082 - val_accuracy: 0.9888\n",
      "Epoch 1905/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1113 - val_accuracy: 0.9888\n",
      "Epoch 1906/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1136 - val_accuracy: 0.9879\n",
      "Epoch 1907/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1100 - val_accuracy: 0.9879\n",
      "Epoch 1908/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.1068 - val_accuracy: 0.9869\n",
      "Epoch 1909/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.1183 - val_accuracy: 0.9860\n",
      "Epoch 1910/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.1078 - val_accuracy: 0.9869\n",
      "Epoch 1911/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1094 - val_accuracy: 0.9879\n",
      "Epoch 1912/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1096 - val_accuracy: 0.9888\n",
      "Epoch 1913/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1098 - val_accuracy: 0.9879\n",
      "Epoch 1914/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1126 - val_accuracy: 0.9897\n",
      "Epoch 1915/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.1075 - val_accuracy: 0.9869\n",
      "Epoch 1916/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1146 - val_accuracy: 0.9897\n",
      "Epoch 1917/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1084 - val_accuracy: 0.9888\n",
      "Epoch 1918/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.1126 - val_accuracy: 0.9888\n",
      "Epoch 1919/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1115 - val_accuracy: 0.9888\n",
      "Epoch 1920/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1097 - val_accuracy: 0.9888\n",
      "Epoch 1921/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9954 - val_loss: 0.1210 - val_accuracy: 0.9879\n",
      "Epoch 1922/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.1082 - val_accuracy: 0.9851\n",
      "Epoch 1923/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9949 - val_loss: 0.1322 - val_accuracy: 0.9860\n",
      "Epoch 1924/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.1048 - val_accuracy: 0.9869\n",
      "Epoch 1925/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9945 - val_loss: 0.1116 - val_accuracy: 0.9888\n",
      "Epoch 1926/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.1119 - val_accuracy: 0.9888\n",
      "Epoch 1927/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.1135 - val_accuracy: 0.9879\n",
      "Epoch 1928/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.1055 - val_accuracy: 0.9888\n",
      "Epoch 1929/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1089 - val_accuracy: 0.9888\n",
      "Epoch 1930/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1066 - val_accuracy: 0.9879\n",
      "Epoch 1931/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1103 - val_accuracy: 0.9879\n",
      "Epoch 1932/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.1130 - val_accuracy: 0.9888\n",
      "Epoch 1933/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1056 - val_accuracy: 0.9879\n",
      "Epoch 1934/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.1139 - val_accuracy: 0.9897\n",
      "Epoch 1935/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1076 - val_accuracy: 0.9888\n",
      "Epoch 1936/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1125 - val_accuracy: 0.9888\n",
      "Epoch 1937/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1050 - val_accuracy: 0.9869\n",
      "Epoch 1938/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 0.1090 - val_accuracy: 0.9879\n",
      "Epoch 1939/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1129 - val_accuracy: 0.9888\n",
      "Epoch 1940/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9972 - val_loss: 0.1115 - val_accuracy: 0.9897\n",
      "Epoch 1941/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1061 - val_accuracy: 0.9869\n",
      "Epoch 1942/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1110 - val_accuracy: 0.9888\n",
      "Epoch 1943/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1087 - val_accuracy: 0.9879\n",
      "Epoch 1944/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1121 - val_accuracy: 0.9888\n",
      "Epoch 1945/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.1091 - val_accuracy: 0.9879\n",
      "Epoch 1946/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1149 - val_accuracy: 0.9888\n",
      "Epoch 1947/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1075 - val_accuracy: 0.9888\n",
      "Epoch 1948/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1180 - val_accuracy: 0.9888\n",
      "Epoch 1949/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.1076 - val_accuracy: 0.9879\n",
      "Epoch 1950/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9959 - val_loss: 0.1207 - val_accuracy: 0.9869\n",
      "Epoch 1951/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.1062 - val_accuracy: 0.9879\n",
      "Epoch 1952/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1164 - val_accuracy: 0.9897\n",
      "Epoch 1953/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.1057 - val_accuracy: 0.9879\n",
      "Epoch 1954/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1148 - val_accuracy: 0.9888\n",
      "Epoch 1955/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.1067 - val_accuracy: 0.9841\n",
      "Epoch 1956/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9954 - val_loss: 0.1169 - val_accuracy: 0.9888\n",
      "Epoch 1957/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.1072 - val_accuracy: 0.9851\n",
      "Epoch 1958/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.1183 - val_accuracy: 0.9888\n",
      "Epoch 1959/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.1045 - val_accuracy: 0.9860\n",
      "Epoch 1960/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.1072 - val_accuracy: 0.9879\n",
      "Epoch 1961/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.1090 - val_accuracy: 0.9888\n",
      "Epoch 1962/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.1140 - val_accuracy: 0.9888\n",
      "Epoch 1963/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1088 - val_accuracy: 0.9888\n",
      "Epoch 1964/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1091 - val_accuracy: 0.9888\n",
      "Epoch 1965/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.1152 - val_accuracy: 0.9897\n",
      "Epoch 1966/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1114 - val_accuracy: 0.9888\n",
      "Epoch 1967/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1097 - val_accuracy: 0.9888\n",
      "Epoch 1968/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1162 - val_accuracy: 0.9897\n",
      "Epoch 1969/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1106 - val_accuracy: 0.9888\n",
      "Epoch 1970/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1111 - val_accuracy: 0.9888\n",
      "Epoch 1971/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.1144 - val_accuracy: 0.9888\n",
      "Epoch 1972/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1101 - val_accuracy: 0.9879\n",
      "Epoch 1973/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1192 - val_accuracy: 0.9869\n",
      "Epoch 1974/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.1149 - val_accuracy: 0.9888\n",
      "Epoch 1975/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.1094 - val_accuracy: 0.9869\n",
      "Epoch 1976/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.1131 - val_accuracy: 0.9888\n",
      "Epoch 1977/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.1154 - val_accuracy: 0.9879\n",
      "Epoch 1978/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.1120 - val_accuracy: 0.9879\n",
      "Epoch 1979/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1088 - val_accuracy: 0.9869\n",
      "Epoch 1980/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1170 - val_accuracy: 0.9888\n",
      "Epoch 1981/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1098 - val_accuracy: 0.9860\n",
      "Epoch 1982/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.1119 - val_accuracy: 0.9879\n",
      "Epoch 1983/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1160 - val_accuracy: 0.9860\n",
      "Epoch 1984/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.1162 - val_accuracy: 0.9888\n",
      "Epoch 1985/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1123 - val_accuracy: 0.9888\n",
      "Epoch 1986/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1104 - val_accuracy: 0.9888\n",
      "Epoch 1987/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1147 - val_accuracy: 0.9888\n",
      "Epoch 1988/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1156 - val_accuracy: 0.9897\n",
      "Epoch 1989/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1091 - val_accuracy: 0.9879\n",
      "Epoch 1990/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.1194 - val_accuracy: 0.9888\n",
      "Epoch 1991/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.1123 - val_accuracy: 0.9879\n",
      "Epoch 1992/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.1226 - val_accuracy: 0.9888\n",
      "Epoch 1993/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.1089 - val_accuracy: 0.9869\n",
      "Epoch 1994/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1143 - val_accuracy: 0.9888\n",
      "Epoch 1995/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1123 - val_accuracy: 0.9879\n",
      "Epoch 1996/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.1158 - val_accuracy: 0.9888\n",
      "Epoch 1997/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9972 - val_loss: 0.1113 - val_accuracy: 0.9879\n",
      "Epoch 1998/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1145 - val_accuracy: 0.9888\n",
      "Epoch 1999/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1124 - val_accuracy: 0.9888\n",
      "Epoch 2000/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1182 - val_accuracy: 0.9897\n",
      "Epoch 2001/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1098 - val_accuracy: 0.9869\n",
      "Epoch 2002/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1266 - val_accuracy: 0.9860\n",
      "Epoch 2003/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.1113 - val_accuracy: 0.9860\n",
      "Epoch 2004/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.1130 - val_accuracy: 0.9888\n",
      "Epoch 2005/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9959 - val_loss: 0.1204 - val_accuracy: 0.9888\n",
      "Epoch 2006/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.1119 - val_accuracy: 0.9888\n",
      "Epoch 2007/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1215 - val_accuracy: 0.9888\n",
      "Epoch 2008/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.1108 - val_accuracy: 0.9869\n",
      "Epoch 2009/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1208 - val_accuracy: 0.9888\n",
      "Epoch 2010/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.1115 - val_accuracy: 0.9888\n",
      "Epoch 2011/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1144 - val_accuracy: 0.9879\n",
      "Epoch 2012/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1142 - val_accuracy: 0.9869\n",
      "Epoch 2013/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.1224 - val_accuracy: 0.9879\n",
      "Epoch 2014/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.1105 - val_accuracy: 0.9869\n",
      "Epoch 2015/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9949 - val_loss: 0.1256 - val_accuracy: 0.9860\n",
      "Epoch 2016/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9959 - val_loss: 0.1092 - val_accuracy: 0.9860\n",
      "Epoch 2017/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.1110 - val_accuracy: 0.9869\n",
      "Epoch 2018/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.1317 - val_accuracy: 0.9851\n",
      "Epoch 2019/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.1134 - val_accuracy: 0.9851\n",
      "Epoch 2020/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9931 - val_loss: 0.1204 - val_accuracy: 0.9888\n",
      "Epoch 2021/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1156 - val_accuracy: 0.9879\n",
      "Epoch 2022/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.1196 - val_accuracy: 0.9860\n",
      "Epoch 2023/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9949 - val_loss: 0.1168 - val_accuracy: 0.9897\n",
      "Epoch 2024/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1096 - val_accuracy: 0.9879\n",
      "Epoch 2025/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1165 - val_accuracy: 0.9879\n",
      "Epoch 2026/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.1106 - val_accuracy: 0.9869\n",
      "Epoch 2027/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1187 - val_accuracy: 0.9897\n",
      "Epoch 2028/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1120 - val_accuracy: 0.9879\n",
      "Epoch 2029/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.1209 - val_accuracy: 0.9879\n",
      "Epoch 2030/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1097 - val_accuracy: 0.9869\n",
      "Epoch 2031/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.1180 - val_accuracy: 0.9897\n",
      "Epoch 2032/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.1121 - val_accuracy: 0.9860\n",
      "Epoch 2033/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1223 - val_accuracy: 0.9897\n",
      "Epoch 2034/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1101 - val_accuracy: 0.9869\n",
      "Epoch 2035/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1164 - val_accuracy: 0.9888\n",
      "Epoch 2036/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1183 - val_accuracy: 0.9860\n",
      "Epoch 2037/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1165 - val_accuracy: 0.9888\n",
      "Epoch 2038/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1126 - val_accuracy: 0.9888\n",
      "Epoch 2039/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1235 - val_accuracy: 0.9879\n",
      "Epoch 2040/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.1161 - val_accuracy: 0.9879\n",
      "Epoch 2041/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1110 - val_accuracy: 0.9879\n",
      "Epoch 2042/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.1175 - val_accuracy: 0.9888\n",
      "Epoch 2043/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 0.1237 - val_accuracy: 0.9888\n",
      "Epoch 2044/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9959 - val_loss: 0.1097 - val_accuracy: 0.9869\n",
      "Epoch 2045/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.1207 - val_accuracy: 0.9897\n",
      "Epoch 2046/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1152 - val_accuracy: 0.9888\n",
      "Epoch 2047/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.1192 - val_accuracy: 0.9897\n",
      "Epoch 2048/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.1132 - val_accuracy: 0.9888\n",
      "Epoch 2049/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1252 - val_accuracy: 0.9879\n",
      "Epoch 2050/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.1116 - val_accuracy: 0.9879\n",
      "Epoch 2051/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.1353 - val_accuracy: 0.9851\n",
      "Epoch 2052/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.1119 - val_accuracy: 0.9851\n",
      "Epoch 2053/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.1363 - val_accuracy: 0.9851\n",
      "Epoch 2054/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.1142 - val_accuracy: 0.9869\n",
      "Epoch 2055/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1221 - val_accuracy: 0.9860\n",
      "Epoch 2056/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9954 - val_loss: 0.1125 - val_accuracy: 0.9879\n",
      "Epoch 2057/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1134 - val_accuracy: 0.9888\n",
      "Epoch 2058/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1140 - val_accuracy: 0.9879\n",
      "Epoch 2059/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.1175 - val_accuracy: 0.9907\n",
      "Epoch 2060/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1094 - val_accuracy: 0.9869\n",
      "Epoch 2061/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1233 - val_accuracy: 0.9897\n",
      "Epoch 2062/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1108 - val_accuracy: 0.9888\n",
      "Epoch 2063/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1213 - val_accuracy: 0.9869\n",
      "Epoch 2064/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1147 - val_accuracy: 0.9879\n",
      "Epoch 2065/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1236 - val_accuracy: 0.9879\n",
      "Epoch 2066/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1137 - val_accuracy: 0.9869\n",
      "Epoch 2067/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1144 - val_accuracy: 0.9879\n",
      "Epoch 2068/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1164 - val_accuracy: 0.9879\n",
      "Epoch 2069/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1215 - val_accuracy: 0.9888\n",
      "Epoch 2070/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1158 - val_accuracy: 0.9888\n",
      "Epoch 2071/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1146 - val_accuracy: 0.9888\n",
      "Epoch 2072/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1201 - val_accuracy: 0.9879\n",
      "Epoch 2073/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1184 - val_accuracy: 0.9888\n",
      "Epoch 2074/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1167 - val_accuracy: 0.9879\n",
      "Epoch 2075/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1135 - val_accuracy: 0.9869\n",
      "Epoch 2076/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.1242 - val_accuracy: 0.9869\n",
      "Epoch 2077/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1114 - val_accuracy: 0.9879\n",
      "Epoch 2078/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.1149 - val_accuracy: 0.9888\n",
      "Epoch 2079/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1164 - val_accuracy: 0.9897\n",
      "Epoch 2080/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1144 - val_accuracy: 0.9888\n",
      "Epoch 2081/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1116 - val_accuracy: 0.9879\n",
      "Epoch 2082/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1210 - val_accuracy: 0.9897\n",
      "Epoch 2083/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1134 - val_accuracy: 0.9869\n",
      "Epoch 2084/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1161 - val_accuracy: 0.9879\n",
      "Epoch 2085/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1172 - val_accuracy: 0.9888\n",
      "Epoch 2086/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.1118 - val_accuracy: 0.9879\n",
      "Epoch 2087/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1232 - val_accuracy: 0.9860\n",
      "Epoch 2088/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1111 - val_accuracy: 0.9879\n",
      "Epoch 2089/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1219 - val_accuracy: 0.9888\n",
      "Epoch 2090/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1165 - val_accuracy: 0.9860\n",
      "Epoch 2091/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9954 - val_loss: 0.1269 - val_accuracy: 0.9869\n",
      "Epoch 2092/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1132 - val_accuracy: 0.9860\n",
      "Epoch 2093/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9959 - val_loss: 0.1410 - val_accuracy: 0.9851\n",
      "Epoch 2094/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.1100 - val_accuracy: 0.9879\n",
      "Epoch 2095/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.1202 - val_accuracy: 0.9897\n",
      "Epoch 2096/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.1148 - val_accuracy: 0.9879\n",
      "Epoch 2097/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1169 - val_accuracy: 0.9879\n",
      "Epoch 2098/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1121 - val_accuracy: 0.9869\n",
      "Epoch 2099/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.1148 - val_accuracy: 0.9869\n",
      "Epoch 2100/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1148 - val_accuracy: 0.9888\n",
      "Epoch 2101/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1136 - val_accuracy: 0.9879\n",
      "Epoch 2102/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1260 - val_accuracy: 0.9869\n",
      "Epoch 2103/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.1150 - val_accuracy: 0.9879\n",
      "Epoch 2104/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.1260 - val_accuracy: 0.9860\n",
      "Epoch 2105/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.1123 - val_accuracy: 0.9869\n",
      "Epoch 2106/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1152 - val_accuracy: 0.9869\n",
      "Epoch 2107/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.1168 - val_accuracy: 0.9869\n",
      "Epoch 2108/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1142 - val_accuracy: 0.9869\n",
      "Epoch 2109/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1185 - val_accuracy: 0.9879\n",
      "Epoch 2110/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1146 - val_accuracy: 0.9869\n",
      "Epoch 2111/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.1268 - val_accuracy: 0.9869\n",
      "Epoch 2112/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.1125 - val_accuracy: 0.9869\n",
      "Epoch 2113/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.1356 - val_accuracy: 0.9869\n",
      "Epoch 2114/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.1134 - val_accuracy: 0.9879\n",
      "Epoch 2115/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1375 - val_accuracy: 0.9860\n",
      "Epoch 2116/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.1155 - val_accuracy: 0.9879\n",
      "Epoch 2117/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.1167 - val_accuracy: 0.9879\n",
      "Epoch 2118/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.1196 - val_accuracy: 0.9879\n",
      "Epoch 2119/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.1189 - val_accuracy: 0.9879\n",
      "Epoch 2120/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1168 - val_accuracy: 0.9888\n",
      "Epoch 2121/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1134 - val_accuracy: 0.9869\n",
      "Epoch 2122/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1229 - val_accuracy: 0.9888\n",
      "Epoch 2123/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.1156 - val_accuracy: 0.9888\n",
      "Epoch 2124/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1138 - val_accuracy: 0.9869\n",
      "Epoch 2125/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.1200 - val_accuracy: 0.9869\n",
      "Epoch 2126/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1215 - val_accuracy: 0.9879\n",
      "Epoch 2127/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1129 - val_accuracy: 0.9879\n",
      "Epoch 2128/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.1219 - val_accuracy: 0.9888\n",
      "Epoch 2129/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1153 - val_accuracy: 0.9860\n",
      "Epoch 2130/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1211 - val_accuracy: 0.9888\n",
      "Epoch 2131/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1130 - val_accuracy: 0.9888\n",
      "Epoch 2132/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1197 - val_accuracy: 0.9879\n",
      "Epoch 2133/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1143 - val_accuracy: 0.9879\n",
      "Epoch 2134/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1268 - val_accuracy: 0.9869\n",
      "Epoch 2135/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.1133 - val_accuracy: 0.9879\n",
      "Epoch 2136/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1217 - val_accuracy: 0.9879\n",
      "Epoch 2137/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.1152 - val_accuracy: 0.9869\n",
      "Epoch 2138/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.1226 - val_accuracy: 0.9888\n",
      "Epoch 2139/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1126 - val_accuracy: 0.9879\n",
      "Epoch 2140/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9954 - val_loss: 0.1322 - val_accuracy: 0.9851\n",
      "Epoch 2141/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.1131 - val_accuracy: 0.9869\n",
      "Epoch 2142/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9959 - val_loss: 0.1292 - val_accuracy: 0.9869\n",
      "Epoch 2143/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.1150 - val_accuracy: 0.9888\n",
      "Epoch 2144/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.1217 - val_accuracy: 0.9879\n",
      "Epoch 2145/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1141 - val_accuracy: 0.9860\n",
      "Epoch 2146/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1188 - val_accuracy: 0.9879\n",
      "Epoch 2147/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1146 - val_accuracy: 0.9860\n",
      "Epoch 2148/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1174 - val_accuracy: 0.9860\n",
      "Epoch 2149/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.1169 - val_accuracy: 0.9869\n",
      "Epoch 2150/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1261 - val_accuracy: 0.9869\n",
      "Epoch 2151/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.1205 - val_accuracy: 0.9832\n",
      "Epoch 2152/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9885 - val_loss: 0.1679 - val_accuracy: 0.9813\n",
      "Epoch 2153/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.1314 - val_accuracy: 0.9851\n",
      "Epoch 2154/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.1206 - val_accuracy: 0.9869\n",
      "Epoch 2155/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9940 - val_loss: 0.1103 - val_accuracy: 0.9869\n",
      "Epoch 2156/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.1237 - val_accuracy: 0.9869\n",
      "Epoch 2157/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9936 - val_loss: 0.1246 - val_accuracy: 0.9860\n",
      "Epoch 2158/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.1093 - val_accuracy: 0.9869\n",
      "Epoch 2159/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9949 - val_loss: 0.1466 - val_accuracy: 0.9851\n",
      "Epoch 2160/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.1221 - val_accuracy: 0.9823\n",
      "Epoch 2161/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9940 - val_loss: 0.1409 - val_accuracy: 0.9851\n",
      "Epoch 2162/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.1129 - val_accuracy: 0.9879\n",
      "Epoch 2163/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9945 - val_loss: 0.1211 - val_accuracy: 0.9879\n",
      "Epoch 2164/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1209 - val_accuracy: 0.9869\n",
      "Epoch 2165/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1182 - val_accuracy: 0.9869\n",
      "Epoch 2166/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1217 - val_accuracy: 0.9897\n",
      "Epoch 2167/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.1182 - val_accuracy: 0.9869\n",
      "Epoch 2168/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.1212 - val_accuracy: 0.9888\n",
      "Epoch 2169/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1164 - val_accuracy: 0.9888\n",
      "Epoch 2170/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.1203 - val_accuracy: 0.9879\n",
      "Epoch 2171/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1202 - val_accuracy: 0.9879\n",
      "Epoch 2172/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1228 - val_accuracy: 0.9879\n",
      "Epoch 2173/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1160 - val_accuracy: 0.9879\n",
      "Epoch 2174/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1171 - val_accuracy: 0.9879\n",
      "Epoch 2175/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1218 - val_accuracy: 0.9879\n",
      "Epoch 2176/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.1192 - val_accuracy: 0.9888\n",
      "Epoch 2177/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.1208 - val_accuracy: 0.9897\n",
      "Epoch 2178/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1170 - val_accuracy: 0.9869\n",
      "Epoch 2179/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1183 - val_accuracy: 0.9869\n",
      "Epoch 2180/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.1228 - val_accuracy: 0.9888\n",
      "Epoch 2181/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1169 - val_accuracy: 0.9879\n",
      "Epoch 2182/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1215 - val_accuracy: 0.9869\n",
      "Epoch 2183/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.1203 - val_accuracy: 0.9879\n",
      "Epoch 2184/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1203 - val_accuracy: 0.9888\n",
      "Epoch 2185/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.1220 - val_accuracy: 0.9879\n",
      "Epoch 2186/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1187 - val_accuracy: 0.9888\n",
      "Epoch 2187/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1218 - val_accuracy: 0.9879\n",
      "Epoch 2188/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1231 - val_accuracy: 0.9879\n",
      "Epoch 2189/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.1155 - val_accuracy: 0.9879\n",
      "Epoch 2190/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.1271 - val_accuracy: 0.9888\n",
      "Epoch 2191/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1168 - val_accuracy: 0.9879\n",
      "Epoch 2192/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.1206 - val_accuracy: 0.9879\n",
      "Epoch 2193/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1172 - val_accuracy: 0.9869\n",
      "Epoch 2194/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.1255 - val_accuracy: 0.9860\n",
      "Epoch 2195/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1153 - val_accuracy: 0.9869\n",
      "Epoch 2196/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1170 - val_accuracy: 0.9869\n",
      "Epoch 2197/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1221 - val_accuracy: 0.9869\n",
      "Epoch 2198/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1228 - val_accuracy: 0.9869\n",
      "Epoch 2199/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1137 - val_accuracy: 0.9879\n",
      "Epoch 2200/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.1266 - val_accuracy: 0.9879\n",
      "Epoch 2201/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.1208 - val_accuracy: 0.9879\n",
      "Epoch 2202/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1244 - val_accuracy: 0.9869\n",
      "Epoch 2203/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1185 - val_accuracy: 0.9879\n",
      "Epoch 2204/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1173 - val_accuracy: 0.9869\n",
      "Epoch 2205/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1228 - val_accuracy: 0.9869\n",
      "Epoch 2206/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1188 - val_accuracy: 0.9879\n",
      "Epoch 2207/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1222 - val_accuracy: 0.9879\n",
      "Epoch 2208/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1214 - val_accuracy: 0.9879\n",
      "Epoch 2209/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1210 - val_accuracy: 0.9879\n",
      "Epoch 2210/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1211 - val_accuracy: 0.9879\n",
      "Epoch 2211/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1199 - val_accuracy: 0.9879\n",
      "Epoch 2212/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1222 - val_accuracy: 0.9879\n",
      "Epoch 2213/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1176 - val_accuracy: 0.9888\n",
      "Epoch 2214/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.1237 - val_accuracy: 0.9888\n",
      "Epoch 2215/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.1199 - val_accuracy: 0.9888\n",
      "Epoch 2216/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.1158 - val_accuracy: 0.9869\n",
      "Epoch 2217/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9926 - val_loss: 0.1507 - val_accuracy: 0.9879\n",
      "Epoch 2218/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9881 - val_loss: 0.1287 - val_accuracy: 0.9776\n",
      "Epoch 2219/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9922 - val_loss: 0.1558 - val_accuracy: 0.9841\n",
      "Epoch 2220/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9949 - val_loss: 0.1176 - val_accuracy: 0.9832\n",
      "Epoch 2221/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.1469 - val_accuracy: 0.9832\n",
      "Epoch 2222/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.1220 - val_accuracy: 0.9813\n",
      "Epoch 2223/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9931 - val_loss: 0.1231 - val_accuracy: 0.9869\n",
      "Epoch 2224/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1170 - val_accuracy: 0.9869\n",
      "Epoch 2225/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1214 - val_accuracy: 0.9888\n",
      "Epoch 2226/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.1140 - val_accuracy: 0.9888\n",
      "Epoch 2227/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1215 - val_accuracy: 0.9879\n",
      "Epoch 2228/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1185 - val_accuracy: 0.9879\n",
      "Epoch 2229/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1141 - val_accuracy: 0.9869\n",
      "Epoch 2230/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.1254 - val_accuracy: 0.9879\n",
      "Epoch 2231/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.1159 - val_accuracy: 0.9879\n",
      "Epoch 2232/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.1194 - val_accuracy: 0.9879\n",
      "Epoch 2233/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.1150 - val_accuracy: 0.9841\n",
      "Epoch 2234/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9871 - val_loss: 0.1544 - val_accuracy: 0.9823\n",
      "Epoch 2235/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.1285 - val_accuracy: 0.9813\n",
      "Epoch 2236/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9922 - val_loss: 0.1403 - val_accuracy: 0.9851\n",
      "Epoch 2237/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.1082 - val_accuracy: 0.9860\n",
      "Epoch 2238/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.1200 - val_accuracy: 0.9879\n",
      "Epoch 2239/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1190 - val_accuracy: 0.9879\n",
      "Epoch 2240/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.1306 - val_accuracy: 0.9869\n",
      "Epoch 2241/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.1284 - val_accuracy: 0.9879\n",
      "Epoch 2242/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1185 - val_accuracy: 0.9888\n",
      "Epoch 2243/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.1219 - val_accuracy: 0.9879\n",
      "Epoch 2244/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 0.1182 - val_accuracy: 0.9869\n",
      "Epoch 2245/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.1212 - val_accuracy: 0.9879\n",
      "Epoch 2246/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1204 - val_accuracy: 0.9879\n",
      "Epoch 2247/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1186 - val_accuracy: 0.9888\n",
      "Epoch 2248/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1282 - val_accuracy: 0.9879\n",
      "Epoch 2249/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.1139 - val_accuracy: 0.9879\n",
      "Epoch 2250/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.1201 - val_accuracy: 0.9897\n",
      "Epoch 2251/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1256 - val_accuracy: 0.9860\n",
      "Epoch 2252/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1238 - val_accuracy: 0.9888\n",
      "Epoch 2253/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1183 - val_accuracy: 0.9869\n",
      "Epoch 2254/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.1189 - val_accuracy: 0.9879\n",
      "Epoch 2255/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1207 - val_accuracy: 0.9888\n",
      "Epoch 2256/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9940 - val_loss: 0.1310 - val_accuracy: 0.9869\n",
      "Epoch 2257/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.1179 - val_accuracy: 0.9869\n",
      "Epoch 2258/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.1221 - val_accuracy: 0.9879\n",
      "Epoch 2259/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.1197 - val_accuracy: 0.9869\n",
      "Epoch 2260/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1207 - val_accuracy: 0.9869\n",
      "Epoch 2261/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1325 - val_accuracy: 0.9879\n",
      "Epoch 2262/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.1189 - val_accuracy: 0.9879\n",
      "Epoch 2263/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1246 - val_accuracy: 0.9888\n",
      "Epoch 2264/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1195 - val_accuracy: 0.9869\n",
      "Epoch 2265/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.1231 - val_accuracy: 0.9879\n",
      "Epoch 2266/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1203 - val_accuracy: 0.9879\n",
      "Epoch 2267/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1242 - val_accuracy: 0.9879\n",
      "Epoch 2268/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.1185 - val_accuracy: 0.9869\n",
      "Epoch 2269/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9940 - val_loss: 0.1427 - val_accuracy: 0.9860\n",
      "Epoch 2270/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.1182 - val_accuracy: 0.9869\n",
      "Epoch 2271/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9945 - val_loss: 0.1349 - val_accuracy: 0.9860\n",
      "Epoch 2272/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.1221 - val_accuracy: 0.9879\n",
      "Epoch 2273/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.1192 - val_accuracy: 0.9869\n",
      "Epoch 2274/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.1210 - val_accuracy: 0.9888\n",
      "Epoch 2275/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1198 - val_accuracy: 0.9869\n",
      "Epoch 2276/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1207 - val_accuracy: 0.9879\n",
      "Epoch 2277/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.1187 - val_accuracy: 0.9869\n",
      "Epoch 2278/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.1259 - val_accuracy: 0.9888\n",
      "Epoch 2279/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1165 - val_accuracy: 0.9879\n",
      "Epoch 2280/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.1313 - val_accuracy: 0.9869\n",
      "Epoch 2281/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.1181 - val_accuracy: 0.9879\n",
      "Epoch 2282/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1229 - val_accuracy: 0.9869\n",
      "Epoch 2283/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1198 - val_accuracy: 0.9869\n",
      "Epoch 2284/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1204 - val_accuracy: 0.9869\n",
      "Epoch 2285/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1221 - val_accuracy: 0.9869\n",
      "Epoch 2286/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1195 - val_accuracy: 0.9869\n",
      "Epoch 2287/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1252 - val_accuracy: 0.9860\n",
      "Epoch 2288/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.1201 - val_accuracy: 0.9869\n",
      "Epoch 2289/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.1175 - val_accuracy: 0.9869\n",
      "Epoch 2290/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1310 - val_accuracy: 0.9860\n",
      "Epoch 2291/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1201 - val_accuracy: 0.9879\n",
      "Epoch 2292/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.1186 - val_accuracy: 0.9869\n",
      "Epoch 2293/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.1207 - val_accuracy: 0.9879\n",
      "Epoch 2294/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1249 - val_accuracy: 0.9879\n",
      "Epoch 2295/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.1195 - val_accuracy: 0.9869\n",
      "Epoch 2296/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.1161 - val_accuracy: 0.9869\n",
      "Epoch 2297/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1221 - val_accuracy: 0.9879\n",
      "Epoch 2298/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1225 - val_accuracy: 0.9869\n",
      "Epoch 2299/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.1207 - val_accuracy: 0.9879\n",
      "Epoch 2300/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.1203 - val_accuracy: 0.9879\n",
      "Epoch 2301/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1183 - val_accuracy: 0.9869\n",
      "Epoch 2302/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.1250 - val_accuracy: 0.9869\n",
      "Epoch 2303/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.1180 - val_accuracy: 0.9869\n",
      "Epoch 2304/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9954 - val_loss: 0.1240 - val_accuracy: 0.9888\n",
      "Epoch 2305/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.1219 - val_accuracy: 0.9879\n",
      "Epoch 2306/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.1349 - val_accuracy: 0.9860\n",
      "Epoch 2307/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1172 - val_accuracy: 0.9869\n",
      "Epoch 2308/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9963 - val_loss: 0.1162 - val_accuracy: 0.9869\n",
      "Epoch 2309/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1303 - val_accuracy: 0.9879\n",
      "Epoch 2310/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.1232 - val_accuracy: 0.9869\n",
      "Epoch 2311/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1229 - val_accuracy: 0.9869\n",
      "Epoch 2312/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1203 - val_accuracy: 0.9879\n",
      "Epoch 2313/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.1248 - val_accuracy: 0.9879\n",
      "Epoch 2314/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1242 - val_accuracy: 0.9860\n",
      "Epoch 2315/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1219 - val_accuracy: 0.9879\n",
      "Epoch 2316/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.1206 - val_accuracy: 0.9869\n",
      "Epoch 2317/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1202 - val_accuracy: 0.9869\n",
      "Epoch 2318/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1230 - val_accuracy: 0.9879\n",
      "Epoch 2319/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1278 - val_accuracy: 0.9879\n",
      "Epoch 2320/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.1194 - val_accuracy: 0.9860\n",
      "Epoch 2321/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.1281 - val_accuracy: 0.9897\n",
      "Epoch 2322/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.1192 - val_accuracy: 0.9879\n",
      "Epoch 2323/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9954 - val_loss: 0.1389 - val_accuracy: 0.9860\n",
      "Epoch 2324/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.1165 - val_accuracy: 0.9869\n",
      "Epoch 2325/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.1250 - val_accuracy: 0.9879\n",
      "Epoch 2326/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.1217 - val_accuracy: 0.9879\n",
      "Epoch 2327/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.1180 - val_accuracy: 0.9869\n",
      "Epoch 2328/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1287 - val_accuracy: 0.9879\n",
      "Epoch 2329/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1209 - val_accuracy: 0.9860\n",
      "Epoch 2330/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1176 - val_accuracy: 0.9869\n",
      "Epoch 2331/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.1252 - val_accuracy: 0.9879\n",
      "Epoch 2332/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1241 - val_accuracy: 0.9879\n",
      "Epoch 2333/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1249 - val_accuracy: 0.9869\n",
      "Epoch 2334/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1233 - val_accuracy: 0.9888\n",
      "Epoch 2335/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1201 - val_accuracy: 0.9879\n",
      "Epoch 2336/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.1217 - val_accuracy: 0.9869\n",
      "Epoch 2337/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1221 - val_accuracy: 0.9869\n",
      "Epoch 2338/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1256 - val_accuracy: 0.9869\n",
      "Epoch 2339/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1195 - val_accuracy: 0.9869\n",
      "Epoch 2340/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1215 - val_accuracy: 0.9869\n",
      "Epoch 2341/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1264 - val_accuracy: 0.9879\n",
      "Epoch 2342/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1243 - val_accuracy: 0.9879\n",
      "Epoch 2343/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1215 - val_accuracy: 0.9869\n",
      "Epoch 2344/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1202 - val_accuracy: 0.9860\n",
      "Epoch 2345/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1275 - val_accuracy: 0.9879\n",
      "Epoch 2346/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1201 - val_accuracy: 0.9869\n",
      "Epoch 2347/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1248 - val_accuracy: 0.9869\n",
      "Epoch 2348/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1230 - val_accuracy: 0.9879\n",
      "Epoch 2349/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1262 - val_accuracy: 0.9869\n",
      "Epoch 2350/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1258 - val_accuracy: 0.9879\n",
      "Epoch 2351/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1197 - val_accuracy: 0.9869\n",
      "Epoch 2352/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1219 - val_accuracy: 0.9869\n",
      "Epoch 2353/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1228 - val_accuracy: 0.9879\n",
      "Epoch 2354/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1231 - val_accuracy: 0.9879\n",
      "Epoch 2355/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1229 - val_accuracy: 0.9869\n",
      "Epoch 2356/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1177 - val_accuracy: 0.9869\n",
      "Epoch 2357/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1273 - val_accuracy: 0.9879\n",
      "Epoch 2358/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1202 - val_accuracy: 0.9869\n",
      "Epoch 2359/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1254 - val_accuracy: 0.9869\n",
      "Epoch 2360/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1198 - val_accuracy: 0.9869\n",
      "Epoch 2361/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.1238 - val_accuracy: 0.9879\n",
      "Epoch 2362/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.1223 - val_accuracy: 0.9879\n",
      "Epoch 2363/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1225 - val_accuracy: 0.9869\n",
      "Epoch 2364/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1197 - val_accuracy: 0.9869\n",
      "Epoch 2365/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1286 - val_accuracy: 0.9869\n",
      "Epoch 2366/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.1215 - val_accuracy: 0.9860\n",
      "Epoch 2367/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1297 - val_accuracy: 0.9888\n",
      "Epoch 2368/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.1209 - val_accuracy: 0.9869\n",
      "Epoch 2369/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.1281 - val_accuracy: 0.9869\n",
      "Epoch 2370/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1184 - val_accuracy: 0.9869\n",
      "Epoch 2371/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1222 - val_accuracy: 0.9879\n",
      "Epoch 2372/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1273 - val_accuracy: 0.9879\n",
      "Epoch 2373/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1234 - val_accuracy: 0.9879\n",
      "Epoch 2374/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1227 - val_accuracy: 0.9879\n",
      "Epoch 2375/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1208 - val_accuracy: 0.9869\n",
      "Epoch 2376/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.1253 - val_accuracy: 0.9888\n",
      "Epoch 2377/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.1243 - val_accuracy: 0.9879\n",
      "Epoch 2378/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1244 - val_accuracy: 0.9869\n",
      "Epoch 2379/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1192 - val_accuracy: 0.9869\n",
      "Epoch 2380/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.1232 - val_accuracy: 0.9869\n",
      "Epoch 2381/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1233 - val_accuracy: 0.9879\n",
      "Epoch 2382/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1289 - val_accuracy: 0.9869\n",
      "Epoch 2383/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1203 - val_accuracy: 0.9869\n",
      "Epoch 2384/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1229 - val_accuracy: 0.9869\n",
      "Epoch 2385/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1311 - val_accuracy: 0.9888\n",
      "Epoch 2386/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1168 - val_accuracy: 0.9869\n",
      "Epoch 2387/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.1246 - val_accuracy: 0.9879\n",
      "Epoch 2388/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1257 - val_accuracy: 0.9869\n",
      "Epoch 2389/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.1210 - val_accuracy: 0.9869\n",
      "Epoch 2390/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1285 - val_accuracy: 0.9879\n",
      "Epoch 2391/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.1213 - val_accuracy: 0.9879\n",
      "Epoch 2392/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1331 - val_accuracy: 0.9879\n",
      "Epoch 2393/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1207 - val_accuracy: 0.9860\n",
      "Epoch 2394/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1276 - val_accuracy: 0.9888\n",
      "Epoch 2395/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.1223 - val_accuracy: 0.9869\n",
      "Epoch 2396/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1278 - val_accuracy: 0.9879\n",
      "Epoch 2397/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1223 - val_accuracy: 0.9879\n",
      "Epoch 2398/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.1361 - val_accuracy: 0.9879\n",
      "Epoch 2399/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.1243 - val_accuracy: 0.9879\n",
      "Epoch 2400/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1250 - val_accuracy: 0.9879\n",
      "Epoch 2401/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1199 - val_accuracy: 0.9869\n",
      "Epoch 2402/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9945 - val_loss: 0.1423 - val_accuracy: 0.9860\n",
      "Epoch 2403/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.1230 - val_accuracy: 0.9879\n",
      "Epoch 2404/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.1423 - val_accuracy: 0.9860\n",
      "Epoch 2405/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.1187 - val_accuracy: 0.9879\n",
      "Epoch 2406/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1318 - val_accuracy: 0.9879\n",
      "Epoch 2407/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.1283 - val_accuracy: 0.9879\n",
      "Epoch 2408/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.1218 - val_accuracy: 0.9869\n",
      "Epoch 2409/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9959 - val_loss: 0.1268 - val_accuracy: 0.9879\n",
      "Epoch 2410/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.1236 - val_accuracy: 0.9879\n",
      "Epoch 2411/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.1372 - val_accuracy: 0.9879\n",
      "Epoch 2412/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.1197 - val_accuracy: 0.9879\n",
      "Epoch 2413/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9959 - val_loss: 0.1289 - val_accuracy: 0.9879\n",
      "Epoch 2414/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1232 - val_accuracy: 0.9869\n",
      "Epoch 2415/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1259 - val_accuracy: 0.9879\n",
      "Epoch 2416/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1287 - val_accuracy: 0.9860\n",
      "Epoch 2417/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1216 - val_accuracy: 0.9869\n",
      "Epoch 2418/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1190 - val_accuracy: 0.9869\n",
      "Epoch 2419/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1355 - val_accuracy: 0.9851\n",
      "Epoch 2420/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.1221 - val_accuracy: 0.9869\n",
      "Epoch 2421/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1270 - val_accuracy: 0.9907\n",
      "Epoch 2422/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1230 - val_accuracy: 0.9860\n",
      "Epoch 2423/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1311 - val_accuracy: 0.9869\n",
      "Epoch 2424/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1210 - val_accuracy: 0.9869\n",
      "Epoch 2425/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1246 - val_accuracy: 0.9869\n",
      "Epoch 2426/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1282 - val_accuracy: 0.9879\n",
      "Epoch 2427/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1225 - val_accuracy: 0.9869\n",
      "Epoch 2428/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1211 - val_accuracy: 0.9869\n",
      "Epoch 2429/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1292 - val_accuracy: 0.9879\n",
      "Epoch 2430/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.1324 - val_accuracy: 0.9869\n",
      "Epoch 2431/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1224 - val_accuracy: 0.9869\n",
      "Epoch 2432/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1224 - val_accuracy: 0.9869\n",
      "Epoch 2433/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1249 - val_accuracy: 0.9869\n",
      "Epoch 2434/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1258 - val_accuracy: 0.9860\n",
      "Epoch 2435/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1234 - val_accuracy: 0.9869\n",
      "Epoch 2436/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1338 - val_accuracy: 0.9879\n",
      "Epoch 2437/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.1217 - val_accuracy: 0.9869\n",
      "Epoch 2438/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1300 - val_accuracy: 0.9860\n",
      "Epoch 2439/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1238 - val_accuracy: 0.9860\n",
      "Epoch 2440/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1313 - val_accuracy: 0.9888\n",
      "Epoch 2441/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1223 - val_accuracy: 0.9869\n",
      "Epoch 2442/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9926 - val_loss: 0.1602 - val_accuracy: 0.9841\n",
      "Epoch 2443/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9936 - val_loss: 0.1154 - val_accuracy: 0.9869\n",
      "Epoch 2444/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.1192 - val_accuracy: 0.9879\n",
      "Epoch 2445/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9913 - val_loss: 0.1607 - val_accuracy: 0.9823\n",
      "Epoch 2446/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9954 - val_loss: 0.1222 - val_accuracy: 0.9869\n",
      "Epoch 2447/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.1275 - val_accuracy: 0.9888\n",
      "Epoch 2448/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1256 - val_accuracy: 0.9879\n",
      "Epoch 2449/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.1338 - val_accuracy: 0.9888\n",
      "Epoch 2450/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1226 - val_accuracy: 0.9869\n",
      "Epoch 2451/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9977 - val_loss: 0.1285 - val_accuracy: 0.9888\n",
      "Epoch 2452/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1229 - val_accuracy: 0.9879\n",
      "Epoch 2453/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1252 - val_accuracy: 0.9860\n",
      "Epoch 2454/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1279 - val_accuracy: 0.9869\n",
      "Epoch 2455/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.1206 - val_accuracy: 0.9879\n",
      "Epoch 2456/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1248 - val_accuracy: 0.9879\n",
      "Epoch 2457/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1252 - val_accuracy: 0.9869\n",
      "Epoch 2458/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.1277 - val_accuracy: 0.9888\n",
      "Epoch 2459/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1230 - val_accuracy: 0.9869\n",
      "Epoch 2460/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1331 - val_accuracy: 0.9879\n",
      "Epoch 2461/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.1229 - val_accuracy: 0.9879\n",
      "Epoch 2462/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9954 - val_loss: 0.1422 - val_accuracy: 0.9869\n",
      "Epoch 2463/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.1238 - val_accuracy: 0.9841\n",
      "Epoch 2464/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9940 - val_loss: 0.1720 - val_accuracy: 0.9841\n",
      "Epoch 2465/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.1371 - val_accuracy: 0.9767\n",
      "Epoch 2466/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9931 - val_loss: 0.2038 - val_accuracy: 0.9795\n",
      "Epoch 2467/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.1594 - val_accuracy: 0.9692\n",
      "Epoch 2468/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9844 - val_loss: 0.1475 - val_accuracy: 0.9860\n",
      "Epoch 2469/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9903 - val_loss: 0.1383 - val_accuracy: 0.9869\n",
      "Epoch 2470/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.1337 - val_accuracy: 0.9869\n",
      "Epoch 2471/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.1133 - val_accuracy: 0.9860\n",
      "Epoch 2472/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.1266 - val_accuracy: 0.9888\n",
      "Epoch 2473/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1327 - val_accuracy: 0.9860\n",
      "Epoch 2474/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.1273 - val_accuracy: 0.9869\n",
      "Epoch 2475/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1185 - val_accuracy: 0.9879\n",
      "Epoch 2476/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.1230 - val_accuracy: 0.9869\n",
      "Epoch 2477/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.1263 - val_accuracy: 0.9860\n",
      "Epoch 2478/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.1305 - val_accuracy: 0.9897\n",
      "Epoch 2479/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1209 - val_accuracy: 0.9869\n",
      "Epoch 2480/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1223 - val_accuracy: 0.9869\n",
      "Epoch 2481/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1241 - val_accuracy: 0.9879\n",
      "Epoch 2482/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.1274 - val_accuracy: 0.9869\n",
      "Epoch 2483/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1217 - val_accuracy: 0.9860\n",
      "Epoch 2484/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9959 - val_loss: 0.1259 - val_accuracy: 0.9879\n",
      "Epoch 2485/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.1226 - val_accuracy: 0.9869\n",
      "Epoch 2486/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9959 - val_loss: 0.1276 - val_accuracy: 0.9869\n",
      "Epoch 2487/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1282 - val_accuracy: 0.9869\n",
      "Epoch 2488/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1263 - val_accuracy: 0.9879\n",
      "Epoch 2489/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1245 - val_accuracy: 0.9869\n",
      "Epoch 2490/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1218 - val_accuracy: 0.9869\n",
      "Epoch 2491/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1262 - val_accuracy: 0.9860\n",
      "Epoch 2492/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.1261 - val_accuracy: 0.9869\n",
      "Epoch 2493/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.1235 - val_accuracy: 0.9869\n",
      "Epoch 2494/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1236 - val_accuracy: 0.9869\n",
      "Epoch 2495/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.1275 - val_accuracy: 0.9869\n",
      "Epoch 2496/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1269 - val_accuracy: 0.9869\n",
      "Epoch 2497/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1260 - val_accuracy: 0.9869\n",
      "Epoch 2498/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1252 - val_accuracy: 0.9860\n",
      "Epoch 2499/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1273 - val_accuracy: 0.9869\n",
      "Epoch 2500/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1236 - val_accuracy: 0.9869\n",
      "Epoch 2501/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1254 - val_accuracy: 0.9860\n",
      "Epoch 2502/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1280 - val_accuracy: 0.9879\n",
      "Epoch 2503/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1257 - val_accuracy: 0.9869\n",
      "Epoch 2504/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1270 - val_accuracy: 0.9869\n",
      "Epoch 2505/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1228 - val_accuracy: 0.9860\n",
      "Epoch 2506/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1266 - val_accuracy: 0.9869\n",
      "Epoch 2507/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.1240 - val_accuracy: 0.9869\n",
      "Epoch 2508/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1244 - val_accuracy: 0.9869\n",
      "Epoch 2509/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1256 - val_accuracy: 0.9860\n",
      "Epoch 2510/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1264 - val_accuracy: 0.9860\n",
      "Epoch 2511/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1297 - val_accuracy: 0.9879\n",
      "Epoch 2512/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1215 - val_accuracy: 0.9869\n",
      "Epoch 2513/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1299 - val_accuracy: 0.9879\n",
      "Epoch 2514/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.1250 - val_accuracy: 0.9869\n",
      "Epoch 2515/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1259 - val_accuracy: 0.9860\n",
      "Epoch 2516/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1238 - val_accuracy: 0.9869\n",
      "Epoch 2517/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 0.1334 - val_accuracy: 0.9897\n",
      "Epoch 2518/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.1217 - val_accuracy: 0.9860\n",
      "Epoch 2519/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9954 - val_loss: 0.1484 - val_accuracy: 0.9851\n",
      "Epoch 2520/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.1250 - val_accuracy: 0.9841\n",
      "Epoch 2521/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.1253 - val_accuracy: 0.9897\n",
      "Epoch 2522/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1282 - val_accuracy: 0.9851\n",
      "Epoch 2523/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1332 - val_accuracy: 0.9879\n",
      "Epoch 2524/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1224 - val_accuracy: 0.9860\n",
      "Epoch 2525/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1273 - val_accuracy: 0.9879\n",
      "Epoch 2526/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1227 - val_accuracy: 0.9869\n",
      "Epoch 2527/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1331 - val_accuracy: 0.9879\n",
      "Epoch 2528/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1273 - val_accuracy: 0.9869\n",
      "Epoch 2529/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1249 - val_accuracy: 0.9869\n",
      "Epoch 2530/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.1349 - val_accuracy: 0.9879\n",
      "Epoch 2531/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1242 - val_accuracy: 0.9869\n",
      "Epoch 2532/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1310 - val_accuracy: 0.9869\n",
      "Epoch 2533/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1257 - val_accuracy: 0.9869\n",
      "Epoch 2534/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.1277 - val_accuracy: 0.9869\n",
      "Epoch 2535/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1296 - val_accuracy: 0.9879\n",
      "Epoch 2536/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1306 - val_accuracy: 0.9860\n",
      "Epoch 2537/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.1239 - val_accuracy: 0.9869\n",
      "Epoch 2538/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1234 - val_accuracy: 0.9879\n",
      "Epoch 2539/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1253 - val_accuracy: 0.9860\n",
      "Epoch 2540/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1255 - val_accuracy: 0.9869\n",
      "Epoch 2541/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1292 - val_accuracy: 0.9879\n",
      "Epoch 2542/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1249 - val_accuracy: 0.9869\n",
      "Epoch 2543/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9963 - val_loss: 0.1313 - val_accuracy: 0.9879\n",
      "Epoch 2544/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9972 - val_loss: 0.1234 - val_accuracy: 0.9879\n",
      "Epoch 2545/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1312 - val_accuracy: 0.9888\n",
      "Epoch 2546/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1265 - val_accuracy: 0.9869\n",
      "Epoch 2547/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1302 - val_accuracy: 0.9879\n",
      "Epoch 2548/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1259 - val_accuracy: 0.9869\n",
      "Epoch 2549/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.1279 - val_accuracy: 0.9869\n",
      "Epoch 2550/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1245 - val_accuracy: 0.9860\n",
      "Epoch 2551/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1269 - val_accuracy: 0.9879\n",
      "Epoch 2552/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1222 - val_accuracy: 0.9869\n",
      "Epoch 2553/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.1349 - val_accuracy: 0.9879\n",
      "Epoch 2554/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.1272 - val_accuracy: 0.9879\n",
      "Epoch 2555/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1308 - val_accuracy: 0.9879\n",
      "Epoch 2556/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1243 - val_accuracy: 0.9869\n",
      "Epoch 2557/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1339 - val_accuracy: 0.9879\n",
      "Epoch 2558/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1229 - val_accuracy: 0.9869\n",
      "Epoch 2559/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1296 - val_accuracy: 0.9879\n",
      "Epoch 2560/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1278 - val_accuracy: 0.9869\n",
      "Epoch 2561/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1297 - val_accuracy: 0.9879\n",
      "Epoch 2562/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1226 - val_accuracy: 0.9879\n",
      "Epoch 2563/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.1267 - val_accuracy: 0.9869\n",
      "Epoch 2564/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1275 - val_accuracy: 0.9860\n",
      "Epoch 2565/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1289 - val_accuracy: 0.9879\n",
      "Epoch 2566/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.1302 - val_accuracy: 0.9879\n",
      "Epoch 2567/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1252 - val_accuracy: 0.9869\n",
      "Epoch 2568/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1276 - val_accuracy: 0.9860\n",
      "Epoch 2569/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.1347 - val_accuracy: 0.9879\n",
      "Epoch 2570/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.1214 - val_accuracy: 0.9860\n",
      "Epoch 2571/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1334 - val_accuracy: 0.9888\n",
      "Epoch 2572/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1283 - val_accuracy: 0.9869\n",
      "Epoch 2573/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1233 - val_accuracy: 0.9869\n",
      "Epoch 2574/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1298 - val_accuracy: 0.9888\n",
      "Epoch 2575/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1284 - val_accuracy: 0.9860\n",
      "Epoch 2576/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1287 - val_accuracy: 0.9860\n",
      "Epoch 2577/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.1269 - val_accuracy: 0.9869\n",
      "Epoch 2578/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1269 - val_accuracy: 0.9860\n",
      "Epoch 2579/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.1310 - val_accuracy: 0.9869\n",
      "Epoch 2580/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.1247 - val_accuracy: 0.9869\n",
      "Epoch 2581/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1279 - val_accuracy: 0.9888\n",
      "Epoch 2582/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.1291 - val_accuracy: 0.9851\n",
      "Epoch 2583/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1302 - val_accuracy: 0.9869\n",
      "Epoch 2584/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1239 - val_accuracy: 0.9869\n",
      "Epoch 2585/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9959 - val_loss: 0.1336 - val_accuracy: 0.9888\n",
      "Epoch 2586/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.1289 - val_accuracy: 0.9851\n",
      "Epoch 2587/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.1301 - val_accuracy: 0.9879\n",
      "Epoch 2588/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1237 - val_accuracy: 0.9869\n",
      "Epoch 2589/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.1347 - val_accuracy: 0.9869\n",
      "Epoch 2590/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.1236 - val_accuracy: 0.9879\n",
      "Epoch 2591/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 0.1353 - val_accuracy: 0.9888\n",
      "Epoch 2592/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1235 - val_accuracy: 0.9869\n",
      "Epoch 2593/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1387 - val_accuracy: 0.9879\n",
      "Epoch 2594/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1236 - val_accuracy: 0.9860\n",
      "Epoch 2595/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1288 - val_accuracy: 0.9860\n",
      "Epoch 2596/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.1276 - val_accuracy: 0.9869\n",
      "Epoch 2597/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1323 - val_accuracy: 0.9869\n",
      "Epoch 2598/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1320 - val_accuracy: 0.9869\n",
      "Epoch 2599/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1294 - val_accuracy: 0.9869\n",
      "Epoch 2600/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1259 - val_accuracy: 0.9869\n",
      "Epoch 2601/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1300 - val_accuracy: 0.9860\n",
      "Epoch 2602/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1297 - val_accuracy: 0.9860\n",
      "Epoch 2603/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.1275 - val_accuracy: 0.9869\n",
      "Epoch 2604/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.1467 - val_accuracy: 0.9869\n",
      "Epoch 2605/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9949 - val_loss: 0.1304 - val_accuracy: 0.9823\n",
      "Epoch 2606/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.1692 - val_accuracy: 0.9851\n",
      "Epoch 2607/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.1462 - val_accuracy: 0.9748\n",
      "Epoch 2608/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9913 - val_loss: 0.1728 - val_accuracy: 0.9832\n",
      "Epoch 2609/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9913 - val_loss: 0.1343 - val_accuracy: 0.9879\n",
      "Epoch 2610/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.1282 - val_accuracy: 0.9879\n",
      "Epoch 2611/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9940 - val_loss: 0.1318 - val_accuracy: 0.9888\n",
      "Epoch 2612/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.1457 - val_accuracy: 0.9879\n",
      "Epoch 2613/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 0.1276 - val_accuracy: 0.9860\n",
      "Epoch 2614/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1240 - val_accuracy: 0.9869\n",
      "Epoch 2615/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.1274 - val_accuracy: 0.9879\n",
      "Epoch 2616/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1290 - val_accuracy: 0.9860\n",
      "Epoch 2617/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.1309 - val_accuracy: 0.9869\n",
      "Epoch 2618/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1243 - val_accuracy: 0.9869\n",
      "Epoch 2619/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1285 - val_accuracy: 0.9869\n",
      "Epoch 2620/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1316 - val_accuracy: 0.9869\n",
      "Epoch 2621/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1313 - val_accuracy: 0.9879\n",
      "Epoch 2622/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1259 - val_accuracy: 0.9860\n",
      "Epoch 2623/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1285 - val_accuracy: 0.9860\n",
      "Epoch 2624/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1302 - val_accuracy: 0.9869\n",
      "Epoch 2625/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1276 - val_accuracy: 0.9860\n",
      "Epoch 2626/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1295 - val_accuracy: 0.9869\n",
      "Epoch 2627/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1275 - val_accuracy: 0.9860\n",
      "Epoch 2628/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1304 - val_accuracy: 0.9869\n",
      "Epoch 2629/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1312 - val_accuracy: 0.9860\n",
      "Epoch 2630/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1305 - val_accuracy: 0.9860\n",
      "Epoch 2631/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1323 - val_accuracy: 0.9869\n",
      "Epoch 2632/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1275 - val_accuracy: 0.9888\n",
      "Epoch 2633/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1250 - val_accuracy: 0.9869\n",
      "Epoch 2634/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1410 - val_accuracy: 0.9888\n",
      "Epoch 2635/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.1270 - val_accuracy: 0.9860\n",
      "Epoch 2636/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1387 - val_accuracy: 0.9888\n",
      "Epoch 2637/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.1251 - val_accuracy: 0.9879\n",
      "Epoch 2638/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9963 - val_loss: 0.1396 - val_accuracy: 0.9888\n",
      "Epoch 2639/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.1270 - val_accuracy: 0.9860\n",
      "Epoch 2640/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1295 - val_accuracy: 0.9869\n",
      "Epoch 2641/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1264 - val_accuracy: 0.9860\n",
      "Epoch 2642/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1407 - val_accuracy: 0.9897\n",
      "Epoch 2643/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.1280 - val_accuracy: 0.9860\n",
      "Epoch 2644/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9949 - val_loss: 0.1413 - val_accuracy: 0.9888\n",
      "Epoch 2645/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.1287 - val_accuracy: 0.9869\n",
      "Epoch 2646/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.1337 - val_accuracy: 0.9879\n",
      "Epoch 2647/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1291 - val_accuracy: 0.9860\n",
      "Epoch 2648/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1304 - val_accuracy: 0.9860\n",
      "Epoch 2649/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1288 - val_accuracy: 0.9860\n",
      "Epoch 2650/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1344 - val_accuracy: 0.9879\n",
      "Epoch 2651/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1268 - val_accuracy: 0.9879\n",
      "Epoch 2652/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.1348 - val_accuracy: 0.9888\n",
      "Epoch 2653/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.1269 - val_accuracy: 0.9860\n",
      "Epoch 2654/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.1366 - val_accuracy: 0.9888\n",
      "Epoch 2655/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.1250 - val_accuracy: 0.9869\n",
      "Epoch 2656/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 0.1370 - val_accuracy: 0.9888\n",
      "Epoch 2657/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1261 - val_accuracy: 0.9869\n",
      "Epoch 2658/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1356 - val_accuracy: 0.9888\n",
      "Epoch 2659/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1269 - val_accuracy: 0.9860\n",
      "Epoch 2660/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.1323 - val_accuracy: 0.9879\n",
      "Epoch 2661/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1274 - val_accuracy: 0.9869\n",
      "Epoch 2662/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1293 - val_accuracy: 0.9851\n",
      "Epoch 2663/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1271 - val_accuracy: 0.9860\n",
      "Epoch 2664/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1416 - val_accuracy: 0.9860\n",
      "Epoch 2665/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1245 - val_accuracy: 0.9869\n",
      "Epoch 2666/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1272 - val_accuracy: 0.9869\n",
      "Epoch 2667/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1425 - val_accuracy: 0.9860\n",
      "Epoch 2668/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1314 - val_accuracy: 0.9869\n",
      "Epoch 2669/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1276 - val_accuracy: 0.9860\n",
      "Epoch 2670/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1247 - val_accuracy: 0.9860\n",
      "Epoch 2671/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1391 - val_accuracy: 0.9869\n",
      "Epoch 2672/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1257 - val_accuracy: 0.9869\n",
      "Epoch 2673/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1280 - val_accuracy: 0.9888\n",
      "Epoch 2674/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1271 - val_accuracy: 0.9860\n",
      "Epoch 2675/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9977 - val_loss: 0.1402 - val_accuracy: 0.9888\n",
      "Epoch 2676/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1277 - val_accuracy: 0.9860\n",
      "Epoch 2677/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.1330 - val_accuracy: 0.9869\n",
      "Epoch 2678/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1321 - val_accuracy: 0.9860\n",
      "Epoch 2679/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1323 - val_accuracy: 0.9869\n",
      "Epoch 2680/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.1290 - val_accuracy: 0.9869\n",
      "Epoch 2681/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1353 - val_accuracy: 0.9879\n",
      "Epoch 2682/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1294 - val_accuracy: 0.9869\n",
      "Epoch 2683/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1325 - val_accuracy: 0.9869\n",
      "Epoch 2684/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1288 - val_accuracy: 0.9851\n",
      "Epoch 2685/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1388 - val_accuracy: 0.9888\n",
      "Epoch 2686/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.1271 - val_accuracy: 0.9841\n",
      "Epoch 2687/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.1490 - val_accuracy: 0.9869\n",
      "Epoch 2688/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.1310 - val_accuracy: 0.9841\n",
      "Epoch 2689/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9899 - val_loss: 0.1726 - val_accuracy: 0.9841\n",
      "Epoch 2690/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9922 - val_loss: 0.1331 - val_accuracy: 0.9823\n",
      "Epoch 2691/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9949 - val_loss: 0.1678 - val_accuracy: 0.9841\n",
      "Epoch 2692/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9940 - val_loss: 0.1227 - val_accuracy: 0.9832\n",
      "Epoch 2693/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9954 - val_loss: 0.1427 - val_accuracy: 0.9869\n",
      "Epoch 2694/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.1285 - val_accuracy: 0.9832\n",
      "Epoch 2695/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9936 - val_loss: 0.1429 - val_accuracy: 0.9879\n",
      "Epoch 2696/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.1239 - val_accuracy: 0.9851\n",
      "Epoch 2697/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.1521 - val_accuracy: 0.9860\n",
      "Epoch 2698/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9949 - val_loss: 0.1280 - val_accuracy: 0.9869\n",
      "Epoch 2699/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.1403 - val_accuracy: 0.9869\n",
      "Epoch 2700/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.1279 - val_accuracy: 0.9869\n",
      "Epoch 2701/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1258 - val_accuracy: 0.9879\n",
      "Epoch 2702/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1257 - val_accuracy: 0.9879\n",
      "Epoch 2703/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.1278 - val_accuracy: 0.9860\n",
      "Epoch 2704/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1348 - val_accuracy: 0.9879\n",
      "Epoch 2705/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1269 - val_accuracy: 0.9860\n",
      "Epoch 2706/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1286 - val_accuracy: 0.9860\n",
      "Epoch 2707/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.1290 - val_accuracy: 0.9860\n",
      "Epoch 2708/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1283 - val_accuracy: 0.9869\n",
      "Epoch 2709/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1296 - val_accuracy: 0.9860\n",
      "Epoch 2710/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1276 - val_accuracy: 0.9869\n",
      "Epoch 2711/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1342 - val_accuracy: 0.9879\n",
      "Epoch 2712/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1258 - val_accuracy: 0.9869\n",
      "Epoch 2713/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1317 - val_accuracy: 0.9869\n",
      "Epoch 2714/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1278 - val_accuracy: 0.9869\n",
      "Epoch 2715/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1304 - val_accuracy: 0.9879\n",
      "Epoch 2716/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1270 - val_accuracy: 0.9869\n",
      "Epoch 2717/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1329 - val_accuracy: 0.9879\n",
      "Epoch 2718/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.1282 - val_accuracy: 0.9860\n",
      "Epoch 2719/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1295 - val_accuracy: 0.9860\n",
      "Epoch 2720/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1278 - val_accuracy: 0.9869\n",
      "Epoch 2721/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1239 - val_accuracy: 0.9860\n",
      "Epoch 2722/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9954 - val_loss: 0.1442 - val_accuracy: 0.9879\n",
      "Epoch 2723/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.1238 - val_accuracy: 0.9879\n",
      "Epoch 2724/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.1368 - val_accuracy: 0.9879\n",
      "Epoch 2725/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1278 - val_accuracy: 0.9869\n",
      "Epoch 2726/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9972 - val_loss: 0.1333 - val_accuracy: 0.9897\n",
      "Epoch 2727/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1263 - val_accuracy: 0.9869\n",
      "Epoch 2728/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1331 - val_accuracy: 0.9869\n",
      "Epoch 2729/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.1258 - val_accuracy: 0.9869\n",
      "Epoch 2730/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1299 - val_accuracy: 0.9869\n",
      "Epoch 2731/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1274 - val_accuracy: 0.9869\n",
      "Epoch 2732/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1371 - val_accuracy: 0.9888\n",
      "Epoch 2733/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1227 - val_accuracy: 0.9879\n",
      "Epoch 2734/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9954 - val_loss: 0.1350 - val_accuracy: 0.9888\n",
      "Epoch 2735/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.1311 - val_accuracy: 0.9851\n",
      "Epoch 2736/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.1306 - val_accuracy: 0.9879\n",
      "Epoch 2737/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1266 - val_accuracy: 0.9869\n",
      "Epoch 2738/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1454 - val_accuracy: 0.9869\n",
      "Epoch 2739/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9954 - val_loss: 0.1244 - val_accuracy: 0.9879\n",
      "Epoch 2740/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.1475 - val_accuracy: 0.9860\n",
      "Epoch 2741/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.1252 - val_accuracy: 0.9851\n",
      "Epoch 2742/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.1376 - val_accuracy: 0.9888\n",
      "Epoch 2743/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1260 - val_accuracy: 0.9860\n",
      "Epoch 2744/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1286 - val_accuracy: 0.9860\n",
      "Epoch 2745/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1344 - val_accuracy: 0.9879\n",
      "Epoch 2746/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.1331 - val_accuracy: 0.9869\n",
      "Epoch 2747/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1284 - val_accuracy: 0.9860\n",
      "Epoch 2748/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1297 - val_accuracy: 0.9860\n",
      "Epoch 2749/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1330 - val_accuracy: 0.9869\n",
      "Epoch 2750/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1286 - val_accuracy: 0.9860\n",
      "Epoch 2751/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.1311 - val_accuracy: 0.9869\n",
      "Epoch 2752/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1342 - val_accuracy: 0.9869\n",
      "Epoch 2753/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1314 - val_accuracy: 0.9869\n",
      "Epoch 2754/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1318 - val_accuracy: 0.9860\n",
      "Epoch 2755/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1287 - val_accuracy: 0.9879\n",
      "Epoch 2756/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1354 - val_accuracy: 0.9879\n",
      "Epoch 2757/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.1286 - val_accuracy: 0.9860\n",
      "Epoch 2758/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1336 - val_accuracy: 0.9879\n",
      "Epoch 2759/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1323 - val_accuracy: 0.9869\n",
      "Epoch 2760/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1291 - val_accuracy: 0.9879\n",
      "Epoch 2761/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1337 - val_accuracy: 0.9869\n",
      "Epoch 2762/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1280 - val_accuracy: 0.9869\n",
      "Epoch 2763/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1330 - val_accuracy: 0.9869\n",
      "Epoch 2764/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1296 - val_accuracy: 0.9869\n",
      "Epoch 2765/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1359 - val_accuracy: 0.9888\n",
      "Epoch 2766/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1259 - val_accuracy: 0.9869\n",
      "Epoch 2767/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1371 - val_accuracy: 0.9897\n",
      "Epoch 2768/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1284 - val_accuracy: 0.9869\n",
      "Epoch 2769/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1384 - val_accuracy: 0.9888\n",
      "Epoch 2770/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1283 - val_accuracy: 0.9869\n",
      "Epoch 2771/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1358 - val_accuracy: 0.9869\n",
      "Epoch 2772/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1285 - val_accuracy: 0.9869\n",
      "Epoch 2773/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1351 - val_accuracy: 0.9897\n",
      "Epoch 2774/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1281 - val_accuracy: 0.9860\n",
      "Epoch 2775/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1397 - val_accuracy: 0.9888\n",
      "Epoch 2776/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1282 - val_accuracy: 0.9860\n",
      "Epoch 2777/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1345 - val_accuracy: 0.9879\n",
      "Epoch 2778/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1294 - val_accuracy: 0.9869\n",
      "Epoch 2779/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1369 - val_accuracy: 0.9879\n",
      "Epoch 2780/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1285 - val_accuracy: 0.9869\n",
      "Epoch 2781/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1371 - val_accuracy: 0.9888\n",
      "Epoch 2782/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1316 - val_accuracy: 0.9851\n",
      "Epoch 2783/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1379 - val_accuracy: 0.9879\n",
      "Epoch 2784/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1259 - val_accuracy: 0.9869\n",
      "Epoch 2785/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.1334 - val_accuracy: 0.9888\n",
      "Epoch 2786/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1362 - val_accuracy: 0.9851\n",
      "Epoch 2787/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1376 - val_accuracy: 0.9869\n",
      "Epoch 2788/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1275 - val_accuracy: 0.9869\n",
      "Epoch 2789/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1363 - val_accuracy: 0.9869\n",
      "Epoch 2790/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1300 - val_accuracy: 0.9860\n",
      "Epoch 2791/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1348 - val_accuracy: 0.9879\n",
      "Epoch 2792/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1320 - val_accuracy: 0.9851\n",
      "Epoch 2793/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1463 - val_accuracy: 0.9879\n",
      "Epoch 2794/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.1311 - val_accuracy: 0.9869\n",
      "Epoch 2795/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1387 - val_accuracy: 0.9888\n",
      "Epoch 2796/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1299 - val_accuracy: 0.9869\n",
      "Epoch 2797/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1382 - val_accuracy: 0.9888\n",
      "Epoch 2798/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9972 - val_loss: 0.1322 - val_accuracy: 0.9851\n",
      "Epoch 2799/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1375 - val_accuracy: 0.9888\n",
      "Epoch 2800/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1310 - val_accuracy: 0.9869\n",
      "Epoch 2801/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1334 - val_accuracy: 0.9860\n",
      "Epoch 2802/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1336 - val_accuracy: 0.9860\n",
      "Epoch 2803/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1316 - val_accuracy: 0.9869\n",
      "Epoch 2804/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9959 - val_loss: 0.1481 - val_accuracy: 0.9879\n",
      "Epoch 2805/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1284 - val_accuracy: 0.9869\n",
      "Epoch 2806/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1328 - val_accuracy: 0.9879\n",
      "Epoch 2807/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1322 - val_accuracy: 0.9869\n",
      "Epoch 2808/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1413 - val_accuracy: 0.9879\n",
      "Epoch 2809/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.1272 - val_accuracy: 0.9860\n",
      "Epoch 2810/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.1360 - val_accuracy: 0.9897\n",
      "Epoch 2811/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1275 - val_accuracy: 0.9860\n",
      "Epoch 2812/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.1501 - val_accuracy: 0.9888\n",
      "Epoch 2813/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1299 - val_accuracy: 0.9851\n",
      "Epoch 2814/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9954 - val_loss: 0.1407 - val_accuracy: 0.9897\n",
      "Epoch 2815/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1377 - val_accuracy: 0.9841\n",
      "Epoch 2816/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1377 - val_accuracy: 0.9888\n",
      "Epoch 2817/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1292 - val_accuracy: 0.9869\n",
      "Epoch 2818/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1370 - val_accuracy: 0.9869\n",
      "Epoch 2819/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1321 - val_accuracy: 0.9860\n",
      "Epoch 2820/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1360 - val_accuracy: 0.9879\n",
      "Epoch 2821/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1357 - val_accuracy: 0.9841\n",
      "Epoch 2822/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1328 - val_accuracy: 0.9879\n",
      "Epoch 2823/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1328 - val_accuracy: 0.9860\n",
      "Epoch 2824/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1374 - val_accuracy: 0.9860\n",
      "Epoch 2825/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1330 - val_accuracy: 0.9860\n",
      "Epoch 2826/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1385 - val_accuracy: 0.9879\n",
      "Epoch 2827/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.1326 - val_accuracy: 0.9860\n",
      "Epoch 2828/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1383 - val_accuracy: 0.9888\n",
      "Epoch 2829/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1283 - val_accuracy: 0.9860\n",
      "Epoch 2830/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 0.1496 - val_accuracy: 0.9879\n",
      "Epoch 2831/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.1351 - val_accuracy: 0.9860\n",
      "Epoch 2832/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1310 - val_accuracy: 0.9860\n",
      "Epoch 2833/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1324 - val_accuracy: 0.9869\n",
      "Epoch 2834/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.1339 - val_accuracy: 0.9860\n",
      "Epoch 2835/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1379 - val_accuracy: 0.9869\n",
      "Epoch 2836/3500\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.99 - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1316 - val_accuracy: 0.9869\n",
      "Epoch 2837/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1314 - val_accuracy: 0.9869\n",
      "Epoch 2838/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.1516 - val_accuracy: 0.9869\n",
      "Epoch 2839/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.1291 - val_accuracy: 0.9869\n",
      "Epoch 2840/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1348 - val_accuracy: 0.9860\n",
      "Epoch 2841/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1365 - val_accuracy: 0.9869\n",
      "Epoch 2842/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1363 - val_accuracy: 0.9869\n",
      "Epoch 2843/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1386 - val_accuracy: 0.9869\n",
      "Epoch 2844/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1279 - val_accuracy: 0.9879\n",
      "Epoch 2845/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.1339 - val_accuracy: 0.9879\n",
      "Epoch 2846/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.1454 - val_accuracy: 0.9888\n",
      "Epoch 2847/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 0.1341 - val_accuracy: 0.9869\n",
      "Epoch 2848/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.1336 - val_accuracy: 0.9860\n",
      "Epoch 2849/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1324 - val_accuracy: 0.9879\n",
      "Epoch 2850/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.1469 - val_accuracy: 0.9879\n",
      "Epoch 2851/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1318 - val_accuracy: 0.9869\n",
      "Epoch 2852/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1337 - val_accuracy: 0.9879\n",
      "Epoch 2853/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1333 - val_accuracy: 0.9869\n",
      "Epoch 2854/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1369 - val_accuracy: 0.9860\n",
      "Epoch 2855/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.1531 - val_accuracy: 0.9869\n",
      "Epoch 2856/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.1290 - val_accuracy: 0.9869\n",
      "Epoch 2857/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1380 - val_accuracy: 0.9869\n",
      "Epoch 2858/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1332 - val_accuracy: 0.9869\n",
      "Epoch 2859/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1393 - val_accuracy: 0.9879\n",
      "Epoch 2860/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1370 - val_accuracy: 0.9841\n",
      "Epoch 2861/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.1295 - val_accuracy: 0.9860\n",
      "Epoch 2862/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.1395 - val_accuracy: 0.9888\n",
      "Epoch 2863/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.1394 - val_accuracy: 0.9869\n",
      "Epoch 2864/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1318 - val_accuracy: 0.9869\n",
      "Epoch 2865/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.1396 - val_accuracy: 0.9888\n",
      "Epoch 2866/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1373 - val_accuracy: 0.9851\n",
      "Epoch 2867/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1404 - val_accuracy: 0.9879\n",
      "Epoch 2868/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1346 - val_accuracy: 0.9879\n",
      "Epoch 2869/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.1423 - val_accuracy: 0.9888\n",
      "Epoch 2870/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1359 - val_accuracy: 0.9860\n",
      "Epoch 2871/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1322 - val_accuracy: 0.9879\n",
      "Epoch 2872/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1330 - val_accuracy: 0.9869\n",
      "Epoch 2873/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1423 - val_accuracy: 0.9869\n",
      "Epoch 2874/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1313 - val_accuracy: 0.9869\n",
      "Epoch 2875/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1336 - val_accuracy: 0.9860\n",
      "Epoch 2876/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1365 - val_accuracy: 0.9860\n",
      "Epoch 2877/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1331 - val_accuracy: 0.9869\n",
      "Epoch 2878/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1409 - val_accuracy: 0.9869\n",
      "Epoch 2879/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1336 - val_accuracy: 0.9869\n",
      "Epoch 2880/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1367 - val_accuracy: 0.9860\n",
      "Epoch 2881/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1385 - val_accuracy: 0.9860\n",
      "Epoch 2882/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1341 - val_accuracy: 0.9860\n",
      "Epoch 2883/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1397 - val_accuracy: 0.9879\n",
      "Epoch 2884/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1341 - val_accuracy: 0.9869\n",
      "Epoch 2885/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1467 - val_accuracy: 0.9888\n",
      "Epoch 2886/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.1330 - val_accuracy: 0.9869\n",
      "Epoch 2887/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9972 - val_loss: 0.1405 - val_accuracy: 0.9879\n",
      "Epoch 2888/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.1353 - val_accuracy: 0.9832\n",
      "Epoch 2889/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9940 - val_loss: 0.1412 - val_accuracy: 0.9897\n",
      "Epoch 2890/3500\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.1370 - val_accuracy: 0.9860\n",
      "Epoch 2891/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.1340 - val_accuracy: 0.9869\n",
      "Epoch 2892/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9954 - val_loss: 0.1392 - val_accuracy: 0.9897\n",
      "Epoch 2893/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.1386 - val_accuracy: 0.9841\n",
      "Epoch 2894/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 0.1397 - val_accuracy: 0.9860\n",
      "Epoch 2895/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.1295 - val_accuracy: 0.9879\n",
      "Epoch 2896/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.1374 - val_accuracy: 0.9860\n",
      "Epoch 2897/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1398 - val_accuracy: 0.9851\n",
      "Epoch 2898/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1330 - val_accuracy: 0.9869\n",
      "Epoch 2899/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1366 - val_accuracy: 0.9851\n",
      "Epoch 2900/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.1408 - val_accuracy: 0.9879\n",
      "Epoch 2901/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.1364 - val_accuracy: 0.9869\n",
      "Epoch 2902/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.1418 - val_accuracy: 0.9869\n",
      "Epoch 2903/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1334 - val_accuracy: 0.9860\n",
      "Epoch 2904/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1413 - val_accuracy: 0.9869\n",
      "Epoch 2905/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1330 - val_accuracy: 0.9869\n",
      "Epoch 2906/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.1431 - val_accuracy: 0.9879\n",
      "Epoch 2907/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1396 - val_accuracy: 0.9869\n",
      "Epoch 2908/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1384 - val_accuracy: 0.9860\n",
      "Epoch 2909/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1384 - val_accuracy: 0.9860\n",
      "Epoch 2910/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1321 - val_accuracy: 0.9869\n",
      "Epoch 2911/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.1441 - val_accuracy: 0.9888\n",
      "Epoch 2912/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1380 - val_accuracy: 0.9860\n",
      "Epoch 2913/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1456 - val_accuracy: 0.9897\n",
      "Epoch 2914/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.1354 - val_accuracy: 0.9869\n",
      "Epoch 2915/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1368 - val_accuracy: 0.9860\n",
      "Epoch 2916/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1493 - val_accuracy: 0.9888\n",
      "Epoch 2917/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.1347 - val_accuracy: 0.9860\n",
      "Epoch 2918/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.1412 - val_accuracy: 0.9888\n",
      "Epoch 2919/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.1495 - val_accuracy: 0.9841\n",
      "Epoch 2920/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1340 - val_accuracy: 0.9860\n",
      "Epoch 2921/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9931 - val_loss: 0.1568 - val_accuracy: 0.9888\n",
      "Epoch 2922/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.1432 - val_accuracy: 0.9851\n",
      "Epoch 2923/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.1484 - val_accuracy: 0.9860\n",
      "Epoch 2924/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.1425 - val_accuracy: 0.9888\n",
      "Epoch 2925/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.1336 - val_accuracy: 0.9851\n",
      "Epoch 2926/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9917 - val_loss: 0.1883 - val_accuracy: 0.9841\n",
      "Epoch 2927/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.1454 - val_accuracy: 0.9785\n",
      "Epoch 2928/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9936 - val_loss: 0.1561 - val_accuracy: 0.9888\n",
      "Epoch 2929/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.1409 - val_accuracy: 0.9851\n",
      "Epoch 2930/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.1524 - val_accuracy: 0.9879\n",
      "Epoch 2931/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1298 - val_accuracy: 0.9860\n",
      "Epoch 2932/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.1367 - val_accuracy: 0.9869\n",
      "Epoch 2933/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1393 - val_accuracy: 0.9851\n",
      "Epoch 2934/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.1399 - val_accuracy: 0.9860\n",
      "Epoch 2935/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1386 - val_accuracy: 0.9860\n",
      "Epoch 2936/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1397 - val_accuracy: 0.9860\n",
      "Epoch 2937/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1395 - val_accuracy: 0.9860\n",
      "Epoch 2938/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1439 - val_accuracy: 0.9869\n",
      "Epoch 2939/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1390 - val_accuracy: 0.9851\n",
      "Epoch 2940/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.1660 - val_accuracy: 0.9851\n",
      "Epoch 2941/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.1299 - val_accuracy: 0.9879\n",
      "Epoch 2942/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.1413 - val_accuracy: 0.9888\n",
      "Epoch 2943/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9972 - val_loss: 0.1524 - val_accuracy: 0.9841\n",
      "Epoch 2944/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9959 - val_loss: 0.1644 - val_accuracy: 0.9879\n",
      "Epoch 2945/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1415 - val_accuracy: 0.9823\n",
      "Epoch 2946/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.1920 - val_accuracy: 0.9841\n",
      "Epoch 2947/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.1370 - val_accuracy: 0.9841\n",
      "Epoch 2948/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1511 - val_accuracy: 0.9869\n",
      "Epoch 2949/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.1377 - val_accuracy: 0.9841\n",
      "Epoch 2950/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1631 - val_accuracy: 0.9860\n",
      "Epoch 2951/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.1378 - val_accuracy: 0.9869\n",
      "Epoch 2952/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1375 - val_accuracy: 0.9879\n",
      "Epoch 2953/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1335 - val_accuracy: 0.9860\n",
      "Epoch 2954/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9972 - val_loss: 0.1391 - val_accuracy: 0.9860\n",
      "Epoch 2955/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1436 - val_accuracy: 0.9860\n",
      "Epoch 2956/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1377 - val_accuracy: 0.9860\n",
      "Epoch 2957/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1404 - val_accuracy: 0.9869\n",
      "Epoch 2958/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1372 - val_accuracy: 0.9860\n",
      "Epoch 2959/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1395 - val_accuracy: 0.9869\n",
      "Epoch 2960/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1365 - val_accuracy: 0.9860\n",
      "Epoch 2961/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1353 - val_accuracy: 0.9869\n",
      "Epoch 2962/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1395 - val_accuracy: 0.9869\n",
      "Epoch 2963/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1471 - val_accuracy: 0.9841\n",
      "Epoch 2964/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1357 - val_accuracy: 0.9869\n",
      "Epoch 2965/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9954 - val_loss: 0.1454 - val_accuracy: 0.9888\n",
      "Epoch 2966/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.1411 - val_accuracy: 0.9851\n",
      "Epoch 2967/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.1492 - val_accuracy: 0.9888\n",
      "Epoch 2968/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1271 - val_accuracy: 0.9869\n",
      "Epoch 2969/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.1429 - val_accuracy: 0.9888\n",
      "Epoch 2970/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.1392 - val_accuracy: 0.9851\n",
      "Epoch 2971/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.1623 - val_accuracy: 0.9851\n",
      "Epoch 2972/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9954 - val_loss: 0.1309 - val_accuracy: 0.9860\n",
      "Epoch 2973/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9945 - val_loss: 0.1574 - val_accuracy: 0.9888\n",
      "Epoch 2974/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.1399 - val_accuracy: 0.9860\n",
      "Epoch 2975/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1555 - val_accuracy: 0.9869\n",
      "Epoch 2976/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1315 - val_accuracy: 0.9869\n",
      "Epoch 2977/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1433 - val_accuracy: 0.9879\n",
      "Epoch 2978/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1373 - val_accuracy: 0.9860\n",
      "Epoch 2979/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1409 - val_accuracy: 0.9869\n",
      "Epoch 2980/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1379 - val_accuracy: 0.9869\n",
      "Epoch 2981/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1439 - val_accuracy: 0.9879\n",
      "Epoch 2982/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1423 - val_accuracy: 0.9860\n",
      "Epoch 2983/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1352 - val_accuracy: 0.9860\n",
      "Epoch 2984/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1398 - val_accuracy: 0.9860\n",
      "Epoch 2985/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1449 - val_accuracy: 0.9869\n",
      "Epoch 2986/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1432 - val_accuracy: 0.9869\n",
      "Epoch 2987/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1431 - val_accuracy: 0.9869\n",
      "Epoch 2988/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1400 - val_accuracy: 0.9860\n",
      "Epoch 2989/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1401 - val_accuracy: 0.9860\n",
      "Epoch 2990/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1397 - val_accuracy: 0.9860\n",
      "Epoch 2991/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1432 - val_accuracy: 0.9869\n",
      "Epoch 2992/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1373 - val_accuracy: 0.9860\n",
      "Epoch 2993/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1448 - val_accuracy: 0.9879\n",
      "Epoch 2994/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1418 - val_accuracy: 0.9860\n",
      "Epoch 2995/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1430 - val_accuracy: 0.9860\n",
      "Epoch 2996/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1387 - val_accuracy: 0.9860\n",
      "Epoch 2997/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1428 - val_accuracy: 0.9869\n",
      "Epoch 2998/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1375 - val_accuracy: 0.9869\n",
      "Epoch 2999/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1425 - val_accuracy: 0.9869\n",
      "Epoch 3000/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1491 - val_accuracy: 0.9879\n",
      "Epoch 3001/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1352 - val_accuracy: 0.9888\n",
      "Epoch 3002/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1356 - val_accuracy: 0.9869\n",
      "Epoch 3003/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.1480 - val_accuracy: 0.9879\n",
      "Epoch 3004/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.1385 - val_accuracy: 0.9832\n",
      "Epoch 3005/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9917 - val_loss: 0.2059 - val_accuracy: 0.9795\n",
      "Epoch 3006/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.1715 - val_accuracy: 0.9720\n",
      "Epoch 3007/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9908 - val_loss: 0.1785 - val_accuracy: 0.9851\n",
      "Epoch 3008/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.1471 - val_accuracy: 0.9888\n",
      "Epoch 3009/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9913 - val_loss: 0.1521 - val_accuracy: 0.9879\n",
      "Epoch 3010/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9940 - val_loss: 0.1587 - val_accuracy: 0.9860\n",
      "Epoch 3011/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1455 - val_accuracy: 0.9869\n",
      "Epoch 3012/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9949 - val_loss: 0.1371 - val_accuracy: 0.9888\n",
      "Epoch 3013/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.1460 - val_accuracy: 0.9879\n",
      "Epoch 3014/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1402 - val_accuracy: 0.9841\n",
      "Epoch 3015/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.1460 - val_accuracy: 0.9888\n",
      "Epoch 3016/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.1393 - val_accuracy: 0.9860\n",
      "Epoch 3017/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1495 - val_accuracy: 0.9888\n",
      "Epoch 3018/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.1386 - val_accuracy: 0.9869\n",
      "Epoch 3019/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1437 - val_accuracy: 0.9869\n",
      "Epoch 3020/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1424 - val_accuracy: 0.9860\n",
      "Epoch 3021/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1415 - val_accuracy: 0.9869\n",
      "Epoch 3022/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1376 - val_accuracy: 0.9860\n",
      "Epoch 3023/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1423 - val_accuracy: 0.9869\n",
      "Epoch 3024/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1400 - val_accuracy: 0.9860\n",
      "Epoch 3025/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1393 - val_accuracy: 0.9860\n",
      "Epoch 3026/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1413 - val_accuracy: 0.9860\n",
      "Epoch 3027/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1422 - val_accuracy: 0.9851\n",
      "Epoch 3028/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1453 - val_accuracy: 0.9869\n",
      "Epoch 3029/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1364 - val_accuracy: 0.9860\n",
      "Epoch 3030/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1398 - val_accuracy: 0.9860\n",
      "Epoch 3031/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1452 - val_accuracy: 0.9841\n",
      "Epoch 3032/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1439 - val_accuracy: 0.9869\n",
      "Epoch 3033/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.1382 - val_accuracy: 0.9860\n",
      "Epoch 3034/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1420 - val_accuracy: 0.9860\n",
      "Epoch 3035/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1424 - val_accuracy: 0.9860\n",
      "Epoch 3036/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1428 - val_accuracy: 0.9869\n",
      "Epoch 3037/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1401 - val_accuracy: 0.9860\n",
      "Epoch 3038/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1402 - val_accuracy: 0.9860\n",
      "Epoch 3039/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1414 - val_accuracy: 0.9860\n",
      "Epoch 3040/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1363 - val_accuracy: 0.9860\n",
      "Epoch 3041/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1428 - val_accuracy: 0.9869\n",
      "Epoch 3042/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1407 - val_accuracy: 0.9860\n",
      "Epoch 3043/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1427 - val_accuracy: 0.9869\n",
      "Epoch 3044/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1422 - val_accuracy: 0.9860\n",
      "Epoch 3045/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1362 - val_accuracy: 0.9869\n",
      "Epoch 3046/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1481 - val_accuracy: 0.9907\n",
      "Epoch 3047/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9954 - val_loss: 0.1364 - val_accuracy: 0.9869\n",
      "Epoch 3048/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.1520 - val_accuracy: 0.9907\n",
      "Epoch 3049/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.1428 - val_accuracy: 0.9851\n",
      "Epoch 3050/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.1428 - val_accuracy: 0.9869\n",
      "Epoch 3051/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9949 - val_loss: 0.1390 - val_accuracy: 0.9897\n",
      "Epoch 3052/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1397 - val_accuracy: 0.9860\n",
      "Epoch 3053/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9972 - val_loss: 0.1458 - val_accuracy: 0.9851\n",
      "Epoch 3054/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1408 - val_accuracy: 0.9860\n",
      "Epoch 3055/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1467 - val_accuracy: 0.9907\n",
      "Epoch 3056/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.1344 - val_accuracy: 0.9879\n",
      "Epoch 3057/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.1640 - val_accuracy: 0.9879\n",
      "Epoch 3058/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.1342 - val_accuracy: 0.9851\n",
      "Epoch 3059/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9959 - val_loss: 0.1618 - val_accuracy: 0.9869\n",
      "Epoch 3060/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.1391 - val_accuracy: 0.9860\n",
      "Epoch 3061/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9949 - val_loss: 0.1681 - val_accuracy: 0.9869\n",
      "Epoch 3062/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.1362 - val_accuracy: 0.9869\n",
      "Epoch 3063/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.1564 - val_accuracy: 0.9879\n",
      "Epoch 3064/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1376 - val_accuracy: 0.9869\n",
      "Epoch 3065/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1422 - val_accuracy: 0.9869\n",
      "Epoch 3066/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1445 - val_accuracy: 0.9841\n",
      "Epoch 3067/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.1466 - val_accuracy: 0.9879\n",
      "Epoch 3068/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1352 - val_accuracy: 0.9879\n",
      "Epoch 3069/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1442 - val_accuracy: 0.9888\n",
      "Epoch 3070/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1389 - val_accuracy: 0.9869\n",
      "Epoch 3071/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1447 - val_accuracy: 0.9869\n",
      "Epoch 3072/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1411 - val_accuracy: 0.9869\n",
      "Epoch 3073/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1424 - val_accuracy: 0.9869\n",
      "Epoch 3074/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1457 - val_accuracy: 0.9860\n",
      "Epoch 3075/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1399 - val_accuracy: 0.9860\n",
      "Epoch 3076/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1446 - val_accuracy: 0.9879\n",
      "Epoch 3077/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1421 - val_accuracy: 0.9860\n",
      "Epoch 3078/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1567 - val_accuracy: 0.9888\n",
      "Epoch 3079/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.1355 - val_accuracy: 0.9851\n",
      "Epoch 3080/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9940 - val_loss: 0.1772 - val_accuracy: 0.9860\n",
      "Epoch 3081/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9913 - val_loss: 0.1701 - val_accuracy: 0.9739\n",
      "Epoch 3082/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9917 - val_loss: 0.1976 - val_accuracy: 0.9823\n",
      "Epoch 3083/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 0.1518 - val_accuracy: 0.9823\n",
      "Epoch 3084/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.1742 - val_accuracy: 0.9860\n",
      "Epoch 3085/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.1331 - val_accuracy: 0.9832\n",
      "Epoch 3086/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9949 - val_loss: 0.1486 - val_accuracy: 0.9888\n",
      "Epoch 3087/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 0.1342 - val_accuracy: 0.9869\n",
      "Epoch 3088/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.1489 - val_accuracy: 0.9879\n",
      "Epoch 3089/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1442 - val_accuracy: 0.9869\n",
      "Epoch 3090/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1403 - val_accuracy: 0.9860\n",
      "Epoch 3091/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1450 - val_accuracy: 0.9869\n",
      "Epoch 3092/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1427 - val_accuracy: 0.9860\n",
      "Epoch 3093/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1450 - val_accuracy: 0.9860\n",
      "Epoch 3094/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1444 - val_accuracy: 0.9860\n",
      "Epoch 3095/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1463 - val_accuracy: 0.9860\n",
      "Epoch 3096/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1441 - val_accuracy: 0.9860\n",
      "Epoch 3097/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1441 - val_accuracy: 0.9860\n",
      "Epoch 3098/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1422 - val_accuracy: 0.9860\n",
      "Epoch 3099/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1466 - val_accuracy: 0.9869\n",
      "Epoch 3100/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1421 - val_accuracy: 0.9860\n",
      "Epoch 3101/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1474 - val_accuracy: 0.9879\n",
      "Epoch 3102/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1392 - val_accuracy: 0.9860\n",
      "Epoch 3103/3500\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.99 - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1473 - val_accuracy: 0.9869\n",
      "Epoch 3104/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1460 - val_accuracy: 0.9860\n",
      "Epoch 3105/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1426 - val_accuracy: 0.9860\n",
      "Epoch 3106/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1448 - val_accuracy: 0.9860\n",
      "Epoch 3107/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.1456 - val_accuracy: 0.9860\n",
      "Epoch 3108/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1435 - val_accuracy: 0.9860\n",
      "Epoch 3109/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1497 - val_accuracy: 0.9879\n",
      "Epoch 3110/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1410 - val_accuracy: 0.9851\n",
      "Epoch 3111/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1510 - val_accuracy: 0.9888\n",
      "Epoch 3112/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1383 - val_accuracy: 0.9860\n",
      "Epoch 3113/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9931 - val_loss: 0.1484 - val_accuracy: 0.9897\n",
      "Epoch 3114/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.1490 - val_accuracy: 0.9851\n",
      "Epoch 3115/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9968 - val_loss: 0.1478 - val_accuracy: 0.9879\n",
      "Epoch 3116/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1386 - val_accuracy: 0.9860\n",
      "Epoch 3117/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1431 - val_accuracy: 0.9869\n",
      "Epoch 3118/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1423 - val_accuracy: 0.9860\n",
      "Epoch 3119/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1452 - val_accuracy: 0.9869\n",
      "Epoch 3120/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1432 - val_accuracy: 0.9869\n",
      "Epoch 3121/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1405 - val_accuracy: 0.9860\n",
      "Epoch 3122/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.1394 - val_accuracy: 0.9897\n",
      "Epoch 3123/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.1455 - val_accuracy: 0.9860\n",
      "Epoch 3124/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1482 - val_accuracy: 0.9851\n",
      "Epoch 3125/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1413 - val_accuracy: 0.9860\n",
      "Epoch 3126/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1416 - val_accuracy: 0.9888\n",
      "Epoch 3127/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1473 - val_accuracy: 0.9869\n",
      "Epoch 3128/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1499 - val_accuracy: 0.9860\n",
      "Epoch 3129/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1450 - val_accuracy: 0.9869\n",
      "Epoch 3130/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1406 - val_accuracy: 0.9879\n",
      "Epoch 3131/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 0.1593 - val_accuracy: 0.9869\n",
      "Epoch 3132/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1413 - val_accuracy: 0.9869\n",
      "Epoch 3133/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.1405 - val_accuracy: 0.9860\n",
      "Epoch 3134/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.1470 - val_accuracy: 0.9869\n",
      "Epoch 3135/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1438 - val_accuracy: 0.9869\n",
      "Epoch 3136/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1439 - val_accuracy: 0.9869\n",
      "Epoch 3137/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1503 - val_accuracy: 0.9860\n",
      "Epoch 3138/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9972 - val_loss: 0.1407 - val_accuracy: 0.9860\n",
      "Epoch 3139/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1437 - val_accuracy: 0.9888\n",
      "Epoch 3140/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1419 - val_accuracy: 0.9860\n",
      "Epoch 3141/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1653 - val_accuracy: 0.9860\n",
      "Epoch 3142/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.1373 - val_accuracy: 0.9869\n",
      "Epoch 3143/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9963 - val_loss: 0.1496 - val_accuracy: 0.9897\n",
      "Epoch 3144/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1457 - val_accuracy: 0.9869\n",
      "Epoch 3145/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1467 - val_accuracy: 0.9860\n",
      "Epoch 3146/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1455 - val_accuracy: 0.9860\n",
      "Epoch 3147/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1428 - val_accuracy: 0.9879\n",
      "Epoch 3148/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9972 - val_loss: 0.1457 - val_accuracy: 0.9869\n",
      "Epoch 3149/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1432 - val_accuracy: 0.9860\n",
      "Epoch 3150/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1432 - val_accuracy: 0.9860\n",
      "Epoch 3151/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1465 - val_accuracy: 0.9860\n",
      "Epoch 3152/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1440 - val_accuracy: 0.9869\n",
      "Epoch 3153/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1457 - val_accuracy: 0.9869\n",
      "Epoch 3154/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1421 - val_accuracy: 0.9860\n",
      "Epoch 3155/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1409 - val_accuracy: 0.9860\n",
      "Epoch 3156/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1498 - val_accuracy: 0.9869\n",
      "Epoch 3157/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1448 - val_accuracy: 0.9860\n",
      "Epoch 3158/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1425 - val_accuracy: 0.9860\n",
      "Epoch 3159/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1450 - val_accuracy: 0.9860\n",
      "Epoch 3160/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1464 - val_accuracy: 0.9860\n",
      "Epoch 3161/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1468 - val_accuracy: 0.9869\n",
      "Epoch 3162/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1455 - val_accuracy: 0.9860\n",
      "Epoch 3163/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1437 - val_accuracy: 0.9860\n",
      "Epoch 3164/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1446 - val_accuracy: 0.9860\n",
      "Epoch 3165/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1466 - val_accuracy: 0.9869\n",
      "Epoch 3166/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1463 - val_accuracy: 0.9869\n",
      "Epoch 3167/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1451 - val_accuracy: 0.9860\n",
      "Epoch 3168/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1441 - val_accuracy: 0.9860\n",
      "Epoch 3169/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1453 - val_accuracy: 0.9860\n",
      "Epoch 3170/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1419 - val_accuracy: 0.9869\n",
      "Epoch 3171/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1454 - val_accuracy: 0.9860\n",
      "Epoch 3172/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1467 - val_accuracy: 0.9860\n",
      "Epoch 3173/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1415 - val_accuracy: 0.9869\n",
      "Epoch 3174/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.1464 - val_accuracy: 0.9879\n",
      "Epoch 3175/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1459 - val_accuracy: 0.9860\n",
      "Epoch 3176/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1438 - val_accuracy: 0.9860\n",
      "Epoch 3177/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.1481 - val_accuracy: 0.9888\n",
      "Epoch 3178/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1454 - val_accuracy: 0.9860\n",
      "Epoch 3179/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1525 - val_accuracy: 0.9869\n",
      "Epoch 3180/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1433 - val_accuracy: 0.9860\n",
      "Epoch 3181/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1599 - val_accuracy: 0.9879\n",
      "Epoch 3182/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.1385 - val_accuracy: 0.9879\n",
      "Epoch 3183/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1478 - val_accuracy: 0.9888\n",
      "Epoch 3184/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1500 - val_accuracy: 0.9841\n",
      "Epoch 3185/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1507 - val_accuracy: 0.9897\n",
      "Epoch 3186/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1389 - val_accuracy: 0.9888\n",
      "Epoch 3187/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1506 - val_accuracy: 0.9869\n",
      "Epoch 3188/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1418 - val_accuracy: 0.9860\n",
      "Epoch 3189/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1477 - val_accuracy: 0.9888\n",
      "Epoch 3190/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1440 - val_accuracy: 0.9860\n",
      "Epoch 3191/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1468 - val_accuracy: 0.9860\n",
      "Epoch 3192/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1453 - val_accuracy: 0.9860\n",
      "Epoch 3193/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1464 - val_accuracy: 0.9860\n",
      "Epoch 3194/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1472 - val_accuracy: 0.9860\n",
      "Epoch 3195/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1440 - val_accuracy: 0.9860\n",
      "Epoch 3196/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1487 - val_accuracy: 0.9888\n",
      "Epoch 3197/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.1424 - val_accuracy: 0.9860\n",
      "Epoch 3198/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1486 - val_accuracy: 0.9860\n",
      "Epoch 3199/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1478 - val_accuracy: 0.9879\n",
      "Epoch 3200/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1478 - val_accuracy: 0.9860\n",
      "Epoch 3201/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1466 - val_accuracy: 0.9869\n",
      "Epoch 3202/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1413 - val_accuracy: 0.9869\n",
      "Epoch 3203/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1469 - val_accuracy: 0.9860\n",
      "Epoch 3204/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1515 - val_accuracy: 0.9860\n",
      "Epoch 3205/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1524 - val_accuracy: 0.9888\n",
      "Epoch 3206/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9972 - val_loss: 0.1437 - val_accuracy: 0.9860\n",
      "Epoch 3207/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1484 - val_accuracy: 0.9860\n",
      "Epoch 3208/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1488 - val_accuracy: 0.9879\n",
      "Epoch 3209/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1480 - val_accuracy: 0.9860\n",
      "Epoch 3210/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1461 - val_accuracy: 0.9860\n",
      "Epoch 3211/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1483 - val_accuracy: 0.9860\n",
      "Epoch 3212/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1457 - val_accuracy: 0.9860\n",
      "Epoch 3213/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1481 - val_accuracy: 0.9869\n",
      "Epoch 3214/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1469 - val_accuracy: 0.9841\n",
      "Epoch 3215/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.1596 - val_accuracy: 0.9897\n",
      "Epoch 3216/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1367 - val_accuracy: 0.9869\n",
      "Epoch 3217/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9949 - val_loss: 0.1800 - val_accuracy: 0.9879\n",
      "Epoch 3218/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9922 - val_loss: 0.1507 - val_accuracy: 0.9888\n",
      "Epoch 3219/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.1446 - val_accuracy: 0.9860\n",
      "Epoch 3220/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.1591 - val_accuracy: 0.9860\n",
      "Epoch 3221/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.1518 - val_accuracy: 0.9851\n",
      "Epoch 3222/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1461 - val_accuracy: 0.9888\n",
      "Epoch 3223/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1471 - val_accuracy: 0.9888\n",
      "Epoch 3224/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1506 - val_accuracy: 0.9869\n",
      "Epoch 3225/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1488 - val_accuracy: 0.9869\n",
      "Epoch 3226/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.1479 - val_accuracy: 0.9879\n",
      "Epoch 3227/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1451 - val_accuracy: 0.9869\n",
      "Epoch 3228/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1517 - val_accuracy: 0.9869\n",
      "Epoch 3229/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1416 - val_accuracy: 0.9869\n",
      "Epoch 3230/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.1492 - val_accuracy: 0.9888\n",
      "Epoch 3231/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.1502 - val_accuracy: 0.9860\n",
      "Epoch 3232/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1471 - val_accuracy: 0.9860\n",
      "Epoch 3233/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1484 - val_accuracy: 0.9869\n",
      "Epoch 3234/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1493 - val_accuracy: 0.9869\n",
      "Epoch 3235/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1501 - val_accuracy: 0.9860\n",
      "Epoch 3236/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9977 - val_loss: 0.1449 - val_accuracy: 0.9860\n",
      "Epoch 3237/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1474 - val_accuracy: 0.9869\n",
      "Epoch 3238/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1479 - val_accuracy: 0.9860\n",
      "Epoch 3239/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1509 - val_accuracy: 0.9869\n",
      "Epoch 3240/3500\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.99 - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1433 - val_accuracy: 0.9860\n",
      "Epoch 3241/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1496 - val_accuracy: 0.9869\n",
      "Epoch 3242/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1544 - val_accuracy: 0.9841\n",
      "Epoch 3243/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1456 - val_accuracy: 0.9860\n",
      "Epoch 3244/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1468 - val_accuracy: 0.9879\n",
      "Epoch 3245/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1476 - val_accuracy: 0.9860\n",
      "Epoch 3246/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1511 - val_accuracy: 0.9860\n",
      "Epoch 3247/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1482 - val_accuracy: 0.9860\n",
      "Epoch 3248/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1492 - val_accuracy: 0.9869\n",
      "Epoch 3249/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1497 - val_accuracy: 0.9869\n",
      "Epoch 3250/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1457 - val_accuracy: 0.9860\n",
      "Epoch 3251/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1486 - val_accuracy: 0.9860\n",
      "Epoch 3252/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1462 - val_accuracy: 0.9860\n",
      "Epoch 3253/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1552 - val_accuracy: 0.9879\n",
      "Epoch 3254/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1405 - val_accuracy: 0.9879\n",
      "Epoch 3255/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.1593 - val_accuracy: 0.9897\n",
      "Epoch 3256/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1475 - val_accuracy: 0.9851\n",
      "Epoch 3257/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1629 - val_accuracy: 0.9897\n",
      "Epoch 3258/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9972 - val_loss: 0.1427 - val_accuracy: 0.9879\n",
      "Epoch 3259/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1516 - val_accuracy: 0.9869\n",
      "Epoch 3260/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1438 - val_accuracy: 0.9860\n",
      "Epoch 3261/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1535 - val_accuracy: 0.9888\n",
      "Epoch 3262/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1431 - val_accuracy: 0.9860\n",
      "Epoch 3263/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1499 - val_accuracy: 0.9860\n",
      "Epoch 3264/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1479 - val_accuracy: 0.9879\n",
      "Epoch 3265/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1491 - val_accuracy: 0.9879\n",
      "Epoch 3266/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1507 - val_accuracy: 0.9869\n",
      "Epoch 3267/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1453 - val_accuracy: 0.9860\n",
      "Epoch 3268/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1499 - val_accuracy: 0.9888\n",
      "Epoch 3269/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1478 - val_accuracy: 0.9860\n",
      "Epoch 3270/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1497 - val_accuracy: 0.9860\n",
      "Epoch 3271/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1493 - val_accuracy: 0.9879\n",
      "Epoch 3272/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1471 - val_accuracy: 0.9860\n",
      "Epoch 3273/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1520 - val_accuracy: 0.9879\n",
      "Epoch 3274/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1446 - val_accuracy: 0.9860\n",
      "Epoch 3275/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1520 - val_accuracy: 0.9879\n",
      "Epoch 3276/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1473 - val_accuracy: 0.9860\n",
      "Epoch 3277/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1521 - val_accuracy: 0.9888\n",
      "Epoch 3278/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.1489 - val_accuracy: 0.9860\n",
      "Epoch 3279/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1516 - val_accuracy: 0.9869\n",
      "Epoch 3280/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1476 - val_accuracy: 0.9860\n",
      "Epoch 3281/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1471 - val_accuracy: 0.9860\n",
      "Epoch 3282/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1521 - val_accuracy: 0.9879\n",
      "Epoch 3283/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1487 - val_accuracy: 0.9860\n",
      "Epoch 3284/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1533 - val_accuracy: 0.9869\n",
      "Epoch 3285/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1463 - val_accuracy: 0.9860\n",
      "Epoch 3286/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1502 - val_accuracy: 0.9860\n",
      "Epoch 3287/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1572 - val_accuracy: 0.9869\n",
      "Epoch 3288/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1478 - val_accuracy: 0.9888\n",
      "Epoch 3289/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1473 - val_accuracy: 0.9869\n",
      "Epoch 3290/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1539 - val_accuracy: 0.9860\n",
      "Epoch 3291/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1517 - val_accuracy: 0.9879\n",
      "Epoch 3292/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1483 - val_accuracy: 0.9879\n",
      "Epoch 3293/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1489 - val_accuracy: 0.9860\n",
      "Epoch 3294/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1504 - val_accuracy: 0.9869\n",
      "Epoch 3295/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1505 - val_accuracy: 0.9860\n",
      "Epoch 3296/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1549 - val_accuracy: 0.9879\n",
      "Epoch 3297/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1480 - val_accuracy: 0.9860\n",
      "Epoch 3298/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1443 - val_accuracy: 0.9869\n",
      "Epoch 3299/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9963 - val_loss: 0.1570 - val_accuracy: 0.9888\n",
      "Epoch 3300/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1499 - val_accuracy: 0.9869\n",
      "Epoch 3301/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1478 - val_accuracy: 0.9860\n",
      "Epoch 3302/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.1561 - val_accuracy: 0.9897\n",
      "Epoch 3303/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.1428 - val_accuracy: 0.9879\n",
      "Epoch 3304/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9908 - val_loss: 0.1860 - val_accuracy: 0.9851\n",
      "Epoch 3305/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.1490 - val_accuracy: 0.9851\n",
      "Epoch 3306/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9954 - val_loss: 0.1660 - val_accuracy: 0.9879\n",
      "Epoch 3307/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9954 - val_loss: 0.1425 - val_accuracy: 0.9888\n",
      "Epoch 3308/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1542 - val_accuracy: 0.9879\n",
      "Epoch 3309/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9972 - val_loss: 0.1516 - val_accuracy: 0.9860\n",
      "Epoch 3310/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.1456 - val_accuracy: 0.9879\n",
      "Epoch 3311/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9936 - val_loss: 0.1518 - val_accuracy: 0.9869\n",
      "Epoch 3312/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.1473 - val_accuracy: 0.9860\n",
      "Epoch 3313/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9945 - val_loss: 0.1524 - val_accuracy: 0.9897\n",
      "Epoch 3314/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.1474 - val_accuracy: 0.9869\n",
      "Epoch 3315/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1611 - val_accuracy: 0.9860\n",
      "Epoch 3316/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.1517 - val_accuracy: 0.9869\n",
      "Epoch 3317/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1509 - val_accuracy: 0.9869\n",
      "Epoch 3318/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1567 - val_accuracy: 0.9860\n",
      "Epoch 3319/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1498 - val_accuracy: 0.9869\n",
      "Epoch 3320/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1502 - val_accuracy: 0.9860\n",
      "Epoch 3321/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1551 - val_accuracy: 0.9869\n",
      "Epoch 3322/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1523 - val_accuracy: 0.9860\n",
      "Epoch 3323/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1477 - val_accuracy: 0.9879\n",
      "Epoch 3324/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9959 - val_loss: 0.1692 - val_accuracy: 0.9879\n",
      "Epoch 3325/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.1458 - val_accuracy: 0.9869\n",
      "Epoch 3326/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1519 - val_accuracy: 0.9860\n",
      "Epoch 3327/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9894 - val_loss: 0.1981 - val_accuracy: 0.9813\n",
      "Epoch 3328/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 0.1536 - val_accuracy: 0.9851\n",
      "Epoch 3329/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.1761 - val_accuracy: 0.9860\n",
      "Epoch 3330/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1462 - val_accuracy: 0.9869\n",
      "Epoch 3331/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9959 - val_loss: 0.1536 - val_accuracy: 0.9879\n",
      "Epoch 3332/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.1479 - val_accuracy: 0.9860\n",
      "Epoch 3333/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1715 - val_accuracy: 0.9860\n",
      "Epoch 3334/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 0.1492 - val_accuracy: 0.9841\n",
      "Epoch 3335/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1521 - val_accuracy: 0.9869\n",
      "Epoch 3336/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1479 - val_accuracy: 0.9869\n",
      "Epoch 3337/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1585 - val_accuracy: 0.9869\n",
      "Epoch 3338/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1533 - val_accuracy: 0.9869\n",
      "Epoch 3339/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1524 - val_accuracy: 0.9860\n",
      "Epoch 3340/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1528 - val_accuracy: 0.9860\n",
      "Epoch 3341/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1538 - val_accuracy: 0.9860\n",
      "Epoch 3342/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1523 - val_accuracy: 0.9860\n",
      "Epoch 3343/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1547 - val_accuracy: 0.9860\n",
      "Epoch 3344/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1510 - val_accuracy: 0.9860\n",
      "Epoch 3345/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1566 - val_accuracy: 0.9860\n",
      "Epoch 3346/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1554 - val_accuracy: 0.9860\n",
      "Epoch 3347/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1549 - val_accuracy: 0.9860\n",
      "Epoch 3348/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1597 - val_accuracy: 0.9879\n",
      "Epoch 3349/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.1497 - val_accuracy: 0.9860\n",
      "Epoch 3350/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1630 - val_accuracy: 0.9888\n",
      "Epoch 3351/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9954 - val_loss: 0.1465 - val_accuracy: 0.9869\n",
      "Epoch 3352/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1558 - val_accuracy: 0.9869\n",
      "Epoch 3353/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1530 - val_accuracy: 0.9860\n",
      "Epoch 3354/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1555 - val_accuracy: 0.9860\n",
      "Epoch 3355/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1490 - val_accuracy: 0.9860\n",
      "Epoch 3356/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1517 - val_accuracy: 0.9860\n",
      "Epoch 3357/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1667 - val_accuracy: 0.9851\n",
      "Epoch 3358/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1550 - val_accuracy: 0.9860\n",
      "Epoch 3359/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1479 - val_accuracy: 0.9860\n",
      "Epoch 3360/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1511 - val_accuracy: 0.9860\n",
      "Epoch 3361/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1606 - val_accuracy: 0.9869\n",
      "Epoch 3362/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1498 - val_accuracy: 0.9860\n",
      "Epoch 3363/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1528 - val_accuracy: 0.9869\n",
      "Epoch 3364/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1593 - val_accuracy: 0.9869\n",
      "Epoch 3365/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1516 - val_accuracy: 0.9860\n",
      "Epoch 3366/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1576 - val_accuracy: 0.9879\n",
      "Epoch 3367/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1524 - val_accuracy: 0.9841\n",
      "Epoch 3368/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.1550 - val_accuracy: 0.9860\n",
      "Epoch 3369/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1515 - val_accuracy: 0.9860\n",
      "Epoch 3370/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1514 - val_accuracy: 0.9860\n",
      "Epoch 3371/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.1609 - val_accuracy: 0.9888\n",
      "Epoch 3372/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.1510 - val_accuracy: 0.9860\n",
      "Epoch 3373/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1665 - val_accuracy: 0.9869\n",
      "Epoch 3374/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1530 - val_accuracy: 0.9869\n",
      "Epoch 3375/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.1535 - val_accuracy: 0.9860\n",
      "Epoch 3376/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1514 - val_accuracy: 0.9860\n",
      "Epoch 3377/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1604 - val_accuracy: 0.9869\n",
      "Epoch 3378/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1535 - val_accuracy: 0.9869\n",
      "Epoch 3379/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1534 - val_accuracy: 0.9860\n",
      "Epoch 3380/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1600 - val_accuracy: 0.9841\n",
      "Epoch 3381/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1636 - val_accuracy: 0.9869\n",
      "Epoch 3382/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1461 - val_accuracy: 0.9869\n",
      "Epoch 3383/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.1689 - val_accuracy: 0.9888\n",
      "Epoch 3384/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9963 - val_loss: 0.1537 - val_accuracy: 0.9860\n",
      "Epoch 3385/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1578 - val_accuracy: 0.9869\n",
      "Epoch 3386/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.1518 - val_accuracy: 0.9860\n",
      "Epoch 3387/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1648 - val_accuracy: 0.9888\n",
      "Epoch 3388/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.1501 - val_accuracy: 0.9860\n",
      "Epoch 3389/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.1742 - val_accuracy: 0.9879\n",
      "Epoch 3390/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.1504 - val_accuracy: 0.9860\n",
      "Epoch 3391/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1551 - val_accuracy: 0.9888\n",
      "Epoch 3392/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1467 - val_accuracy: 0.9869\n",
      "Epoch 3393/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.1849 - val_accuracy: 0.9860\n",
      "Epoch 3394/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.1499 - val_accuracy: 0.9813\n",
      "Epoch 3395/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9936 - val_loss: 0.1763 - val_accuracy: 0.9879\n",
      "Epoch 3396/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.1495 - val_accuracy: 0.9841\n",
      "Epoch 3397/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.1595 - val_accuracy: 0.9879\n",
      "Epoch 3398/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1510 - val_accuracy: 0.9869\n",
      "Epoch 3399/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1616 - val_accuracy: 0.9879\n",
      "Epoch 3400/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1558 - val_accuracy: 0.9851\n",
      "Epoch 3401/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1547 - val_accuracy: 0.9869\n",
      "Epoch 3402/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1505 - val_accuracy: 0.9860\n",
      "Epoch 3403/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1603 - val_accuracy: 0.9869\n",
      "Epoch 3404/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1537 - val_accuracy: 0.9860\n",
      "Epoch 3405/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1535 - val_accuracy: 0.9860\n",
      "Epoch 3406/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1533 - val_accuracy: 0.9860\n",
      "Epoch 3407/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.1604 - val_accuracy: 0.9869\n",
      "Epoch 3408/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1531 - val_accuracy: 0.9860\n",
      "Epoch 3409/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1547 - val_accuracy: 0.9860\n",
      "Epoch 3410/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1567 - val_accuracy: 0.9860\n",
      "Epoch 3411/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1566 - val_accuracy: 0.9869\n",
      "Epoch 3412/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1557 - val_accuracy: 0.9860\n",
      "Epoch 3413/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1552 - val_accuracy: 0.9860\n",
      "Epoch 3414/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1693 - val_accuracy: 0.9879\n",
      "Epoch 3415/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1495 - val_accuracy: 0.9879\n",
      "Epoch 3416/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.1535 - val_accuracy: 0.9860\n",
      "Epoch 3417/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1622 - val_accuracy: 0.9851\n",
      "Epoch 3418/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1538 - val_accuracy: 0.9860\n",
      "Epoch 3419/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1547 - val_accuracy: 0.9860\n",
      "Epoch 3420/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1646 - val_accuracy: 0.9879\n",
      "Epoch 3421/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.1531 - val_accuracy: 0.9860\n",
      "Epoch 3422/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1586 - val_accuracy: 0.9879\n",
      "Epoch 3423/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.1578 - val_accuracy: 0.9851\n",
      "Epoch 3424/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1560 - val_accuracy: 0.9860\n",
      "Epoch 3425/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.1501 - val_accuracy: 0.9869\n",
      "Epoch 3426/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1554 - val_accuracy: 0.9879\n",
      "Epoch 3427/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.1615 - val_accuracy: 0.9841\n",
      "Epoch 3428/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1535 - val_accuracy: 0.9879\n",
      "Epoch 3429/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9954 - val_loss: 0.1557 - val_accuracy: 0.9897\n",
      "Epoch 3430/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1561 - val_accuracy: 0.9851\n",
      "Epoch 3431/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1545 - val_accuracy: 0.9860\n",
      "Epoch 3432/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1525 - val_accuracy: 0.9888\n",
      "Epoch 3433/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.1497 - val_accuracy: 0.9869\n",
      "Epoch 3434/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1564 - val_accuracy: 0.9869\n",
      "Epoch 3435/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1475 - val_accuracy: 0.9869\n",
      "Epoch 3436/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1615 - val_accuracy: 0.9869\n",
      "Epoch 3437/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.1605 - val_accuracy: 0.9851\n",
      "Epoch 3438/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1487 - val_accuracy: 0.9860\n",
      "Epoch 3439/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1502 - val_accuracy: 0.9860\n",
      "Epoch 3440/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1580 - val_accuracy: 0.9869\n",
      "Epoch 3441/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1596 - val_accuracy: 0.9879\n",
      "Epoch 3442/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1547 - val_accuracy: 0.9860\n",
      "Epoch 3443/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1545 - val_accuracy: 0.9860\n",
      "Epoch 3444/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1552 - val_accuracy: 0.9860\n",
      "Epoch 3445/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1555 - val_accuracy: 0.9879\n",
      "Epoch 3446/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1596 - val_accuracy: 0.9860\n",
      "Epoch 3447/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1572 - val_accuracy: 0.9860\n",
      "Epoch 3448/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1574 - val_accuracy: 0.9860\n",
      "Epoch 3449/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1575 - val_accuracy: 0.9860\n",
      "Epoch 3450/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1577 - val_accuracy: 0.9869\n",
      "Epoch 3451/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1599 - val_accuracy: 0.9879\n",
      "Epoch 3452/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1586 - val_accuracy: 0.9860\n",
      "Epoch 3453/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1585 - val_accuracy: 0.9860\n",
      "Epoch 3454/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1538 - val_accuracy: 0.9851\n",
      "Epoch 3455/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9926 - val_loss: 0.2449 - val_accuracy: 0.9804\n",
      "Epoch 3456/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9871 - val_loss: 0.2080 - val_accuracy: 0.9664\n",
      "Epoch 3457/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9871 - val_loss: 0.2308 - val_accuracy: 0.9832\n",
      "Epoch 3458/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 0.1574 - val_accuracy: 0.9851\n",
      "Epoch 3459/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9963 - val_loss: 0.1802 - val_accuracy: 0.9879\n",
      "Epoch 3460/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.1471 - val_accuracy: 0.9841\n",
      "Epoch 3461/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.1612 - val_accuracy: 0.9879\n",
      "Epoch 3462/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1614 - val_accuracy: 0.9851\n",
      "Epoch 3463/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1593 - val_accuracy: 0.9860\n",
      "Epoch 3464/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1489 - val_accuracy: 0.9869\n",
      "Epoch 3465/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1520 - val_accuracy: 0.9869\n",
      "Epoch 3466/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1614 - val_accuracy: 0.9841\n",
      "Epoch 3467/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1571 - val_accuracy: 0.9860\n",
      "Epoch 3468/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1533 - val_accuracy: 0.9888\n",
      "Epoch 3469/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1545 - val_accuracy: 0.9869\n",
      "Epoch 3470/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1541 - val_accuracy: 0.9869\n",
      "Epoch 3471/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1598 - val_accuracy: 0.9879\n",
      "Epoch 3472/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1533 - val_accuracy: 0.9860\n",
      "Epoch 3473/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1585 - val_accuracy: 0.9879\n",
      "Epoch 3474/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1536 - val_accuracy: 0.9851\n",
      "Epoch 3475/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1567 - val_accuracy: 0.9869\n",
      "Epoch 3476/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1556 - val_accuracy: 0.9860\n",
      "Epoch 3477/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1599 - val_accuracy: 0.9879\n",
      "Epoch 3478/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1568 - val_accuracy: 0.9860\n",
      "Epoch 3479/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1626 - val_accuracy: 0.9851\n",
      "Epoch 3480/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1547 - val_accuracy: 0.9860\n",
      "Epoch 3481/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1570 - val_accuracy: 0.9879\n",
      "Epoch 3482/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1575 - val_accuracy: 0.9860\n",
      "Epoch 3483/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1558 - val_accuracy: 0.9860\n",
      "Epoch 3484/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1577 - val_accuracy: 0.9860\n",
      "Epoch 3485/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1591 - val_accuracy: 0.9860\n",
      "Epoch 3486/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1569 - val_accuracy: 0.9860\n",
      "Epoch 3487/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1582 - val_accuracy: 0.9879\n",
      "Epoch 3488/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1594 - val_accuracy: 0.9860\n",
      "Epoch 3489/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1585 - val_accuracy: 0.9860\n",
      "Epoch 3490/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.1599 - val_accuracy: 0.9860\n",
      "Epoch 3491/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1569 - val_accuracy: 0.9860\n",
      "Epoch 3492/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1599 - val_accuracy: 0.9860\n",
      "Epoch 3493/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1549 - val_accuracy: 0.9869\n",
      "Epoch 3494/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1587 - val_accuracy: 0.9879\n",
      "Epoch 3495/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1596 - val_accuracy: 0.9860\n",
      "Epoch 3496/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1575 - val_accuracy: 0.9869\n",
      "Epoch 3497/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9977 - val_loss: 0.1559 - val_accuracy: 0.9860\n",
      "Epoch 3498/3500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1629 - val_accuracy: 0.9888\n",
      "Epoch 3499/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1550 - val_accuracy: 0.9860\n",
      "Epoch 3500/3500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1631 - val_accuracy: 0.9860\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df_pre.sample(frac = 0.5) \n",
    "\n",
    "# 모델 실행 및 저장\n",
    "history = model.fit(X, Y, validation_split = 0.33, epochs = 3500, batch_size = 500)\n",
    "\n",
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc = history.history['accuracy']\n",
    "\n",
    "# x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = numpy.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c = 'red', markersize = 3)\n",
    "plt.plot(x_len, y_acc, \"o\", c = 'blue', markersize = 3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
